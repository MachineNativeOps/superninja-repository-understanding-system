{
  "audit_timestamp": "2026-01-16T11:14:15.004851",

  "total_findings": 63,

  "summary": {

    "critical": 7,

    "high": 29,

    "medium": 27,

    "low": 0,

    "info": 0

  },

  "by_severity": {

    "critical": [

      {

        "file": "workspace/src/core/training_system/example_library.py",

        "line": 297,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded password",

        "code": "AND password = '{password}'",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "    query = f\\\"\\\"\\\"\n    SELECT * FROM users\n    WHERE username = '{username}'\n    AND password = '{password}'\n    \\\"\\\"\\\"\n    return db.execute(query)\n"

      },

      {

        "file": "workspace/src/core/training_system/example_library.py",

        "line": 304,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded password",

        "code": "# \u7d50\u679c: SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "# \u653b\u64ca\u8005\u53ef\u4ee5\u7e5e\u904e\u767b\u9304\uff1a\n# username: admin' --\n# password: anything\n# \u7d50\u679c: SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'\n\"\"\",\n            good_code=\"\"\"\n# \u2705 \u4f7f\u7528\u53c3\u6578\u5316\u67e5\u8a62"

      },

      {

        "file": "workspace/src/core/training_system/skills_training.py",

        "line": 580,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded password",

        "code": "query = f\"SELECT * FROM users WHERE email = '{email}' AND password = '{password}'\"",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "                    \"question\": \"\"\"\n\u4fee\u5fa9\u9019\u6bb5\u4ee3\u78bc\u7684\u5b89\u5168\u6f0f\u6d1e\uff1a\ndef login(email, password):\n    query = f\"SELECT * FROM users WHERE email = '{email}' AND password = '{password}'\"\n    user = db.execute(query)\n    return user\n\"\"\","

      },

      {

        "file": "workspace/src/core/plugins/training_system/example_library.py",

        "line": 295,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded password",

        "code": "AND password = '{password}'",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "    query = f\\\"\\\"\\\"\n    SELECT * FROM users\n    WHERE username = '{username}'\n    AND password = '{password}'\n    \\\"\\\"\\\"\n    return db.execute(query)\n"

      },

      {

        "file": "workspace/src/core/plugins/training_system/example_library.py",

        "line": 302,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded password",

        "code": "# \u7d50\u679c: SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "# \u653b\u64ca\u8005\u53ef\u4ee5\u7e5e\u904e\u767b\u9304\uff1a\n# username: admin' --\n# password: anything\n# \u7d50\u679c: SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'\n\"\"\",\n            good_code=\"\"\"\n# \u2705 \u4f7f\u7528\u53c3\u6578\u5316\u67e5\u8a62"

      },

      {

        "file": "workspace/src/core/plugins/training_system/skills_training.py",

        "line": 580,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded password",

        "code": "query = f\"SELECT * FROM users WHERE email = '{email}' AND password = '{password}'\"",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "                    \"question\": \"\"\"\n\u4fee\u5fa9\u9019\u6bb5\u4ee3\u78bc\u7684\u5b89\u5168\u6f0f\u6d1e\uff1a\ndef login(email, password):\n    query = f\"SELECT * FROM users WHERE email = '{email}' AND password = '{password}'\"\n    user = db.execute(query)\n    return user\n\"\"\","

      },

      {

        "file": "workspace/src/enterprise/execution/secrets.py",

        "line": 32,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded secret/token",

        "code": "OAUTH_CLIENT_SECRET = \"oauth_client_secret\"",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "    PROVIDER_TOKEN = os.getenv(\"PROVIDER_TOKEN\", \"provider_token\")\n    API_KEY = \"api_key\"\n    ENCRYPTION_KEY = \"encryption_key\"\n    OAUTH_CLIENT_SECRET = \"oauth_client_secret\"\n    SIGNING_KEY = \"signing_key\"\n    DATABASE_PASSWORD = os.getenv(\"DATABASE_PASSWORD\", \"database_password\")\n    SERVICE_ACCOUNT = \"service_account\""

      }

    ],

    "high": [

      {

        "file": "code_quality_analyzer.py",

        "line": 159,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "(r\"eval\\s*\\(\", \"\u9ad8\u5371\uff1a\u4f7f\u7528 eval() \u53ef\u80fd\u5c0e\u81f4\u4ee3\u78bc\u6ce8\u5165\u6f0f\u6d1e\"),",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    def check_security(self, file_path, content, lines):\n        \"\"\"Check for security issues\"\"\"\n        security_patterns = [\n            (r\"eval\\s*\\(\", \"\u9ad8\u5371\uff1a\u4f7f\u7528 eval() \u53ef\u80fd\u5c0e\u81f4\u4ee3\u78bc\u6ce8\u5165\u6f0f\u6d1e\"),\n            (r\"exec\\s*\\(\", \"\u9ad8\u5371\uff1a\u4f7f\u7528 exec() \u53ef\u80fd\u5c0e\u81f4\u4ee3\u78bc\u6ce8\u5165\u6f0f\u6d1e\"),\n            (r\"pickle\\.(loads|load)\\s*\\(\", \"\u9ad8\u5371\uff1a\u4f7f\u7528 pickle \u53ef\u80fd\u5c0e\u81f4\u53cd\u5e8f\u5217\u5316\u6f0f\u6d1e\"),\n            (r\"md5\\s*\\(\", \"\u4e2d\u5371\uff1aMD5 \u4e0d\u662f\u5b89\u5168\u7684\u54c8\u5e0c\u7b97\u6cd5\"),"

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 7,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "- 77 security vulnerabilities (MD5, eval())",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "\nThis script addresses the remaining 866 low-severity issues:\n- 772 import order violations\n- 77 security vulnerabilities (MD5, eval())\n- 72 code smells (hardcoded URLs)\n- 22 missing docstrings\n\"\"\""

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 172,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "\"\"\"Replace unsafe eval() with safer alternatives.\"\"\"",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "            return False\n\n    def fix_eval_usage(self, file_path: Path) -> bool:\n        \"\"\"Replace unsafe eval() with safer alternatives.\"\"\"\n        try:\n            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                content = f.read()"

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 177,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" not in content:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                content = f.read()\n\n            if \"eval(\" not in content:\n                return False\n\n            # Note: eval() replacement is complex and context-dependent"

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 192,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in line and \"# TODO: Security\" not in line:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                # Find eval() lines and add warning\n                modified_lines = []\n                for line in lines:\n                    if \"eval(\" in line and \"# TODO: Security\" not in line:\n                        # Insert warning before the line\n                        indent = len(line) - len(line.lstrip())\n                        modified_lines.append(\" \" * indent + warning.rstrip())"

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 325,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "print(\"  \u26a0\ufe0f  eval() usage marked for review\")",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                    print(\"  \u2705 MD5 replaced with SHA256\")\n                if results[\"eval_fixed\"]:\n                    summary[\"eval_fixed\"] += 1\n                    print(\"  \u26a0\ufe0f  eval() usage marked for review\")\n\n                summary[\"total_fixes\"] += results[\"total_fixes\"]\n"

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 361,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "print(f\"eval() reviews: {summary['eval_fixed']}\")",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    print(f\"Hardcoded URL fixes: {summary['hardcoded_urls_fixed']}\")\n    print(f\"Docstrings added: {summary['docstrings_added']}\")\n    print(f\"MD5 replacements: {summary['md5_fixed']}\")\n    print(f\"eval() reviews: {summary['eval_fixed']}\")\n    print(f\"Total fixes applied: {summary['total_fixes']}\")\n    print(f\"Errors encountered: {summary['errors']}\")\n    print(\"=\" * 60)"

      },

      {

        "file": "00-namespaces/namespaces-adk/adk/core/workflow_orchestrator.py",

        "line": 367,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "return eval(condition, {\"__builtins__\": {}}, context)",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        try:\n            # For now, support simple comparisons\n            # In production, use a safe expression evaluator\n            return eval(condition, {\"__builtins__\": {}}, context)\n        except Exception as e:\n            self.logger.warning(f\"Condition evaluation failed: {e}\")\n            return False"

      },

      {

        "file": "workspace/teams/holy-grail/automation/architect/core/analysis/security_scanner.py",

        "line": 114,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "(r\"eval\\s*\\(\", \"eval-usage\", \"Use of eval() can lead to code injection\"),",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                \"xss\",\n                \"Potential XSS vulnerability via document.write\",\n            ),\n            (r\"eval\\s*\\(\", \"eval-usage\", \"Use of eval() can lead to code injection\"),\n        ]\n\n        # \u4e0d\u5b89\u5168\u7684\u52a0\u5bc6"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/pipeline_service.py",

        "line": 361,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "result = eval(user_input)",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    test_code = \"\"\"\ndef unsafe_function(user_input):\n    # Security issue: eval\n    result = eval(user_input)\n\n    # Performance issue: nested loops\n    for i in range(100):"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/examples/demo.py",

        "line": 42,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "result = eval(user_input)",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    problematic_code = \"\"\"\ndef process_user_data(user_input, password):\n    # Security issue: using eval\n    result = eval(user_input)\n\n    # Security issue: hardcoded password\n    db_password = os.getenv(\"DATABASE_PASSWORD\", \"admin123\")"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/test-vectors/generator.py",

        "line": 221,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "\"    result = eval(user_input)\",",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "            \"    # Multiple security issues for comprehensive testing\",\n            \"    \",\n            \"    # Issue 1: Eval injection\",\n            \"    result = eval(user_input)\",\n            \"    \",\n            \"    # Issue 2: Hardcoded credential\",\n            '    db_password = \"PLACEHOLDER_TEST_ONLY\"',"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/agents/task_executor.py",

        "line": 135,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in code or \"exec(\" in code:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        issues = []\n\n        # Basic security pattern detection\n        if \"eval(\" in code or \"exec(\" in code:\n            issues.append(\n                {\n                    \"type\": \"security\","

      },

      {

        "file": "workspace/src/automation/architect/core/analysis/security_scanner.py",

        "line": 114,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "(r\"eval\\s*\\(\", \"eval-usage\", \"Use of eval() can lead to code injection\"),",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                \"xss\",\n                \"Potential XSS vulnerability via document.write\",\n            ),\n            (r\"eval\\s*\\(\", \"eval-usage\", \"Use of eval() can lead to code injection\"),\n        ]\n\n        # \u4e0d\u5b89\u5168\u7684\u52a0\u5bc6"

      },

      {

        "file": "workspace/src/core/run-debug/cli.py",

        "line": 387,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "def eval(expression):",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "\n@debug.command()\n@click.argument(\"expression\")\ndef eval(expression):\n    \"\"\"\u8a55\u4f30\u8868\u9054\u5f0f\"\"\"\n    cli = DebugCLI()\n    asyncio.run(cli.evaluate_expression(expression))"

      },

      {

        "file": "workspace/src/core/training_system/example_library.py",

        "line": 383,

        "severity": "high",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "import hashlib\n\ndef hash_password_weak(password: str) -> str:\n    return hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01\n\n# \u554f\u984c 3\uff1a\u6c92\u6709\u52a0\u9e7d\ndef hash_password_no_salt(password: str) -> str:"

      },

      {

        "file": "workspace/src/core/training_system/knowledge_base.py",

        "line": 425,

        "severity": "high",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "hashed = hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "\n# \u274c \u4f7f\u7528\u5f31\u54c8\u5e0c\nimport hashlib\nhashed = hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01\n\"\"\",\n            priority=\"critical\",\n            tags=[\"password\", \"authentication\", \"hashing\"],"

      },

      {

        "file": "workspace/src/core/virtual_experts/domain_experts.py",

        "line": 505,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in code_lower or \"exec(\" in code_lower:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                    }\n                )\n\n        if \"eval(\" in code_lower or \"exec(\" in code_lower:\n            issues.append(\n                {\n                    \"severity\": \"critical\","

      },

      {

        "file": "workspace/src/core/plugins/training_system/example_library.py",

        "line": 381,

        "severity": "high",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "import hashlib\n\ndef hash_password_weak(password: str) -> str:\n    return hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01\n\n# \u554f\u984c 3\uff1a\u6c92\u6709\u52a0\u9e7d\ndef hash_password_no_salt(password: str) -> str:"

      },

      {

        "file": "workspace/src/core/plugins/training_system/knowledge_base.py",

        "line": 424,

        "severity": "high",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "hashed = hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "\n# \u274c \u4f7f\u7528\u5f31\u54c8\u5e0c\nimport hashlib\nhashed = hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01\n\"\"\",\n            priority=\"critical\",\n            tags=[\"password\", \"authentication\", \"hashing\"],"

      },

      {

        "file": "workspace/src/core/plugins/virtual_experts/domain_experts.py",

        "line": 500,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in code_lower or \"exec(\" in code_lower:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                    }\n                )\n\n        if \"eval(\" in code_lower or \"exec(\" in code_lower:\n            issues.append(\n                {\n                    \"severity\": \"critical\","

      },

      {

        "file": "workspace/src/autonomous/agents/pipeline_service.py",

        "line": 361,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "result = eval(user_input)",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    test_code = \"\"\"\ndef unsafe_function(user_input):\n    # Security issue: eval\n    result = eval(user_input)\n\n    # Performance issue: nested loops\n    for i in range(100):"

      },

      {

        "file": "workspace/src/autonomous/agents/examples/demo.py",

        "line": 42,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "result = eval(user_input)",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    problematic_code = \"\"\"\ndef process_user_data(user_input, password):\n    # Security issue: using eval\n    result = eval(user_input)\n\n    # Security issue: hardcoded password\n    db_password = os.getenv(\"DATABASE_PASSWORD\", \"admin123\")"

      },

      {

        "file": "workspace/src/autonomous/agents/test-vectors/generator.py",

        "line": 221,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "\"    result = eval(user_input)\",",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "            \"    # Multiple security issues for comprehensive testing\",\n            \"    \",\n            \"    # Issue 1: Eval injection\",\n            \"    result = eval(user_input)\",\n            \"    \",\n            \"    # Issue 2: Hardcoded credential\",\n            '    db_password = \"PLACEHOLDER_TEST_ONLY\"',"

      },

      {

        "file": "workspace/src/autonomous/agents/agents/task_executor.py",

        "line": 135,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in code or \"exec(\" in code:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        issues = []\n\n        # Basic security pattern detection\n        if \"eval(\" in code or \"exec(\" in code:\n            issues.append(\n                {\n                    \"type\": \"security\","

      },

      {

        "file": "workspace/tools/security_audit.py",

        "line": 6,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "analyzing MD5 usage, eval() usage, and other security concerns.",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "Security Audit Tool\n\nThis script performs a comprehensive security audit of the codebase,\nanalyzing MD5 usage, eval() usage, and other security concerns.\n\"\"\"\n\nimport ast"

      },

      {

        "file": "workspace/tools/security_audit.py",

        "line": 150,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "\"\"\"Check for eval() usage.\"\"\"",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        return findings\n\n    def check_eval_usage(self, file_path: Path) -> List[SecurityFinding]:\n        \"\"\"Check for eval() usage.\"\"\"\n        findings = []\n\n        try:"

      },

      {

        "file": "workspace/tools/security_audit.py",

        "line": 190,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "issue=\"eval() function usage detected\",",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                        line_number=line_num,\n                        severity=severity,\n                        category=\"Code Injection\",\n                        issue=\"eval() function usage detected\",\n                        code_snippet=code_snippet,\n                        recommendation=\"Avoid eval() as it can execute arbitrary code. \"\n                        \"Consider using ast.literal_eval() for parsing literals, \""

      },

      {

        "file": "workspace/tools/security_audit.py",

        "line": 192,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "recommendation=\"Avoid eval() as it can execute arbitrary code. \"",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                        category=\"Code Injection\",\n                        issue=\"eval() function usage detected\",\n                        code_snippet=code_snippet,\n                        recommendation=\"Avoid eval() as it can execute arbitrary code. \"\n                        \"Consider using ast.literal_eval() for parsing literals, \"\n                        \"or implement a proper parser for your use case.\",\n                        context=context,"

      }

    ],

    "medium": [

      {

        "file": "fix_remaining_issues.py",

        "line": 184,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in content:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "            # This is a basic implementation - manual review recommended\n            # We'll add a warning comment instead of automatic replacement\n\n            if \"eval(\" in content:\n                # Add security warning comment\n                warning = \"# TODO: Security - Consider replacing eval() with safer alternatives like ast.literal_eval()\\n\"\n                lines = content.split(\"\\n\")"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/agents/task_executor.py",

        "line": 234,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in code or \"exec(\" in code:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        fixed_code = code\n\n        if issue[\"type\"] == \"security\":\n            if \"eval(\" in code or \"exec(\" in code:\n                # Remove dangerous code execution\n                fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")\n                fixed_code = fixed_code.replace(\"exec(\", \"# REMOVED_exec(\")"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/agents/task_executor.py",

        "line": 236,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        if issue[\"type\"] == \"security\":\n            if \"eval(\" in code or \"exec(\" in code:\n                # Remove dangerous code execution\n                fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")\n                fixed_code = fixed_code.replace(\"exec(\", \"# REMOVED_exec(\")\n                logger.info(\"Applied security fix: removed eval/exec\")\n"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/agents/task_executor.py",

        "line": 293,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "result = eval(user_input)  # Security issue!",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    # Example: Analyze potentially unsafe code\n    test_code = \"\"\"\ndef process_data(user_input):\n    result = eval(user_input)  # Security issue!\n    password = \"hardcoded123\"   # Security issue!\n\n    for i in range(len(data)):"

      },

      {

        "file": "workspace/teams/holy-grail/agents/services/dependency-manager/src/enterprise/security.py",

        "line": 296,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _generate_serial(self) -> str:\n        \"\"\"\u751f\u6210\u5e8f\u5217\u865f\"\"\"\n        timestamp = datetime.now().isoformat()\n        return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"\n\n    def _get_spec_version(self, sbom_format: SBOMFormat) -> str:\n        \"\"\"\u53d6\u5f97\u898f\u7bc4\u7248\u672c\"\"\""

      },

      {

        "file": "workspace/teams/holy-grail/agents/services/dependency-manager/src/enterprise/security.py",

        "line": 702,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "actual = hashlib.md5(content).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        elif algorithm == \"sha512\":\n            actual = hashlib.sha512(content).hexdigest()\n        elif algorithm == \"md5\":\n            actual = hashlib.md5(content).hexdigest()\n        else:\n            actual = hashlib.sha256(content).hexdigest()\n"

      },

      {

        "file": "workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/enterprise/security.py",

        "line": 296,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _generate_serial(self) -> str:\n        \"\"\"\u751f\u6210\u5e8f\u5217\u865f\"\"\"\n        timestamp = datetime.now().isoformat()\n        return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"\n\n    def _get_spec_version(self, sbom_format: SBOMFormat) -> str:\n        \"\"\"\u53d6\u5f97\u898f\u7bc4\u7248\u672c\"\"\""

      },

      {

        "file": "workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/enterprise/security.py",

        "line": 702,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "actual = hashlib.md5(content).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        elif algorithm == \"sha512\":\n            actual = hashlib.sha512(content).hexdigest()\n        elif algorithm == \"md5\":\n            actual = hashlib.md5(content).hexdigest()\n        else:\n            actual = hashlib.sha256(content).hexdigest()\n"

      },

      {

        "file": "workspace/src/ai/agents/dependency-manager/src/enterprise/security.py",

        "line": 296,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _generate_serial(self) -> str:\n        \"\"\"\u751f\u6210\u5e8f\u5217\u865f\"\"\"\n        timestamp = datetime.now().isoformat()\n        return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"\n\n    def _get_spec_version(self, sbom_format: SBOMFormat) -> str:\n        \"\"\"\u53d6\u5f97\u898f\u7bc4\u7248\u672c\"\"\""

      },

      {

        "file": "workspace/src/ai/agents/dependency-manager/src/enterprise/security.py",

        "line": 702,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "actual = hashlib.md5(content).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        elif algorithm == \"sha512\":\n            actual = hashlib.sha512(content).hexdigest()\n        elif algorithm == \"md5\":\n            actual = hashlib.md5(content).hexdigest()\n        else:\n            actual = hashlib.sha256(content).hexdigest()\n"

      },

      {

        "file": "workspace/src/core/island_ai_runtime/knowledge_engine.py",

        "line": 322,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return hashlib.md5(path.encode()).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    @staticmethod\n    def _generate_id(path: str) -> str:\n        \"\"\"\u751f\u6210\u7bc0\u9ede ID\"\"\"\n        return hashlib.md5(path.encode()).hexdigest()\n"

      },

      {

        "file": "workspace/src/autonomous/agents/agents/task_executor.py",

        "line": 234,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in code or \"exec(\" in code:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        fixed_code = code\n\n        if issue[\"type\"] == \"security\":\n            if \"eval(\" in code or \"exec(\" in code:\n                # Remove dangerous code execution\n                fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")\n                fixed_code = fixed_code.replace(\"exec(\", \"# REMOVED_exec(\")"

      },

      {

        "file": "workspace/src/autonomous/agents/agents/task_executor.py",

        "line": 236,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        if issue[\"type\"] == \"security\":\n            if \"eval(\" in code or \"exec(\" in code:\n                # Remove dangerous code execution\n                fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")\n                fixed_code = fixed_code.replace(\"exec(\", \"# REMOVED_exec(\")\n                logger.info(\"Applied security fix: removed eval/exec\")\n"

      },

      {

        "file": "workspace/src/autonomous/agents/agents/task_executor.py",

        "line": 293,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "result = eval(user_input)  # Security issue!",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    # Example: Analyze potentially unsafe code\n    test_code = \"\"\"\ndef process_data(user_input):\n    result = eval(user_input)  # Security issue!\n    password = \"hardcoded123\"   # Security issue!\n\n    for i in range(len(data)):"

      },

      {

        "file": "workspace/src/services/agents/dependency-manager/src/enterprise/security.py",

        "line": 296,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _generate_serial(self) -> str:\n        \"\"\"\u751f\u6210\u5e8f\u5217\u865f\"\"\"\n        timestamp = datetime.now().isoformat()\n        return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"\n\n    def _get_spec_version(self, sbom_format: SBOMFormat) -> str:\n        \"\"\"\u53d6\u5f97\u898f\u7bc4\u7248\u672c\"\"\""

      },

      {

        "file": "workspace/src/services/agents/dependency-manager/src/enterprise/security.py",

        "line": 702,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "actual = hashlib.md5(content).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        elif algorithm == \"sha512\":\n            actual = hashlib.sha512(content).hexdigest()\n        elif algorithm == \"md5\":\n            actual = hashlib.md5(content).hexdigest()\n        else:\n            actual = hashlib.sha256(content).hexdigest()\n"

      },

      {

        "file": "workspace/src/frontend/ui/services/code_analyzer.py",

        "line": 198,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return f\"analysis:{hashlib.md5(content.encode()).hexdigest()}\"",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _get_cache_key(self, code: str, file_path: str) -> str:\n        \"\"\"\u751f\u6210\u7de9\u5b58\u9375\"\"\"\n        content = f\"{code}:{file_path}\"\n        return f\"analysis:{hashlib.md5(content.encode()).hexdigest()}\"\n\n    async def analyze(\n        self,"

      },

      {

        "file": "workspace/src/apps/web-backend/services/code_analyzer.py",

        "line": 195,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return f\"analysis:{hashlib.md5(content.encode()).hexdigest()}\"",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _get_cache_key(self, code: str, file_path: str) -> str:\n        \"\"\"\u751f\u6210\u7de9\u5b58\u9375\"\"\"\n        content = f\"{code}:{file_path}\"\n        return f\"analysis:{hashlib.md5(content.encode()).hexdigest()}\"\n\n    async def analyze(\n        self,"

      },

      {

        "file": "workspace/tools/find_duplicate_scripts.py",

        "line": 75,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "hasher = hashlib.md5()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "\n    def _hash_file(self, file_path: Path) -> str:\n        \"\"\"\u8a08\u7b97\u6587\u4ef6\u7684\u54c8\u5e0c\u503c\"\"\"\n        hasher = hashlib.md5()\n        with open(file_path, \"rb\") as f:\n            hasher.update(f.read())\n        return hasher.hexdigest()"

      },

      {

        "file": "workspace/tools/autonomous_cleanup_toolkit.py",

        "line": 212,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "md5_hash = hashlib.md5(content).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "\n                try:\n                    content = file_path.read_bytes()\n                    md5_hash = hashlib.md5(content).hexdigest()\n                    hash_map[md5_hash].append(\n                        str(file_path.relative_to(self.repo_path))\n                    )"

      },

      {

        "file": "workspace/tools/cleanup_duplicates.py",

        "line": 83,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "empty_init_hash = hashlib.md5(b\"\").hexdigest()  # \u7a7a\u6587\u4ef6\u54c8\u5e0c",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        \"\"\"\u6e05\u7406\u7a7a\u7684 __init__.py \u6587\u4ef6\u91cd\u8907\"\"\"\n        print(\"\\n3\ufe0f\u20e3  \u6e05\u7406\u7a7a __init__.py \u91cd\u8907...\")\n\n        empty_init_hash = hashlib.md5(b\"\").hexdigest()  # \u7a7a\u6587\u4ef6\u54c8\u5e0c\n        init_files = list(self.repo_root.rglob(\"__init__.py\"))\n\n        # \u6309\u76ee\u9304\u5206\u7d44"

      },

      {

        "file": "workspace/tools/cleanup_duplicates.py",

        "line": 106,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "hasher = hashlib.md5()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _hash_file(self, file_path: Path) -> str:\n        \"\"\"\u8a08\u7b97\u6587\u4ef6\u54c8\u5e0c\"\"\"\n        try:\n            hasher = hashlib.md5()\n            with open(file_path, \"rb\") as f:\n                hasher.update(f.read())\n            return hasher.hexdigest()"

      },

      {

        "file": "workspace/tools/automation/engines/integration_automation_engine.py",

        "line": 153,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "file_hash = hashlib.md5(content).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        for file in self._target_path.rglob(\"*\"):\n            if file.is_file():\n                content = file.read_bytes()\n                file_hash = hashlib.md5(content).hexdigest()\n                if file_hash in hashes:\n                    duplicates.append((str(file), hashes[file_hash]))\n                else:"

      },

      {

        "file": "workspace/tools/refactor/process_legacy_scratch.py",

        "line": 827,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "file_hash = hashlib.md5(content.encode()).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        content = filepath.read_text(encoding=\"utf-8\", errors=\"ignore\")\n\n        # \u8a08\u7b97\u54c8\u5e0c\n        file_hash = hashlib.md5(content.encode()).hexdigest()\n\n        # \u8a5e\u5f59\u6383\u63cf\n        print(\"   \u8a5e\u5f59\u6383\u63cf...\")"

      },

      {

        "file": "workspace/tools/quantum-alignment-engine/src/core/transformer.py",

        "line": 139,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "policy_hash = hashlib.md5(b\"axiom-naming-v9\").hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        \"\"\"\n        # In production, load from governance-manifest.yaml\n        # For now, generate deterministic vector from policy hash\n        policy_hash = hashlib.md5(b\"axiom-naming-v9\").hexdigest()\n\n        # Convert hash to vector\n        vector = np.array([int(c, 16) for c in policy_hash], dtype=float)"

      },

      {

        "file": "workspace/tools/quantum-alignment-engine/src/core/transformer.py",

        "line": 225,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "namespace_hash = hashlib.md5(namespace.encode()).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        Generate 8192-dimensional semantic vector for namespace\n        \"\"\"\n        # Create deterministic vector from namespace string\n        namespace_hash = hashlib.md5(namespace.encode()).hexdigest()\n\n        # Convert to vector\n        vector = np.array([int(c, 16) for c in namespace_hash], dtype=float)"

      },

      {

        "file": "workspace/tools/quantum-alignment-engine/src/core/transformer.py",

        "line": 764,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "text_hash = hashlib.md5(text.encode()).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        # In production, use proper embedding model (e.g., sentence-transformers)\n        # For now, generate deterministic vector from hash\n\n        text_hash = hashlib.md5(text.encode()).hexdigest()\n        vector = np.array([int(c, 16) for c in text_hash], dtype=float)\n\n        # Expand to 8192 dimensions"

      }

    ],

    "low": [],

    "info": []

  },

  "by_category": {

    "Code Injection": [

      {

        "file": "code_quality_analyzer.py",

        "line": 159,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "(r\"eval\\s*\\(\", \"\u9ad8\u5371\uff1a\u4f7f\u7528 eval() \u53ef\u80fd\u5c0e\u81f4\u4ee3\u78bc\u6ce8\u5165\u6f0f\u6d1e\"),",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    def check_security(self, file_path, content, lines):\n        \"\"\"Check for security issues\"\"\"\n        security_patterns = [\n            (r\"eval\\s*\\(\", \"\u9ad8\u5371\uff1a\u4f7f\u7528 eval() \u53ef\u80fd\u5c0e\u81f4\u4ee3\u78bc\u6ce8\u5165\u6f0f\u6d1e\"),\n            (r\"exec\\s*\\(\", \"\u9ad8\u5371\uff1a\u4f7f\u7528 exec() \u53ef\u80fd\u5c0e\u81f4\u4ee3\u78bc\u6ce8\u5165\u6f0f\u6d1e\"),\n            (r\"pickle\\.(loads|load)\\s*\\(\", \"\u9ad8\u5371\uff1a\u4f7f\u7528 pickle \u53ef\u80fd\u5c0e\u81f4\u53cd\u5e8f\u5217\u5316\u6f0f\u6d1e\"),\n            (r\"md5\\s*\\(\", \"\u4e2d\u5371\uff1aMD5 \u4e0d\u662f\u5b89\u5168\u7684\u54c8\u5e0c\u7b97\u6cd5\"),"

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 7,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "- 77 security vulnerabilities (MD5, eval())",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "\nThis script addresses the remaining 866 low-severity issues:\n- 772 import order violations\n- 77 security vulnerabilities (MD5, eval())\n- 72 code smells (hardcoded URLs)\n- 22 missing docstrings\n\"\"\""

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 172,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "\"\"\"Replace unsafe eval() with safer alternatives.\"\"\"",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "            return False\n\n    def fix_eval_usage(self, file_path: Path) -> bool:\n        \"\"\"Replace unsafe eval() with safer alternatives.\"\"\"\n        try:\n            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                content = f.read()"

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 177,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" not in content:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                content = f.read()\n\n            if \"eval(\" not in content:\n                return False\n\n            # Note: eval() replacement is complex and context-dependent"

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 184,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in content:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "            # This is a basic implementation - manual review recommended\n            # We'll add a warning comment instead of automatic replacement\n\n            if \"eval(\" in content:\n                # Add security warning comment\n                warning = \"# TODO: Security - Consider replacing eval() with safer alternatives like ast.literal_eval()\\n\"\n                lines = content.split(\"\\n\")"

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 192,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in line and \"# TODO: Security\" not in line:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                # Find eval() lines and add warning\n                modified_lines = []\n                for line in lines:\n                    if \"eval(\" in line and \"# TODO: Security\" not in line:\n                        # Insert warning before the line\n                        indent = len(line) - len(line.lstrip())\n                        modified_lines.append(\" \" * indent + warning.rstrip())"

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 325,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "print(\"  \u26a0\ufe0f  eval() usage marked for review\")",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                    print(\"  \u2705 MD5 replaced with SHA256\")\n                if results[\"eval_fixed\"]:\n                    summary[\"eval_fixed\"] += 1\n                    print(\"  \u26a0\ufe0f  eval() usage marked for review\")\n\n                summary[\"total_fixes\"] += results[\"total_fixes\"]\n"

      },

      {

        "file": "fix_remaining_issues.py",

        "line": 361,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "print(f\"eval() reviews: {summary['eval_fixed']}\")",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    print(f\"Hardcoded URL fixes: {summary['hardcoded_urls_fixed']}\")\n    print(f\"Docstrings added: {summary['docstrings_added']}\")\n    print(f\"MD5 replacements: {summary['md5_fixed']}\")\n    print(f\"eval() reviews: {summary['eval_fixed']}\")\n    print(f\"Total fixes applied: {summary['total_fixes']}\")\n    print(f\"Errors encountered: {summary['errors']}\")\n    print(\"=\" * 60)"

      },

      {

        "file": "00-namespaces/namespaces-adk/adk/core/workflow_orchestrator.py",

        "line": 367,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "return eval(condition, {\"__builtins__\": {}}, context)",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        try:\n            # For now, support simple comparisons\n            # In production, use a safe expression evaluator\n            return eval(condition, {\"__builtins__\": {}}, context)\n        except Exception as e:\n            self.logger.warning(f\"Condition evaluation failed: {e}\")\n            return False"

      },

      {

        "file": "workspace/teams/holy-grail/automation/architect/core/analysis/security_scanner.py",

        "line": 114,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "(r\"eval\\s*\\(\", \"eval-usage\", \"Use of eval() can lead to code injection\"),",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                \"xss\",\n                \"Potential XSS vulnerability via document.write\",\n            ),\n            (r\"eval\\s*\\(\", \"eval-usage\", \"Use of eval() can lead to code injection\"),\n        ]\n\n        # \u4e0d\u5b89\u5168\u7684\u52a0\u5bc6"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/pipeline_service.py",

        "line": 361,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "result = eval(user_input)",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    test_code = \"\"\"\ndef unsafe_function(user_input):\n    # Security issue: eval\n    result = eval(user_input)\n\n    # Performance issue: nested loops\n    for i in range(100):"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/examples/demo.py",

        "line": 42,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "result = eval(user_input)",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    problematic_code = \"\"\"\ndef process_user_data(user_input, password):\n    # Security issue: using eval\n    result = eval(user_input)\n\n    # Security issue: hardcoded password\n    db_password = os.getenv(\"DATABASE_PASSWORD\", \"admin123\")"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/test-vectors/generator.py",

        "line": 221,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "\"    result = eval(user_input)\",",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "            \"    # Multiple security issues for comprehensive testing\",\n            \"    \",\n            \"    # Issue 1: Eval injection\",\n            \"    result = eval(user_input)\",\n            \"    \",\n            \"    # Issue 2: Hardcoded credential\",\n            '    db_password = \"PLACEHOLDER_TEST_ONLY\"',"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/agents/task_executor.py",

        "line": 135,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in code or \"exec(\" in code:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        issues = []\n\n        # Basic security pattern detection\n        if \"eval(\" in code or \"exec(\" in code:\n            issues.append(\n                {\n                    \"type\": \"security\","

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/agents/task_executor.py",

        "line": 234,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in code or \"exec(\" in code:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        fixed_code = code\n\n        if issue[\"type\"] == \"security\":\n            if \"eval(\" in code or \"exec(\" in code:\n                # Remove dangerous code execution\n                fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")\n                fixed_code = fixed_code.replace(\"exec(\", \"# REMOVED_exec(\")"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/agents/task_executor.py",

        "line": 236,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        if issue[\"type\"] == \"security\":\n            if \"eval(\" in code or \"exec(\" in code:\n                # Remove dangerous code execution\n                fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")\n                fixed_code = fixed_code.replace(\"exec(\", \"# REMOVED_exec(\")\n                logger.info(\"Applied security fix: removed eval/exec\")\n"

      },

      {

        "file": "workspace/teams/holy-grail/agents/autonomous/agents/task_executor.py",

        "line": 293,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "result = eval(user_input)  # Security issue!",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    # Example: Analyze potentially unsafe code\n    test_code = \"\"\"\ndef process_data(user_input):\n    result = eval(user_input)  # Security issue!\n    password = \"hardcoded123\"   # Security issue!\n\n    for i in range(len(data)):"

      },

      {

        "file": "workspace/src/automation/architect/core/analysis/security_scanner.py",

        "line": 114,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "(r\"eval\\s*\\(\", \"eval-usage\", \"Use of eval() can lead to code injection\"),",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                \"xss\",\n                \"Potential XSS vulnerability via document.write\",\n            ),\n            (r\"eval\\s*\\(\", \"eval-usage\", \"Use of eval() can lead to code injection\"),\n        ]\n\n        # \u4e0d\u5b89\u5168\u7684\u52a0\u5bc6"

      },

      {

        "file": "workspace/src/core/run-debug/cli.py",

        "line": 387,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "def eval(expression):",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "\n@debug.command()\n@click.argument(\"expression\")\ndef eval(expression):\n    \"\"\"\u8a55\u4f30\u8868\u9054\u5f0f\"\"\"\n    cli = DebugCLI()\n    asyncio.run(cli.evaluate_expression(expression))"

      },

      {

        "file": "workspace/src/core/virtual_experts/domain_experts.py",

        "line": 505,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in code_lower or \"exec(\" in code_lower:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                    }\n                )\n\n        if \"eval(\" in code_lower or \"exec(\" in code_lower:\n            issues.append(\n                {\n                    \"severity\": \"critical\","

      },

      {

        "file": "workspace/src/core/plugins/virtual_experts/domain_experts.py",

        "line": 500,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in code_lower or \"exec(\" in code_lower:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                    }\n                )\n\n        if \"eval(\" in code_lower or \"exec(\" in code_lower:\n            issues.append(\n                {\n                    \"severity\": \"critical\","

      },

      {

        "file": "workspace/src/autonomous/agents/pipeline_service.py",

        "line": 361,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "result = eval(user_input)",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    test_code = \"\"\"\ndef unsafe_function(user_input):\n    # Security issue: eval\n    result = eval(user_input)\n\n    # Performance issue: nested loops\n    for i in range(100):"

      },

      {

        "file": "workspace/src/autonomous/agents/examples/demo.py",

        "line": 42,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "result = eval(user_input)",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    problematic_code = \"\"\"\ndef process_user_data(user_input, password):\n    # Security issue: using eval\n    result = eval(user_input)\n\n    # Security issue: hardcoded password\n    db_password = os.getenv(\"DATABASE_PASSWORD\", \"admin123\")"

      },

      {

        "file": "workspace/src/autonomous/agents/test-vectors/generator.py",

        "line": 221,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "\"    result = eval(user_input)\",",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "            \"    # Multiple security issues for comprehensive testing\",\n            \"    \",\n            \"    # Issue 1: Eval injection\",\n            \"    result = eval(user_input)\",\n            \"    \",\n            \"    # Issue 2: Hardcoded credential\",\n            '    db_password = \"PLACEHOLDER_TEST_ONLY\"',"

      },

      {

        "file": "workspace/src/autonomous/agents/agents/task_executor.py",

        "line": 135,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in code or \"exec(\" in code:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        issues = []\n\n        # Basic security pattern detection\n        if \"eval(\" in code or \"exec(\" in code:\n            issues.append(\n                {\n                    \"type\": \"security\","

      },

      {

        "file": "workspace/src/autonomous/agents/agents/task_executor.py",

        "line": 234,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "if \"eval(\" in code or \"exec(\" in code:",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        fixed_code = code\n\n        if issue[\"type\"] == \"security\":\n            if \"eval(\" in code or \"exec(\" in code:\n                # Remove dangerous code execution\n                fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")\n                fixed_code = fixed_code.replace(\"exec(\", \"# REMOVED_exec(\")"

      },

      {

        "file": "workspace/src/autonomous/agents/agents/task_executor.py",

        "line": 236,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        if issue[\"type\"] == \"security\":\n            if \"eval(\" in code or \"exec(\" in code:\n                # Remove dangerous code execution\n                fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")\n                fixed_code = fixed_code.replace(\"exec(\", \"# REMOVED_exec(\")\n                logger.info(\"Applied security fix: removed eval/exec\")\n"

      },

      {

        "file": "workspace/src/autonomous/agents/agents/task_executor.py",

        "line": 293,

        "severity": "medium",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "result = eval(user_input)  # Security issue!",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "    # Example: Analyze potentially unsafe code\n    test_code = \"\"\"\ndef process_data(user_input):\n    result = eval(user_input)  # Security issue!\n    password = \"hardcoded123\"   # Security issue!\n\n    for i in range(len(data)):"

      },

      {

        "file": "workspace/tools/security_audit.py",

        "line": 6,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "analyzing MD5 usage, eval() usage, and other security concerns.",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "Security Audit Tool\n\nThis script performs a comprehensive security audit of the codebase,\nanalyzing MD5 usage, eval() usage, and other security concerns.\n\"\"\"\n\nimport ast"

      },

      {

        "file": "workspace/tools/security_audit.py",

        "line": 150,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "\"\"\"Check for eval() usage.\"\"\"",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "        return findings\n\n    def check_eval_usage(self, file_path: Path) -> List[SecurityFinding]:\n        \"\"\"Check for eval() usage.\"\"\"\n        findings = []\n\n        try:"

      },

      {

        "file": "workspace/tools/security_audit.py",

        "line": 190,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "issue=\"eval() function usage detected\",",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                        line_number=line_num,\n                        severity=severity,\n                        category=\"Code Injection\",\n                        issue=\"eval() function usage detected\",\n                        code_snippet=code_snippet,\n                        recommendation=\"Avoid eval() as it can execute arbitrary code. \"\n                        \"Consider using ast.literal_eval() for parsing literals, \""

      },

      {

        "file": "workspace/tools/security_audit.py",

        "line": 192,

        "severity": "high",

        "category": "Code Injection",

        "issue": "eval() function usage detected",

        "code": "recommendation=\"Avoid eval() as it can execute arbitrary code. \"",

        "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

        "context": "                        category=\"Code Injection\",\n                        issue=\"eval() function usage detected\",\n                        code_snippet=code_snippet,\n                        recommendation=\"Avoid eval() as it can execute arbitrary code. \"\n                        \"Consider using ast.literal_eval() for parsing literals, \"\n                        \"or implement a proper parser for your use case.\",\n                        context=context,"

      }

    ],

    "Cryptographic": [

      {

        "file": "workspace/teams/holy-grail/agents/services/dependency-manager/src/enterprise/security.py",

        "line": 296,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _generate_serial(self) -> str:\n        \"\"\"\u751f\u6210\u5e8f\u5217\u865f\"\"\"\n        timestamp = datetime.now().isoformat()\n        return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"\n\n    def _get_spec_version(self, sbom_format: SBOMFormat) -> str:\n        \"\"\"\u53d6\u5f97\u898f\u7bc4\u7248\u672c\"\"\""

      },

      {

        "file": "workspace/teams/holy-grail/agents/services/dependency-manager/src/enterprise/security.py",

        "line": 702,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "actual = hashlib.md5(content).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        elif algorithm == \"sha512\":\n            actual = hashlib.sha512(content).hexdigest()\n        elif algorithm == \"md5\":\n            actual = hashlib.md5(content).hexdigest()\n        else:\n            actual = hashlib.sha256(content).hexdigest()\n"

      },

      {

        "file": "workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/enterprise/security.py",

        "line": 296,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _generate_serial(self) -> str:\n        \"\"\"\u751f\u6210\u5e8f\u5217\u865f\"\"\"\n        timestamp = datetime.now().isoformat()\n        return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"\n\n    def _get_spec_version(self, sbom_format: SBOMFormat) -> str:\n        \"\"\"\u53d6\u5f97\u898f\u7bc4\u7248\u672c\"\"\""

      },

      {

        "file": "workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/enterprise/security.py",

        "line": 702,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "actual = hashlib.md5(content).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        elif algorithm == \"sha512\":\n            actual = hashlib.sha512(content).hexdigest()\n        elif algorithm == \"md5\":\n            actual = hashlib.md5(content).hexdigest()\n        else:\n            actual = hashlib.sha256(content).hexdigest()\n"

      },

      {

        "file": "workspace/src/ai/agents/dependency-manager/src/enterprise/security.py",

        "line": 296,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _generate_serial(self) -> str:\n        \"\"\"\u751f\u6210\u5e8f\u5217\u865f\"\"\"\n        timestamp = datetime.now().isoformat()\n        return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"\n\n    def _get_spec_version(self, sbom_format: SBOMFormat) -> str:\n        \"\"\"\u53d6\u5f97\u898f\u7bc4\u7248\u672c\"\"\""

      },

      {

        "file": "workspace/src/ai/agents/dependency-manager/src/enterprise/security.py",

        "line": 702,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "actual = hashlib.md5(content).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        elif algorithm == \"sha512\":\n            actual = hashlib.sha512(content).hexdigest()\n        elif algorithm == \"md5\":\n            actual = hashlib.md5(content).hexdigest()\n        else:\n            actual = hashlib.sha256(content).hexdigest()\n"

      },

      {

        "file": "workspace/src/core/training_system/example_library.py",

        "line": 383,

        "severity": "high",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "import hashlib\n\ndef hash_password_weak(password: str) -> str:\n    return hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01\n\n# \u554f\u984c 3\uff1a\u6c92\u6709\u52a0\u9e7d\ndef hash_password_no_salt(password: str) -> str:"

      },

      {

        "file": "workspace/src/core/training_system/knowledge_base.py",

        "line": 425,

        "severity": "high",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "hashed = hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "\n# \u274c \u4f7f\u7528\u5f31\u54c8\u5e0c\nimport hashlib\nhashed = hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01\n\"\"\",\n            priority=\"critical\",\n            tags=[\"password\", \"authentication\", \"hashing\"],"

      },

      {

        "file": "workspace/src/core/island_ai_runtime/knowledge_engine.py",

        "line": 322,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return hashlib.md5(path.encode()).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    @staticmethod\n    def _generate_id(path: str) -> str:\n        \"\"\"\u751f\u6210\u7bc0\u9ede ID\"\"\"\n        return hashlib.md5(path.encode()).hexdigest()\n"

      },

      {

        "file": "workspace/src/core/plugins/training_system/example_library.py",

        "line": 381,

        "severity": "high",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "import hashlib\n\ndef hash_password_weak(password: str) -> str:\n    return hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01\n\n# \u554f\u984c 3\uff1a\u6c92\u6709\u52a0\u9e7d\ndef hash_password_no_salt(password: str) -> str:"

      },

      {

        "file": "workspace/src/core/plugins/training_system/knowledge_base.py",

        "line": 424,

        "severity": "high",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "hashed = hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "\n# \u274c \u4f7f\u7528\u5f31\u54c8\u5e0c\nimport hashlib\nhashed = hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01\n\"\"\",\n            priority=\"critical\",\n            tags=[\"password\", \"authentication\", \"hashing\"],"

      },

      {

        "file": "workspace/src/services/agents/dependency-manager/src/enterprise/security.py",

        "line": 296,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _generate_serial(self) -> str:\n        \"\"\"\u751f\u6210\u5e8f\u5217\u865f\"\"\"\n        timestamp = datetime.now().isoformat()\n        return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"\n\n    def _get_spec_version(self, sbom_format: SBOMFormat) -> str:\n        \"\"\"\u53d6\u5f97\u898f\u7bc4\u7248\u672c\"\"\""

      },

      {

        "file": "workspace/src/services/agents/dependency-manager/src/enterprise/security.py",

        "line": 702,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "actual = hashlib.md5(content).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        elif algorithm == \"sha512\":\n            actual = hashlib.sha512(content).hexdigest()\n        elif algorithm == \"md5\":\n            actual = hashlib.md5(content).hexdigest()\n        else:\n            actual = hashlib.sha256(content).hexdigest()\n"

      },

      {

        "file": "workspace/src/frontend/ui/services/code_analyzer.py",

        "line": 198,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return f\"analysis:{hashlib.md5(content.encode()).hexdigest()}\"",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _get_cache_key(self, code: str, file_path: str) -> str:\n        \"\"\"\u751f\u6210\u7de9\u5b58\u9375\"\"\"\n        content = f\"{code}:{file_path}\"\n        return f\"analysis:{hashlib.md5(content.encode()).hexdigest()}\"\n\n    async def analyze(\n        self,"

      },

      {

        "file": "workspace/src/apps/web-backend/services/code_analyzer.py",

        "line": 195,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "return f\"analysis:{hashlib.md5(content.encode()).hexdigest()}\"",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _get_cache_key(self, code: str, file_path: str) -> str:\n        \"\"\"\u751f\u6210\u7de9\u5b58\u9375\"\"\"\n        content = f\"{code}:{file_path}\"\n        return f\"analysis:{hashlib.md5(content.encode()).hexdigest()}\"\n\n    async def analyze(\n        self,"

      },

      {

        "file": "workspace/tools/find_duplicate_scripts.py",

        "line": 75,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "hasher = hashlib.md5()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "\n    def _hash_file(self, file_path: Path) -> str:\n        \"\"\"\u8a08\u7b97\u6587\u4ef6\u7684\u54c8\u5e0c\u503c\"\"\"\n        hasher = hashlib.md5()\n        with open(file_path, \"rb\") as f:\n            hasher.update(f.read())\n        return hasher.hexdigest()"

      },

      {

        "file": "workspace/tools/autonomous_cleanup_toolkit.py",

        "line": 212,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "md5_hash = hashlib.md5(content).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "\n                try:\n                    content = file_path.read_bytes()\n                    md5_hash = hashlib.md5(content).hexdigest()\n                    hash_map[md5_hash].append(\n                        str(file_path.relative_to(self.repo_path))\n                    )"

      },

      {

        "file": "workspace/tools/cleanup_duplicates.py",

        "line": 83,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "empty_init_hash = hashlib.md5(b\"\").hexdigest()  # \u7a7a\u6587\u4ef6\u54c8\u5e0c",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        \"\"\"\u6e05\u7406\u7a7a\u7684 __init__.py \u6587\u4ef6\u91cd\u8907\"\"\"\n        print(\"\\n3\ufe0f\u20e3  \u6e05\u7406\u7a7a __init__.py \u91cd\u8907...\")\n\n        empty_init_hash = hashlib.md5(b\"\").hexdigest()  # \u7a7a\u6587\u4ef6\u54c8\u5e0c\n        init_files = list(self.repo_root.rglob(\"__init__.py\"))\n\n        # \u6309\u76ee\u9304\u5206\u7d44"

      },

      {

        "file": "workspace/tools/cleanup_duplicates.py",

        "line": 106,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "hasher = hashlib.md5()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "    def _hash_file(self, file_path: Path) -> str:\n        \"\"\"\u8a08\u7b97\u6587\u4ef6\u54c8\u5e0c\"\"\"\n        try:\n            hasher = hashlib.md5()\n            with open(file_path, \"rb\") as f:\n                hasher.update(f.read())\n            return hasher.hexdigest()"

      },

      {

        "file": "workspace/tools/automation/engines/integration_automation_engine.py",

        "line": 153,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "file_hash = hashlib.md5(content).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        for file in self._target_path.rglob(\"*\"):\n            if file.is_file():\n                content = file.read_bytes()\n                file_hash = hashlib.md5(content).hexdigest()\n                if file_hash in hashes:\n                    duplicates.append((str(file), hashes[file_hash]))\n                else:"

      },

      {

        "file": "workspace/tools/refactor/process_legacy_scratch.py",

        "line": 827,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "file_hash = hashlib.md5(content.encode()).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        content = filepath.read_text(encoding=\"utf-8\", errors=\"ignore\")\n\n        # \u8a08\u7b97\u54c8\u5e0c\n        file_hash = hashlib.md5(content.encode()).hexdigest()\n\n        # \u8a5e\u5f59\u6383\u63cf\n        print(\"   \u8a5e\u5f59\u6383\u63cf...\")"

      },

      {

        "file": "workspace/tools/quantum-alignment-engine/src/core/transformer.py",

        "line": 139,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "policy_hash = hashlib.md5(b\"axiom-naming-v9\").hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        \"\"\"\n        # In production, load from governance-manifest.yaml\n        # For now, generate deterministic vector from policy hash\n        policy_hash = hashlib.md5(b\"axiom-naming-v9\").hexdigest()\n\n        # Convert hash to vector\n        vector = np.array([int(c, 16) for c in policy_hash], dtype=float)"

      },

      {

        "file": "workspace/tools/quantum-alignment-engine/src/core/transformer.py",

        "line": 225,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "namespace_hash = hashlib.md5(namespace.encode()).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        Generate 8192-dimensional semantic vector for namespace\n        \"\"\"\n        # Create deterministic vector from namespace string\n        namespace_hash = hashlib.md5(namespace.encode()).hexdigest()\n\n        # Convert to vector\n        vector = np.array([int(c, 16) for c in namespace_hash], dtype=float)"

      },

      {

        "file": "workspace/tools/quantum-alignment-engine/src/core/transformer.py",

        "line": 764,

        "severity": "medium",

        "category": "Cryptographic",

        "issue": "MD5 hash usage detected",

        "code": "text_hash = hashlib.md5(text.encode()).hexdigest()",

        "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

        "context": "        # In production, use proper embedding model (e.g., sentence-transformers)\n        # For now, generate deterministic vector from hash\n\n        text_hash = hashlib.md5(text.encode()).hexdigest()\n        vector = np.array([int(c, 16) for c in text_hash], dtype=float)\n\n        # Expand to 8192 dimensions"

      }

    ],

    "Secrets Management": [

      {

        "file": "workspace/src/core/training_system/example_library.py",

        "line": 297,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded password",

        "code": "AND password = '{password}'",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "    query = f\\\"\\\"\\\"\n    SELECT * FROM users\n    WHERE username = '{username}'\n    AND password = '{password}'\n    \\\"\\\"\\\"\n    return db.execute(query)\n"

      },

      {

        "file": "workspace/src/core/training_system/example_library.py",

        "line": 304,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded password",

        "code": "# \u7d50\u679c: SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "# \u653b\u64ca\u8005\u53ef\u4ee5\u7e5e\u904e\u767b\u9304\uff1a\n# username: admin' --\n# password: anything\n# \u7d50\u679c: SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'\n\"\"\",\n            good_code=\"\"\"\n# \u2705 \u4f7f\u7528\u53c3\u6578\u5316\u67e5\u8a62"

      },

      {

        "file": "workspace/src/core/training_system/skills_training.py",

        "line": 580,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded password",

        "code": "query = f\"SELECT * FROM users WHERE email = '{email}' AND password = '{password}'\"",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "                    \"question\": \"\"\"\n\u4fee\u5fa9\u9019\u6bb5\u4ee3\u78bc\u7684\u5b89\u5168\u6f0f\u6d1e\uff1a\ndef login(email, password):\n    query = f\"SELECT * FROM users WHERE email = '{email}' AND password = '{password}'\"\n    user = db.execute(query)\n    return user\n\"\"\","

      },

      {

        "file": "workspace/src/core/plugins/training_system/example_library.py",

        "line": 295,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded password",

        "code": "AND password = '{password}'",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "    query = f\\\"\\\"\\\"\n    SELECT * FROM users\n    WHERE username = '{username}'\n    AND password = '{password}'\n    \\\"\\\"\\\"\n    return db.execute(query)\n"

      },

      {

        "file": "workspace/src/core/plugins/training_system/example_library.py",

        "line": 302,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded password",

        "code": "# \u7d50\u679c: SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "# \u653b\u64ca\u8005\u53ef\u4ee5\u7e5e\u904e\u767b\u9304\uff1a\n# username: admin' --\n# password: anything\n# \u7d50\u679c: SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'\n\"\"\",\n            good_code=\"\"\"\n# \u2705 \u4f7f\u7528\u53c3\u6578\u5316\u67e5\u8a62"

      },

      {

        "file": "workspace/src/core/plugins/training_system/skills_training.py",

        "line": 580,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded password",

        "code": "query = f\"SELECT * FROM users WHERE email = '{email}' AND password = '{password}'\"",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "                    \"question\": \"\"\"\n\u4fee\u5fa9\u9019\u6bb5\u4ee3\u78bc\u7684\u5b89\u5168\u6f0f\u6d1e\uff1a\ndef login(email, password):\n    query = f\"SELECT * FROM users WHERE email = '{email}' AND password = '{password}'\"\n    user = db.execute(query)\n    return user\n\"\"\","

      },

      {

        "file": "workspace/src/enterprise/execution/secrets.py",

        "line": 32,

        "severity": "critical",

        "category": "Secrets Management",

        "issue": "Hardcoded secret/token",

        "code": "OAUTH_CLIENT_SECRET = \"oauth_client_secret\"",

        "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

        "context": "    PROVIDER_TOKEN = os.getenv(\"PROVIDER_TOKEN\", \"provider_token\")\n    API_KEY = \"api_key\"\n    ENCRYPTION_KEY = \"encryption_key\"\n    OAUTH_CLIENT_SECRET = \"oauth_client_secret\"\n    SIGNING_KEY = \"signing_key\"\n    DATABASE_PASSWORD = os.getenv(\"DATABASE_PASSWORD\", \"database_password\")\n    SERVICE_ACCOUNT = \"service_account\""

      }

    ]

  },

  "findings": [

    {

      "file": "code_quality_analyzer.py",

      "line": 159,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "(r\"eval\\s*\\(\", \"\u9ad8\u5371\uff1a\u4f7f\u7528 eval() \u53ef\u80fd\u5c0e\u81f4\u4ee3\u78bc\u6ce8\u5165\u6f0f\u6d1e\"),",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "    def check_security(self, file_path, content, lines):\n        \"\"\"Check for security issues\"\"\"\n        security_patterns = [\n            (r\"eval\\s*\\(\", \"\u9ad8\u5371\uff1a\u4f7f\u7528 eval() \u53ef\u80fd\u5c0e\u81f4\u4ee3\u78bc\u6ce8\u5165\u6f0f\u6d1e\"),\n            (r\"exec\\s*\\(\", \"\u9ad8\u5371\uff1a\u4f7f\u7528 exec() \u53ef\u80fd\u5c0e\u81f4\u4ee3\u78bc\u6ce8\u5165\u6f0f\u6d1e\"),\n            (r\"pickle\\.(loads|load)\\s*\\(\", \"\u9ad8\u5371\uff1a\u4f7f\u7528 pickle \u53ef\u80fd\u5c0e\u81f4\u53cd\u5e8f\u5217\u5316\u6f0f\u6d1e\"),\n            (r\"md5\\s*\\(\", \"\u4e2d\u5371\uff1aMD5 \u4e0d\u662f\u5b89\u5168\u7684\u54c8\u5e0c\u7b97\u6cd5\"),"

    },

    {

      "file": "fix_remaining_issues.py",

      "line": 7,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "- 77 security vulnerabilities (MD5, eval())",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "\nThis script addresses the remaining 866 low-severity issues:\n- 772 import order violations\n- 77 security vulnerabilities (MD5, eval())\n- 72 code smells (hardcoded URLs)\n- 22 missing docstrings\n\"\"\""

    },

    {

      "file": "fix_remaining_issues.py",

      "line": 172,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "\"\"\"Replace unsafe eval() with safer alternatives.\"\"\"",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "            return False\n\n    def fix_eval_usage(self, file_path: Path) -> bool:\n        \"\"\"Replace unsafe eval() with safer alternatives.\"\"\"\n        try:\n            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                content = f.read()"

    },

    {

      "file": "fix_remaining_issues.py",

      "line": 177,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "if \"eval(\" not in content:",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                content = f.read()\n\n            if \"eval(\" not in content:\n                return False\n\n            # Note: eval() replacement is complex and context-dependent"

    },

    {

      "file": "fix_remaining_issues.py",

      "line": 184,

      "severity": "medium",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "if \"eval(\" in content:",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "            # This is a basic implementation - manual review recommended\n            # We'll add a warning comment instead of automatic replacement\n\n            if \"eval(\" in content:\n                # Add security warning comment\n                warning = \"# TODO: Security - Consider replacing eval() with safer alternatives like ast.literal_eval()\\n\"\n                lines = content.split(\"\\n\")"

    },

    {

      "file": "fix_remaining_issues.py",

      "line": 192,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "if \"eval(\" in line and \"# TODO: Security\" not in line:",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "                # Find eval() lines and add warning\n                modified_lines = []\n                for line in lines:\n                    if \"eval(\" in line and \"# TODO: Security\" not in line:\n                        # Insert warning before the line\n                        indent = len(line) - len(line.lstrip())\n                        modified_lines.append(\" \" * indent + warning.rstrip())"

    },

    {

      "file": "fix_remaining_issues.py",

      "line": 325,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "print(\"  \u26a0\ufe0f  eval() usage marked for review\")",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "                    print(\"  \u2705 MD5 replaced with SHA256\")\n                if results[\"eval_fixed\"]:\n                    summary[\"eval_fixed\"] += 1\n                    print(\"  \u26a0\ufe0f  eval() usage marked for review\")\n\n                summary[\"total_fixes\"] += results[\"total_fixes\"]\n"

    },

    {

      "file": "fix_remaining_issues.py",

      "line": 361,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "print(f\"eval() reviews: {summary['eval_fixed']}\")",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "    print(f\"Hardcoded URL fixes: {summary['hardcoded_urls_fixed']}\")\n    print(f\"Docstrings added: {summary['docstrings_added']}\")\n    print(f\"MD5 replacements: {summary['md5_fixed']}\")\n    print(f\"eval() reviews: {summary['eval_fixed']}\")\n    print(f\"Total fixes applied: {summary['total_fixes']}\")\n    print(f\"Errors encountered: {summary['errors']}\")\n    print(\"=\" * 60)"

    },

    {

      "file": "00-namespaces/namespaces-adk/adk/core/workflow_orchestrator.py",

      "line": 367,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "return eval(condition, {\"__builtins__\": {}}, context)",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "        try:\n            # For now, support simple comparisons\n            # In production, use a safe expression evaluator\n            return eval(condition, {\"__builtins__\": {}}, context)\n        except Exception as e:\n            self.logger.warning(f\"Condition evaluation failed: {e}\")\n            return False"

    },

    {

      "file": "workspace/teams/holy-grail/automation/architect/core/analysis/security_scanner.py",

      "line": 114,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "(r\"eval\\s*\\(\", \"eval-usage\", \"Use of eval() can lead to code injection\"),",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "                \"xss\",\n                \"Potential XSS vulnerability via document.write\",\n            ),\n            (r\"eval\\s*\\(\", \"eval-usage\", \"Use of eval() can lead to code injection\"),\n        ]\n\n        # \u4e0d\u5b89\u5168\u7684\u52a0\u5bc6"

    },

    {

      "file": "workspace/teams/holy-grail/agents/autonomous/pipeline_service.py",

      "line": 361,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "result = eval(user_input)",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "    test_code = \"\"\"\ndef unsafe_function(user_input):\n    # Security issue: eval\n    result = eval(user_input)\n\n    # Performance issue: nested loops\n    for i in range(100):"

    },

    {

      "file": "workspace/teams/holy-grail/agents/autonomous/examples/demo.py",

      "line": 42,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "result = eval(user_input)",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "    problematic_code = \"\"\"\ndef process_user_data(user_input, password):\n    # Security issue: using eval\n    result = eval(user_input)\n\n    # Security issue: hardcoded password\n    db_password = os.getenv(\"DATABASE_PASSWORD\", \"admin123\")"

    },

    {

      "file": "workspace/teams/holy-grail/agents/autonomous/test-vectors/generator.py",

      "line": 221,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "\"    result = eval(user_input)\",",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "            \"    # Multiple security issues for comprehensive testing\",\n            \"    \",\n            \"    # Issue 1: Eval injection\",\n            \"    result = eval(user_input)\",\n            \"    \",\n            \"    # Issue 2: Hardcoded credential\",\n            '    db_password = \"PLACEHOLDER_TEST_ONLY\"',"

    },

    {

      "file": "workspace/teams/holy-grail/agents/autonomous/agents/task_executor.py",

      "line": 135,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "if \"eval(\" in code or \"exec(\" in code:",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "        issues = []\n\n        # Basic security pattern detection\n        if \"eval(\" in code or \"exec(\" in code:\n            issues.append(\n                {\n                    \"type\": \"security\","

    },

    {

      "file": "workspace/teams/holy-grail/agents/autonomous/agents/task_executor.py",

      "line": 234,

      "severity": "medium",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "if \"eval(\" in code or \"exec(\" in code:",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "        fixed_code = code\n\n        if issue[\"type\"] == \"security\":\n            if \"eval(\" in code or \"exec(\" in code:\n                # Remove dangerous code execution\n                fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")\n                fixed_code = fixed_code.replace(\"exec(\", \"# REMOVED_exec(\")"

    },

    {

      "file": "workspace/teams/holy-grail/agents/autonomous/agents/task_executor.py",

      "line": 236,

      "severity": "medium",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "        if issue[\"type\"] == \"security\":\n            if \"eval(\" in code or \"exec(\" in code:\n                # Remove dangerous code execution\n                fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")\n                fixed_code = fixed_code.replace(\"exec(\", \"# REMOVED_exec(\")\n                logger.info(\"Applied security fix: removed eval/exec\")\n"

    },

    {

      "file": "workspace/teams/holy-grail/agents/autonomous/agents/task_executor.py",

      "line": 293,

      "severity": "medium",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "result = eval(user_input)  # Security issue!",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "    # Example: Analyze potentially unsafe code\n    test_code = \"\"\"\ndef process_data(user_input):\n    result = eval(user_input)  # Security issue!\n    password = \"hardcoded123\"   # Security issue!\n\n    for i in range(len(data)):"

    },

    {

      "file": "workspace/teams/holy-grail/agents/services/dependency-manager/src/enterprise/security.py",

      "line": 296,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "    def _generate_serial(self) -> str:\n        \"\"\"\u751f\u6210\u5e8f\u5217\u865f\"\"\"\n        timestamp = datetime.now().isoformat()\n        return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"\n\n    def _get_spec_version(self, sbom_format: SBOMFormat) -> str:\n        \"\"\"\u53d6\u5f97\u898f\u7bc4\u7248\u672c\"\"\""

    },

    {

      "file": "workspace/teams/holy-grail/agents/services/dependency-manager/src/enterprise/security.py",

      "line": 702,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "actual = hashlib.md5(content).hexdigest()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "        elif algorithm == \"sha512\":\n            actual = hashlib.sha512(content).hexdigest()\n        elif algorithm == \"md5\":\n            actual = hashlib.md5(content).hexdigest()\n        else:\n            actual = hashlib.sha256(content).hexdigest()\n"

    },

    {

      "file": "workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/enterprise/security.py",

      "line": 296,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "    def _generate_serial(self) -> str:\n        \"\"\"\u751f\u6210\u5e8f\u5217\u865f\"\"\"\n        timestamp = datetime.now().isoformat()\n        return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"\n\n    def _get_spec_version(self, sbom_format: SBOMFormat) -> str:\n        \"\"\"\u53d6\u5f97\u898f\u7bc4\u7248\u672c\"\"\""

    },

    {

      "file": "workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/enterprise/security.py",

      "line": 702,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "actual = hashlib.md5(content).hexdigest()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "        elif algorithm == \"sha512\":\n            actual = hashlib.sha512(content).hexdigest()\n        elif algorithm == \"md5\":\n            actual = hashlib.md5(content).hexdigest()\n        else:\n            actual = hashlib.sha256(content).hexdigest()\n"

    },

    {

      "file": "workspace/src/ai/agents/dependency-manager/src/enterprise/security.py",

      "line": 296,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "    def _generate_serial(self) -> str:\n        \"\"\"\u751f\u6210\u5e8f\u5217\u865f\"\"\"\n        timestamp = datetime.now().isoformat()\n        return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"\n\n    def _get_spec_version(self, sbom_format: SBOMFormat) -> str:\n        \"\"\"\u53d6\u5f97\u898f\u7bc4\u7248\u672c\"\"\""

    },

    {

      "file": "workspace/src/ai/agents/dependency-manager/src/enterprise/security.py",

      "line": 702,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "actual = hashlib.md5(content).hexdigest()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "        elif algorithm == \"sha512\":\n            actual = hashlib.sha512(content).hexdigest()\n        elif algorithm == \"md5\":\n            actual = hashlib.md5(content).hexdigest()\n        else:\n            actual = hashlib.sha256(content).hexdigest()\n"

    },

    {

      "file": "workspace/src/automation/architect/core/analysis/security_scanner.py",

      "line": 114,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "(r\"eval\\s*\\(\", \"eval-usage\", \"Use of eval() can lead to code injection\"),",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "                \"xss\",\n                \"Potential XSS vulnerability via document.write\",\n            ),\n            (r\"eval\\s*\\(\", \"eval-usage\", \"Use of eval() can lead to code injection\"),\n        ]\n\n        # \u4e0d\u5b89\u5168\u7684\u52a0\u5bc6"

    },

    {

      "file": "workspace/src/core/run-debug/cli.py",

      "line": 387,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "def eval(expression):",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "\n@debug.command()\n@click.argument(\"expression\")\ndef eval(expression):\n    \"\"\"\u8a55\u4f30\u8868\u9054\u5f0f\"\"\"\n    cli = DebugCLI()\n    asyncio.run(cli.evaluate_expression(expression))"

    },

    {

      "file": "workspace/src/core/training_system/example_library.py",

      "line": 383,

      "severity": "high",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "return hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "import hashlib\n\ndef hash_password_weak(password: str) -> str:\n    return hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01\n\n# \u554f\u984c 3\uff1a\u6c92\u6709\u52a0\u9e7d\ndef hash_password_no_salt(password: str) -> str:"

    },

    {

      "file": "workspace/src/core/training_system/example_library.py",

      "line": 297,

      "severity": "critical",

      "category": "Secrets Management",

      "issue": "Hardcoded password",

      "code": "AND password = '{password}'",

      "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

      "context": "    query = f\\\"\\\"\\\"\n    SELECT * FROM users\n    WHERE username = '{username}'\n    AND password = '{password}'\n    \\\"\\\"\\\"\n    return db.execute(query)\n"

    },

    {

      "file": "workspace/src/core/training_system/example_library.py",

      "line": 304,

      "severity": "critical",

      "category": "Secrets Management",

      "issue": "Hardcoded password",

      "code": "# \u7d50\u679c: SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'",

      "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

      "context": "# \u653b\u64ca\u8005\u53ef\u4ee5\u7e5e\u904e\u767b\u9304\uff1a\n# username: admin' --\n# password: anything\n# \u7d50\u679c: SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'\n\"\"\",\n            good_code=\"\"\"\n# \u2705 \u4f7f\u7528\u53c3\u6578\u5316\u67e5\u8a62"

    },

    {

      "file": "workspace/src/core/training_system/knowledge_base.py",

      "line": 425,

      "severity": "high",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "hashed = hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "\n# \u274c \u4f7f\u7528\u5f31\u54c8\u5e0c\nimport hashlib\nhashed = hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01\n\"\"\",\n            priority=\"critical\",\n            tags=[\"password\", \"authentication\", \"hashing\"],"

    },

    {

      "file": "workspace/src/core/training_system/skills_training.py",

      "line": 580,

      "severity": "critical",

      "category": "Secrets Management",

      "issue": "Hardcoded password",

      "code": "query = f\"SELECT * FROM users WHERE email = '{email}' AND password = '{password}'\"",

      "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

      "context": "                    \"question\": \"\"\"\n\u4fee\u5fa9\u9019\u6bb5\u4ee3\u78bc\u7684\u5b89\u5168\u6f0f\u6d1e\uff1a\ndef login(email, password):\n    query = f\"SELECT * FROM users WHERE email = '{email}' AND password = '{password}'\"\n    user = db.execute(query)\n    return user\n\"\"\","

    },

    {

      "file": "workspace/src/core/island_ai_runtime/knowledge_engine.py",

      "line": 322,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "return hashlib.md5(path.encode()).hexdigest()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "    @staticmethod\n    def _generate_id(path: str) -> str:\n        \"\"\"\u751f\u6210\u7bc0\u9ede ID\"\"\"\n        return hashlib.md5(path.encode()).hexdigest()\n"

    },

    {

      "file": "workspace/src/core/virtual_experts/domain_experts.py",

      "line": 505,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "if \"eval(\" in code_lower or \"exec(\" in code_lower:",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "                    }\n                )\n\n        if \"eval(\" in code_lower or \"exec(\" in code_lower:\n            issues.append(\n                {\n                    \"severity\": \"critical\","

    },

    {

      "file": "workspace/src/core/plugins/training_system/example_library.py",

      "line": 381,

      "severity": "high",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "return hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "import hashlib\n\ndef hash_password_weak(password: str) -> str:\n    return hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01\n\n# \u554f\u984c 3\uff1a\u6c92\u6709\u52a0\u9e7d\ndef hash_password_no_salt(password: str) -> str:"

    },

    {

      "file": "workspace/src/core/plugins/training_system/example_library.py",

      "line": 295,

      "severity": "critical",

      "category": "Secrets Management",

      "issue": "Hardcoded password",

      "code": "AND password = '{password}'",

      "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

      "context": "    query = f\\\"\\\"\\\"\n    SELECT * FROM users\n    WHERE username = '{username}'\n    AND password = '{password}'\n    \\\"\\\"\\\"\n    return db.execute(query)\n"

    },

    {

      "file": "workspace/src/core/plugins/training_system/example_library.py",

      "line": 302,

      "severity": "critical",

      "category": "Secrets Management",

      "issue": "Hardcoded password",

      "code": "# \u7d50\u679c: SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'",

      "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

      "context": "# \u653b\u64ca\u8005\u53ef\u4ee5\u7e5e\u904e\u767b\u9304\uff1a\n# username: admin' --\n# password: anything\n# \u7d50\u679c: SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'\n\"\"\",\n            good_code=\"\"\"\n# \u2705 \u4f7f\u7528\u53c3\u6578\u5316\u67e5\u8a62"

    },

    {

      "file": "workspace/src/core/plugins/training_system/knowledge_base.py",

      "line": 424,

      "severity": "high",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "hashed = hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "\n# \u274c \u4f7f\u7528\u5f31\u54c8\u5e0c\nimport hashlib\nhashed = hashlib.md5(password.encode()).hexdigest()  # MD5 \u592a\u5f31\u4e86\uff01\n\"\"\",\n            priority=\"critical\",\n            tags=[\"password\", \"authentication\", \"hashing\"],"

    },

    {

      "file": "workspace/src/core/plugins/training_system/skills_training.py",

      "line": 580,

      "severity": "critical",

      "category": "Secrets Management",

      "issue": "Hardcoded password",

      "code": "query = f\"SELECT * FROM users WHERE email = '{email}' AND password = '{password}'\"",

      "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

      "context": "                    \"question\": \"\"\"\n\u4fee\u5fa9\u9019\u6bb5\u4ee3\u78bc\u7684\u5b89\u5168\u6f0f\u6d1e\uff1a\ndef login(email, password):\n    query = f\"SELECT * FROM users WHERE email = '{email}' AND password = '{password}'\"\n    user = db.execute(query)\n    return user\n\"\"\","

    },

    {

      "file": "workspace/src/core/plugins/virtual_experts/domain_experts.py",

      "line": 500,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "if \"eval(\" in code_lower or \"exec(\" in code_lower:",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "                    }\n                )\n\n        if \"eval(\" in code_lower or \"exec(\" in code_lower:\n            issues.append(\n                {\n                    \"severity\": \"critical\","

    },

    {

      "file": "workspace/src/autonomous/agents/pipeline_service.py",

      "line": 361,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "result = eval(user_input)",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "    test_code = \"\"\"\ndef unsafe_function(user_input):\n    # Security issue: eval\n    result = eval(user_input)\n\n    # Performance issue: nested loops\n    for i in range(100):"

    },

    {

      "file": "workspace/src/autonomous/agents/examples/demo.py",

      "line": 42,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "result = eval(user_input)",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "    problematic_code = \"\"\"\ndef process_user_data(user_input, password):\n    # Security issue: using eval\n    result = eval(user_input)\n\n    # Security issue: hardcoded password\n    db_password = os.getenv(\"DATABASE_PASSWORD\", \"admin123\")"

    },

    {

      "file": "workspace/src/autonomous/agents/test-vectors/generator.py",

      "line": 221,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "\"    result = eval(user_input)\",",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "            \"    # Multiple security issues for comprehensive testing\",\n            \"    \",\n            \"    # Issue 1: Eval injection\",\n            \"    result = eval(user_input)\",\n            \"    \",\n            \"    # Issue 2: Hardcoded credential\",\n            '    db_password = \"PLACEHOLDER_TEST_ONLY\"',"

    },

    {

      "file": "workspace/src/autonomous/agents/agents/task_executor.py",

      "line": 135,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "if \"eval(\" in code or \"exec(\" in code:",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "        issues = []\n\n        # Basic security pattern detection\n        if \"eval(\" in code or \"exec(\" in code:\n            issues.append(\n                {\n                    \"type\": \"security\","

    },

    {

      "file": "workspace/src/autonomous/agents/agents/task_executor.py",

      "line": 234,

      "severity": "medium",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "if \"eval(\" in code or \"exec(\" in code:",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "        fixed_code = code\n\n        if issue[\"type\"] == \"security\":\n            if \"eval(\" in code or \"exec(\" in code:\n                # Remove dangerous code execution\n                fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")\n                fixed_code = fixed_code.replace(\"exec(\", \"# REMOVED_exec(\")"

    },

    {

      "file": "workspace/src/autonomous/agents/agents/task_executor.py",

      "line": 236,

      "severity": "medium",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "        if issue[\"type\"] == \"security\":\n            if \"eval(\" in code or \"exec(\" in code:\n                # Remove dangerous code execution\n                fixed_code = code.replace(\"eval(\", \"# REMOVED_eval(\")\n                fixed_code = fixed_code.replace(\"exec(\", \"# REMOVED_exec(\")\n                logger.info(\"Applied security fix: removed eval/exec\")\n"

    },

    {

      "file": "workspace/src/autonomous/agents/agents/task_executor.py",

      "line": 293,

      "severity": "medium",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "result = eval(user_input)  # Security issue!",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "    # Example: Analyze potentially unsafe code\n    test_code = \"\"\"\ndef process_data(user_input):\n    result = eval(user_input)  # Security issue!\n    password = \"hardcoded123\"   # Security issue!\n\n    for i in range(len(data)):"

    },

    {

      "file": "workspace/src/services/agents/dependency-manager/src/enterprise/security.py",

      "line": 296,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "    def _generate_serial(self) -> str:\n        \"\"\"\u751f\u6210\u5e8f\u5217\u865f\"\"\"\n        timestamp = datetime.now().isoformat()\n        return f\"urn:uuid:{hashlib.md5(timestamp.encode()).hexdigest()}\"\n\n    def _get_spec_version(self, sbom_format: SBOMFormat) -> str:\n        \"\"\"\u53d6\u5f97\u898f\u7bc4\u7248\u672c\"\"\""

    },

    {

      "file": "workspace/src/services/agents/dependency-manager/src/enterprise/security.py",

      "line": 702,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "actual = hashlib.md5(content).hexdigest()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "        elif algorithm == \"sha512\":\n            actual = hashlib.sha512(content).hexdigest()\n        elif algorithm == \"md5\":\n            actual = hashlib.md5(content).hexdigest()\n        else:\n            actual = hashlib.sha256(content).hexdigest()\n"

    },

    {

      "file": "workspace/src/enterprise/execution/secrets.py",

      "line": 32,

      "severity": "critical",

      "category": "Secrets Management",

      "issue": "Hardcoded secret/token",

      "code": "OAUTH_CLIENT_SECRET = \"oauth_client_secret\"",

      "recommendation": "Move to environment variables or secret management system. Never commit secrets to version control.",

      "context": "    PROVIDER_TOKEN = os.getenv(\"PROVIDER_TOKEN\", \"provider_token\")\n    API_KEY = \"api_key\"\n    ENCRYPTION_KEY = \"encryption_key\"\n    OAUTH_CLIENT_SECRET = \"oauth_client_secret\"\n    SIGNING_KEY = \"signing_key\"\n    DATABASE_PASSWORD = os.getenv(\"DATABASE_PASSWORD\", \"database_password\")\n    SERVICE_ACCOUNT = \"service_account\""

    },

    {

      "file": "workspace/src/frontend/ui/services/code_analyzer.py",

      "line": 198,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "return f\"analysis:{hashlib.md5(content.encode()).hexdigest()}\"",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "    def _get_cache_key(self, code: str, file_path: str) -> str:\n        \"\"\"\u751f\u6210\u7de9\u5b58\u9375\"\"\"\n        content = f\"{code}:{file_path}\"\n        return f\"analysis:{hashlib.md5(content.encode()).hexdigest()}\"\n\n    async def analyze(\n        self,"

    },

    {

      "file": "workspace/src/apps/web-backend/services/code_analyzer.py",

      "line": 195,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "return f\"analysis:{hashlib.md5(content.encode()).hexdigest()}\"",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "    def _get_cache_key(self, code: str, file_path: str) -> str:\n        \"\"\"\u751f\u6210\u7de9\u5b58\u9375\"\"\"\n        content = f\"{code}:{file_path}\"\n        return f\"analysis:{hashlib.md5(content.encode()).hexdigest()}\"\n\n    async def analyze(\n        self,"

    },

    {

      "file": "workspace/tools/find_duplicate_scripts.py",

      "line": 75,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "hasher = hashlib.md5()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "\n    def _hash_file(self, file_path: Path) -> str:\n        \"\"\"\u8a08\u7b97\u6587\u4ef6\u7684\u54c8\u5e0c\u503c\"\"\"\n        hasher = hashlib.md5()\n        with open(file_path, \"rb\") as f:\n            hasher.update(f.read())\n        return hasher.hexdigest()"

    },

    {

      "file": "workspace/tools/autonomous_cleanup_toolkit.py",

      "line": 212,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "md5_hash = hashlib.md5(content).hexdigest()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "\n                try:\n                    content = file_path.read_bytes()\n                    md5_hash = hashlib.md5(content).hexdigest()\n                    hash_map[md5_hash].append(\n                        str(file_path.relative_to(self.repo_path))\n                    )"

    },

    {

      "file": "workspace/tools/security_audit.py",

      "line": 6,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "analyzing MD5 usage, eval() usage, and other security concerns.",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "Security Audit Tool\n\nThis script performs a comprehensive security audit of the codebase,\nanalyzing MD5 usage, eval() usage, and other security concerns.\n\"\"\"\n\nimport ast"

    },

    {

      "file": "workspace/tools/security_audit.py",

      "line": 150,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "\"\"\"Check for eval() usage.\"\"\"",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "        return findings\n\n    def check_eval_usage(self, file_path: Path) -> List[SecurityFinding]:\n        \"\"\"Check for eval() usage.\"\"\"\n        findings = []\n\n        try:"

    },

    {

      "file": "workspace/tools/security_audit.py",

      "line": 190,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "issue=\"eval() function usage detected\",",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "                        line_number=line_num,\n                        severity=severity,\n                        category=\"Code Injection\",\n                        issue=\"eval() function usage detected\",\n                        code_snippet=code_snippet,\n                        recommendation=\"Avoid eval() as it can execute arbitrary code. \"\n                        \"Consider using ast.literal_eval() for parsing literals, \""

    },

    {

      "file": "workspace/tools/security_audit.py",

      "line": 192,

      "severity": "high",

      "category": "Code Injection",

      "issue": "eval() function usage detected",

      "code": "recommendation=\"Avoid eval() as it can execute arbitrary code. \"",

      "recommendation": "Avoid eval() as it can execute arbitrary code. Consider using ast.literal_eval() for parsing literals, or implement a proper parser for your use case.",

      "context": "                        category=\"Code Injection\",\n                        issue=\"eval() function usage detected\",\n                        code_snippet=code_snippet,\n                        recommendation=\"Avoid eval() as it can execute arbitrary code. \"\n                        \"Consider using ast.literal_eval() for parsing literals, \"\n                        \"or implement a proper parser for your use case.\",\n                        context=context,"

    },

    {

      "file": "workspace/tools/cleanup_duplicates.py",

      "line": 83,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "empty_init_hash = hashlib.md5(b\"\").hexdigest()  # \u7a7a\u6587\u4ef6\u54c8\u5e0c",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "        \"\"\"\u6e05\u7406\u7a7a\u7684 __init__.py \u6587\u4ef6\u91cd\u8907\"\"\"\n        print(\"\\n3\ufe0f\u20e3  \u6e05\u7406\u7a7a __init__.py \u91cd\u8907...\")\n\n        empty_init_hash = hashlib.md5(b\"\").hexdigest()  # \u7a7a\u6587\u4ef6\u54c8\u5e0c\n        init_files = list(self.repo_root.rglob(\"__init__.py\"))\n\n        # \u6309\u76ee\u9304\u5206\u7d44"

    },

    {

      "file": "workspace/tools/cleanup_duplicates.py",

      "line": 106,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "hasher = hashlib.md5()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "    def _hash_file(self, file_path: Path) -> str:\n        \"\"\"\u8a08\u7b97\u6587\u4ef6\u54c8\u5e0c\"\"\"\n        try:\n            hasher = hashlib.md5()\n            with open(file_path, \"rb\") as f:\n                hasher.update(f.read())\n            return hasher.hexdigest()"

    },

    {

      "file": "workspace/tools/automation/engines/integration_automation_engine.py",

      "line": 153,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "file_hash = hashlib.md5(content).hexdigest()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "        for file in self._target_path.rglob(\"*\"):\n            if file.is_file():\n                content = file.read_bytes()\n                file_hash = hashlib.md5(content).hexdigest()\n                if file_hash in hashes:\n                    duplicates.append((str(file), hashes[file_hash]))\n                else:"

    },

    {

      "file": "workspace/tools/refactor/process_legacy_scratch.py",

      "line": 827,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "file_hash = hashlib.md5(content.encode()).hexdigest()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "        content = filepath.read_text(encoding=\"utf-8\", errors=\"ignore\")\n\n        # \u8a08\u7b97\u54c8\u5e0c\n        file_hash = hashlib.md5(content.encode()).hexdigest()\n\n        # \u8a5e\u5f59\u6383\u63cf\n        print(\"   \u8a5e\u5f59\u6383\u63cf...\")"

    },

    {

      "file": "workspace/tools/quantum-alignment-engine/src/core/transformer.py",

      "line": 139,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "policy_hash = hashlib.md5(b\"axiom-naming-v9\").hexdigest()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "        \"\"\"\n        # In production, load from governance-manifest.yaml\n        # For now, generate deterministic vector from policy hash\n        policy_hash = hashlib.md5(b\"axiom-naming-v9\").hexdigest()\n\n        # Convert hash to vector\n        vector = np.array([int(c, 16) for c in policy_hash], dtype=float)"

    },

    {

      "file": "workspace/tools/quantum-alignment-engine/src/core/transformer.py",

      "line": 225,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "namespace_hash = hashlib.md5(namespace.encode()).hexdigest()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "        Generate 8192-dimensional semantic vector for namespace\n        \"\"\"\n        # Create deterministic vector from namespace string\n        namespace_hash = hashlib.md5(namespace.encode()).hexdigest()\n\n        # Convert to vector\n        vector = np.array([int(c, 16) for c in namespace_hash], dtype=float)"

    },

    {

      "file": "workspace/tools/quantum-alignment-engine/src/core/transformer.py",

      "line": 764,

      "severity": "medium",

      "category": "Cryptographic",

      "issue": "MD5 hash usage detected",

      "code": "text_hash = hashlib.md5(text.encode()).hexdigest()",

      "recommendation": "Replace with SHA256 for security-sensitive operations. MD5 is considered cryptographically broken.",

      "context": "        # In production, use proper embedding model (e.g., sentence-transformers)\n        # For now, generate deterministic vector from hash\n\n        text_hash = hashlib.md5(text.encode()).hexdigest()\n        vector = np.array([int(c, 16) for c in text_hash], dtype=float)\n\n        # Expand to 8192 dimensions"

    }

  ]

}