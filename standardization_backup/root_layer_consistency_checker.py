#!/usr/bin/env python3
"""
Root Layer Consistency Checker - æ£€æµ‹å’Œæ ‡å‡†åŒ–å‘½åã€æ ‡è®°ã€æ³¨é‡Šçš„ä¸€è‡´æ€§
"""
import os
import re
from pathlib import Path
from typing import Dict, List, Set, Any
import json
from collections import defaultdict

class RootLayerConsistencyChecker:
    """Root Layer ä¸€è‡´æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self, root_dir: str = "."):
        self.root_dir = Path(root_dir)
        self.issues = {
            'naming_inconsistencies': [],
            'comment_inconsistencies': [],
            'marker_inconsistencies': [],
            'documentation_gaps': [],
            'formatting_issues': []
        }
        self.statistics = {
            'total_files_scanned': 0,
            'files_with_issues': 0,
            'total_issues_found': 0
        }
        self._visited_files = set()
    
    def scan_directory(self) -> None:
        """æ‰«æç›®å½•"""
        print("ğŸ” å¼€å§‹æ‰«æ Root Layer...")
        
        # æ‰«æ Python æ–‡ä»¶
        python_files = list(self.root_dir.rglob("*.py"))
        # æ‰«æ Markdown æ–‡ä»¶
        md_files = list(self.root_dir.rglob("*.md"))
        # æ‰«æé…ç½®æ–‡ä»¶
        config_files = list(self.root_dir.rglob("*.yaml")) + list(self.root_dir.rglob("*.yml")) + list(self.root_dir.rglob("*.json"))
        # æ‰«æ Shell è„šæœ¬
        shell_files = list(self.root_dir.rglob("*.sh"))
        
        all_files = python_files + md_files + config_files + shell_files
        
        print(f"ğŸ“ æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶å¾…æ£€æŸ¥")
        
        for file_path in all_files:
            self.check_file_consistency(file_path)
        
        self.statistics['total_files_scanned'] = len(all_files)
        self.statistics['files_with_issues'] = len(set(
            issue['file'] for category in self.issues.values() 
            for issue in category
        ))
        self.statistics['total_issues_found'] = sum(len(issues) for issues in self.issues.values())
    
    def check_file_consistency(self, file_path: Path) -> None:
        """æ£€æŸ¥å•ä¸ªæ–‡ä»¶çš„ä¸€è‡´æ€§"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            file_ext = file_path.suffix.lower()
            
            if file_ext == '.py':
                self.check_python_consistency(file_path, content)
            elif file_ext == '.md':
                self.check_markdown_consistency(file_path, content)
            elif file_ext in ['.yaml', '.yml', '.json']:
                self.check_config_consistency(file_path, content)
            elif file_ext == '.sh':
                self.check_shell_consistency(file_path, content)
                
        except Exception as e:
            print(f"âš ï¸  æ£€æŸ¥æ–‡ä»¶æ—¶å‡ºé”™ {file_path}: {e}")
    
    def check_python_consistency(self, file_path: Path, content: str) -> None:
        """æ£€æŸ¥ Python æ–‡ä»¶ä¸€è‡´æ€§"""
        lines = content.split('\n')
        
        # æ£€æŸ¥å‘½åçº¦å®š
        self.check_naming_conventions(file_path, lines)
        
        # æ£€æŸ¥æ³¨é‡Šé£æ ¼
        self.check_comment_style(file_path, lines)
        
        # æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²
        self.check_docstrings(file_path, content)
        
        # æ£€æŸ¥æ ‡è®°å’Œ TODO
        self.check_markers(file_path, lines)
    
    def check_naming_conventions(self, file_path: Path, lines: List[str]) -> None:
        """æ£€æŸ¥å‘½åçº¦å®š"""
        filename = file_path.name
        
        # æ–‡ä»¶å‘½åçº¦å®š
        if filename.lower().startswith('test_') or filename.lower().endswith('_test.py'):
            # æµ‹è¯•æ–‡ä»¶ - åº”è¯¥ç”¨ snake_case
            if re.search(r'[A-Z]', filename) and not filename.replace('.py', '').isupper():
                self.issues['naming_inconsistencies'].append({
                    'file': str(file_path),
                    'type': 'filename',
                    'severity': 'low',
                    'issue': 'æµ‹è¯•æ–‡ä»¶ååº”ä½¿ç”¨ snake_case',
                    'current': filename,
                    'suggested': re.sub(r'(?<!^)(?=[A-Z])', '_', filename).lower()
                })
        
        # æ£€æŸ¥å‡½æ•°å‘½å
        for i, line in enumerate(lines, 1):
            # å‡½æ•°å®šä¹‰
            func_match = re.match(r'\s*def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\(', line)
            if func_match:
                func_name = func_match.group(1)
                
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ PEP 8 å‘½å
                if re.search(r'[A-Z]', func_name) and not func_name.isupper():
                    self.issues['naming_inconsistencies'].append({
                        'file': str(file_path),
                        'line': i,
                        'type': 'function_name',
                        'severity': 'medium',
                        'issue': 'å‡½æ•°ååº”ä½¿ç”¨ snake_case',
                        'current': func_name,
                        'suggested': re.sub(r'(?<!^)(?=[A-Z])', '_', func_name).lower()
                    })
            
            # ç±»å®šä¹‰
            class_match = re.match(r'\s*class\s+([A-Z][a-zA-Z0-9_]*)\s*:', line)
            if class_match:
                class_name = class_match.group(1)
                
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ CapWords
                if '_' in class_name:
                    self.issues['naming_inconsistencies'].append({
                        'file': str(file_path),
                        'line': i,
                        'type': 'class_name',
                        'severity': 'medium',
                        'issue': 'ç±»ååº”ä½¿ç”¨ CapWords (PascalCase)',
                        'current': class_name,
                        'suggested': ''.join(word.capitalize() for word in class_name.split('_'))
                    })
            
            # å¸¸é‡å®šä¹‰ï¼ˆå…¨å¤§å†™ï¼‰
            const_match = re.match(r'\s*([A-Z_][A-Z0-9_]*)\s*=', line)
            if const_match and not const_match.group(1).isupper():
                const_name = const_match.group(1)
                self.issues['naming_inconsistencies'].append({
                    'file': str(file_path),
                    'line': i,
                    'type': 'constant_name',
                    'severity': 'low',
                    'issue': 'å¸¸é‡åº”ä½¿ç”¨ UPPER_CASE_WITH_UNDERSCORES',
                    'current': const_name,
                    'suggested': const_name.upper()
                })
    
    def check_comment_style(self, file_path: Path, lines: List[str]) -> None:
        """æ£€æŸ¥æ³¨é‡Šé£æ ¼ä¸€è‡´æ€§"""
        comment_styles = []
        
        for i, line in enumerate(lines, 1):
            stripped = line.strip()
            
            # æ£€æŸ¥æ³¨é‡Š
            if stripped.startswith('#'):
                comment = stripped[1:].strip()
                
                # æ£€æŸ¥æ³¨é‡Šé£æ ¼æ˜¯å¦ä¸€è‡´
                if comment and not comment.startswith(' ') and not comment.startswith('#'):
                    # æœ‰äº›æœ‰ç©ºæ ¼ï¼Œæœ‰äº›æ²¡æœ‰
                    pass
                
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ä¸åŒçš„æ ‡è®°è¯­è¨€
                if re.search(r'[\u4e00-\u9fff]', comment):
                    comment_styles.append('chinese')
                elif re.search(r'[a-zA-Z]', comment):
                    comment_styles.append('english')
        
        # æ£€æŸ¥æ³¨é‡Šè¯­è¨€æ··åˆ
        if len(set(comment_styles)) > 1:
            self.issues['comment_inconsistencies'].append({
                'file': str(file_path),
                'type': 'language_mixing',
                'severity': 'low',
                'issue': 'æ–‡ä»¶ä¸­æ··ç”¨äº†ä¸­æ–‡å’Œè‹±æ–‡æ³¨é‡Š',
                'styles_found': set(comment_styles),
                'suggestion': 'ç»Ÿä¸€ä½¿ç”¨ä¸€ç§è¯­è¨€è¿›è¡Œæ³¨é‡Š'
            })
    
    def check_docstrings(self, file_path: Path, content: str) -> None:
        """æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²"""
        if 'def ' not in content:
            return
        
        lines = content.split('\n')
        in_docstring = False
        docstring_start = 0
        
        for i, line in enumerate(lines, 1):
            if '"""' in line or "'''" in line:
                if not in_docstring:
                    in_docstring = True
                    docstring_start = i
                else:
                    in_docstring = False
                    
                    # æ£€æŸ¥å‡½æ•°/ç±»æ˜¯å¦æœ‰æ–‡æ¡£å­—ç¬¦ä¸²
                    if i - docstring_start > 0:
                        # æ£€æŸ¥æ˜¯å¦æœ‰å‡½æ•°å®šä¹‰åœ¨æ–‡æ¡£å­—ç¬¦ä¸²ä¹‹å‰
                        for j in range(max(0, docstring_start - 5), docstring_start):
                            if re.search(r'\s*(def|class)\s+', lines[j]):
                                # è¿™æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ–‡æ¡£å­—ç¬¦ä¸²
                                # æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²é£æ ¼
                                docstring_content = '\n'.join(lines[docstring_start:i])
                                self.check_docstring_style(file_path, docstring_start, docstring_content)
                                break
    
    def check_docstring_style(self, file_path: Path, line_num: int, docstring: str) -> None:
        """æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²é£æ ¼"""
        # æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²æ˜¯å¦ä½¿ç”¨äº†ä¸åŒçš„æ ¼å¼
        has_google_style = bool(re.search(r'Args?:|Returns?:|Raises?:', docstring))
        has_sphinx_style = bool(re.search(r':param|:type|:return:', docstring))
        has_numpy_style = bool(re.search(r'Parameters\n----------|Returns\n-------', docstring))
        
        styles = []
        if has_google_style:
            styles.append('Google')
        if has_sphinx_style:
            styles.append('Sphinx')
        if has_numpy_style:
            styles.append('NumPy')
        
        # å¦‚æœæ²¡æœ‰ç»Ÿä¸€çš„é£æ ¼ï¼Œæ ‡è®°ä¸ºä¸ä¸€è‡´
        if len(styles) > 1:
            self.issues['comment_inconsistencies'].append({
                'file': str(file_path),
                'line': line_num,
                'type': 'docstring_style',
                'severity': 'low',
                'issue': 'æ–‡æ¡£å­—ç¬¦ä¸²æ··ç”¨äº†å¤šç§é£æ ¼',
                'styles_found': styles,
                'suggestion': 'ç»Ÿä¸€ä½¿ç”¨ä¸€ç§æ–‡æ¡£å­—ç¬¦ä¸²é£æ ¼ï¼ˆæ¨è Google é£æ ¼ï¼‰'
            })
        
        # å¦‚æœå®Œå…¨æ²¡æœ‰æ ¼å¼ï¼Œæ ‡è®°ä¸ºéœ€è¦æ”¹è¿›
        if len(styles) == 0 and len(docstring) > 50:
            self.issues['documentation_gaps'].append({
                'file': str(file_path),
                'line': line_num,
                'type': 'docstring_formatting',
                'severity': 'low',
                'issue': 'æ–‡æ¡£å­—ç¬¦ä¸²ç¼ºå°‘æ ‡å‡†æ ¼å¼',
                'current': docstring[:100] + '...',
                'suggestion': 'ä½¿ç”¨ Google æˆ– Sphinx é£æ ¼æ ¼å¼åŒ–æ–‡æ¡£å­—ç¬¦ä¸²'
            })
    
    def check_markers(self, file_path: Path, lines: List[str]) -> None:
        """æ£€æŸ¥æ ‡è®°å’Œ TODO"""
        todo_patterns = [
            r'# TODO[:\s]',
            r'# FIXME[:\s]',
            r'# HACK[:\s]',
            r'# NOTE[:\s]',
            r'# WARNING[:\s]',
            r'# SECURITY[:\s]',
            r'# XXX[:\s]'
        ]
        
        markers_found = set()
        
        for i, line in enumerate(lines, 1):
            for pattern in todo_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    marker_type = pattern.split(r'[:\s]')[0].replace('#', '').upper()
                    markers_found.add(marker_type)
        
        # æ£€æŸ¥æ ‡è®°æ ¼å¼çš„ä¸€è‡´æ€§
        if markers_found:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ä¸åŒçš„æ ‡è®°æ ¼å¼
            marker_formats = []
            for marker in markers_found:
                if marker in ['TODO', 'FIXME', 'HACK', 'NOTE']:
                    marker_formats.append('standard')
                elif marker in ['WARNING', 'SECURITY']:
                    marker_formats.append('important')
                elif marker == 'XXX':
                    marker_formats.append('deprecated')
            
            if len(set(marker_formats)) > 1:
                self.issues['marker_inconsistencies'].append({
                    'file': str(file_path),
                    'type': 'marker_format',
                    'severity': 'low',
                    'issue': 'ä½¿ç”¨äº†å¤šç§ä¸åŒç±»å‹çš„æ ‡è®°',
                    'markers_found': list(markers_found),
                    'suggestion': 'ç»Ÿä¸€æ ‡è®°æ ¼å¼ï¼Œä¼˜å…ˆä½¿ç”¨æ ‡å‡†æ ‡è®°ï¼ˆTODO, FIXME, NOTEï¼‰'
                })
    
    def check_markdown_consistency(self, file_path: Path, content: str) -> None:
        """æ£€æŸ¥ Markdown æ–‡ä»¶ä¸€è‡´æ€§"""
        lines = content.split('\n')
        
        # æ£€æŸ¥æ ‡é¢˜ä¸€è‡´æ€§
        heading_levels = []
        for i, line in enumerate(lines, 1):
            if line.strip().startswith('#'):
                # è®¡ç®—æ ‡é¢˜çº§åˆ«
                level = len(line) - len(line.lstrip('#'))
                heading_levels.append((i, level, line.strip()))
        
        # æ£€æŸ¥æ ‡é¢˜çº§åˆ«è·³è·ƒ
        for i in range(len(heading_levels) - 1):
            current_line, current_level, current_text = heading_levels[i]
            next_line, next_level, next_text = heading_levels[i + 1]
            
            if next_level - current_level > 1:
                self.issues['formatting_issues'].append({
                    'file': str(file_path),
                    'line': next_line,
                    'type': 'heading_skip',
                    'severity': 'low',
                    'issue': f'æ ‡é¢˜çº§åˆ«ä» {current_level} è·³åˆ° {next_level}',
                    'current': next_text,
                    'suggestion': f'åº”è¯¥ä½¿ç”¨ {current_level + 1} çº§æ ‡é¢˜'
                })
    
    def check_config_consistency(self, file_path: Path, content: str) -> None:
        """æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸€è‡´æ€§"""
        lines = content.split('\n')
        
        # æ£€æŸ¥ç¼©è¿›ä¸€è‡´æ€§
        indent_sizes = set()
        for line in lines:
            if line.strip() and not line.strip().startswith('#'):
                # è®¡ç®—ç¼©è¿›
                indent = len(line) - len(line.lstrip())
                if indent > 0:
                    indent_sizes.add(indent)
        
        if len(indent_sizes) > 1:
            self.issues['formatting_issues'].append({
                'file': str(file_path),
                'type': 'indentation',
                'severity': 'medium',
                'issue': 'ç¼©è¿›ä¸ä¸€è‡´',
                'indent_sizes': list(indent_sizes),
                'suggestion': 'ç»Ÿä¸€ç¼©è¿›å¤§å°ï¼ˆæ¨è 2 ç©ºæ ¼æˆ– 4 ç©ºæ ¼ï¼‰'
            })
    
    def check_shell_consistency(self, file_path: Path, content: str) -> None:
        """æ£€æŸ¥ Shell è„šæœ¬ä¸€è‡´æ€§"""
        lines = content.split('\n')
        
        # æ£€æŸ¥æ³¨é‡Šé£æ ¼
        comment_styles = []
        for i, line in enumerate(lines, 1):
            stripped = line.strip()
            if stripped.startswith('#'):
                comment = stripped[1:].strip()
                
                if re.search(r'[\u4e00-\u9fff]', comment):
                    comment_styles.append('chinese')
                elif re.search(r'[a-zA-Z]', comment):
                    comment_styles.append('english')
        
        if len(set(comment_styles)) > 1:
            self.issues['comment_inconsistencies'].append({
                'file': str(file_path),
                'type': 'language_mixing',
                'severity': 'low',
                'issue': 'Shell è„šæœ¬ä¸­æ··ç”¨äº†ä¸­æ–‡å’Œè‹±æ–‡æ³¨é‡Š',
                'styles_found': set(comment_styles),
                'suggestion': 'ç»Ÿä¸€ä½¿ç”¨ä¸€ç§è¯­è¨€è¿›è¡Œæ³¨é‡Š'
            })
    
    def _convert_to_serializable(self, obj):
        """å°†å¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼"""
        if isinstance(obj, set):
            return list(obj)
        elif isinstance(obj, Path):
            return str(obj)
        elif isinstance(obj, dict):
            return {k: self._convert_to_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_to_serializable(item) for item in obj]
        else:
            return obj
    
    def generate_report(self) -> Dict[str, Any]:
        """ç”ŸæˆæŠ¥å‘Š"""
        return {
            'statistics': self.statistics,
            'issues': self._convert_to_serializable(self.issues),
            'summary': self._convert_to_serializable(self._generate_summary())
        }
    
    def _generate_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ‘˜è¦"""
        total_issues = self.statistics['total_issues_found']
        
        severity_counts = defaultdict(int)
        for category in self.issues.values():
            for issue in category:
                severity_counts[issue.get('severity', 'low')] += 1
        
        return {
            'total_files': self.statistics['total_files_scanned'],
            'files_with_issues': self.statistics['files_with_issues'],
            'total_issues': total_issues,
            'issues_by_severity': dict(severity_counts),
            'issues_by_category': {
                category: len(issues)
                for category, issues in self.issues.items()
            }
        }

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("Root Layer ä¸€è‡´æ€§æ£€æŸ¥å·¥å…·")
    print("=" * 60)
    
    # åˆ›å»ºæ£€æŸ¥å™¨
    checker = RootLayerConsistencyChecker()
    
    # æ‰«æç›®å½•
    checker.scan_directory()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = checker.generate_report()
    
    # ä¿å­˜æŠ¥å‘Š
    with open('root_layer_consistency_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°æ‘˜è¦
    print(f"\nğŸ“Š æ£€æŸ¥æ‘˜è¦:")
    print(f"   æ‰«ææ–‡ä»¶æ•°: {report['summary']['total_files']}")
    print(f"   æœ‰é—®é¢˜çš„æ–‡ä»¶: {report['summary']['files_with_issues']}")
    print(f"   æ€»é—®é¢˜æ•°: {report['summary']['total_issues']}")
    
    print(f"\nğŸ“‹ é—®é¢˜æŒ‰ç±»åˆ«ç»Ÿè®¡:")
    for category, count in report['summary']['issues_by_category'].items():
        print(f"   {category}: {count}")
    
    print(f"\nâš ï¸  é—®é¢˜æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡:")
    for severity, count in report['summary']['issues_by_severity'].items():
        print(f"   {severity.upper()}: {count}")
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: root_layer_consistency_report.json")
    
    return report

if __name__ == "__main__":
    report = main()