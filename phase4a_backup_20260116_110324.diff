diff --git a/00-namespaces/namespaces-mcp/level1/validation/tests/test_extended_validator.py b/00-namespaces/namespaces-mcp/level1/validation/tests/test_extended_validator.py
index b750d21..cf1f812 100644
--- a/00-namespaces/namespaces-mcp/level1/validation/tests/test_extended_validator.py
+++ b/00-namespaces/namespaces-mcp/level1/validation/tests/test_extended_validator.py
@@ -489,9 +489,11 @@ class TestExtendedMCPValidator:
     def test_performance_metrics_collection(self):
         """Test that performance metrics are collected"""
         # Mock the artifact loading
-        with patch("builtins.open", create=True), patch(
-            "yaml.safe_load"
-        ) as mock_yaml, patch("pathlib.Path.exists") as mock_exists:
+        with (
+            patch("builtins.open", create=True),
+            patch("yaml.safe_load") as mock_yaml,
+            patch("pathlib.Path.exists") as mock_exists,
+        ):
 
             mock_exists.return_value = True
             mock_yaml.return_value = self.test_artifact
@@ -554,11 +556,12 @@ class TestIntegration:
         }
 
         # Mock file operations and endpoint validation
-        with patch("builtins.open", create=True), patch(
-            "yaml.safe_load"
-        ) as mock_yaml, patch("pathlib.Path.exists") as mock_exists, patch(
-            "requests.get"
-        ) as mock_get:
+        with (
+            patch("builtins.open", create=True),
+            patch("yaml.safe_load") as mock_yaml,
+            patch("pathlib.Path.exists") as mock_exists,
+            patch("requests.get") as mock_get,
+        ):
 
             mock_exists.return_value = True
             mock_yaml.return_value = complex_artifact
diff --git a/code_quality_issues.json b/code_quality_issues.json
index 5781c83..05f2282 100644
--- a/code_quality_issues.json
+++ b/code_quality_issues.json
@@ -1,11 +1,11 @@
 {
   "summary": {
-    "files_analyzed": 1149,
-    "lines_analyzed": 376574,
-    "total_issues": 959,
+    "files_analyzed": 1151,
+    "lines_analyzed": 377189,
+    "total_issues": 966,
     "high_severity": 0,
     "medium_severity": 0,
-    "low_severity": 871
+    "low_severity": 872
   },
   "issues": [
     {
@@ -6912,6 +6912,62 @@
       "solution": "Reorder imports to follow PEP 8",
       "fixed_code": null
     },
+    {
+      "severity": "ä½",
+      "location": "/workspace/machine-native-ops/workspace/tools/security_audit.py:9",
+      "issue_type": "ä»£ç¢¼é¢¨æ ¼",
+      "description": "Import order: Standard library imports should come before third party imports",
+      "solution": "Reorder imports to follow PEP 8",
+      "fixed_code": null
+    },
+    {
+      "severity": "é«˜å±",
+      "location": "/workspace/machine-native-ops/workspace/tools/security_audit.py:6",
+      "issue_type": "å®‰å…¨æ¼æ´",
+      "description": "é«˜å±ï¼šä½¿ç”¨ eval() å¯èƒ½å°è‡´ä»£ç¢¼æ³¨å…¥æ¼æ´",
+      "solution": "ä½¿ç”¨æ›´å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ",
+      "fixed_code": null
+    },
+    {
+      "severity": "é«˜å±",
+      "location": "/workspace/machine-native-ops/workspace/tools/security_audit.py:120",
+      "issue_type": "å®‰å…¨æ¼æ´",
+      "description": "é«˜å±ï¼šä½¿ç”¨ eval() å¯èƒ½å°è‡´ä»£ç¢¼æ³¨å…¥æ¼æ´",
+      "solution": "ä½¿ç”¨æ›´å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ",
+      "fixed_code": null
+    },
+    {
+      "severity": "é«˜å±",
+      "location": "/workspace/machine-native-ops/workspace/tools/security_audit.py:128",
+      "issue_type": "å®‰å…¨æ¼æ´",
+      "description": "é«˜å±ï¼šä½¿ç”¨ eval() å¯èƒ½å°è‡´ä»£ç¢¼æ³¨å…¥æ¼æ´",
+      "solution": "ä½¿ç”¨æ›´å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ",
+      "fixed_code": null
+    },
+    {
+      "severity": "é«˜å±",
+      "location": "/workspace/machine-native-ops/workspace/tools/security_audit.py:157",
+      "issue_type": "å®‰å…¨æ¼æ´",
+      "description": "é«˜å±ï¼šä½¿ç”¨ eval() å¯èƒ½å°è‡´ä»£ç¢¼æ³¨å…¥æ¼æ´",
+      "solution": "ä½¿ç”¨æ›´å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ",
+      "fixed_code": null
+    },
+    {
+      "severity": "é«˜å±",
+      "location": "/workspace/machine-native-ops/workspace/tools/security_audit.py:159",
+      "issue_type": "å®‰å…¨æ¼æ´",
+      "description": "é«˜å±ï¼šä½¿ç”¨ eval() å¯èƒ½å°è‡´ä»£ç¢¼æ³¨å…¥æ¼æ´",
+      "solution": "ä½¿ç”¨æ›´å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ",
+      "fixed_code": null
+    },
+    {
+      "severity": "é«˜å±",
+      "location": "/workspace/machine-native-ops/workspace/tools/security_audit.py:160",
+      "issue_type": "å®‰å…¨æ¼æ´",
+      "description": "é«˜å±ï¼šä½¿ç”¨ eval() å¯èƒ½å°è‡´ä»£ç¢¼æ³¨å…¥æ¼æ´",
+      "solution": "ä½¿ç”¨æ›´å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ",
+      "fixed_code": null
+    },
     {
       "severity": "ä½",
       "location": "/workspace/machine-native-ops/workspace/tools/ai-auto-fix.py:21",
diff --git a/fix_remaining_issues.py b/fix_remaining_issues.py
index b4c90b9..779b0b8 100755
--- a/fix_remaining_issues.py
+++ b/fix_remaining_issues.py
@@ -14,7 +14,7 @@ import re
 import subprocess
 import sys
 from pathlib import Path
-from typing import List, Tuple, Set
+from typing import List, Set, Tuple
 
 
 class DeepCodeQualityFixer:
@@ -28,10 +28,10 @@ class DeepCodeQualityFixer:
         """Fix import order using isort."""
         try:
             result = subprocess.run(
-                ['isort', '--force-single-line-imports', str(file_path)],
+                ["isort", "--force-single-line-imports", str(file_path)],
                 capture_output=True,
                 text=True,
-                timeout=10
+                timeout=10,
             )
             return result.returncode == 0
         except Exception as e:
@@ -40,26 +40,34 @@ class DeepCodeQualityFixer:
     def fix_hardcoded_urls(self, file_path: Path) -> bool:
         """Replace hardcoded URLs with configuration variables."""
         try:
-            with open(file_path, 'r', encoding='utf-8') as f:
+            with open(file_path, "r", encoding="utf-8") as f:
                 content = f.read()
 
             # Common hardcoded URL patterns to fix
             replacements = [
                 # GitHub URLs
-                (r'https://github\.com/MachineNativeOps/machine-native-ops\.git', 
-                 'os.getenv("GITHUB_REPO_URL", "https://github.com/MachineNativeOps/machine-native-ops.git")'),
-                (r'https://api\.github\.com', 
-                 'os.getenv("GITHUB_API_URL", "https://api.github.com")'),
-                
+                (
+                    r"https://github\.com/MachineNativeOps/machine-native-ops\.git",
+                    'os.getenv("GITHUB_REPO_URL", "https://github.com/MachineNativeOps/machine-native-ops.git")',
+                ),
+                (
+                    r"https://api\.github\.com",
+                    'os.getenv("GITHUB_API_URL", "https://api.github.com")',
+                ),
                 # Localhost URLs
-                (r'http://localhost:8080', 
-                 'os.getenv("LOCAL_API_URL", "http://localhost:8080")'),
-                (r'http://localhost:\d+', 
-                 'os.getenv("LOCAL_SERVICE_URL", "http://localhost:8080")'),
-                
+                (
+                    r"http://localhost:8080",
+                    'os.getenv("LOCAL_API_URL", "http://localhost:8080")',
+                ),
+                (
+                    r"http://localhost:\d+",
+                    'os.getenv("LOCAL_SERVICE_URL", "http://localhost:8080")',
+                ),
                 # Common API endpoints
-                (r'https://api\.openai\.com/v1', 
-                 'os.getenv("OPENAI_API_ENDPOINT", "https://api.openai.com/v1")'),
+                (
+                    r"https://api\.openai\.com/v1",
+                    'os.getenv("OPENAI_API_ENDPOINT", "https://api.openai.com/v1")',
+                ),
             ]
 
             modified = False
@@ -71,24 +79,26 @@ class DeepCodeQualityFixer:
 
             if modified:
                 # Add os import if needed
-                if 'import os' not in content:
+                if "import os" not in content:
                     # Find first import line and add os before it
-                    lines = content.split('\n')
+                    lines = content.split("\n")
                     import_idx = -1
                     for i, line in enumerate(lines):
-                        if line.strip().startswith('import ') or line.strip().startswith('from '):
+                        if line.strip().startswith(
+                            "import "
+                        ) or line.strip().startswith("from "):
                             import_idx = i
                             break
-                    
+
                     if import_idx >= 0:
-                        lines.insert(import_idx, 'import os')
-                        content = '\n'.join(lines)
+                        lines.insert(import_idx, "import os")
+                        content = "\n".join(lines)
                         modified = True
 
-                with open(file_path, 'w', encoding='utf-8') as f:
+                with open(file_path, "w", encoding="utf-8") as f:
                     f.write(content)
                 return True
-            
+
             return False
         except Exception as e:
             return False
@@ -96,7 +106,7 @@ class DeepCodeQualityFixer:
     def add_missing_docstrings(self, file_path: Path) -> bool:
         """Add missing docstrings to modules and classes."""
         try:
-            with open(file_path, 'r', encoding='utf-8') as f:
+            with open(file_path, "r", encoding="utf-8") as f:
                 content = f.read()
 
             # Parse the file
@@ -106,20 +116,21 @@ class DeepCodeQualityFixer:
                 return False
 
             modified = False
-            lines = content.split('\n')
+            lines = content.split("\n")
 
             # Check for missing module docstring
-            if (len(tree.body) > 0 and 
-                not isinstance(tree.body[0], (ast.Expr, ast.Str, ast.Constant))):
+            if len(tree.body) > 0 and not isinstance(
+                tree.body[0], (ast.Expr, ast.Str, ast.Constant)
+            ):
                 # No docstring at module level
-                file_name = file_path.stem.replace('_', ' ').title()
+                file_name = file_path.stem.replace("_", " ").title()
                 docstring = f'"""\n{file_name}\n\nTODO: Add module docstring.\n"""\n'
                 lines.insert(0, docstring)
                 modified = True
 
             if modified:
-                with open(file_path, 'w', encoding='utf-8') as f:
-                    f.write('\n'.join(lines))
+                with open(file_path, "w", encoding="utf-8") as f:
+                    f.write("\n".join(lines))
                 return True
 
             return False
@@ -129,16 +140,16 @@ class DeepCodeQualityFixer:
     def fix_md5_usage(self, file_path: Path) -> bool:
         """Replace MD5 with SHA256 for security."""
         try:
-            with open(file_path, 'r', encoding='utf-8') as f:
+            with open(file_path, "r", encoding="utf-8") as f:
                 content = f.read()
 
-            if 'hashlib.md5' not in content:
+            if "hashlib.md5" not in content:
                 return False
 
             # Replace md5 with sha256
             replacements = [
-                (r'hashlib\.md5\(', 'hashlib.sha256('),
-                (r'\.md5\(\)', '.sha256()'),
+                (r"hashlib\.md5\(", "hashlib.sha256("),
+                (r"\.md5\(\)", ".sha256()"),
             ]
 
             modified = False
@@ -149,7 +160,7 @@ class DeepCodeQualityFixer:
                     modified = True
 
             if modified:
-                with open(file_path, 'w', encoding='utf-8') as f:
+                with open(file_path, "w", encoding="utf-8") as f:
                     f.write(content)
                 return True
 
@@ -160,33 +171,33 @@ class DeepCodeQualityFixer:
     def fix_eval_usage(self, file_path: Path) -> bool:
         """Replace unsafe eval() with safer alternatives."""
         try:
-            with open(file_path, 'r', encoding='utf-8') as f:
+            with open(file_path, "r", encoding="utf-8") as f:
                 content = f.read()
 
-            if 'eval(' not in content:
+            if "eval(" not in content:
                 return False
 
             # Note: eval() replacement is complex and context-dependent
             # This is a basic implementation - manual review recommended
             # We'll add a warning comment instead of automatic replacement
-            
-            if 'eval(' in content:
+
+            if "eval(" in content:
                 # Add security warning comment
-                warning = '# TODO: Security - Consider replacing eval() with safer alternatives like ast.literal_eval()\n'
-                lines = content.split('\n')
-                
+                warning = "# TODO: Security - Consider replacing eval() with safer alternatives like ast.literal_eval()\n"
+                lines = content.split("\n")
+
                 # Find eval() lines and add warning
                 modified_lines = []
                 for line in lines:
-                    if 'eval(' in line and '# TODO: Security' not in line:
+                    if "eval(" in line and "# TODO: Security" not in line:
                         # Insert warning before the line
                         indent = len(line) - len(line.lstrip())
-                        modified_lines.append(' ' * indent + warning.rstrip())
+                        modified_lines.append(" " * indent + warning.rstrip())
                     modified_lines.append(line)
-                
-                new_content = '\n'.join(modified_lines)
+
+                new_content = "\n".join(modified_lines)
                 if new_content != content:
-                    with open(file_path, 'w', encoding='utf-8') as f:
+                    with open(file_path, "w", encoding="utf-8") as f:
                         f.write(new_content)
                     return True
 
@@ -197,42 +208,42 @@ class DeepCodeQualityFixer:
     def process_file(self, file_path: Path) -> dict:
         """Process a single file and apply all applicable fixes."""
         results = {
-            'file': str(file_path),
-            'import_order_fixed': False,
-            'hardcoded_urls_fixed': False,
-            'docstrings_added': False,
-            'md5_fixed': False,
-            'eval_fixed': False,
-            'total_fixes': 0
+            "file": str(file_path),
+            "import_order_fixed": False,
+            "hardcoded_urls_fixed": False,
+            "docstrings_added": False,
+            "md5_fixed": False,
+            "eval_fixed": False,
+            "total_fixes": 0,
         }
 
         try:
             # Fix import order
             if self.fix_import_order(file_path):
-                results['import_order_fixed'] = True
-                results['total_fixes'] += 1
+                results["import_order_fixed"] = True
+                results["total_fixes"] += 1
 
             # Fix hardcoded URLs
             if self.fix_hardcoded_urls(file_path):
-                results['hardcoded_urls_fixed'] = True
-                results['total_fixes'] += 1
+                results["hardcoded_urls_fixed"] = True
+                results["total_fixes"] += 1
 
             # Add missing docstrings
             if self.add_missing_docstrings(file_path):
-                results['docstrings_added'] = True
-                results['total_fixes'] += 1
+                results["docstrings_added"] = True
+                results["total_fixes"] += 1
 
             # Fix MD5 usage
             if self.fix_md5_usage(file_path):
-                results['md5_fixed'] = True
-                results['total_fixes'] += 1
+                results["md5_fixed"] = True
+                results["total_fixes"] += 1
 
             # Fix eval() usage
             if self.fix_eval_usage(file_path):
-                results['eval_fixed'] = True
-                results['total_fixes'] += 1
+                results["eval_fixed"] = True
+                results["total_fixes"] += 1
 
-            if results['total_fixes'] > 0:
+            if results["total_fixes"] > 0:
                 self.fixed_files.append(file_path)
 
         except Exception as e:
@@ -243,19 +254,21 @@ class DeepCodeQualityFixer:
     def get_files_with_issues(self, issue_file: Path) -> List[Path]:
         """Get list of files with issues from the analysis report."""
         import json
-        
+
         try:
-            with open(issue_file, 'r') as f:
+            with open(issue_file, "r") as f:
                 data = json.load(f)
 
             files_with_issues = set()
-            for issue in data.get('issues', []):
-                location = issue.get('location', '')
-                if ':' in location:
-                    file_path = location.split(':')[0]
+            for issue in data.get("issues", []):
+                location = issue.get("location", "")
+                if ":" in location:
+                    file_path = location.split(":")[0]
                     # Remove /workspace/machine-native-ops prefix if present
-                    if file_path.startswith('/workspace/machine-native-ops/'):
-                        file_path = file_path.replace('/workspace/machine-native-ops/', '')
+                    if file_path.startswith("/workspace/machine-native-ops/"):
+                        file_path = file_path.replace(
+                            "/workspace/machine-native-ops/", ""
+                        )
                     files_with_issues.add(Path(file_path))
 
             return [self.project_root / f for f in files_with_issues]
@@ -265,7 +278,7 @@ class DeepCodeQualityFixer:
 
     def fix_all(self, limit: int = None) -> dict:
         """Fix all files with issues."""
-        issue_file = self.project_root / 'code_quality_issues.json'
+        issue_file = self.project_root / "code_quality_issues.json"
         files_to_fix = self.get_files_with_issues(issue_file)
 
         if limit:
@@ -276,43 +289,45 @@ class DeepCodeQualityFixer:
         print("=" * 60)
 
         summary = {
-            'total_files': total_files,
-            'import_order_fixed': 0,
-            'hardcoded_urls_fixed': 0,
-            'docstrings_added': 0,
-            'md5_fixed': 0,
-            'eval_fixed': 0,
-            'total_fixes': 0,
-            'errors': 0
+            "total_files": total_files,
+            "import_order_fixed": 0,
+            "hardcoded_urls_fixed": 0,
+            "docstrings_added": 0,
+            "md5_fixed": 0,
+            "eval_fixed": 0,
+            "total_fixes": 0,
+            "errors": 0,
         }
 
         for i, file_path in enumerate(files_to_fix, 1):
-            print(f"\n[{i}/{total_files}] Processing: {file_path.relative_to(self.project_root)}")
+            print(
+                f"\n[{i}/{total_files}] Processing: {file_path.relative_to(self.project_root)}"
+            )
 
             try:
                 results = self.process_file(file_path)
 
                 # Update summary
-                if results['import_order_fixed']:
-                    summary['import_order_fixed'] += 1
+                if results["import_order_fixed"]:
+                    summary["import_order_fixed"] += 1
                     print("  âœ… Import order fixed")
-                if results['hardcoded_urls_fixed']:
-                    summary['hardcoded_urls_fixed'] += 1
+                if results["hardcoded_urls_fixed"]:
+                    summary["hardcoded_urls_fixed"] += 1
                     print("  âœ… Hardcoded URLs fixed")
-                if results['docstrings_added']:
-                    summary['docstrings_added'] += 1
+                if results["docstrings_added"]:
+                    summary["docstrings_added"] += 1
                     print("  âœ… Docstrings added")
-                if results['md5_fixed']:
-                    summary['md5_fixed'] += 1
+                if results["md5_fixed"]:
+                    summary["md5_fixed"] += 1
                     print("  âœ… MD5 replaced with SHA256")
-                if results['eval_fixed']:
-                    summary['eval_fixed'] += 1
+                if results["eval_fixed"]:
+                    summary["eval_fixed"] += 1
                     print("  âš ï¸  eval() usage marked for review")
 
-                summary['total_fixes'] += results['total_fixes']
+                summary["total_fixes"] += results["total_fixes"]
 
             except Exception as e:
-                summary['errors'] += 1
+                summary["errors"] += 1
                 print(f"  âŒ Error: {e}")
 
         return summary
@@ -322,8 +337,10 @@ def main():
     import argparse
 
     parser = argparse.ArgumentParser(description="Deep code quality fixes")
-    parser.add_argument('--limit', type=int, help='Limit number of files to fix')
-    parser.add_argument('--test', action='store_true', help='Test mode with limited files')
+    parser.add_argument("--limit", type=int, help="Limit number of files to fix")
+    parser.add_argument(
+        "--test", action="store_true", help="Test mode with limited files"
+    )
 
     args = parser.parse_args()
 
@@ -346,7 +363,7 @@ def main():
     print(f"Errors encountered: {summary['errors']}")
     print("=" * 60)
 
-    if summary['total_fixes'] > 0:
+    if summary["total_fixes"] > 0:
         print("\nâœ… Fixes applied successfully!")
         print("ğŸ’¡ Run 'git diff' to review changes before committing")
     else:
@@ -354,4 +371,4 @@ def main():
 
 
 if __name__ == "__main__":
-    main()
\ No newline at end of file
+    main()
diff --git a/workspace/archive/legacy/v1-python-drones/drones/autopilot_drone.py b/workspace/archive/legacy/v1-python-drones/drones/autopilot_drone.py
index cae220c..dd120e1 100644
--- a/workspace/archive/legacy/v1-python-drones/drones/autopilot_drone.py
+++ b/workspace/archive/legacy/v1-python-drones/drones/autopilot_drone.py
@@ -108,8 +108,12 @@ class AutopilotDrone(BaseDrone):
     def _check_tool(self, tool: str) -> dict[str, Any]:
         """æª¢æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨"""
         try:
-            result = subprocess.run([tool, "--version"], capture_output=True, text=True, timeout=5)
-            version = result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+            result = subprocess.run(
+                [tool, "--version"], capture_output=True, text=True, timeout=5
+            )
+            version = (
+                result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+            )
             return {
                 "tool": tool,
                 "status": "ok" if result.returncode == 0 else "error",
@@ -133,7 +137,9 @@ class AutopilotDrone(BaseDrone):
             print(f"  {icon} {check['tool']}: {version}")
 
         print()
-        self.log_info(f"è¨ºæ–·çµæœ: {diagnosis['passed']} é€šé, {diagnosis['failed']} å¤±æ•—")
+        self.log_info(
+            f"è¨ºæ–·çµæœ: {diagnosis['passed']} é€šé, {diagnosis['failed']} å¤±æ•—"
+        )
 
     def queue_task(self, task_name: str, options: dict | None = None) -> None:
         """
@@ -255,7 +261,9 @@ class AutopilotDrone(BaseDrone):
         self.log_info(f"åŸ·è¡Œæ ¸å¿ƒè‡ªå‹•é§•é§›: {core_script}")
 
         try:
-            result = subprocess.run(["node", str(core_script), "diagnose"], cwd=self.project_root)
+            result = subprocess.run(
+                ["node", str(core_script), "diagnose"], cwd=self.project_root
+            )
             return result.returncode
         except Exception as e:
             self.log_error(f"åŸ·è¡Œå¤±æ•—: {e}")
diff --git a/workspace/archive/legacy/v1-python-drones/drones/base_drone.py b/workspace/archive/legacy/v1-python-drones/drones/base_drone.py
index fb48e4d..69558f3 100644
--- a/workspace/archive/legacy/v1-python-drones/drones/base_drone.py
+++ b/workspace/archive/legacy/v1-python-drones/drones/base_drone.py
@@ -172,4 +172,6 @@ class BaseDrone(ABC):
         }
 
     def __repr__(self) -> str:
-        return f"<{self.__class__.__name__}(name='{self.name}', status='{self.status}')>"
+        return (
+            f"<{self.__class__.__name__}(name='{self.name}', status='{self.status}')>"
+        )
diff --git a/workspace/archive/legacy/v1-python-drones/drones/coordinator_drone.py b/workspace/archive/legacy/v1-python-drones/drones/coordinator_drone.py
index 9984149..7855de2 100644
--- a/workspace/archive/legacy/v1-python-drones/drones/coordinator_drone.py
+++ b/workspace/archive/legacy/v1-python-drones/drones/coordinator_drone.py
@@ -87,14 +87,22 @@ class CoordinatorDrone(BaseDrone):
                 analysis["tools"][tool] = {
                     "installed": result.returncode == 0,
                     "version": (
-                        result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+                        result.stdout.strip().split("\n")[0]
+                        if result.returncode == 0
+                        else None
                     ),
                 }
             except (FileNotFoundError, subprocess.TimeoutExpired):
                 analysis["tools"][tool] = {"installed": False, "version": None}
 
         # æª¢æŸ¥å°ˆæ¡ˆçµæ§‹
-        required_dirs = ["config/dev", ".vscode", "v1-python-drones", "shared", "migration"]
+        required_dirs = [
+            "config/dev",
+            ".vscode",
+            "v1-python-drones",
+            "shared",
+            "migration",
+        ]
         for dir_name in required_dirs:
             dir_path = self.project_root / dir_name
             analysis["structure"][dir_name] = dir_path.exists()
@@ -189,7 +197,9 @@ class CoordinatorDrone(BaseDrone):
         Returns:
             åŸ·è¡Œçµæœä»£ç¢¼
         """
-        core_script = self.project_root / "config/dev" / "automation" / "drone-coordinator.py"
+        core_script = (
+            self.project_root / "config/dev" / "automation" / "drone-coordinator.py"
+        )
 
         if not core_script.exists():
             self.log_error(f"æ ¸å¿ƒå”èª¿å™¨è…³æœ¬ä¸å­˜åœ¨: {core_script}")
diff --git a/workspace/archive/legacy/v1-python-drones/drones/deployment_drone.py b/workspace/archive/legacy/v1-python-drones/drones/deployment_drone.py
index fdac3e5..8fb9d1a 100644
--- a/workspace/archive/legacy/v1-python-drones/drones/deployment_drone.py
+++ b/workspace/archive/legacy/v1-python-drones/drones/deployment_drone.py
@@ -121,10 +121,14 @@ class DeploymentDrone(BaseDrone):
         # æª¢æŸ¥ Docker Compose
         try:
             # å˜—è©¦æ–°ç‰ˆ docker compose
-            result = subprocess.run(["docker", "compose", "version"], capture_output=True)
+            result = subprocess.run(
+                ["docker", "compose", "version"], capture_output=True
+            )
             if result.returncode != 0:
                 # å˜—è©¦èˆŠç‰ˆ docker-compose
-                subprocess.run(["docker-compose", "--version"], capture_output=True, check=True)
+                subprocess.run(
+                    ["docker-compose", "--version"], capture_output=True, check=True
+                )
             self.log_success("  Docker Compose âœ“")
         except (FileNotFoundError, subprocess.CalledProcessError):
             self.log_error("  Docker Compose æœªå®‰è£")
@@ -143,7 +147,9 @@ class DeploymentDrone(BaseDrone):
         self.log_info(f"ğŸ”§ æº–å‚™éƒ¨ç½²ç’°å¢ƒ: {self.deploy_env}")
 
         # è¼‰å…¥ç’°å¢ƒé…ç½®
-        env_file = self.project_root / "config/dev" / "environments" / f"{self.deploy_env}.env"
+        env_file = (
+            self.project_root / "config/dev" / "environments" / f"{self.deploy_env}.env"
+        )
 
         if env_file.exists():
             self.log_info(f"  è¼‰å…¥ç’°å¢ƒé…ç½®: {env_file}")
@@ -200,7 +206,9 @@ class DeploymentDrone(BaseDrone):
             )
         except subprocess.TimeoutExpired:
             self.log_warn("  å®‰è£è¶…æ™‚ï¼Œå˜—è©¦ npm install")
-            subprocess.run(["npm", "install"], cwd=self.project_root, capture_output=True)
+            subprocess.run(
+                ["npm", "install"], cwd=self.project_root, capture_output=True
+            )
         except Exception:
             pass
 
@@ -252,12 +260,16 @@ class DeploymentDrone(BaseDrone):
         """åŸ·è¡Œ docker compose å‘½ä»¤"""
         try:
             # å˜—è©¦æ–°ç‰ˆ docker compose
-            result = subprocess.run(["docker", "compose"] + args, cwd=cwd, capture_output=True)
+            result = subprocess.run(
+                ["docker", "compose"] + args, cwd=cwd, capture_output=True
+            )
             if result.returncode == 0:
                 return True
 
             # å˜—è©¦èˆŠç‰ˆ docker-compose
-            result = subprocess.run(["docker-compose"] + args, cwd=cwd, capture_output=True)
+            result = subprocess.run(
+                ["docker-compose"] + args, cwd=cwd, capture_output=True
+            )
             return result.returncode == 0
         except Exception:
             return False
@@ -294,7 +306,9 @@ class DeploymentDrone(BaseDrone):
                 pass
 
             if i < self.health_check_retries:
-                self.log_warn(f"  éƒ¨åˆ†æœå‹™å°šæœªå°±ç·’ï¼Œç­‰å¾… {self.health_check_interval}s...")
+                self.log_warn(
+                    f"  éƒ¨åˆ†æœå‹™å°šæœªå°±ç·’ï¼Œç­‰å¾… {self.health_check_interval}s..."
+                )
                 import time
 
                 time.sleep(self.health_check_interval)
@@ -329,7 +343,9 @@ class DeploymentDrone(BaseDrone):
         Returns:
             åŸ·è¡Œçµæœä»£ç¢¼
         """
-        core_script = self.project_root / "config/dev" / "automation" / "deployment-drone.sh"
+        core_script = (
+            self.project_root / "config/dev" / "automation" / "deployment-drone.sh"
+        )
 
         if not core_script.exists():
             self.log_error(f"æ ¸å¿ƒéƒ¨ç½²è…³æœ¬ä¸å­˜åœ¨: {core_script}")
@@ -338,7 +354,9 @@ class DeploymentDrone(BaseDrone):
         self.log_info(f"åŸ·è¡Œæ ¸å¿ƒéƒ¨ç½²è…³æœ¬: {core_script}")
 
         try:
-            result = subprocess.run(["bash", str(core_script), "status"], cwd=self.project_root)
+            result = subprocess.run(
+                ["bash", str(core_script), "status"], cwd=self.project_root
+            )
             return result.returncode
         except Exception as e:
             self.log_error(f"åŸ·è¡Œå¤±æ•—: {e}")
diff --git a/workspace/archive/legacy/v1-python-drones/main.py b/workspace/archive/legacy/v1-python-drones/main.py
index 32234d5..297cb66 100644
--- a/workspace/archive/legacy/v1-python-drones/main.py
+++ b/workspace/archive/legacy/v1-python-drones/main.py
@@ -5,12 +5,13 @@ SynergyMesh v1-python-drones ä¸»åŸ·è¡Œå…¥å£
 Python ç„¡äººæ©Ÿç³»çµ±çš„ä¸»è¦å…¥å£é»ï¼Œæä¾›å‘½ä»¤è¡Œä»‹é¢ã€‚
 """
 
-from utils import Colors, print_error, print_info, print_success
-from drones import AutopilotDrone, CoordinatorDrone, DeploymentDrone
 import argparse
 import sys
 from pathlib import Path
 
+from drones import AutopilotDrone, CoordinatorDrone, DeploymentDrone
+from utils import Colors, print_error, print_info, print_success
+
 # ç¢ºä¿å¯ä»¥å°å…¥æœ¬åœ°æ¨¡çµ„
 _current_dir = Path(__file__).resolve().parent
 sys.path.insert(0, str(_current_dir))
diff --git a/workspace/archive/legacy/v1-python-drones/utils/__init__.py b/workspace/archive/legacy/v1-python-drones/utils/__init__.py
index 3ad15ed..f7ea016 100644
--- a/workspace/archive/legacy/v1-python-drones/utils/__init__.py
+++ b/workspace/archive/legacy/v1-python-drones/utils/__init__.py
@@ -2,7 +2,14 @@
 å·¥å…·æ¨¡çµ„
 """
 
-from .helpers import Colors, print_color, print_error, print_info, print_success, print_warn
+from .helpers import (
+    Colors,
+    print_color,
+    print_error,
+    print_info,
+    print_success,
+    print_warn,
+)
 
 __all__ = [
     "Colors",
diff --git a/workspace/archive/legacy/v2-multi-islands/bridges/language_bridge.py b/workspace/archive/legacy/v2-multi-islands/bridges/language_bridge.py
index 0f2cc7b..7b88320 100644
--- a/workspace/archive/legacy/v2-multi-islands/bridges/language_bridge.py
+++ b/workspace/archive/legacy/v2-multi-islands/bridges/language_bridge.py
@@ -55,7 +55,10 @@ class LanguageBridge:
         return self._project_root
 
     def establish_bridge(
-        self, source_island: str, target_island: str, protocol: str = BridgeProtocol.REST
+        self,
+        source_island: str,
+        target_island: str,
+        protocol: str = BridgeProtocol.REST,
     ) -> bool:
         """
         å»ºç«‹å³¶å¶¼é–“æ©‹æ¥
@@ -83,7 +86,9 @@ class LanguageBridge:
         print(f"[Bridge][SUCCESS] æ©‹æ¥å·²å»ºç«‹: {bridge_id}")
         return True
 
-    def send_message(self, bridge_id: str, message: dict[str, Any]) -> dict[str, Any] | None:
+    def send_message(
+        self, bridge_id: str, message: dict[str, Any]
+    ) -> dict[str, Any] | None:
         """
         é€éæ©‹æ¥ç™¼é€è¨Šæ¯
 
diff --git a/workspace/archive/legacy/v2-multi-islands/config/island_config.py b/workspace/archive/legacy/v2-multi-islands/config/island_config.py
index 28a5f82..a2851a2 100644
--- a/workspace/archive/legacy/v2-multi-islands/config/island_config.py
+++ b/workspace/archive/legacy/v2-multi-islands/config/island_config.py
@@ -82,25 +82,41 @@ class IslandConfig:
                     "name": "Rust æ€§èƒ½æ ¸å¿ƒå³¶",
                     "enabled": True,
                     "priority": 1,
-                    "capabilities": ["performance_monitor", "security_guardian", "data_pipeline"],
+                    "capabilities": [
+                        "performance_monitor",
+                        "security_guardian",
+                        "data_pipeline",
+                    ],
                 },
                 "go": {
                     "name": "Go é›²åŸç”Ÿæœå‹™å³¶",
                     "enabled": True,
                     "priority": 2,
-                    "capabilities": ["api_gateway", "microservice_mesh", "container_manager"],
+                    "capabilities": [
+                        "api_gateway",
+                        "microservice_mesh",
+                        "container_manager",
+                    ],
                 },
                 "typescript": {
                     "name": "TypeScript å…¨æ£§é–‹ç™¼å³¶",
                     "enabled": True,
                     "priority": 3,
-                    "capabilities": ["web_dashboard", "api_client_generator", "real_time_monitor"],
+                    "capabilities": [
+                        "web_dashboard",
+                        "api_client_generator",
+                        "real_time_monitor",
+                    ],
                 },
                 "python": {
                     "name": "Python AI æ•¸æ“šå³¶",
                     "enabled": True,
                     "priority": 4,
-                    "capabilities": ["ai_code_assistant", "data_analysis", "ml_pipeline"],
+                    "capabilities": [
+                        "ai_code_assistant",
+                        "data_analysis",
+                        "ml_pipeline",
+                    ],
                 },
                 "java": {
                     "name": "Java ä¼æ¥­æœå‹™å³¶",
@@ -160,5 +176,7 @@ class IslandConfig:
     def get_enabled_islands(self) -> list[str]:
         """å–å¾—æ‰€æœ‰å•Ÿç”¨çš„å³¶å¶¼"""
         return [
-            island_id for island_id, config in self.islands.items() if config.get("enabled", True)
+            island_id
+            for island_id, config in self.islands.items()
+            if config.get("enabled", True)
         ]
diff --git a/workspace/archive/legacy/v2-multi-islands/islands/base_island.py b/workspace/archive/legacy/v2-multi-islands/islands/base_island.py
index 1c8aeb0..a535680 100644
--- a/workspace/archive/legacy/v2-multi-islands/islands/base_island.py
+++ b/workspace/archive/legacy/v2-multi-islands/islands/base_island.py
@@ -120,7 +120,9 @@ class BaseIsland(ABC):
         """
         cmd, arg = self._get_language_check_command()
         try:
-            result = subprocess.run([cmd, arg], capture_output=True, text=True, timeout=5)
+            result = subprocess.run(
+                [cmd, arg], capture_output=True, text=True, timeout=5
+            )
             if result.returncode == 0:
                 version = result.stdout.strip().split("\n")[0]
                 return True, version
@@ -181,7 +183,9 @@ class BaseIsland(ABC):
             "island_id": self.island_id,
             "language": self.language,
             "status": self.status,
-            "activated_at": self.activated_at.isoformat() if self.activated_at else None,
+            "activated_at": (
+                self.activated_at.isoformat() if self.activated_at else None
+            ),
             "capabilities": self.capabilities,
             "tool_available": available,
             "tool_version": version,
@@ -189,4 +193,6 @@ class BaseIsland(ABC):
         }
 
     def __repr__(self) -> str:
-        return f"<{self.__class__.__name__}(name='{self.name}', status='{self.status}')>"
+        return (
+            f"<{self.__class__.__name__}(name='{self.name}', status='{self.status}')>"
+        )
diff --git a/workspace/archive/legacy/v2-multi-islands/islands/java_island.py b/workspace/archive/legacy/v2-multi-islands/islands/java_island.py
index 8fd1c73..6246b6a 100644
--- a/workspace/archive/legacy/v2-multi-islands/islands/java_island.py
+++ b/workspace/archive/legacy/v2-multi-islands/islands/java_island.py
@@ -100,7 +100,11 @@ class JavaIsland(BaseIsland):
         for tool_name, cmd in tool_commands:
             try:
                 result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
-                version = result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+                version = (
+                    result.stdout.strip().split("\n")[0]
+                    if result.returncode == 0
+                    else None
+                )
                 tools[tool_name] = {
                     "available": result.returncode == 0,
                     "version": version,
diff --git a/workspace/archive/legacy/v2-multi-islands/islands/python_island.py b/workspace/archive/legacy/v2-multi-islands/islands/python_island.py
index 40c84da..10f7d95 100644
--- a/workspace/archive/legacy/v2-multi-islands/islands/python_island.py
+++ b/workspace/archive/legacy/v2-multi-islands/islands/python_island.py
@@ -30,7 +30,9 @@ class PythonIsland(BaseIsland):
     """
 
     def __init__(self) -> None:
-        super().__init__(name="ğŸ Python AI æ•¸æ“šå³¶", island_id="python", language="python")
+        super().__init__(
+            name="ğŸ Python AI æ•¸æ“šå³¶", island_id="python", language="python"
+        )
         self.capabilities = [
             "ai_code_assistant",
             "data_analysis",
@@ -148,7 +150,9 @@ class PythonIsland(BaseIsland):
         self.log_info("åŸ·è¡Œ v1-python-drones ç³»çµ±...")
 
         try:
-            result = subprocess.run(["python3", str(v1_main), "--mode=auto"], cwd=self.project_root)
+            result = subprocess.run(
+                ["python3", str(v1_main), "--mode=auto"], cwd=self.project_root
+            )
             return result.returncode
         except Exception as e:
             self.log_error(f"åŸ·è¡Œå¤±æ•—: {e}")
diff --git a/workspace/archive/legacy/v2-multi-islands/islands/typescript_island.py b/workspace/archive/legacy/v2-multi-islands/islands/typescript_island.py
index fa9f8c8..e9b36ad 100644
--- a/workspace/archive/legacy/v2-multi-islands/islands/typescript_island.py
+++ b/workspace/archive/legacy/v2-multi-islands/islands/typescript_island.py
@@ -30,7 +30,9 @@ class TypeScriptIsland(BaseIsland):
 
     def __init__(self) -> None:
         super().__init__(
-            name="âš¡ TypeScript å…¨æ£§é–‹ç™¼å³¶", island_id="typescript", language="typescript"
+            name="âš¡ TypeScript å…¨æ£§é–‹ç™¼å³¶",
+            island_id="typescript",
+            language="typescript",
         )
         self.capabilities = [
             "web_dashboard",
@@ -89,7 +91,9 @@ class TypeScriptIsland(BaseIsland):
     def _check_node(self) -> bool:
         """æª¢æŸ¥ Node.js"""
         try:
-            result = subprocess.run(["node", "--version"], capture_output=True, timeout=5)
+            result = subprocess.run(
+                ["node", "--version"], capture_output=True, timeout=5
+            )
             return result.returncode == 0
         except (FileNotFoundError, subprocess.TimeoutExpired):
             return False
@@ -111,7 +115,9 @@ class TypeScriptIsland(BaseIsland):
                 tools[tool_name] = {
                     "available": result.returncode == 0,
                     "version": (
-                        result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+                        result.stdout.strip().split("\n")[0]
+                        if result.returncode == 0
+                        else None
                     ),
                 }
             except (FileNotFoundError, subprocess.TimeoutExpired):
@@ -141,5 +147,9 @@ class TypeScriptIsland(BaseIsland):
             print(f"    {status} {tool}: {version}")
 
         print("\n  å°ˆæ¡ˆ:")
-        print(f"    package.json: {'âœ…' if result['project_info']['has_package_json'] else 'âŒ'}")
-        print(f"    tsconfig.json: {'âœ…' if result['project_info']['has_tsconfig'] else 'âŒ'}")
+        print(
+            f"    package.json: {'âœ…' if result['project_info']['has_package_json'] else 'âŒ'}"
+        )
+        print(
+            f"    tsconfig.json: {'âœ…' if result['project_info']['has_tsconfig'] else 'âŒ'}"
+        )
diff --git a/workspace/archive/legacy/v2-multi-islands/main.py b/workspace/archive/legacy/v2-multi-islands/main.py
index be705fd..3e2528c 100644
--- a/workspace/archive/legacy/v2-multi-islands/main.py
+++ b/workspace/archive/legacy/v2-multi-islands/main.py
@@ -5,13 +5,14 @@ SynergyMesh v2-multi-islands ä¸»åŸ·è¡Œå…¥å£
 å¤šèªè¨€è‡ªå‹•åŒ–ç„¡äººä¹‹å³¶ç³»çµ±çš„ä¸»è¦å…¥å£é»ï¼Œæä¾›å‘½ä»¤è¡Œä»‹é¢ã€‚
 """
 
-from utils import Colors, print_error, print_info, print_success
-from orchestrator import IslandOrchestrator
-from islands import GoIsland, JavaIsland, PythonIsland, RustIsland, TypeScriptIsland
 import argparse
 import sys
 from pathlib import Path
 
+from islands import GoIsland, JavaIsland, PythonIsland, RustIsland, TypeScriptIsland
+from orchestrator import IslandOrchestrator
+from utils import Colors, print_error, print_info, print_success
+
 # ç¢ºä¿å¯ä»¥å°å…¥æœ¬åœ°æ¨¡çµ„
 _current_dir = Path(__file__).resolve().parent
 sys.path.insert(0, str(_current_dir))
diff --git a/workspace/archive/legacy/v2-multi-islands/orchestrator/island_orchestrator.py b/workspace/archive/legacy/v2-multi-islands/orchestrator/island_orchestrator.py
index b3a17ab..a9ffbaf 100644
--- a/workspace/archive/legacy/v2-multi-islands/orchestrator/island_orchestrator.py
+++ b/workspace/archive/legacy/v2-multi-islands/orchestrator/island_orchestrator.py
@@ -6,13 +6,14 @@ SynergyMesh å³¶å¶¼å”èª¿å™¨ (Island Orchestrator)
 å°æ‡‰ config/dev/automation/drone-coordinator.py
 """
 
-from utils import print_error, print_info, print_success
 import subprocess
 import sys
 from datetime import datetime
 from pathlib import Path
 from typing import Any
 
+from utils import print_error, print_info, print_success
+
 _current_dir = Path(__file__).resolve().parent
 sys.path.insert(0, str(_current_dir.parent))
 
@@ -197,11 +198,15 @@ class IslandOrchestrator:
 
         for lang, (cmd, arg) in language_tools.items():
             try:
-                result = subprocess.run([cmd, arg], capture_output=True, text=True, timeout=5)
+                result = subprocess.run(
+                    [cmd, arg], capture_output=True, text=True, timeout=5
+                )
                 analysis["tools"][lang] = {
                     "installed": result.returncode == 0,
                     "version": (
-                        result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+                        result.stdout.strip().split("\n")[0]
+                        if result.returncode == 0
+                        else None
                     ),
                 }
             except (FileNotFoundError, subprocess.TimeoutExpired):
diff --git a/workspace/archive/legacy/v2-multi-islands/utils/__init__.py b/workspace/archive/legacy/v2-multi-islands/utils/__init__.py
index 3ad15ed..f7ea016 100644
--- a/workspace/archive/legacy/v2-multi-islands/utils/__init__.py
+++ b/workspace/archive/legacy/v2-multi-islands/utils/__init__.py
@@ -2,7 +2,14 @@
 å·¥å…·æ¨¡çµ„
 """
 
-from .helpers import Colors, print_color, print_error, print_info, print_success, print_warn
+from .helpers import (
+    Colors,
+    print_color,
+    print_error,
+    print_info,
+    print_success,
+    print_warn,
+)
 
 __all__ = [
     "Colors",
diff --git a/workspace/chat_app.py b/workspace/chat_app.py
index 23b9e50..1f18bc3 100644
--- a/workspace/chat_app.py
+++ b/workspace/chat_app.py
@@ -2,9 +2,7 @@ from typing import Dict, List
 
 from guardrails_client import chat_completion, client_available, get_api_key
 
-SYSTEM_PROMPT = (
-    "You are an AI assistant who can chat with users about the project and its codebase."
-)
+SYSTEM_PROMPT = "You are an AI assistant who can chat with users about the project and its codebase."
 
 
 def initial_messages() -> List[Dict[str, str]]:
@@ -42,9 +40,13 @@ def run_chat() -> None:
     configured_key = get_api_key()
     if not client_available():
         if not configured_key:
-            print("AI client not configured. Set AI_INTEGRATIONS_OPENAI_API_KEY or OPENAI_API_KEY.")
+            print(
+                "AI client not configured. Set AI_INTEGRATIONS_OPENAI_API_KEY or OPENAI_API_KEY."
+            )
         else:
-            print("AI client dependencies missing. Please install guardrails or openai packages.")
+            print(
+                "AI client dependencies missing. Please install guardrails or openai packages."
+            )
         return
 
     messages = initial_messages()
diff --git a/workspace/code_assistant.py b/workspace/code_assistant.py
index 9448b9d..7057c1f 100644
--- a/workspace/code_assistant.py
+++ b/workspace/code_assistant.py
@@ -95,7 +95,10 @@ tools = [
                         "type": "string",
                         "description": "The file path to write (relative to workspace)",
                     },
-                    "content": {"type": "string", "description": "The content to write"},
+                    "content": {
+                        "type": "string",
+                        "description": "The content to write",
+                    },
                 },
                 "required": ["file_path", "content"],
             },
@@ -108,7 +111,9 @@ tools = [
             "description": "Run a safe shell command (limited to: ls, cat, head, tail, wc, find, tree)",
             "parameters": {
                 "type": "object",
-                "properties": {"command": {"type": "string", "description": "The command to run"}},
+                "properties": {
+                    "command": {"type": "string", "description": "The command to run"}
+                },
                 "required": ["command"],
             },
         },
@@ -213,7 +218,12 @@ def run_command(command: str) -> str:
         return f"Command not allowed. Only these are permitted: {allowed}"
     try:
         result = subprocess.run(
-            cmd_parts, shell=False, capture_output=True, text=True, cwd=WORKSPACE, timeout=10
+            cmd_parts,
+            shell=False,
+            capture_output=True,
+            text=True,
+            cwd=WORKSPACE,
+            timeout=10,
         )
         output = result.stdout or result.stderr
         return output[:3000] if output else "Command executed (no output)"
@@ -290,7 +300,9 @@ When using tools, explain what you're doing and summarize the results clearly.""
         messages.append({"role": "user", "content": user_input})
 
         try:
-            response = chat_completion(model="gpt-4o-mini", messages=messages, tools=tools)
+            response = chat_completion(
+                model="gpt-4o-mini", messages=messages, tools=tools
+            )
 
             assistant_message = response.choices[0].message
 
@@ -306,10 +318,16 @@ When using tools, explain what you're doing and summarize the results clearly.""
                     result = execute_tool(tool_name, tool_args)
 
                     messages.append(
-                        {"role": "tool", "tool_call_id": tool_call.id, "content": result}
+                        {
+                            "role": "tool",
+                            "tool_call_id": tool_call.id,
+                            "content": result,
+                        }
                     )
 
-                response = chat_completion(model="gpt-4o-mini", messages=messages, tools=tools)
+                response = chat_completion(
+                    model="gpt-4o-mini", messages=messages, tools=tools
+                )
                 assistant_message = response.choices[0].message
 
             final_content = assistant_message.content
diff --git a/workspace/config/dev/automation/drone-coordinator.py b/workspace/config/dev/automation/drone-coordinator.py
index 053be8b..71cc886 100755
--- a/workspace/config/dev/automation/drone-coordinator.py
+++ b/workspace/config/dev/automation/drone-coordinator.py
@@ -125,7 +125,9 @@ class DroneCoordinator:
                 analysis["tools"][tool] = {
                     "installed": result.returncode == 0,
                     "version": (
-                        result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+                        result.stdout.strip().split("\n")[0]
+                        if result.returncode == 0
+                        else None
                     ),
                 }
             except (FileNotFoundError, subprocess.TimeoutExpired):
@@ -191,7 +193,9 @@ class DroneCoordinator:
         print_info("ğŸš€ è‡ªå‹•å•Ÿå‹•ç„¡äººæ©Ÿ...")
 
         # æŒ‰å„ªå…ˆç´šæ’åº
-        sorted_drones = sorted(self.drones.items(), key=lambda x: x[1].get("priority", 99))
+        sorted_drones = sorted(
+            self.drones.items(), key=lambda x: x[1].get("priority", 99)
+        )
 
         for drone_id, drone in sorted_drones:
             if drone.get("auto_start"):
@@ -295,7 +299,8 @@ class DroneCoordinator:
 def main() -> int:
     """ä¸»ç¨‹å¼é€²å…¥é»"""
     parser = argparse.ArgumentParser(
-        description="SynergyMesh ç„¡äººæ©Ÿå”èª¿å™¨", formatter_class=argparse.RawDescriptionHelpFormatter
+        description="SynergyMesh ç„¡äººæ©Ÿå”èª¿å™¨",
+        formatter_class=argparse.RawDescriptionHelpFormatter,
     )
 
     parser.add_argument(
diff --git a/workspace/config/dev/validation-system/scripts/adaptive_decision_engine.py b/workspace/config/dev/validation-system/scripts/adaptive_decision_engine.py
index 20db776..12e20bb 100644
--- a/workspace/config/dev/validation-system/scripts/adaptive_decision_engine.py
+++ b/workspace/config/dev/validation-system/scripts/adaptive_decision_engine.py
@@ -138,7 +138,9 @@ class DynamicPolicyController:
             ),
         }
 
-    def adjust_parameters(self, noise_level: float, coherence_time: float) -> DynamicParameters:
+    def adjust_parameters(
+        self, noise_level: float, coherence_time: float
+    ) -> DynamicParameters:
         """
         æ ¹æ“šé‡å­ç‹€æ…‹èª¿æ•´åƒæ•¸
 
@@ -176,7 +178,9 @@ class DynamicPolicyController:
         return self.presets["standard_v3"]
 
     def activate_emergency_mode(
-        self, strategy: str = "classic_aggressive", quantum_preset: str = "lightweight_v2"
+        self,
+        strategy: str = "classic_aggressive",
+        quantum_preset: str = "lightweight_v2",
     ):
         """å•Ÿç”¨ç·Šæ€¥æ¨¡å¼"""
         self.emergency_mode = True
@@ -204,12 +208,17 @@ class FusionEngine:
             # ç°¡åŒ–çš„è²è‘‰æ–¯èåˆ
             prior = 0.5
             likelihood = classic_score * quantum_score
-            return (likelihood * prior) / ((likelihood * prior) + ((1 - likelihood) * (1 - prior)))
+            return (likelihood * prior) / (
+                (likelihood * prior) + ((1 - likelihood) * (1 - prior))
+            )
         else:
             # é›†æˆæŠ•ç¥¨
             threshold = 0.6
             votes = sum(
-                [1 if classic_score > threshold else 0, 1 if quantum_score > threshold else 0]
+                [
+                    1 if classic_score > threshold else 0,
+                    1 if quantum_score > threshold else 0,
+                ]
             )
             return 1.0 if votes >= 1 else 0.0
 
@@ -272,13 +281,20 @@ class FusionEngine:
             quantum_score = quantum_dict.get(dim_name, 0.99)
 
             hybrid_score = self.fuse_scores(
-                classic_score, quantum_score, params.classic_weight, params.quantum_weight
+                classic_score,
+                quantum_score,
+                params.classic_weight,
+                params.quantum_weight,
             )
 
             status = (
                 ValidationStatus.PASS
                 if hybrid_score > 0.9
-                else ValidationStatus.WARNING if hybrid_score > 0.7 else ValidationStatus.FAIL
+                else (
+                    ValidationStatus.WARNING
+                    if hybrid_score > 0.7
+                    else ValidationStatus.FAIL
+                )
             )
 
             dimensions.append(
@@ -299,7 +315,9 @@ class FusionEngine:
         overall_status = (
             ValidationStatus.PASS
             if total_score > 0.9
-            else ValidationStatus.WARNING if total_score > 0.7 else ValidationStatus.FAIL
+            else (
+                ValidationStatus.WARNING if total_score > 0.7 else ValidationStatus.FAIL
+            )
         )
 
         return HybridDecision(
@@ -380,7 +398,9 @@ class AdaptiveDecisionEngine:
         return {
             "validation_report": {
                 "document": document_path,
-                "timestamp": datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
+                "timestamp": datetime.now(timezone.utc)
+                .isoformat()
+                .replace("+00:00", "Z"),
                 "overall_status": decision.overall_status.value,
                 "confidence": round(decision.confidence, 4),
                 "verification_matrix": [
@@ -437,7 +457,9 @@ def main():
     """ä¸»å‡½æ•¸"""
     import argparse
 
-    parser = argparse.ArgumentParser(description="è‡ªé©æ‡‰æ±ºç­–å¼•æ“ - MachineNativeOps é©—è­‰ç³»çµ±")
+    parser = argparse.ArgumentParser(
+        description="è‡ªé©æ‡‰æ±ºç­–å¼•æ“ - MachineNativeOps é©—è­‰ç³»çµ±"
+    )
     parser.add_argument("--demo", action="store_true", help="é‹è¡Œæ¼”ç¤ºæ¨¡å¼")
     parser.add_argument("--output", default=None, help="è¼¸å‡ºæ–‡ä»¶è·¯å¾‘")
 
diff --git a/workspace/config/dev/validation-system/scripts/emergency_mode_manager.py b/workspace/config/dev/validation-system/scripts/emergency_mode_manager.py
index 4e9058d..2c473eb 100644
--- a/workspace/config/dev/validation-system/scripts/emergency_mode_manager.py
+++ b/workspace/config/dev/validation-system/scripts/emergency_mode_manager.py
@@ -170,14 +170,25 @@ class EmergencyModeManager:
         }
 
         # ç‹€æ…‹è½‰æ›é‚è¼¯
-        if level == EmergencyLevel.EMERGENCY and previous_level != EmergencyLevel.EMERGENCY:
+        if (
+            level == EmergencyLevel.EMERGENCY
+            and previous_level != EmergencyLevel.EMERGENCY
+        ):
             self._activate_emergency(health, "Multiple critical conditions detected")
             response["action_taken"] = "emergency_activated"
-        elif level == EmergencyLevel.CRITICAL and previous_level == EmergencyLevel.NORMAL:
-            self._activate_fallback(FallbackStrategy.LIGHTWEIGHT, "Critical condition detected")
+        elif (
+            level == EmergencyLevel.CRITICAL and previous_level == EmergencyLevel.NORMAL
+        ):
+            self._activate_fallback(
+                FallbackStrategy.LIGHTWEIGHT, "Critical condition detected"
+            )
             response["action_taken"] = "fallback_activated"
-        elif level == EmergencyLevel.WARNING and previous_level == EmergencyLevel.NORMAL:
-            self._activate_fallback(FallbackStrategy.STANDBY, "Warning conditions detected")
+        elif (
+            level == EmergencyLevel.WARNING and previous_level == EmergencyLevel.NORMAL
+        ):
+            self._activate_fallback(
+                FallbackStrategy.STANDBY, "Warning conditions detected"
+            )
             response["action_taken"] = "standby_activated"
         elif level == EmergencyLevel.NORMAL and previous_level != EmergencyLevel.NORMAL:
             self._attempt_recovery()
@@ -198,7 +209,9 @@ class EmergencyModeManager:
 
         self.state.level = EmergencyLevel.EMERGENCY
         self.state.strategy = FallbackStrategy.CLASSIC_AGGRESSIVE
-        self.state.activated_at = datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")
+        self.state.activated_at = (
+            datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")
+        )
         self.state.reason = reason
         self.state.recovery_attempts = 0
 
@@ -208,7 +221,9 @@ class EmergencyModeManager:
 
         self.state.level = EmergencyLevel.WARNING
         self.state.strategy = strategy
-        self.state.activated_at = datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")
+        self.state.activated_at = (
+            datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")
+        )
         self.state.reason = reason
 
     def _attempt_recovery(self):
@@ -220,7 +235,9 @@ class EmergencyModeManager:
         self.state.recovery_attempts += 1
 
         if self.state.recovery_attempts >= self.state.max_recovery_attempts:
-            logger.warning(f"Max recovery attempts ({self.state.max_recovery_attempts}) reached")
+            logger.warning(
+                f"Max recovery attempts ({self.state.max_recovery_attempts}) reached"
+            )
             return
 
         logger.info(
@@ -288,18 +305,26 @@ def run_demo():
     # å ´æ™¯ 1ï¼šæ­£å¸¸ç‹€æ…‹
     print("\nğŸ“— å ´æ™¯ 1ï¼šæ­£å¸¸é‹è¡Œ")
     print("-" * 50)
-    health_normal = SystemHealth(coherence=0.85, noise_level=0.10, error_rate=0.01, latency_ms=150)
+    health_normal = SystemHealth(
+        coherence=0.85, noise_level=0.10, error_rate=0.01, latency_ms=150
+    )
     result = manager.check_and_respond(health_normal)
-    print(f"å¥åº·è©•ä¼°: coherence={health_normal.coherence}, noise={health_normal.noise_level}")
+    print(
+        f"å¥åº·è©•ä¼°: coherence={health_normal.coherence}, noise={health_normal.noise_level}"
+    )
     print(f"è¡Œå‹•: {result['action_taken']}")
     print(f"ç­‰ç´š: {result['current_level']}")
 
     # å ´æ™¯ 2ï¼šè­¦å‘Šç‹€æ…‹
     print("\nğŸ“™ å ´æ™¯ 2ï¼šè­¦å‘Šæ¢ä»¶")
     print("-" * 50)
-    health_warning = SystemHealth(coherence=0.76, noise_level=0.16, error_rate=0.02, latency_ms=200)
+    health_warning = SystemHealth(
+        coherence=0.76, noise_level=0.16, error_rate=0.02, latency_ms=200
+    )
     result = manager.check_and_respond(health_warning)
-    print(f"å¥åº·è©•ä¼°: coherence={health_warning.coherence}, noise={health_warning.noise_level}")
+    print(
+        f"å¥åº·è©•ä¼°: coherence={health_warning.coherence}, noise={health_warning.noise_level}"
+    )
     print(f"è¡Œå‹•: {result['action_taken']}")
     print(f"ç­‰ç´š: {result['current_level']}")
 
@@ -310,7 +335,9 @@ def run_demo():
         coherence=0.65, noise_level=0.25, error_rate=0.08, latency_ms=900
     )
     result = manager.check_and_respond(health_emergency)
-    print(f"å¥åº·è©•ä¼°: coherence={health_emergency.coherence}, noise={health_emergency.noise_level}")
+    print(
+        f"å¥åº·è©•ä¼°: coherence={health_emergency.coherence}, noise={health_emergency.noise_level}"
+    )
     print(f"è¡Œå‹•: {result['action_taken']}")
     print(f"ç­‰ç´š: {result['current_level']}")
 
@@ -321,7 +348,9 @@ def run_demo():
         coherence=0.82, noise_level=0.12, error_rate=0.02, latency_ms=180
     )
     result = manager.check_and_respond(health_recovered)
-    print(f"å¥åº·è©•ä¼°: coherence={health_recovered.coherence}, noise={health_recovered.noise_level}")
+    print(
+        f"å¥åº·è©•ä¼°: coherence={health_recovered.coherence}, noise={health_recovered.noise_level}"
+    )
     print(f"è¡Œå‹•: {result['action_taken']}")
     print(f"ç­‰ç´š: {result['current_level']}")
 
@@ -336,7 +365,9 @@ def main():
     """ä¸»å‡½æ•¸"""
     import argparse
 
-    parser = argparse.ArgumentParser(description="ç·Šæ€¥æ¨¡å¼ç®¡ç†å™¨ - MachineNativeOps é©—è­‰ç³»çµ±")
+    parser = argparse.ArgumentParser(
+        description="ç·Šæ€¥æ¨¡å¼ç®¡ç†å™¨ - MachineNativeOps é©—è­‰ç³»çµ±"
+    )
     parser.add_argument(
         "command",
         nargs="?",
@@ -344,7 +375,9 @@ def main():
         default="status",
         help="åŸ·è¡Œçš„å‘½ä»¤",
     )
-    parser.add_argument("--reason", default="Manual activation", help="å•Ÿç”¨ç·Šæ€¥æ¨¡å¼çš„åŸå› ")
+    parser.add_argument(
+        "--reason", default="Manual activation", help="å•Ÿç”¨ç·Šæ€¥æ¨¡å¼çš„åŸå› "
+    )
     parser.add_argument("--json", action="store_true", help="ä»¥ JSON æ ¼å¼è¼¸å‡º")
 
     args = parser.parse_args()
diff --git a/workspace/config/dev/validation-system/scripts/quantum_feature_extractor.py b/workspace/config/dev/validation-system/scripts/quantum_feature_extractor.py
index 09a6e5d..09b03c6 100644
--- a/workspace/config/dev/validation-system/scripts/quantum_feature_extractor.py
+++ b/workspace/config/dev/validation-system/scripts/quantum_feature_extractor.py
@@ -145,7 +145,8 @@ class QuantumFeatureExtractor:
             name=path.name,
             path=str(path.absolute()),
             size=len(content),
-            last_modified=datetime.fromtimestamp(path.stat().st_mtime).isoformat() + "Z",
+            last_modified=datetime.fromtimestamp(path.stat().st_mtime).isoformat()
+            + "Z",
             sha256=hashlib.sha256(content).hexdigest(),
             sha512=hashlib.sha512(content).hexdigest(),
         )
@@ -183,7 +184,9 @@ class QuantumFeatureExtractor:
             error_mitigated=self.error_mitigation,
         )
 
-    def generate_quantum_signature(self, doc_path: str, features: QuantumFeatures) -> str:
+    def generate_quantum_signature(
+        self, doc_path: str, features: QuantumFeatures
+    ) -> str:
         """
         ç”Ÿæˆé‡å­ç°½å
 
@@ -195,7 +198,9 @@ class QuantumFeatureExtractor:
             str: é‡å­ç°½åå­—ç¬¦ä¸²
         """
         # çµ„åˆç‰¹å¾µç”Ÿæˆç°½åç¨®å­
-        seed_data = f"{doc_path}:{features.metrics.coherence}:{features.metrics.fidelity}"
+        seed_data = (
+            f"{doc_path}:{features.metrics.coherence}:{features.metrics.fidelity}"
+        )
         signature_hash = hashlib.sha256(seed_data.encode()).hexdigest()[:16]
 
         return f"qsig:2:{self.backend}:0x{signature_hash}"
@@ -255,11 +260,17 @@ def main():
     """ä¸»å‡½æ•¸"""
     import argparse
 
-    parser = argparse.ArgumentParser(description="é‡å­ç‰¹å¾µæå–å™¨ - MachineNativeOps é©—è­‰ç³»çµ±")
+    parser = argparse.ArgumentParser(
+        description="é‡å­ç‰¹å¾µæå–å™¨ - MachineNativeOps é©—è­‰ç³»çµ±"
+    )
     parser.add_argument("document", nargs="?", default=None, help="è¦è™•ç†çš„æ–‡æª”è·¯å¾‘")
-    parser.add_argument("--backend", default="ibm_kyiv", help="é‡å­å¾Œç«¯ (default: ibm_kyiv)")
+    parser.add_argument(
+        "--backend", default="ibm_kyiv", help="é‡å­å¾Œç«¯ (default: ibm_kyiv)"
+    )
     parser.add_argument("--depth", type=int, default=8, help="é›»è·¯æ·±åº¦ (default: 8)")
-    parser.add_argument("--shots", type=int, default=1024, help="æ¸¬é‡æ¬¡æ•¸ (default: 1024)")
+    parser.add_argument(
+        "--shots", type=int, default=1024, help="æ¸¬é‡æ¬¡æ•¸ (default: 1024)"
+    )
     parser.add_argument("--output", default=None, help="è¼¸å‡ºæ–‡ä»¶è·¯å¾‘")
 
     args = parser.parse_args()
diff --git a/workspace/config/integrations/jira-integration.py b/workspace/config/integrations/jira-integration.py
index b6f91f4..14dbb84 100755
--- a/workspace/config/integrations/jira-integration.py
+++ b/workspace/config/integrations/jira-integration.py
@@ -22,7 +22,10 @@ class JiraIntegration:
         # request debugging is disabled.
         self.auth = (username, api_token)
         self.project_key = project_key
-        self.headers = {"Content-Type": "application/json", "Accept": "application/json"}
+        self.headers = {
+            "Content-Type": "application/json",
+            "Accept": "application/json",
+        }
 
     def create_security_issue(
         self,
@@ -190,10 +193,15 @@ def main():
         sys.exit(1)
 
     # Get alert details from command line or environment
-    severity = os.getenv("ALERT_SEVERITY", sys.argv[1] if len(sys.argv) > 1 else "medium")
-    summary = os.getenv("ALERT_SUMMARY", sys.argv[2] if len(sys.argv) > 2 else "Security Alert")
+    severity = os.getenv(
+        "ALERT_SEVERITY", sys.argv[1] if len(sys.argv) > 1 else "medium"
+    )
+    summary = os.getenv(
+        "ALERT_SUMMARY", sys.argv[2] if len(sys.argv) > 2 else "Security Alert"
+    )
     description = os.getenv(
-        "ALERT_DESCRIPTION", sys.argv[3] if len(sys.argv) > 3 else "Security issue detected"
+        "ALERT_DESCRIPTION",
+        sys.argv[3] if len(sys.argv) > 3 else "Security issue detected",
     )
     alert_type = os.getenv("ALERT_TYPE", "Security Alert")
     repository = os.getenv("GITHUB_REPOSITORY", "unknown")
diff --git a/workspace/docs/architecture/configuration/python/config_validator.py b/workspace/docs/architecture/configuration/python/config_validator.py
index d6012ed..a0d4a4f 100755
--- a/workspace/docs/architecture/configuration/python/config_validator.py
+++ b/workspace/docs/architecture/configuration/python/config_validator.py
@@ -70,7 +70,11 @@ class ConfigValidator:
 
     def validate_docker_compose(self) -> Dict:
         """é©—è­‰Docker Composeé…ç½®"""
-        compose_files = ["docker-compose.yml", "docker-compose.yaml", "docker-compose.override.yml"]
+        compose_files = [
+            "docker-compose.yml",
+            "docker-compose.yaml",
+            "docker-compose.override.yml",
+        ]
 
         results = {"files_checked": [], "valid": True, "errors": [], "warnings": []}
 
@@ -111,7 +115,10 @@ class ConfigValidator:
                             results["valid"] = False
 
                         # æª¢æŸ¥å¿…éœ€å­—æ®µ
-                        if "image" not in service_config and "build" not in service_config:
+                        if (
+                            "image" not in service_config
+                            and "build" not in service_config
+                        ):
                             results["warnings"].append(
                                 {
                                     "file": filename,
@@ -155,7 +162,10 @@ class ConfigValidator:
                     for field, field_type in required_fields.items():
                         if field not in manifest:
                             results["errors"].append(
-                                {"file": k8s_file, "error": f"Missing required field: {field}"}
+                                {
+                                    "file": k8s_file,
+                                    "error": f"Missing required field: {field}",
+                                }
                             )
                             results["invalid_files"] += 1
                             break
@@ -265,7 +275,15 @@ class ConfigValidator:
                     d
                     for d in dirs
                     if d
-                    not in ["node_modules", ".git", "__pycache__", ".venv", "venv", "dist", "build"]
+                    not in [
+                        "node_modules",
+                        ".git",
+                        "__pycache__",
+                        ".venv",
+                        "venv",
+                        "dist",
+                        "build",
+                    ]
                 ]
 
                 for pattern in patterns:
diff --git a/workspace/docs/architecture/configuration/python/security_scanner.py b/workspace/docs/architecture/configuration/python/security_scanner.py
index 43724a9..6a6017a 100755
--- a/workspace/docs/architecture/configuration/python/security_scanner.py
+++ b/workspace/docs/architecture/configuration/python/security_scanner.py
@@ -49,13 +49,25 @@ class SecurityScanner:
                 "timestamp": datetime.now().isoformat(),
                 "total_issues": len(report.get("results", [])),
                 "high_severity": len(
-                    [r for r in report.get("results", []) if r.get("issue_severity") == "HIGH"]
+                    [
+                        r
+                        for r in report.get("results", [])
+                        if r.get("issue_severity") == "HIGH"
+                    ]
                 ),
                 "medium_severity": len(
-                    [r for r in report.get("results", []) if r.get("issue_severity") == "MEDIUM"]
+                    [
+                        r
+                        for r in report.get("results", [])
+                        if r.get("issue_severity") == "MEDIUM"
+                    ]
                 ),
                 "low_severity": len(
-                    [r for r in report.get("results", []) if r.get("issue_severity") == "LOW"]
+                    [
+                        r
+                        for r in report.get("results", [])
+                        if r.get("issue_severity") == "LOW"
+                    ]
                 ),
                 "metrics": report.get("metrics", {}),
             }
@@ -71,7 +83,9 @@ class SecurityScanner:
         cmd = ["safety", "check", "--json"]
 
         try:
-            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_path)
+            result = subprocess.run(
+                cmd, capture_output=True, text=True, cwd=self.project_path
+            )
 
             # è§£æè¼¸å‡º
             try:
@@ -90,7 +104,9 @@ class SecurityScanner:
                 "tool": "safety",
                 "timestamp": datetime.now().isoformat(),
                 "total_vulnerabilities": len(vulnerabilities),
-                "packages_affected": len(set([v.get("package", "") for v in vulnerabilities])),
+                "packages_affected": len(
+                    set([v.get("package", "") for v in vulnerabilities])
+                ),
                 "vulnerabilities": vulnerabilities,
             }
 
@@ -108,7 +124,9 @@ class SecurityScanner:
         cmd = ["npm", "audit", "--json"]
 
         try:
-            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_path)
+            result = subprocess.run(
+                cmd, capture_output=True, text=True, cwd=self.project_path
+            )
 
             report = json.loads(result.stdout) if result.stdout else {}
 
@@ -125,11 +143,15 @@ class SecurityScanner:
                 "critical": report.get("metadata", {})
                 .get("vulnerabilities", {})
                 .get("critical", 0),
-                "high": report.get("metadata", {}).get("vulnerabilities", {}).get("high", 0),
+                "high": report.get("metadata", {})
+                .get("vulnerabilities", {})
+                .get("high", 0),
                 "moderate": report.get("metadata", {})
                 .get("vulnerabilities", {})
                 .get("moderate", 0),
-                "low": report.get("metadata", {}).get("vulnerabilities", {}).get("low", 0),
+                "low": report.get("metadata", {})
+                .get("vulnerabilities", {})
+                .get("low", 0),
             }
 
             return summary
@@ -146,7 +168,9 @@ class SecurityScanner:
         cmd = ["snyk", "test", "--json"]
 
         try:
-            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_path)
+            result = subprocess.run(
+                cmd, capture_output=True, text=True, cwd=self.project_path
+            )
 
             report = json.loads(result.stdout) if result.stdout else {}
 
@@ -167,13 +191,25 @@ class SecurityScanner:
                     ]
                 ),
                 "high": len(
-                    [v for v in report.get("vulnerabilities", []) if v.get("severity") == "high"]
+                    [
+                        v
+                        for v in report.get("vulnerabilities", [])
+                        if v.get("severity") == "high"
+                    ]
                 ),
                 "medium": len(
-                    [v for v in report.get("vulnerabilities", []) if v.get("severity") == "medium"]
+                    [
+                        v
+                        for v in report.get("vulnerabilities", [])
+                        if v.get("severity") == "medium"
+                    ]
                 ),
                 "low": len(
-                    [v for v in report.get("vulnerabilities", []) if v.get("severity") == "low"]
+                    [
+                        v
+                        for v in report.get("vulnerabilities", [])
+                        if v.get("severity") == "low"
+                    ]
                 ),
             }
 
@@ -231,7 +267,9 @@ class SecurityScanner:
         """æª¢æŸ¥é …ç›®æ˜¯å¦åŒ…å«Pythonæ–‡ä»¶"""
         for root, dirs, files in os.walk(self.project_path):
             # æ’é™¤å¸¸è¦‹çš„ä¾è³´ç›®éŒ„
-            dirs[:] = [d for d in dirs if d not in ["venv", ".venv", "node_modules", ".git"]]
+            dirs[:] = [
+                d for d in dirs if d not in ["venv", ".venv", "node_modules", ".git"]
+            ]
             if any(f.endswith(".py") for f in files):
                 return True
         return False
@@ -254,7 +292,9 @@ class SecurityScanner:
             if "critical" in scan_result:
                 critical_count += scan_result["critical"]
             if "high" in scan_result or "high_severity" in scan_result:
-                high_count += scan_result.get("high", scan_result.get("high_severity", 0))
+                high_count += scan_result.get(
+                    "high", scan_result.get("high_severity", 0)
+                )
 
         return {
             "total_issues": total_issues,
diff --git a/workspace/docs/examples/configuration/python/config_validator.py b/workspace/docs/examples/configuration/python/config_validator.py
index 7f8d594..0f9d837 100755
--- a/workspace/docs/examples/configuration/python/config_validator.py
+++ b/workspace/docs/examples/configuration/python/config_validator.py
@@ -69,7 +69,11 @@ class ConfigValidator:
 
     def validate_docker_compose(self) -> dict:
         """é©—è­‰Docker Composeé…ç½®"""
-        compose_files = ["docker-compose.yml", "docker-compose.yaml", "docker-compose.override.yml"]
+        compose_files = [
+            "docker-compose.yml",
+            "docker-compose.yaml",
+            "docker-compose.override.yml",
+        ]
 
         results = {"files_checked": [], "valid": True, "errors": [], "warnings": []}
 
@@ -110,7 +114,10 @@ class ConfigValidator:
                             results["valid"] = False
 
                         # æª¢æŸ¥å¿…éœ€å­—æ®µ
-                        if "image" not in service_config and "build" not in service_config:
+                        if (
+                            "image" not in service_config
+                            and "build" not in service_config
+                        ):
                             results["warnings"].append(
                                 {
                                     "file": filename,
@@ -154,7 +161,10 @@ class ConfigValidator:
                     for field, field_type in required_fields.items():
                         if field not in manifest:
                             results["errors"].append(
-                                {"file": k8s_file, "error": f"Missing required field: {field}"}
+                                {
+                                    "file": k8s_file,
+                                    "error": f"Missing required field: {field}",
+                                }
                             )
                             results["invalid_files"] += 1
                             break
@@ -240,7 +250,9 @@ class ConfigValidator:
 
         return results
 
-    def _find_files(self, patterns: list[str], directories: list[str] | None = None) -> list[str]:
+    def _find_files(
+        self, patterns: list[str], directories: list[str] | None = None
+    ) -> list[str]:
         """æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶"""
         matched_files = []
         search_dirs = directories or [self.project_path]
@@ -262,7 +274,15 @@ class ConfigValidator:
                     d
                     for d in dirs
                     if d
-                    not in ["node_modules", ".git", "__pycache__", ".venv", "venv", "dist", "build"]
+                    not in [
+                        "node_modules",
+                        ".git",
+                        "__pycache__",
+                        ".venv",
+                        "venv",
+                        "dist",
+                        "build",
+                    ]
                 ]
 
                 for pattern in patterns:
diff --git a/workspace/docs/examples/configuration/python/security_scanner.py b/workspace/docs/examples/configuration/python/security_scanner.py
index ded8b69..f3bbdeb 100755
--- a/workspace/docs/examples/configuration/python/security_scanner.py
+++ b/workspace/docs/examples/configuration/python/security_scanner.py
@@ -34,12 +34,16 @@ def validate_project_path(input_path: str) -> str:
     except Exception as e:
         raise ValueError(f"Invalid project path: {input_path}") from e
     if not resolved_path.exists() or not resolved_path.is_dir():
-        raise ValueError(f"Project path does not exist or is not a directory: {resolved_path}")
+        raise ValueError(
+            f"Project path does not exist or is not a directory: {resolved_path}"
+        )
     try:
         # Ensure path is within base_dir
         resolved_path.relative_to(base_dir)
     except ValueError as e:
-        raise ValueError("Project path must be within the current working directory") from e
+        raise ValueError(
+            "Project path must be within the current working directory"
+        ) from e
     return str(resolved_path)
 
 
@@ -82,13 +86,25 @@ class SecurityScanner:
                 "timestamp": datetime.now().isoformat(),
                 "total_issues": len(report.get("results", [])),
                 "high_severity": len(
-                    [r for r in report.get("results", []) if r.get("issue_severity") == "HIGH"]
+                    [
+                        r
+                        for r in report.get("results", [])
+                        if r.get("issue_severity") == "HIGH"
+                    ]
                 ),
                 "medium_severity": len(
-                    [r for r in report.get("results", []) if r.get("issue_severity") == "MEDIUM"]
+                    [
+                        r
+                        for r in report.get("results", [])
+                        if r.get("issue_severity") == "MEDIUM"
+                    ]
                 ),
                 "low_severity": len(
-                    [r for r in report.get("results", []) if r.get("issue_severity") == "LOW"]
+                    [
+                        r
+                        for r in report.get("results", [])
+                        if r.get("issue_severity") == "LOW"
+                    ]
                 ),
                 "metrics": report.get("metrics", {}),
             }
@@ -104,7 +120,9 @@ class SecurityScanner:
         cmd = ["safety", "check", "--json"]
 
         try:
-            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_path)
+            result = subprocess.run(
+                cmd, capture_output=True, text=True, cwd=self.project_path
+            )
 
             # è§£æè¼¸å‡º
             try:
@@ -123,7 +141,9 @@ class SecurityScanner:
                 "tool": "safety",
                 "timestamp": datetime.now().isoformat(),
                 "total_vulnerabilities": len(vulnerabilities),
-                "packages_affected": len({v.get("package", "") for v in vulnerabilities}),
+                "packages_affected": len(
+                    {v.get("package", "") for v in vulnerabilities}
+                ),
                 "vulnerabilities": vulnerabilities,
             }
 
@@ -141,7 +161,9 @@ class SecurityScanner:
         cmd = ["npm", "audit", "--json"]
 
         try:
-            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_path)
+            result = subprocess.run(
+                cmd, capture_output=True, text=True, cwd=self.project_path
+            )
 
             report = json.loads(result.stdout) if result.stdout else {}
 
@@ -158,11 +180,15 @@ class SecurityScanner:
                 "critical": report.get("metadata", {})
                 .get("vulnerabilities", {})
                 .get("critical", 0),
-                "high": report.get("metadata", {}).get("vulnerabilities", {}).get("high", 0),
+                "high": report.get("metadata", {})
+                .get("vulnerabilities", {})
+                .get("high", 0),
                 "moderate": report.get("metadata", {})
                 .get("vulnerabilities", {})
                 .get("moderate", 0),
-                "low": report.get("metadata", {}).get("vulnerabilities", {}).get("low", 0),
+                "low": report.get("metadata", {})
+                .get("vulnerabilities", {})
+                .get("low", 0),
             }
 
             return summary
@@ -179,7 +205,9 @@ class SecurityScanner:
         cmd = ["snyk", "test", "--json"]
 
         try:
-            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_path)
+            result = subprocess.run(
+                cmd, capture_output=True, text=True, cwd=self.project_path
+            )
 
             report = json.loads(result.stdout) if result.stdout else {}
 
@@ -200,13 +228,25 @@ class SecurityScanner:
                     ]
                 ),
                 "high": len(
-                    [v for v in report.get("vulnerabilities", []) if v.get("severity") == "high"]
+                    [
+                        v
+                        for v in report.get("vulnerabilities", [])
+                        if v.get("severity") == "high"
+                    ]
                 ),
                 "medium": len(
-                    [v for v in report.get("vulnerabilities", []) if v.get("severity") == "medium"]
+                    [
+                        v
+                        for v in report.get("vulnerabilities", [])
+                        if v.get("severity") == "medium"
+                    ]
                 ),
                 "low": len(
-                    [v for v in report.get("vulnerabilities", []) if v.get("severity") == "low"]
+                    [
+                        v
+                        for v in report.get("vulnerabilities", [])
+                        if v.get("severity") == "low"
+                    ]
                 ),
             }
 
@@ -264,7 +304,9 @@ class SecurityScanner:
         """æª¢æŸ¥é …ç›®æ˜¯å¦åŒ…å«Pythonæ–‡ä»¶"""
         for _root, dirs, files in os.walk(self.project_path):
             # æ’é™¤å¸¸è¦‹çš„ä¾è³´ç›®éŒ„
-            dirs[:] = [d for d in dirs if d not in ["venv", ".venv", "node_modules", ".git"]]
+            dirs[:] = [
+                d for d in dirs if d not in ["venv", ".venv", "node_modules", ".git"]
+            ]
             if any(f.endswith(".py") for f in files):
                 return True
         return False
@@ -287,7 +329,9 @@ class SecurityScanner:
             if "critical" in scan_result:
                 critical_count += scan_result["critical"]
             if "high" in scan_result or "high_severity" in scan_result:
-                high_count += scan_result.get("high", scan_result.get("high_severity", 0))
+                high_count += scan_result.get(
+                    "high", scan_result.get("high_severity", 0)
+                )
 
         return {
             "total_issues": total_issues,
diff --git a/workspace/docs/refactor_playbooks/templates/contract-engine.py b/workspace/docs/refactor_playbooks/templates/contract-engine.py
index e5cd953..34cef60 100644
--- a/workspace/docs/refactor_playbooks/templates/contract-engine.py
+++ b/workspace/docs/refactor_playbooks/templates/contract-engine.py
@@ -401,7 +401,9 @@ class ContractEngine:
         # Get ordered layers by priority
         ordered_layers = sorted(
             self.validation_gates.keys(),
-            key=lambda layer: self.config["validation"]["layers"][layer.name]["priority"],
+            key=lambda layer: self.config["validation"]["layers"][layer.name][
+                "priority"
+            ],
         )
 
         for layer in ordered_layers:
@@ -433,7 +435,9 @@ class ContractEngine:
                 context.validation_results.append(result)
 
                 if not result.success and result in [g for g in gates if g.required]:
-                    self.logger.warning(f"Required validation gate failed: {result.gate_name}")
+                    self.logger.warning(
+                        f"Required validation gate failed: {result.gate_name}"
+                    )
                     return False
 
         return True
@@ -520,7 +524,9 @@ class ContractEngine:
             **self.metrics,
             "active_contracts": len(self.active_contracts),
             "validation_layers": len(self.validation_gates),
-            "total_validation_gates": sum(len(gates) for gates in self.validation_gates.values()),
+            "total_validation_gates": sum(
+                len(gates) for gates in self.validation_gates.values()
+            ),
         }
 
     def get_contract_by_intent(self, intent: str) -> Optional[BehaviorContract]:
diff --git a/workspace/docs/refactor_playbooks/templates/contract-generator.py b/workspace/docs/refactor_playbooks/templates/contract-generator.py
index 615c858..64bc575 100644
--- a/workspace/docs/refactor_playbooks/templates/contract-generator.py
+++ b/workspace/docs/refactor_playbooks/templates/contract-generator.py
@@ -102,7 +102,10 @@ class ContractGenerator:
                 "intent": "automate_deployment",
                 "conditions": {"triggers": [], "prerequisites": []},
                 "actions": [],
-                "validation_requirements": {"layers": ["L-A", "L-B", "L-C", "L-E"], "gates": []},
+                "validation_requirements": {
+                    "layers": ["L-A", "L-B", "L-C", "L-E"],
+                    "gates": [],
+                },
                 "metadata": {"owner": "", "category": "deployment", "tags": []},
             },
             required_fields=["name", "intent", "actions"],
@@ -128,7 +131,10 @@ class ContractGenerator:
                     "prerequisites": [],
                 },
                 "actions": [],
-                "validation_requirements": {"layers": ["L-A", "L-D", "L-E"], "gates": []},
+                "validation_requirements": {
+                    "layers": ["L-A", "L-D", "L-E"],
+                    "gates": [],
+                },
                 "metadata": {},
             },
             required_fields=["name", "metrics"],
@@ -151,7 +157,10 @@ class ContractGenerator:
                 "intent": "optimize_resources",
                 "conditions": {"triggers": [], "prerequisites": []},
                 "actions": [],
-                "validation_requirements": {"layers": ["L-A", "L-D", "L-E", "L-F"], "gates": []},
+                "validation_requirements": {
+                    "layers": ["L-A", "L-D", "L-E", "L-F"],
+                    "gates": [],
+                },
                 "metadata": {},
             },
             required_fields=["name", "optimization_targets"],
@@ -174,7 +183,10 @@ class ContractGenerator:
                 "intent": "enforce_security",
                 "conditions": {"triggers": [], "prerequisites": []},
                 "actions": [],
-                "validation_requirements": {"layers": ["L-A", "L-B", "L-C"], "gates": []},
+                "validation_requirements": {
+                    "layers": ["L-A", "L-B", "L-C"],
+                    "gates": [],
+                },
                 "metadata": {},
             },
             required_fields=["name", "security_controls"],
@@ -200,7 +212,10 @@ class ContractGenerator:
                     "prerequisites": [],
                 },
                 "actions": [],
-                "validation_requirements": {"layers": ["L-A", "L-B", "L-D"], "gates": []},
+                "validation_requirements": {
+                    "layers": ["L-A", "L-B", "L-D"],
+                    "gates": [],
+                },
                 "metadata": {},
             },
             required_fields=["name", "backup_targets"],
@@ -235,7 +250,9 @@ class ContractGenerator:
             template = self.templates["deployment"]
 
         # Generate contract
-        contract_def = self._build_contract_from_template(template, description, intent_analysis)
+        contract_def = self._build_contract_from_template(
+            template, description, intent_analysis
+        )
 
         # Validate
         validation = self._validate_contract(contract_def)
@@ -318,7 +335,9 @@ class ContractGenerator:
                 "intent": "monitor_system_health",
                 "actions": ["collect_metrics", "alert"],
             }
-        elif any(word in description_lower for word in ["optimize", "improve", "performance"]):
+        elif any(
+            word in description_lower for word in ["optimize", "improve", "performance"]
+        ):
             return {
                 "template": "optimization",
                 "confidence": 0.80,
@@ -332,7 +351,9 @@ class ContractGenerator:
                 "intent": "enforce_security",
                 "actions": ["scan", "enforce"],
             }
-        elif any(word in description_lower for word in ["backup", "snapshot", "archive"]):
+        elif any(
+            word in description_lower for word in ["backup", "snapshot", "archive"]
+        ):
             return {
                 "template": "backup",
                 "confidence": 0.90,
@@ -493,8 +514,12 @@ def main():
     """Command-line interface for contract generation"""
     import argparse
 
-    parser = argparse.ArgumentParser(description="Generate intelligent behavior contracts")
-    parser.add_argument("description", help="Natural language description of desired behavior")
+    parser = argparse.ArgumentParser(
+        description="Generate intelligent behavior contracts"
+    )
+    parser.add_argument(
+        "description", help="Natural language description of desired behavior"
+    )
     parser.add_argument(
         "--output", "-o", default="./generated-contract.yaml", help="Output file path"
     )
diff --git a/workspace/docs/refactor_playbooks/templates/emergency_recovery.py b/workspace/docs/refactor_playbooks/templates/emergency_recovery.py
index 64849f0..a11faec 100644
--- a/workspace/docs/refactor_playbooks/templates/emergency_recovery.py
+++ b/workspace/docs/refactor_playbooks/templates/emergency_recovery.py
@@ -45,7 +45,8 @@ class EmergencyRecovery:
         }
 
         self.log_file = (
-            self.recovery_log / f"recovery_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
+            self.recovery_log
+            / f"recovery_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
         )
 
     def log(self, message: str, level: str = "INFO"):
@@ -136,10 +137,14 @@ class EmergencyRecovery:
         self.log("âš ï¸  å°è¯•å›é€€æ–¹æ¡ˆï¼šsubprocesså¯åŠ¨...")
 
         try:
-            orchestrator_path = self.base_path / "tools" / "automation" / "master_orchestrator.py"
+            orchestrator_path = (
+                self.base_path / "tools" / "automation" / "master_orchestrator.py"
+            )
 
             if not orchestrator_path.exists():
-                self.log(f"âŒ æ‰¾ä¸åˆ° master_orchestrator.py: {orchestrator_path}", "ERROR")
+                self.log(
+                    f"âŒ æ‰¾ä¸åˆ° master_orchestrator.py: {orchestrator_path}", "ERROR"
+                )
                 return False
 
             # ä½¿ç”¨subprocesså¯åŠ¨ç‹¬ç«‹è¿›ç¨‹
@@ -205,10 +210,16 @@ class EmergencyRecovery:
             try:
                 with open(status_file, "r") as f:
                     status_data = json.load(f)
-                health_status["checks"]["status_file"] = {"status": "healthy", "data": status_data}
+                health_status["checks"]["status_file"] = {
+                    "status": "healthy",
+                    "data": status_data,
+                }
                 self.log(f"  âœ“ çŠ¶æ€æ–‡ä»¶å­˜åœ¨: {status_data.get('status', 'unknown')}")
             except Exception as e:
-                health_status["checks"]["status_file"] = {"status": "error", "message": str(e)}
+                health_status["checks"]["status_file"] = {
+                    "status": "error",
+                    "message": str(e),
+                }
                 self.log(f"  âœ— çŠ¶æ€æ–‡ä»¶è¯»å–å¤±è´¥: {e}", "ERROR")
         else:
             health_status["checks"]["status_file"] = {
@@ -220,30 +231,45 @@ class EmergencyRecovery:
         # æ£€æŸ¥3: æ—¥å¿—æ–‡ä»¶
         log_dir = self.base_path / "logs"
         if log_dir.exists():
-            recent_logs = sorted(log_dir.glob("*.log"), key=os.path.getmtime, reverse=True)
+            recent_logs = sorted(
+                log_dir.glob("*.log"), key=os.path.getmtime, reverse=True
+            )
             if recent_logs:
                 latest_log = recent_logs[0]
                 health_status["checks"]["logs"] = {
                     "status": "healthy",
                     "latest_log": str(latest_log),
-                    "modified": datetime.fromtimestamp(os.path.getmtime(latest_log)).isoformat(),
+                    "modified": datetime.fromtimestamp(
+                        os.path.getmtime(latest_log)
+                    ).isoformat(),
                 }
                 self.log(f"  âœ“ æœ€æ–°æ—¥å¿—: {latest_log.name}")
             else:
-                health_status["checks"]["logs"] = {"status": "warning", "message": "æ—¥å¿—ç›®å½•ä¸ºç©º"}
+                health_status["checks"]["logs"] = {
+                    "status": "warning",
+                    "message": "æ—¥å¿—ç›®å½•ä¸ºç©º",
+                }
                 self.log("  âš  æ—¥å¿—ç›®å½•ä¸ºç©º", "WARNING")
         else:
-            health_status["checks"]["logs"] = {"status": "missing", "message": "æ—¥å¿—ç›®å½•ä¸å­˜åœ¨"}
+            health_status["checks"]["logs"] = {
+                "status": "missing",
+                "message": "æ—¥å¿—ç›®å½•ä¸å­˜åœ¨",
+            }
             self.log("  âœ— æ—¥å¿—ç›®å½•ä¸å­˜åœ¨", "WARNING")
 
         # ä¿å­˜å¥åº·æ£€æŸ¥ç»“æœ
-        health_file = self.recovery_log / f"health_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
+        health_file = (
+            self.recovery_log
+            / f"health_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
+        )
         with open(health_file, "w") as f:
             json.dump(health_status, f, indent=2)
 
         # æ€»ç»“
         healthy_checks = sum(
-            1 for check in health_status["checks"].values() if check["status"] == "healthy"
+            1
+            for check in health_status["checks"].values()
+            if check["status"] == "healthy"
         )
         total_checks = len(health_status["checks"])
 
diff --git a/workspace/docs/refactor_playbooks/templates/multi-layer-validator.py b/workspace/docs/refactor_playbooks/templates/multi-layer-validator.py
index 4f4d78e..1f167cd 100644
--- a/workspace/docs/refactor_playbooks/templates/multi-layer-validator.py
+++ b/workspace/docs/refactor_playbooks/templates/multi-layer-validator.py
@@ -198,7 +198,9 @@ class ValidationGateRegistry:
     # Layer A: Intent Validation
     # ------------------------------------------------------------------------
 
-    async def _validate_intent_clarity(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_intent_clarity(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         """Validate that user intent is clear and unambiguous"""
         start_time = time.perf_counter()
 
@@ -223,7 +225,9 @@ class ValidationGateRegistry:
             details={"intent": intent, "clarity_score": clarity_score},
         )
 
-    async def _validate_goal_alignment(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_goal_alignment(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         """Validate that requested action aligns with system goals"""
         start_time = time.perf_counter()
 
@@ -242,7 +246,9 @@ class ValidationGateRegistry:
             duration_ms=duration_ms,
         )
 
-    async def _validate_user_authorization(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_user_authorization(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         """Validate user is authorized for this intent"""
         start_time = time.perf_counter()
 
@@ -284,7 +290,9 @@ class ValidationGateRegistry:
             duration_ms=duration_ms,
         )
 
-    async def _validate_quantum_signature(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_quantum_signature(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         """Validate quantum-resistant cryptographic signature"""
         start_time = time.perf_counter()
 
@@ -303,7 +311,9 @@ class ValidationGateRegistry:
             duration_ms=duration_ms,
         )
 
-    async def _validate_threat_detection(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_threat_detection(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         """Detect potential security threats"""
         start_time = time.perf_counter()
 
@@ -326,7 +336,9 @@ class ValidationGateRegistry:
     # Layer C: Compliance Validation
     # ------------------------------------------------------------------------
 
-    async def _validate_policy_compliance(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_policy_compliance(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         """Validate compliance with organizational policies"""
         start_time = time.perf_counter()
 
@@ -344,7 +356,9 @@ class ValidationGateRegistry:
             duration_ms=duration_ms,
         )
 
-    async def _validate_regulatory_compliance(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_regulatory_compliance(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         """Validate regulatory compliance (GDPR, HIPAA, etc.)"""
         start_time = time.perf_counter()
 
@@ -362,7 +376,9 @@ class ValidationGateRegistry:
             duration_ms=duration_ms,
         )
 
-    async def _validate_ethical_boundaries(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_ethical_boundaries(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         """Validate ethical boundaries are respected"""
         start_time = time.perf_counter()
 
@@ -384,7 +400,9 @@ class ValidationGateRegistry:
     # Placeholder implementations for other layers (D, E, F)
     # ------------------------------------------------------------------------
 
-    async def _validate_resource_availability(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_resource_availability(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         start_time = time.perf_counter()
         duration_ms = (time.perf_counter() - start_time) * 1000
         return ValidationResult(
@@ -410,7 +428,9 @@ class ValidationGateRegistry:
             duration_ms=duration_ms,
         )
 
-    async def _validate_cost_optimization(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_cost_optimization(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         start_time = time.perf_counter()
         duration_ms = (time.perf_counter() - start_time) * 1000
         return ValidationResult(
@@ -423,7 +443,9 @@ class ValidationGateRegistry:
             duration_ms=duration_ms,
         )
 
-    async def _validate_pattern_analysis(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_pattern_analysis(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         start_time = time.perf_counter()
         duration_ms = (time.perf_counter() - start_time) * 1000
         return ValidationResult(
@@ -436,7 +458,9 @@ class ValidationGateRegistry:
             duration_ms=duration_ms,
         )
 
-    async def _validate_anomaly_detection(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_anomaly_detection(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         start_time = time.perf_counter()
         duration_ms = (time.perf_counter() - start_time) * 1000
         return ValidationResult(
@@ -462,7 +486,9 @@ class ValidationGateRegistry:
             duration_ms=duration_ms,
         )
 
-    async def _validate_output_quality(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_output_quality(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         start_time = time.perf_counter()
         duration_ms = (time.perf_counter() - start_time) * 1000
         return ValidationResult(
@@ -475,7 +501,9 @@ class ValidationGateRegistry:
             duration_ms=duration_ms,
         )
 
-    async def _validate_performance_sla(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_performance_sla(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         start_time = time.perf_counter()
         duration_ms = (time.perf_counter() - start_time) * 1000
         return ValidationResult(
@@ -488,7 +516,9 @@ class ValidationGateRegistry:
             duration_ms=duration_ms,
         )
 
-    async def _validate_user_satisfaction(self, context: Dict[str, Any]) -> ValidationResult:
+    async def _validate_user_satisfaction(
+        self, context: Dict[str, Any]
+    ) -> ValidationResult:
         start_time = time.perf_counter()
         duration_ms = (time.perf_counter() - start_time) * 1000
         return ValidationResult(
@@ -522,7 +552,9 @@ class MultiLayerValidator:
         # Load layer configurations
         self.layers = self._load_layer_config()
 
-        self.logger.info(f"MultiLayerValidator initialized with {len(self.layers)} layers")
+        self.logger.info(
+            f"MultiLayerValidator initialized with {len(self.layers)} layers"
+        )
 
     def _load_config(self, config_path: str) -> Dict[str, Any]:
         """Load validation configuration"""
@@ -548,7 +580,9 @@ class MultiLayerValidator:
         """Load layer configuration from main config"""
         return self.config.get("validation", {}).get("layers", {})
 
-    async def validate(self, context: Dict[str, Any]) -> Tuple[bool, List[LayerValidationResult]]:
+    async def validate(
+        self, context: Dict[str, Any]
+    ) -> Tuple[bool, List[LayerValidationResult]]:
         """
         Execute complete validation pipeline across all layers
 
@@ -562,7 +596,9 @@ class MultiLayerValidator:
         overall_success = True
 
         # Get ordered layers by priority
-        ordered_layers = sorted(self.layers.items(), key=lambda x: x[1].get("priority", 999))
+        ordered_layers = sorted(
+            self.layers.items(), key=lambda x: x[1].get("priority", 999)
+        )
 
         for layer_name, layer_config in ordered_layers:
             if not layer_config.get("enabled", False):
@@ -575,7 +611,9 @@ class MultiLayerValidator:
             # Check for blocking failures
             if layer_result.has_blocking_failures:
                 overall_success = False
-                self.logger.warning(f"Blocking failure in layer {layer_name}, stopping validation")
+                self.logger.warning(
+                    f"Blocking failure in layer {layer_name}, stopping validation"
+                )
                 break
 
             if not layer_result.passed:
@@ -606,7 +644,8 @@ class MultiLayerValidator:
 
         # Execute gates in parallel
         gate_tasks = [
-            self._execute_gate(gate_id, timeout_ms / 1000.0, context) for gate_id in gates
+            self._execute_gate(gate_id, timeout_ms / 1000.0, context)
+            for gate_id in gates
         ]
 
         gate_results = await asyncio.gather(*gate_tasks, return_exceptions=True)
@@ -640,7 +679,9 @@ class MultiLayerValidator:
             layer_status = ValidationStatus.WARNING
 
         # Update metrics
-        self.metrics.update(layer_name, duration_ms, layer_status == ValidationStatus.PASSED)
+        self.metrics.update(
+            layer_name, duration_ms, layer_status == ValidationStatus.PASSED
+        )
 
         return LayerValidationResult(
             layer_id=layer_name,
@@ -713,7 +754,10 @@ async def main():
             "intent": "deploy application to production",
             "preferences": {},
         },
-        "system_context": {"environment": "production", "resources": {"cpu": 0.5, "memory": 0.7}},
+        "system_context": {
+            "environment": "production",
+            "resources": {"cpu": 0.5, "memory": 0.7},
+        },
     }
 
     # Execute validation
diff --git a/workspace/docs/tutorials/namespace/tests/test_network_policy.py b/workspace/docs/tutorials/namespace/tests/test_network_policy.py
index 4ee2d46..7de09ba 100644
--- a/workspace/docs/tutorials/namespace/tests/test_network_policy.py
+++ b/workspace/docs/tutorials/namespace/tests/test_network_policy.py
@@ -72,7 +72,9 @@ def create_namespace(name: str, labels: Optional[dict] = None) -> None:
 def delete_namespace(name: str) -> None:
     """åˆªé™¤å‘½åç©ºé–“"""
     try:
-        run_kubectl(["delete", "namespace", name, "--grace-period=0", "--force", "--wait=false"])
+        run_kubectl(
+            ["delete", "namespace", name, "--grace-period=0", "--force", "--wait=false"]
+        )
     except KubectlError:
         pass
 
@@ -191,7 +193,9 @@ class TestNetworkPolicyCreation:
                         "from": [
                             {
                                 "namespaceSelector": {
-                                    "matchLabels": {"kubernetes.io/metadata.name": test_namespace}
+                                    "matchLabels": {
+                                        "kubernetes.io/metadata.name": test_namespace
+                                    }
                                 }
                             }
                         ]
@@ -249,7 +253,13 @@ class TestNetworkPolicyRules:
             "spec": {
                 "podSelector": {},
                 "policyTypes": ["Ingress"],
-                "ingress": [{"from": [{"namespaceSelector": {"matchLabels": {"role": "source"}}}]}],
+                "ingress": [
+                    {
+                        "from": [
+                            {"namespaceSelector": {"matchLabels": {"role": "source"}}}
+                        ]
+                    }
+                ],
             },
         }
 
@@ -310,7 +320,14 @@ class TestNetworkPolicyValidation:
                 "policyTypes": ["Egress"],
                 "egress": [
                     {
-                        "to": [{"ipBlock": {"cidr": "10.0.0.0/8", "except": ["10.0.0.0/24"]}}],
+                        "to": [
+                            {
+                                "ipBlock": {
+                                    "cidr": "10.0.0.0/8",
+                                    "except": ["10.0.0.0/24"],
+                                }
+                            }
+                        ],
                         "ports": [{"protocol": "TCP", "port": 443}],
                     }
                 ],
@@ -320,7 +337,9 @@ class TestNetworkPolicyValidation:
         apply_manifest(policy)
 
         policies = get_network_policies(test_namespace)
-        cidr_policy = next((p for p in policies if p["metadata"]["name"] == "allow-external"), None)
+        cidr_policy = next(
+            (p for p in policies if p["metadata"]["name"] == "allow-external"), None
+        )
 
         assert cidr_policy is not None
         ip_block = cidr_policy["spec"]["egress"][0]["to"][0]["ipBlock"]
@@ -367,7 +386,9 @@ class TestDNSPolicy:
                         "to": [
                             {
                                 "namespaceSelector": {
-                                    "matchLabels": {"kubernetes.io/metadata.name": "kube-system"}
+                                    "matchLabels": {
+                                        "kubernetes.io/metadata.name": "kube-system"
+                                    }
                                 }
                             }
                         ],
@@ -383,7 +404,9 @@ class TestDNSPolicy:
         apply_manifest(policy)
 
         policies = get_network_policies(test_namespace)
-        dns_policy = next((p for p in policies if p["metadata"]["name"] == "allow-dns"), None)
+        dns_policy = next(
+            (p for p in policies if p["metadata"]["name"] == "allow-dns"), None
+        )
 
         assert dns_policy is not None
         egress_ports = dns_policy["spec"]["egress"][0]["ports"]
diff --git a/workspace/docs/tutorials/namespace/tests/test_resource_quota.py b/workspace/docs/tutorials/namespace/tests/test_resource_quota.py
index ab8bdad..f57f7d9 100644
--- a/workspace/docs/tutorials/namespace/tests/test_resource_quota.py
+++ b/workspace/docs/tutorials/namespace/tests/test_resource_quota.py
@@ -72,7 +72,9 @@ def create_namespace(name: str, labels: Optional[dict] = None) -> None:
 def delete_namespace(name: str) -> None:
     """åˆªé™¤å‘½åç©ºé–“"""
     try:
-        run_kubectl(["delete", "namespace", name, "--grace-period=0", "--force", "--wait=false"])
+        run_kubectl(
+            ["delete", "namespace", name, "--grace-period=0", "--force", "--wait=false"]
+        )
     except KubectlError:
         pass
 
@@ -160,7 +162,9 @@ class TestResourceQuotaCreation:
         apply_manifest(quota)
 
         quotas = get_resource_quotas(test_namespace)
-        object_quota = next((q for q in quotas if q["metadata"]["name"] == "object-quota"), None)
+        object_quota = next(
+            (q for q in quotas if q["metadata"]["name"] == "object-quota"), None
+        )
 
         assert object_quota is not None
         assert object_quota["spec"]["hard"]["pods"] == "20"
@@ -183,7 +187,9 @@ class TestResourceQuotaCreation:
         apply_manifest(quota)
 
         quotas = get_resource_quotas(test_namespace)
-        storage_quota = next((q for q in quotas if q["metadata"]["name"] == "storage-quota"), None)
+        storage_quota = next(
+            (q for q in quotas if q["metadata"]["name"] == "storage-quota"), None
+        )
 
         assert storage_quota is not None
         assert storage_quota["spec"]["hard"]["requests.storage"] == "100Gi"
@@ -244,7 +250,9 @@ class TestLimitRangeCreation:
         apply_manifest(limit_range)
 
         limits = get_limit_ranges(test_namespace)
-        pod_limits = next((lr for lr in limits if lr["metadata"]["name"] == "pod-limits"), None)
+        pod_limits = next(
+            (lr for lr in limits if lr["metadata"]["name"] == "pod-limits"), None
+        )
 
         assert pod_limits is not None
         limit_spec = pod_limits["spec"]["limits"][0]
@@ -270,7 +278,9 @@ class TestLimitRangeCreation:
         apply_manifest(limit_range)
 
         limits = get_limit_ranges(test_namespace)
-        pvc_limits = next((lr for lr in limits if lr["metadata"]["name"] == "pvc-limits"), None)
+        pvc_limits = next(
+            (lr for lr in limits if lr["metadata"]["name"] == "pvc-limits"), None
+        )
 
         assert pvc_limits is not None
 
@@ -338,7 +348,9 @@ class TestQuotaScopes:
         apply_manifest(quota)
 
         quotas = get_resource_quotas(test_namespace)
-        be_quota = next((q for q in quotas if q["metadata"]["name"] == "best-effort-quota"), None)
+        be_quota = next(
+            (q for q in quotas if q["metadata"]["name"] == "best-effort-quota"), None
+        )
 
         assert be_quota is not None
         assert "BestEffort" in be_quota["spec"]["scopes"]
@@ -363,7 +375,8 @@ class TestQuotaScopes:
 
         quotas = get_resource_quotas(test_namespace)
         nbe_quota = next(
-            (q for q in quotas if q["metadata"]["name"] == "not-best-effort-quota"), None
+            (q for q in quotas if q["metadata"]["name"] == "not-best-effort-quota"),
+            None,
         )
 
         assert nbe_quota is not None
diff --git a/workspace/engine/machinenativenops-auto-monitor/setup.py b/workspace/engine/machinenativenops-auto-monitor/setup.py
index 0055420..a515e47 100755
--- a/workspace/engine/machinenativenops-auto-monitor/setup.py
+++ b/workspace/engine/machinenativenops-auto-monitor/setup.py
@@ -9,7 +9,9 @@ from setuptools import find_packages, setup
 
 # Read README
 readme_file = Path(__file__).parent / "README.md"
-long_description = readme_file.read_text(encoding="utf-8") if readme_file.exists() else ""
+long_description = (
+    readme_file.read_text(encoding="utf-8") if readme_file.exists() else ""
+)
 
 setup(
     name="machinenativenops-auto-monitor",
diff --git a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/__main__.py b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/__main__.py
index 1b87f21..7604d5c 100644
--- a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/__main__.py
+++ b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/__main__.py
@@ -72,11 +72,17 @@ Examples:
         default="/etc/machinenativeops/auto-monitor.yaml",
         help="Configuration file path (YAML)",
     )
-    parser.add_argument("--verbose", "-v", action="store_true", help="Enable verbose logging")
     parser.add_argument(
-        "--dry-run", action="store_true", help="Run without actually sending alerts or storing data"
+        "--verbose", "-v", action="store_true", help="Enable verbose logging"
+    )
+    parser.add_argument(
+        "--dry-run",
+        action="store_true",
+        help="Run without actually sending alerts or storing data",
+    )
+    parser.add_argument(
+        "--daemon", "-d", action="store_true", help="Run as daemon process"
     )
-    parser.add_argument("--daemon", "-d", action="store_true", help="Run as daemon process")
 
     # Parse arguments
     args = parser.parse_args()
@@ -93,12 +99,19 @@ Examples:
     monitor = AutoMonitor(config)
     monitor.run()
     parser.add_argument(
-        "--config", default="config/auto-monitor.yaml", help="Path to configuration file"
+        "--config",
+        default="config/auto-monitor.yaml",
+        help="Path to configuration file",
+    )
+    parser.add_argument(
+        "--mode",
+        choices=["collect", "alert", "monitor"],
+        default="monitor",
+        help="Operation mode",
     )
     parser.add_argument(
-        "--mode", choices=["collect", "alert", "monitor"], default="monitor", help="Operation mode"
+        "--interval", type=int, default=60, help="Collection interval in seconds"
     )
-    parser.add_argument("--interval", type=int, default=60, help="Collection interval in seconds")
     parser.add_argument("-v", "--verbose", action="store_true", help="Verbose output")
     parser.add_argument("--daemon", action="store_true", help="Run as daemon")
 
@@ -114,7 +127,9 @@ Examples:
         # Load configuration
         config_path = Path(args.config)
         if not config_path.exists():
-            logger.warning(f"Configuration file not found: {config_path}, using defaults")
+            logger.warning(
+                f"Configuration file not found: {config_path}, using defaults"
+            )
             config = AutoMonitorConfig()
         else:
             logger.info(f"Loading configuration from: {config_path}")
@@ -265,23 +280,31 @@ def main():
         default="/etc/machinenativeops/auto-monitor.yaml",
         help="Configuration file path (default: /etc/machinenativeops/auto-monitor.yaml)",
     )
-    parser.add_argument("--verbose", "-v", action="store_true", help="Enable verbose logging")
+    parser.add_argument(
+        "--verbose", "-v", action="store_true", help="Enable verbose logging"
+    )
 
     # Create subparsers for commands
     subparsers = parser.add_subparsers(dest="command", help="Available commands")
 
     # Serve command
     serve_parser = subparsers.add_parser("serve", help="Start monitoring service")
-    serve_parser.add_argument("--daemon", "-d", action="store_true", help="Run as daemon process")
+    serve_parser.add_argument(
+        "--daemon", "-d", action="store_true", help="Run as daemon process"
+    )
     serve_parser.set_defaults(func=cmd_serve)
 
     # Once command
     once_parser = subparsers.add_parser("once", help="Run collection once")
-    once_parser.add_argument("--output", "-o", help="Output file for results (JSON format)")
+    once_parser.add_argument(
+        "--output", "-o", help="Output file for results (JSON format)"
+    )
     once_parser.set_defaults(func=cmd_once)
 
     # Validate config command
-    validate_parser = subparsers.add_parser("validate-config", help="Validate configuration file")
+    validate_parser = subparsers.add_parser(
+        "validate-config", help="Validate configuration file"
+    )
     validate_parser.set_defaults(func=cmd_validate_config)
 
     # Parse arguments
diff --git a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/alerts.py b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/alerts.py
index 5e15fef..a5e720b 100644
--- a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/alerts.py
+++ b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/alerts.py
@@ -129,7 +129,11 @@ class AlertManager:
                 state=AlertState.FIRING,
                 message=f"{metric_name} is at {value:.1f}% (threshold: {threshold}%)",
                 source="auto-monitor",
-                metadata={"metric": metric_name, "value": value, "threshold": threshold},
+                metadata={
+                    "metric": metric_name,
+                    "value": value,
+                    "threshold": threshold,
+                },
             )
             return alert
 
@@ -157,7 +161,9 @@ class AlertManager:
             existing.timestamp = alert.timestamp
             existing.metadata = alert.metadata
         else:
-            logger.info(f"New alert: {alert.name} - {alert.severity.value} - {alert.message}")
+            logger.info(
+                f"New alert: {alert.name} - {alert.severity.value} - {alert.message}"
+            )
             self.active_alerts.append(alert)
             self._notify_alert(alert)
 
@@ -349,7 +355,9 @@ class AlertManager:
         self.active_alerts[rule.name] = alert
         self.alert_history.append(alert)
 
-        self.logger.warning(f"ALERT FIRED: {alert.name} [{alert.severity.value}] - {alert.message}")
+        self.logger.warning(
+            f"ALERT FIRED: {alert.name} [{alert.severity.value}] - {alert.message}"
+        )
 
         # Send notification (would integrate with actual notification system)
         self._send_notification(alert)
@@ -385,7 +393,9 @@ class AlertManager:
         """
         # In production, this would integrate with notification channels
         # (email, Slack, PagerDuty, etc.)
-        self.logger.info(f"Notification sent for alert: {alert.name} ({alert.state.value})")
+        self.logger.info(
+            f"Notification sent for alert: {alert.name} ({alert.state.value})"
+        )
 
     def get_active_alerts(self) -> List[Alert]:
         """Get list of active alerts."""
diff --git a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/app.py b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/app.py
index 4870e25..9764909 100644
--- a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/app.py
+++ b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/app.py
@@ -8,18 +8,20 @@ Auto-Monitor Application
 Main application logic for the auto-monitor system.
 """
 
-from .config import MonitorConfig
-from .collectors import MetricCollector, ServiceCollector, SystemCollector
-from .alerts import AlertManager, AlertSeverity
 import logging
 import threading
 import time
 from datetime import datetime
 from typing import Any, Dict
 
-from .alerts import AlertManager
-from .collectors import MetricsCollector, ServiceCollector, SystemCollector
-from .config import AutoMonitorConfig
+from .alerts import AlertManager, AlertSeverity
+from .collectors import (
+    MetricCollector,
+    MetricsCollector,
+    ServiceCollector,
+    SystemCollector,
+)
+from .config import AutoMonitorConfig, MonitorConfig
 from .å„²å­˜ import StorageManager
 
 
@@ -51,7 +53,9 @@ class AutoMonitorApp:
         # Metrics collectors
         self.system_collector = SystemCollector(config.collectors.get("system", {}))
         self.service_collector = ServiceCollector(config.collectors.get("service", {}))
-        self.metrics_collector = MetricsCollector([self.system_collector, self.service_collector])
+        self.metrics_collector = MetricsCollector(
+            [self.system_collector, self.service_collector]
+        )
 
         # Alert manager
         self.alert_manager = AlertManager(config.alerts)
@@ -211,7 +215,11 @@ class AutoMonitorApp:
 
             # Store metrics
             self._store_metrics(
-                {"system": system_metrics, "services": service_metrics, "custom": custom_metrics}
+                {
+                    "system": system_metrics,
+                    "services": service_metrics,
+                    "custom": custom_metrics,
+                }
             )
 
             logger.info("Collection cycle complete")
@@ -290,7 +298,9 @@ class AutoMonitorApp:
                 )
                 self.alert_manager.add_alert(alert)
             else:
-                self.alert_manager.resolve_alert(f"service_{service_name}_down", "auto-monitor")
+                self.alert_manager.resolve_alert(
+                    f"service_{service_name}_down", "auto-monitor"
+                )
 
     def _store_metrics(self, metrics: Dict[str, Any]):
         """Store collected metrics"""
@@ -523,11 +533,15 @@ class MachineNativeOpsAutoMonitor:
     def _init_prometheus_metrics(self):
         """Initialize Prometheus metrics"""
         self.metrics = {
-            "cpu_usage": Gauge("machinenativenops_cpu_usage_percent", "CPU usage percentage"),
+            "cpu_usage": Gauge(
+                "machinenativenops_cpu_usage_percent", "CPU usage percentage"
+            ),
             "memory_usage": Gauge(
                 "machinenativenops_memory_usage_percent", "Memory usage percentage"
             ),
-            "disk_usage": Gauge("machinenativenops_disk_usage_percent", "Disk usage percentage"),
+            "disk_usage": Gauge(
+                "machinenativenops_disk_usage_percent", "Disk usage percentage"
+            ),
             "network_bytes_sent": Gauge(
                 "machinenativenops_network_bytes_sent_total", "Total bytes sent"
             ),
@@ -538,7 +552,8 @@ class MachineNativeOpsAutoMonitor:
                 "machinenativenops_quantum_fidelity", "Quantum state fidelity"
             ),
             "quantum_coherence_time": Gauge(
-                "machinenativenops_quantum_coherence_time_microseconds", "Quantum coherence time"
+                "machinenativenops_quantum_coherence_time_microseconds",
+                "Quantum coherence time",
             ),
             "quantum_error_rate": Gauge(
                 "machinenativenops_quantum_error_rate", "Quantum error rate"
@@ -549,7 +564,9 @@ class MachineNativeOpsAutoMonitor:
             "collection_duration": Histogram(
                 "machinenativenops_collection_duration_seconds", "Collection duration"
             ),
-            "alerts_total": Counter("machinenativenops_alerts_total", "Total alerts triggered"),
+            "alerts_total": Counter(
+                "machinenativenops_alerts_total", "Total alerts triggered"
+            ),
         }
 
         self.logger.info("Prometheus metrics initialized")
@@ -572,7 +589,11 @@ class MachineNativeOpsAutoMonitor:
                     "architecture_hash": self.config.architecture_hash,
                     "database_status": "ok" if db_status else "error",
                     "system_load": system_load,
-                    "uptime": time.time() - self.start_time if hasattr(self, "start_time") else 0,
+                    "uptime": (
+                        time.time() - self.start_time
+                        if hasattr(self, "start_time")
+                        else 0
+                    ),
                 }
 
                 # Include service status if not healthy
@@ -626,7 +647,9 @@ class MachineNativeOpsAutoMonitor:
                 return JSONResponse({"metrics": metrics, "count": len(metrics)})
             except Exception as e:
                 self.logger.error(f"Failed to get metrics: {e}")
-                raise HTTPException(status_code=500, detail="Failed to retrieve metrics")
+                raise HTTPException(
+                    status_code=500, detail="Failed to retrieve metrics"
+                )
 
         @self.app.get("/api/v1/alerts")
         async def get_alerts():
diff --git a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/collectors.py b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/collectors.py
index 703999d..2a85d8d 100644
--- a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/collectors.py
+++ b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/collectors.py
@@ -8,13 +8,11 @@ Metric Collectors
 Collects various metrics from the system and services.
 """
 
-from typing import Dict, List, Optional
-from dataclasses import asdict, dataclass
 import logging
 import platform
 import subprocess
 from abc import ABC, abstractmethod
-from dataclasses import dataclass
+from dataclasses import asdict, dataclass
 from datetime import datetime
 from typing import Any, Dict, List, Optional
 
@@ -256,7 +254,9 @@ class MetricsCollector:
                 all_metrics.update(collector_metrics)
 
             except Exception as e:
-                self.logger.error(f"Error collecting from {collector.__class__.__name__}: {e}")
+                self.logger.error(
+                    f"Error collecting from {collector.__class__.__name__}: {e}"
+                )
 
         return all_metrics
 
@@ -276,7 +276,9 @@ class MetricsCollector:
         Args:
             collector_class: Class of collector to remove
         """
-        self.collectors = [c for c in self.collectors if not isinstance(c, collector_class)]
+        self.collectors = [
+            c for c in self.collectors if not isinstance(c, collector_class)
+        ]
 
 
 logger = logging.getLogger(__name__)
@@ -385,7 +387,9 @@ class ServiceCollector(MetricCollector):
 
         return service_metrics
 
-    def _check_service(self, service_name: str, config: Dict[str, Any]) -> Dict[str, Any]:
+    def _check_service(
+        self, service_name: str, config: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Check individual service health"""
         check_type = config.get("type", "process")
 
@@ -399,7 +403,9 @@ class ServiceCollector(MetricCollector):
             logger.warning(f"Unknown service check type: {check_type}")
             return {"healthy": False, "error": "unknown check type"}
 
-    def _check_process(self, service_name: str, config: Dict[str, Any]) -> Dict[str, Any]:
+    def _check_process(
+        self, service_name: str, config: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Check if a process is running"""
         process_name = config.get("process_name", service_name)
 
@@ -424,7 +430,9 @@ class ServiceCollector(MetricCollector):
             logger.error(f"Error checking process {process_name}: {e}")
             return {"healthy": False, "status": "error", "error": str(e)}
 
-    def _check_http_endpoint(self, service_name: str, config: Dict[str, Any]) -> Dict[str, Any]:
+    def _check_http_endpoint(
+        self, service_name: str, config: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Check HTTP endpoint health"""
         # TODO: Implement HTTP health check
         logger.warning(f"HTTP health check not implemented for {service_name}")
@@ -567,7 +575,9 @@ class MetricsCollector:
                 "memory_mb": process.memory_info().rss / (1024**2),
                 "num_threads": process.num_threads(),
                 "status": process.status(),
-                "create_time": datetime.fromtimestamp(process.create_time()).isoformat(),
+                "create_time": datetime.fromtimestamp(
+                    process.create_time()
+                ).isoformat(),
             }
         except Exception as e:
             logger.error(f"Error collecting process metrics: {e}")
@@ -636,7 +646,9 @@ class EventCollector:
                 severity="warning",
             )
 
-    def add_event(self, type: str, description: str, severity: str, metadata: Dict = None):
+    def add_event(
+        self, type: str, description: str, severity: str, metadata: Dict = None
+    ):
         """Add an event to the buffer."""
         event = Event(
             type=type,
@@ -772,7 +784,9 @@ class SystemCollector:
                     "load_average": load_avg,
                     "os_info": {
                         "system": os.name,
-                        "platform": os.uname().sysname if hasattr(os, "uname") else None,
+                        "platform": (
+                            os.uname().sysname if hasattr(os, "uname") else None
+                        ),
                         "release": os.uname().release if hasattr(os, "uname") else None,
                         "version": os.uname().version if hasattr(os, "uname") else None,
                     },
@@ -789,7 +803,9 @@ class SystemCollector:
             self.logger.error(f"Failed to collect system metrics: {e}")
             raise
 
-    def _flatten_metrics(self, metrics: Dict[str, Any], prefix: str = "") -> Dict[str, Any]:
+    def _flatten_metrics(
+        self, metrics: Dict[str, Any], prefix: str = ""
+    ) -> Dict[str, Any]:
         """Flatten nested metrics dictionary"""
         flat = {}
 
@@ -850,7 +866,11 @@ class QuantumCollector:
         """Get quantum fidelity (simulated)"""
         # In real implementation, this would query quantum hardware
         return max(
-            0.0, min(1.0, self.config.fidelity_threshold + (hash(time.time()) % 100 - 50) / 1000)
+            0.0,
+            min(
+                1.0,
+                self.config.fidelity_threshold + (hash(time.time()) % 100 - 50) / 1000,
+            ),
         )
 
     def _get_quantum_coherence_time(self) -> float:
@@ -861,7 +881,9 @@ class QuantumCollector:
     def _get_quantum_error_rate(self) -> float:
         """Get quantum error rate (simulated)"""
         # In real implementation, this would measure actual error rates
-        return max(0.0, self.config.error_rate_threshold - (hash(time.time()) % 100) / 10000)
+        return max(
+            0.0, self.config.error_rate_threshold - (hash(time.time()) % 100) / 10000
+        )
 
     def _get_active_qubits(self) -> int:
         """Get number of active qubits (simulated)"""
@@ -1013,7 +1035,9 @@ class KubernetesCollector:
                         )
 
                     # Check if deployment is ready
-                    if (deploy.status.ready_replicas or 0) == (deploy.spec.replicas or 0):
+                    if (deploy.status.ready_replicas or 0) == (
+                        deploy.spec.replicas or 0
+                    ):
                         ready_deployments += 1
 
                     deployments.append(deployment_info)
diff --git a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/config.py b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/config.py
index 0d2af01..3258fa3 100644
--- a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/config.py
+++ b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/config.py
@@ -8,10 +8,8 @@ Configuration Module
 Manages configuration for the auto-monitor system.
 """
 
-from dataclasses import asdict, dataclass, field
-from typing import Dict, Optional
 import logging
-from dataclasses import dataclass, field
+from dataclasses import asdict, dataclass, field
 from pathlib import Path
 from typing import Any, Dict, Optional
 
@@ -281,7 +279,9 @@ def validate_config(config: MonitorConfig) -> bool:
     alert_rules = config.get("alerts", {}).get("alert_rules", {})
     for threshold_name, threshold_value in alert_rules.items():
         if not isinstance(threshold_value, (int, float)):
-            logger.error(f"Invalid threshold value for {threshold_name}: {threshold_value}")
+            logger.error(
+                f"Invalid threshold value for {threshold_name}: {threshold_value}"
+            )
             return False
         if threshold_value < 0 or threshold_value > 100:
             logger.warning(
diff --git a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/storage.py b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/storage.py
index 6c9af64..9cdb76f 100644
--- a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/storage.py
+++ b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/storage.py
@@ -113,7 +113,8 @@ class DatabaseManager:
             with self._get_connection() as conn:
                 cursor = conn.cursor()
                 cursor.execute(
-                    "INSERT INTO metrics (timestamp, data) VALUES (?, ?)", (timestamp, data_json)
+                    "INSERT INTO metrics (timestamp, data) VALUES (?, ?)",
+                    (timestamp, data_json),
                 )
                 conn.commit()
 
@@ -175,7 +176,9 @@ class DatabaseManager:
         try:
             with self._get_connection() as conn:
                 cursor = conn.cursor()
-                cursor.execute("SELECT * FROM metrics ORDER BY timestamp DESC LIMIT ?", (limit,))
+                cursor.execute(
+                    "SELECT * FROM metrics ORDER BY timestamp DESC LIMIT ?", (limit,)
+                )
                 rows = cursor.fetchall()
 
                 metrics = []
@@ -194,7 +197,11 @@ class DatabaseManager:
             raise
 
     def store_alert(
-        self, alert_type: str, severity: str, message: str, data: Optional[Dict[str, Any]] = None
+        self,
+        alert_type: str,
+        severity: str,
+        message: str,
+        data: Optional[Dict[str, Any]] = None,
     ):
         """Store alert data"""
         try:
@@ -266,7 +273,11 @@ class DatabaseManager:
             raise
 
     def store_system_event(
-        self, event_type: str, component: str, message: str, data: Optional[Dict[str, Any]] = None
+        self,
+        event_type: str,
+        component: str,
+        message: str,
+        data: Optional[Dict[str, Any]] = None,
     ):
         """Store system event"""
         try:
@@ -289,7 +300,10 @@ class DatabaseManager:
             raise
 
     def get_system_events(
-        self, event_type: Optional[str] = None, component: Optional[str] = None, limit: int = 100
+        self,
+        event_type: Optional[str] = None,
+        component: Optional[str] = None,
+        limit: int = 100,
     ) -> List[Dict[str, Any]]:
         """Get system events"""
         try:
@@ -343,7 +357,9 @@ class DatabaseManager:
                 cursor = conn.cursor()
 
                 # Clean old metrics
-                cursor.execute("DELETE FROM metrics WHERE created_at < ?", (cutoff_iso,))
+                cursor.execute(
+                    "DELETE FROM metrics WHERE created_at < ?", (cutoff_iso,)
+                )
                 metrics_deleted = cursor.rowcount
 
                 # Clean old resolved alerts
@@ -355,7 +371,9 @@ class DatabaseManager:
                 alerts_deleted = cursor.rowcount
 
                 # Clean old system events
-                cursor.execute("DELETE FROM system_events WHERE created_at < ?", (cutoff_iso,))
+                cursor.execute(
+                    "DELETE FROM system_events WHERE created_at < ?", (cutoff_iso,)
+                )
                 events_deleted = cursor.rowcount
 
                 conn.commit()
diff --git "a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/\345\204\262\345\255\230.py" "b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/\345\204\262\345\255\230.py"
index e2db180..e56df34 100644
--- "a/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/\345\204\262\345\255\230.py"
+++ "b/workspace/engine/machinenativenops-auto-monitor/src/machinenativenops_auto_monitor/\345\204\262\345\255\230.py"
@@ -10,11 +10,11 @@ Handles metric and alert data storage.
 è™•ç†æŒ‡æ¨™å’Œå‘Šè­¦æ•¸æ“šçš„å„²å­˜ã€‚
 """
 
-from abc import ABC, abstractmethod
-from collections import deque
 import json
 import logging
 import sqlite3
+from abc import ABC, abstractmethod
+from collections import deque
 from dataclasses import dataclass
 from datetime import datetime, timedelta
 from pathlib import Path
@@ -141,7 +141,9 @@ class TimeSeriesStorage:
         except Exception as e:
             self.logger.error(f"Error storing metric {name}: {e}")
 
-    def store_metrics(self, metrics: Dict[str, float], timestamp: Optional[datetime] = None):
+    def store_metrics(
+        self, metrics: Dict[str, float], timestamp: Optional[datetime] = None
+    ):
         """
         æ‰¹é‡å„²å­˜æŒ‡æ¨™ / Store multiple metrics in batch.
 
@@ -156,7 +158,10 @@ class TimeSeriesStorage:
             cursor = self.connection.cursor()
 
             # æº–å‚™æ‰¹é‡æ’å…¥æ•¸æ“š / Prepare batch insert data
-            data = [(name, value, timestamp, json.dumps({})) for name, value in metrics.items()]
+            data = [
+                (name, value, timestamp, json.dumps({}))
+                for name, value in metrics.items()
+            ]
 
             cursor.executemany(
                 """
@@ -413,7 +418,9 @@ class MemoryStorage(MetricStorage):
         if metric_name not in self.metrics:
             self.metrics[metric_name] = []
 
-        self.metrics[metric_name].append({"value": value, "timestamp": timestamp.isoformat()})
+        self.metrics[metric_name].append(
+            {"value": value, "timestamp": timestamp.isoformat()}
+        )
 
         # Trim if exceeds max size
         if len(self.metrics[metric_name]) > self.max_size:
diff --git a/workspace/examples/debug-examples/demo.py b/workspace/examples/debug-examples/demo.py
index 00901cb..f73ea46 100644
--- a/workspace/examples/debug-examples/demo.py
+++ b/workspace/examples/debug-examples/demo.py
@@ -9,7 +9,9 @@ import asyncio
 import sys
 from pathlib import Path
 
-from src.core.machinenativenops.run_debug.adapters.python_adapter import PythonDebugAdapter
+from src.core.machinenativenops.run_debug.adapters.python_adapter import (
+    PythonDebugAdapter,
+)
 from src.core.machinenativenops.run_debug.chat_interface import ChatDebugInterface
 from src.core.machinenativenops.run_debug.engine import (
     BreakpointType,
diff --git a/workspace/examples/debug-examples/sample_app.py b/workspace/examples/debug-examples/sample_app.py
index a3a1c3b..9928f80 100644
--- a/workspace/examples/debug-examples/sample_app.py
+++ b/workspace/examples/debug-examples/sample_app.py
@@ -22,13 +22,17 @@ class Calculator:
     def subtract(self, a: float, b: float) -> float:
         """æ¸›æ³•"""
         result = a - b
-        self.history.append({"operation": "subtract", "operands": [a, b], "result": result})
+        self.history.append(
+            {"operation": "subtract", "operands": [a, b], "result": result}
+        )
         return result
 
     def multiply(self, a: float, b: float) -> float:
         """ä¹˜æ³•"""
         result = a * b
-        self.history.append({"operation": "multiply", "operands": [a, b], "result": result})
+        self.history.append(
+            {"operation": "multiply", "operands": [a, b], "result": result}
+        )
         return result
 
     def divide(self, a: float, b: float) -> float:
@@ -39,7 +43,9 @@ class Calculator:
             raise ValueError("Cannot divide by zero")
 
         result = a / b
-        self.history.append({"operation": "divide", "operands": [a, b], "result": result})
+        self.history.append(
+            {"operation": "divide", "operands": [a, b], "result": result}
+        )
         return result
 
     def get_history(self) -> List[Dict]:
diff --git a/workspace/examples/enterprise-orchestrator-example.py b/workspace/examples/enterprise-orchestrator-example.py
index 59ff9c2..1e7a238 100644
--- a/workspace/examples/enterprise-orchestrator-example.py
+++ b/workspace/examples/enterprise-orchestrator-example.py
@@ -168,14 +168,18 @@ async def demo_fault_tolerance():
 
     # åŸ·è¡Œæœƒå¤±æ•—çš„ä»»å‹™
     print("\nâŒ åŸ·è¡Œæœƒå¤±æ•—çš„ä»»å‹™:")
-    result = await orchestrator.execute_with_retry(failing_task, "test_component", tenant_id)
+    result = await orchestrator.execute_with_retry(
+        failing_task, "test_component", tenant_id
+    )
     print(f"  ç‹€æ…‹: {result.status.value}")
     print(f"  é‡è©¦æ¬¡æ•¸: {result.retry_count}")
     print(f"  åŸ·è¡Œæ™‚é–“: {result.duration_ms:.0f} ms")
 
     # åŸ·è¡ŒæˆåŠŸçš„ä»»å‹™
     print("\nâœ… åŸ·è¡ŒæˆåŠŸçš„ä»»å‹™:")
-    result = await orchestrator.execute_with_retry(success_task, "success_component", tenant_id)
+    result = await orchestrator.execute_with_retry(
+        success_task, "success_component", tenant_id
+    )
     print(f"  ç‹€æ…‹: {result.status.value}")
     print(f"  é‡è©¦æ¬¡æ•¸: {result.retry_count}")
     print(f"  è¼¸å‡º: {result.output}")
@@ -197,7 +201,9 @@ async def demo_resource_management():
     # å‰µå»ºä¸åŒé…é¡çš„ç§Ÿæˆ¶
     basic_tenant = orchestrator.create_tenant("åŸºç¤è¨ˆåŠƒå®¢æˆ¶", TenantTier.BASIC)
 
-    enterprise_tenant = orchestrator.create_tenant("ä¼æ¥­è¨ˆåŠƒå®¢æˆ¶", TenantTier.ENTERPRISE)
+    enterprise_tenant = orchestrator.create_tenant(
+        "ä¼æ¥­è¨ˆåŠƒå®¢æˆ¶", TenantTier.ENTERPRISE
+    )
 
     # æª¢æŸ¥é…é¡
     print("\nğŸ“Š åŸºç¤è¨ˆåŠƒé…é¡:")
diff --git a/workspace/governance-system-implementation.py b/workspace/governance-system-implementation.py
index c0e7a66..6fef47f 100755
--- a/workspace/governance-system-implementation.py
+++ b/workspace/governance-system-implementation.py
@@ -32,7 +32,8 @@ import yaml
 
 # Configure logging
 logging.basicConfig(
-    level=logging.INFO, format="%(asctime)s - %(levelname)s - [GovernanceSystem] - %(message)s"
+    level=logging.INFO,
+    format="%(asctime)s - %(levelname)s - [GovernanceSystem] - %(message)s",
 )
 logger = logging.getLogger(__name__)
 
@@ -132,9 +133,15 @@ class GovernanceClosedLoopSystem:
 
     def __init__(self, config_path: str = None):
         self.config = self._load_config(config_path)
-        self.evidence_base_dir = Path(self.config.get("evidence_base_dir", "./governance/evidence"))
-        self.exceptions_dir = Path(self.config.get("exceptions_dir", "./governance/exceptions"))
-        self.rollback_dir = Path(self.config.get("rollback_dir", "./governance/rollback"))
+        self.evidence_base_dir = Path(
+            self.config.get("evidence_base_dir", "./governance/evidence")
+        )
+        self.exceptions_dir = Path(
+            self.config.get("exceptions_dir", "./governance/exceptions")
+        )
+        self.rollback_dir = Path(
+            self.config.get("rollback_dir", "./governance/rollback")
+        )
 
         # å‰µå»ºç›®éŒ„çµæ§‹
         self._setup_directories()
@@ -212,7 +219,9 @@ class GovernanceClosedLoopSystem:
         gate_checks = self._define_gate_checks(verification_results)
 
         for gate_name, gate_config in gate_checks.items():
-            check_result = self._evaluate_single_gate(gate_name, gate_config, verification_results)
+            check_result = self._evaluate_single_gate(
+                gate_name, gate_config, verification_results
+            )
             gate_results["gates"][gate_name] = {
                 "name": check_result.name,
                 "level": check_result.level.value,
@@ -224,7 +233,9 @@ class GovernanceClosedLoopSystem:
             }
 
         # è¨ˆç®—æœ€çµ‚æ±ºç­–
-        gate_results["final_decision"] = self._calculate_final_decision(gate_results["gates"])
+        gate_results["final_decision"] = self._calculate_final_decision(
+            gate_results["gates"]
+        )
 
         logger.info(f"âœ… Gate è©•ä¼°å®Œæˆ: {gate_results['final_decision']['decision']}")
         return gate_results
@@ -279,7 +290,10 @@ class GovernanceClosedLoopSystem:
         }
 
     def _evaluate_single_gate(
-        self, gate_name: str, gate_config: Dict[str, Any], verification_results: Dict[str, Any]
+        self,
+        gate_name: str,
+        gate_config: Dict[str, Any],
+        verification_results: Dict[str, Any],
     ) -> GateCheckResult:
         """è©•ä¼°å–®å€‹ Gate"""
         level = gate_config["level"]
@@ -312,7 +326,9 @@ class GovernanceClosedLoopSystem:
             details={"threshold": threshold, "actual": actual_value, "source": source},
         )
 
-    def _extract_value_from_results(self, source: str, results: Dict[str, Any]) -> float:
+    def _extract_value_from_results(
+        self, source: str, results: Dict[str, Any]
+    ) -> float:
         """å¾é©—è­‰çµæœä¸­æå–æ•¸å€¼"""
         try:
             parts = source.split(".")
@@ -346,7 +362,9 @@ class GovernanceClosedLoopSystem:
         else:
             return GateDecision.LOG_ONLY
 
-    def _calculate_final_decision(self, gate_results: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
+    def _calculate_final_decision(
+        self, gate_results: Dict[str, Dict[str, Any]]
+    ) -> Dict[str, Any]:
         """è¨ˆç®—æœ€çµ‚æ±ºç­–"""
         decisions = [result["decision"] for result in gate_results.values()]
 
@@ -358,9 +376,9 @@ class GovernanceClosedLoopSystem:
             final_score = min(result["score"] for result in gate_results.values())
         else:
             final_decision = "ALLOW"
-            final_score = sum(result["score"] for result in gate_results.values()) / len(
-                gate_results
-            )
+            final_score = sum(
+                result["score"] for result in gate_results.values()
+            ) / len(gate_results)
 
         return {
             "decision": final_decision,
@@ -368,17 +386,23 @@ class GovernanceClosedLoopSystem:
             "passed_checks": sum(
                 1
                 for result in gate_results.values()
-                if result["decision"] in [GateDecision.ALLOW, GateDecision.WARN_WITH_OVERRIDE]
+                if result["decision"]
+                in [GateDecision.ALLOW, GateDecision.WARN_WITH_OVERRIDE]
             ),
             "total_checks": len(gate_results),
             "critical_failures": sum(
-                1 for result in gate_results.values() if result["decision"] == GateDecision.BLOCK
+                1
+                for result in gate_results.values()
+                if result["decision"] == GateDecision.BLOCK
             ),
         }
 
     # ===== 2. Evidence Bundle æ¶æ§‹ =====
     def create_evidence_bundle(
-        self, trace_id: str, verification_results: Dict[str, Any], gate_results: Dict[str, Any]
+        self,
+        trace_id: str,
+        verification_results: Dict[str, Any],
+        gate_results: Dict[str, Any],
     ) -> EvidenceBundle:
         """å‰µå»ºè­‰æ“šåŒ…"""
         logger.info(f"ğŸ“¦ å‰µå»ºè­‰æ“šåŒ…: {trace_id}")
@@ -395,7 +419,9 @@ class GovernanceClosedLoopSystem:
                 "creator": "governance-system@machinenativeops.io",
                 "stages": len(verification_results.get("evidence_chain", [])),
                 "complianceScore": gate_results["final_decision"]["score"],
-                "finalHash": self._calculate_bundle_hash(verification_results, gate_results),
+                "finalHash": self._calculate_bundle_hash(
+                    verification_results, gate_results
+                ),
                 "immutable": True,
                 "retention": f"{self.config['storage']['retention_years']}y",
             }
@@ -476,7 +502,10 @@ class GovernanceClosedLoopSystem:
                 "traceId": bundle_dir.name.replace("trace-", ""),
                 "timestamp": datetime.now(timezone.utc).isoformat(),
                 "version": "v1.0",
-                "algorithms": {"content": self.content_algo, "semantic": self.semantic_algo},
+                "algorithms": {
+                    "content": self.content_algo,
+                    "semantic": self.semantic_algo,
+                },
             },
             "artifacts": [],
         }
@@ -505,7 +534,9 @@ class GovernanceClosedLoopSystem:
                         )
 
         # è¨ˆç®— Bundle Hash
-        bundle_hash = hashlib.sha3_512(json.dumps(digests, sort_keys=True).encode()).hexdigest()
+        bundle_hash = hashlib.sha3_512(
+            json.dumps(digests, sort_keys=True).encode()
+        ).hexdigest()
         digests["bundleHash"] = f"{self.semantic_algo}:{bundle_hash}"
 
         # ä¿å­˜ digests æ–‡ä»¶
@@ -531,7 +562,10 @@ class GovernanceClosedLoopSystem:
                 else:
                     data = yaml.safe_load(content.decode())
                     canonical = yaml.dump(
-                        data, sort_keys=True, default_flow_style=False, allow_unicode=True
+                        data,
+                        sort_keys=True,
+                        default_flow_style=False,
+                        allow_unicode=True,
                     )
 
                 semantic_hash = hashlib.sha3_512(canonical.encode()).hexdigest()
@@ -547,7 +581,9 @@ class GovernanceClosedLoopSystem:
             file_path=str(file_path),
         )
 
-    def _copy_verification_stages(self, bundle_dir: Path, verification_results: Dict[str, Any]):
+    def _copy_verification_stages(
+        self, bundle_dir: Path, verification_results: Dict[str, Any]
+    ):
         """è¤‡è£½é©—è­‰éšæ®µçµæœåˆ°è­‰æ“šåŒ…"""
         evidence_chain = verification_results.get("evidence_chain", [])
 
@@ -561,7 +597,10 @@ class GovernanceClosedLoopSystem:
                 stage_name = getattr(stage_info, "stage_name", "unknown")
                 stage_data_dict = stage_info.__dict__
 
-            stage_dir = bundle_dir / f"stage{stage_num:02d}-{stage_name.replace(' ', '_').lower()}"
+            stage_dir = (
+                bundle_dir
+                / f"stage{stage_num:02d}-{stage_name.replace(' ', '_').lower()}"
+            )
             stage_dir.mkdir(exist_ok=True)
 
             # ä¿å­˜éšæ®µæ•¸æ“š
@@ -581,7 +620,10 @@ class GovernanceClosedLoopSystem:
         self, verification_results: Dict[str, Any], gate_results: Dict[str, Any]
     ) -> str:
         """è¨ˆç®— Bundle æœ€çµ‚ Hash"""
-        combined_data = {"verification_results": verification_results, "gate_results": gate_results}
+        combined_data = {
+            "verification_results": verification_results,
+            "gate_results": gate_results,
+        }
         data_str = json.dumps(combined_data, sort_keys=True, default=str)
         return hashlib.sha3_512(data_str.encode()).hexdigest()
 
@@ -600,7 +642,9 @@ class GovernanceClosedLoopSystem:
         logger.info(f"ğŸš¨ å‰µå»ºä¾‹å¤–è«‹æ±‚: {gate_check}")
 
         request_id = f"EXC-{datetime.now(timezone.utc).strftime('%Y-%m-%d')}-{len(list(self.exceptions_dir.glob('EXC-*'))) + 1:03d}"
-        expiry_date = (datetime.now(timezone.utc) + timedelta(days=expiry_days)).isoformat()
+        expiry_date = (
+            datetime.now(timezone.utc) + timedelta(days=expiry_days)
+        ).isoformat()
 
         exception_request = ExceptionRequest(
             request_id=request_id,
@@ -790,9 +834,13 @@ class GovernanceClosedLoopSystem:
             "calculated_at": datetime.now(timezone.utc).isoformat(),
             "metrics": {
                 "gate_efficiency": self._calculate_gate_efficiency_kpi(time_range),
-                "evidence_integrity": self._calculate_evidence_integrity_kpi(time_range),
+                "evidence_integrity": self._calculate_evidence_integrity_kpi(
+                    time_range
+                ),
                 "reproducibility": self._calculate_reproducibility_kpi(time_range),
-                "exception_management": self._calculate_exception_management_kpi(time_range),
+                "exception_management": self._calculate_exception_management_kpi(
+                    time_range
+                ),
                 "drift_monitoring": self._calculate_drift_monitoring_kpi(time_range),
             },
         }
@@ -810,16 +858,24 @@ class GovernanceClosedLoopSystem:
 
     def _calculate_evidence_integrity_kpi(self, time_range: int) -> Dict[str, float]:
         """è¨ˆç®—è­‰æ“šå®Œæ•´æ€§ KPI"""
-        return {"evidence_completeness_rate": 99.2, "evidence_verification_rate": 98.8}  # %  # %
+        return {
+            "evidence_completeness_rate": 99.2,
+            "evidence_verification_rate": 98.8,
+        }  # %  # %
 
     def _calculate_reproducibility_kpi(self, time_range: int) -> Dict[str, float]:
         """è¨ˆç®—é‡ç¾æ€§ KPI"""
-        return {"replay_consistency_rate": 96.3, "reproducibility_pass_rate": 93.7}  # %  # %
+        return {
+            "replay_consistency_rate": 96.3,
+            "reproducibility_pass_rate": 93.7,
+        }  # %  # %
 
     def _calculate_exception_management_kpi(self, time_range: int) -> Dict[str, float]:
         """è¨ˆç®—ä¾‹å¤–ç®¡ç† KPI"""
         active_exceptions = len(list(self.exceptions_dir.glob("active/*.yaml")))
-        total_exceptions = active_exceptions + len(list(self.exceptions_dir.glob("expired/*.yaml")))
+        total_exceptions = active_exceptions + len(
+            list(self.exceptions_dir.glob("expired/*.yaml"))
+        )
 
         overdue_count = 0
         for exception_file in self.exceptions_dir.glob("active/*.yaml"):
@@ -834,7 +890,10 @@ class GovernanceClosedLoopSystem:
 
     def _calculate_drift_monitoring_kpi(self, time_range: int) -> Dict[str, float]:
         """è¨ˆç®—æ¼‚ç§»ç›£æ§ KPI"""
-        return {"drift_detection_rate": 100.0, "drift_resolution_time": 1.8}  # %  # hours
+        return {
+            "drift_detection_rate": 100.0,
+            "drift_resolution_time": 1.8,
+        }  # %  # hours
 
     def _generate_trace_id(self) -> str:
         """ç”Ÿæˆè¿½è¹¤ ID"""
diff --git a/workspace/governance/naming-governance-v1.0.0-extended/automation/scripts/naming-governance-migration.py b/workspace/governance/naming-governance-v1.0.0-extended/automation/scripts/naming-governance-migration.py
index 1e2bef8..f93d56b 100755
--- a/workspace/governance/naming-governance-v1.0.0-extended/automation/scripts/naming-governance-migration.py
+++ b/workspace/governance/naming-governance-v1.0.0-extended/automation/scripts/naming-governance-migration.py
@@ -358,7 +358,9 @@ class NamingGovernanceMigration:
                         service_account_id = f"serviceaccounts/{result.stdout.strip()}"
                         if service_account_id in asset_map:
                             asset.dependencies.append(service_account_id)
-                            asset_map[service_account_id].dependents.append(asset.resource_id)
+                            asset_map[service_account_id].dependents.append(
+                                asset.resource_id
+                            )
 
                 elif resource_type == "services":
                     # æª¢æŸ¥é—œè¯çš„éƒ¨ç½²
@@ -366,7 +368,8 @@ class NamingGovernanceMigration:
                     if selector:
                         for potential_asset in assets:
                             if (
-                                potential_asset.resource_type in ["deployments", "statefulsets"]
+                                potential_asset.resource_type
+                                in ["deployments", "statefulsets"]
                                 and potential_asset.labels.get("app") == selector
                             ):
                                 asset.dependencies.append(potential_asset.resource_id)
@@ -428,7 +431,16 @@ class NamingGovernanceMigration:
     def _assess_deployment_complexity(self, asset: AssetInfo) -> int:
         """è©•ä¼°éƒ¨ç½²è¤‡é›œåº¦"""
         try:
-            cmd = ["kubectl", "get", "deployment", asset.name, "-n", asset.namespace, "-o", "json"]
+            cmd = [
+                "kubectl",
+                "get",
+                "deployment",
+                asset.name,
+                "-n",
+                asset.namespace,
+                "-o",
+                "json",
+            ]
 
             result = subprocess.run(cmd, capture_output=True, text=True, check=True)
             data = json.loads(result.stdout)
@@ -558,7 +570,9 @@ class NamingGovernanceMigration:
         if not assets:
             return 0.0
 
-        compliant_count = sum(1 for asset in assets if self._is_naming_compliant(asset.name))
+        compliant_count = sum(
+            1 for asset in assets if self._is_naming_compliant(asset.name)
+        )
         return compliant_count / len(assets)
 
     def _generate_risk_recommendations(self, risk_factors: Dict[str, Any]) -> List[str]:
@@ -599,7 +613,9 @@ class NamingGovernanceMigration:
                 simulation_results.append(result)
 
                 if not result["success"]:
-                    logger.error(f"è³‡ç”¢ {asset.resource_id} æ¨¡æ“¬å¤±æ•—: {result['error']}")
+                    logger.error(
+                        f"è³‡ç”¢ {asset.resource_id} æ¨¡æ“¬å¤±æ•—: {result['error']}"
+                    )
                     return False
 
             # ç”Ÿæˆæ¨¡æ“¬å ±å‘Š
@@ -727,7 +743,9 @@ class NamingGovernanceMigration:
 
         return True
 
-    def _generate_dry_run_report(self, plan: MigrationPlan, results: List[Dict[str, Any]]):
+    def _generate_dry_run_report(
+        self, plan: MigrationPlan, results: List[Dict[str, Any]]
+    ):
         """ç”Ÿæˆ Dry-run å ±å‘Š"""
         report = {
             "plan_id": plan.plan_id,
@@ -735,7 +753,9 @@ class NamingGovernanceMigration:
             "total_assets": len(plan.assets),
             "successful_simulations": sum(1 for r in results if r["success"]),
             "failed_simulations": sum(1 for r in results if not r["success"]),
-            "estimated_total_downtime": sum(r.get("estimated_downtime", 0) for r in results),
+            "estimated_total_downtime": sum(
+                r.get("estimated_downtime", 0) for r in results
+            ),
             "results": results,
         }
 
@@ -759,7 +779,8 @@ class NamingGovernanceMigration:
             # æŒ‰æ‰¹æ¬¡åˆ†çµ„é·ç§»
             batch_size = self.config.get("max_concurrent_migrations", 3)
             asset_batches = [
-                plan.assets[i : i + batch_size] for i in range(0, len(plan.assets), batch_size)
+                plan.assets[i : i + batch_size]
+                for i in range(0, len(plan.assets), batch_size)
             ]
 
             successful_migrations = 0
@@ -804,7 +825,8 @@ class NamingGovernanceMigration:
         """é·ç§»è³‡ç”¢æ‰¹æ¬¡"""
         with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
             future_to_asset = {
-                executor.submit(self._migrate_single_asset, asset): asset for asset in assets
+                executor.submit(self._migrate_single_asset, asset): asset
+                for asset in assets
             }
 
             batch_success = True
@@ -880,11 +902,15 @@ class NamingGovernanceMigration:
                 "yaml",
             ]
 
-            result = subprocess.run(export_cmd, capture_output=True, text=True, check=True)
+            result = subprocess.run(
+                export_cmd, capture_output=True, text=True, check=True
+            )
             config_data = result.stdout
 
             # ä¿®æ”¹åç¨±
-            config_data = config_data.replace(f"name: {asset.name}", f"name: {new_name}")
+            config_data = config_data.replace(
+                f"name: {asset.name}", f"name: {new_name}"
+            )
 
             # å‰µå»ºæ–°è³‡æº
             create_cmd = ["kubectl", "apply", "-f", "-"]
@@ -892,7 +918,14 @@ class NamingGovernanceMigration:
             subprocess.run(create_cmd, input=config_data, text=True, check=True)
 
             # é©—è­‰æ–°è³‡æº
-            verify_cmd = ["kubectl", "get", asset.resource_type, new_name, "-n", asset.namespace]
+            verify_cmd = [
+                "kubectl",
+                "get",
+                asset.resource_type,
+                new_name,
+                "-n",
+                asset.namespace,
+            ]
 
             subprocess.run(verify_cmd, check=True)
 
@@ -989,7 +1022,9 @@ class NamingGovernanceMigration:
 
                 result = subprocess.run(old_verify_cmd, capture_output=True, text=True)
                 if result.returncode == 0:
-                    logger.warning(f"èˆŠè³‡æºä»ç„¶å­˜åœ¨: {asset.resource_type}/{asset.name}")
+                    logger.warning(
+                        f"èˆŠè³‡æºä»ç„¶å­˜åœ¨: {asset.resource_type}/{asset.name}"
+                    )
 
             except Exception as e:
                 logger.error(f"é©—è­‰è³‡ç”¢ {asset.resource_id} å¤±æ•—: {e}")
@@ -1012,7 +1047,14 @@ class NamingGovernanceMigration:
         for asset in plan.assets:
             try:
                 # æª¢æŸ¥èˆŠè³‡æºæ˜¯å¦ä»ç„¶å­˜åœ¨
-                cmd = ["kubectl", "get", asset.resource_type, asset.name, "-n", asset.namespace]
+                cmd = [
+                    "kubectl",
+                    "get",
+                    asset.resource_type,
+                    asset.name,
+                    "-n",
+                    asset.namespace,
+                ]
 
                 result = subprocess.run(cmd, capture_output=True, text=True)
                 if result.returncode == 0:
@@ -1092,7 +1134,14 @@ class NamingGovernanceMigration:
         for asset in plan.assets:
             try:
                 # æª¢æŸ¥åŸå§‹è³‡æºæ˜¯å¦å·²æ¢å¾©
-                cmd = ["kubectl", "get", asset.resource_type, asset.name, "-n", asset.namespace]
+                cmd = [
+                    "kubectl",
+                    "get",
+                    asset.resource_type,
+                    asset.name,
+                    "-n",
+                    asset.namespace,
+                ]
 
                 result = subprocess.run(cmd, capture_output=True, text=True)
                 if result.returncode != 0:
@@ -1114,8 +1163,13 @@ class NamingGovernanceMigration:
             "plan_id": plan.plan_id,
             "generated_at": datetime.now().isoformat(),
             "migration_phases": {
-                "discovery": {"assets_discovered": self.migration_stats["total_assets_discovered"]},
-                "planning": {"plan_created": True, "risk_assessment": plan.risk_assessment},
+                "discovery": {
+                    "assets_discovered": self.migration_stats["total_assets_discovered"]
+                },
+                "planning": {
+                    "plan_created": True,
+                    "risk_assessment": plan.risk_assessment,
+                },
                 "execution": {
                     "assets_migrated": self.migration_stats["assets_migrated"],
                     "assets_failed": self.migration_stats["assets_failed"],
@@ -1136,7 +1190,9 @@ class NamingGovernanceMigration:
         if self.migration_stats["assets_failed"] > 0:
             recommendations.append("æœ‰è³‡ç”¢é·ç§»å¤±æ•—ï¼Œå»ºè­°äººå·¥å¯©æ ¸ä¸¦ä¿®å¾©")
 
-        if self.migration_stats["downtime_seconds"] > self.config.get("downtime_threshold", 300):
+        if self.migration_stats["downtime_seconds"] > self.config.get(
+            "downtime_threshold", 300
+        ):
             recommendations.append("å¯¦éš›åœæ©Ÿæ™‚é–“è¶…éé æœŸï¼Œå»ºè­°å„ªåŒ–é·ç§»ç­–ç•¥")
 
         if plan.status == MigrationStatus.ROLLED_BACK:
@@ -1210,9 +1266,13 @@ def main():
         # è¼¸å‡ºæ‘˜è¦
         logger.info(f"é·ç§»å®Œæˆæ‘˜è¦:")
         logger.info(f"  ç¸½è³‡ç”¢æ•¸: {len(assets)}")
-        logger.info(f"  æˆåŠŸé·ç§»: {migration_system.migration_stats['assets_migrated']}")
+        logger.info(
+            f"  æˆåŠŸé·ç§»: {migration_system.migration_stats['assets_migrated']}"
+        )
         logger.info(f"  å¤±æ•—æ•¸é‡: {migration_system.migration_stats['assets_failed']}")
-        logger.info(f"  ç¸½åœæ©Ÿæ™‚é–“: {migration_system.migration_stats['downtime_seconds']} ç§’")
+        logger.info(
+            f"  ç¸½åœæ©Ÿæ™‚é–“: {migration_system.migration_stats['downtime_seconds']} ç§’"
+        )
 
         return 0
 
diff --git a/workspace/governance/naming-governance-v1.0.0-extended/automation/scripts/naming-governance-repair.py b/workspace/governance/naming-governance-v1.0.0-extended/automation/scripts/naming-governance-repair.py
index ca3b2cc..d3cdbc6 100755
--- a/workspace/governance/naming-governance-v1.0.0-extended/automation/scripts/naming-governance-repair.py
+++ b/workspace/governance/naming-governance-v1.0.0-extended/automation/scripts/naming-governance-repair.py
@@ -147,7 +147,9 @@ class NamingGovernanceRepair:
             "compliance_threshold": 0.95,
         }
 
-    def detect_violations(self, namespace: str = "machine-native-ops") -> List[ViolationReport]:
+    def detect_violations(
+        self, namespace: str = "machine-native-ops"
+    ) -> List[ViolationReport]:
         """æª¢æ¸¬å‘½åæ²»ç†é•è¦"""
         logger.info(f"é–‹å§‹æª¢æ¸¬å‘½åæ²»ç†é•è¦ï¼Œå‘½åç©ºé–“: {namespace}")
 
@@ -202,7 +204,11 @@ class NamingGovernanceRepair:
                 if "items" in data:
                     for item in data["items"]:
                         resources.append(
-                            {"type": resource_type, "data": item, "namespace": namespace}
+                            {
+                                "type": resource_type,
+                                "data": item,
+                                "namespace": namespace,
+                            }
                         )
 
             except subprocess.CalledProcessError as e:
@@ -212,7 +218,9 @@ class NamingGovernanceRepair:
 
         return resources
 
-    def _check_resource_violations(self, resource: Dict[str, Any]) -> List[ViolationReport]:
+    def _check_resource_violations(
+        self, resource: Dict[str, Any]
+    ) -> List[ViolationReport]:
         """æª¢æŸ¥å–®å€‹è³‡æºçš„é•è¦"""
         violations = []
         data = resource["data"]
@@ -241,7 +249,9 @@ class NamingGovernanceRepair:
 
         return violations
 
-    def _check_naming_pattern(self, resource: Dict[str, Any]) -> Optional[ViolationReport]:
+    def _check_naming_pattern(
+        self, resource: Dict[str, Any]
+    ) -> Optional[ViolationReport]:
         """æª¢æŸ¥å‘½åæ¨¡å¼é•è¦"""
         metadata = resource["data"].get("metadata", {})
         name = metadata.get("name", "")
@@ -272,7 +282,9 @@ class NamingGovernanceRepair:
 
         return None
 
-    def _check_version_format(self, resource: Dict[str, Any]) -> Optional[ViolationReport]:
+    def _check_version_format(
+        self, resource: Dict[str, Any]
+    ) -> Optional[ViolationReport]:
         """æª¢æŸ¥ç‰ˆæœ¬æ ¼å¼é•è¦"""
         metadata = resource["data"].get("metadata", {})
         name = metadata.get("name", "")
@@ -306,7 +318,9 @@ class NamingGovernanceRepair:
 
         return None
 
-    def _check_required_labels(self, resource: Dict[str, Any]) -> Optional[ViolationReport]:
+    def _check_required_labels(
+        self, resource: Dict[str, Any]
+    ) -> Optional[ViolationReport]:
         """æª¢æŸ¥å¿…éœ€æ¨™ç±¤"""
         metadata = resource["data"].get("metadata", {})
         name = metadata.get("name", "")
@@ -327,12 +341,17 @@ class NamingGovernanceRepair:
                 auto_repairable=True,
                 repair_priority=2,
                 detected_at=datetime.now().isoformat(),
-                metadata={"missing_labels": missing_labels, "existing_labels": list(labels.keys())},
+                metadata={
+                    "missing_labels": missing_labels,
+                    "existing_labels": list(labels.keys()),
+                },
             )
 
         return None
 
-    def _check_security_compliance(self, resource: Dict[str, Any]) -> Optional[ViolationReport]:
+    def _check_security_compliance(
+        self, resource: Dict[str, Any]
+    ) -> Optional[ViolationReport]:
         """æª¢æŸ¥å®‰å…¨åˆè¦æ€§"""
         data = resource["data"]
         metadata = data.get("metadata", {})
@@ -372,7 +391,9 @@ class NamingGovernanceRepair:
             return f"{base_name}-v1.0.0"
         return f"{pattern_key}-v1.0.0"
 
-    def create_repair_plan(self, violations: List[ViolationReport]) -> List[RepairOperation]:
+    def create_repair_plan(
+        self, violations: List[ViolationReport]
+    ) -> List[RepairOperation]:
         """å‰µå»ºä¿®å¾©è¨ˆåŠƒ"""
         logger.info(f"ç‚º {len(violations)} å€‹é•è¦å‰µå»ºä¿®å¾©è¨ˆåŠƒ")
 
@@ -443,7 +464,9 @@ class NamingGovernanceRepair:
         return (
             self.approval_required
             or any(v.severity in ["critical", "high"] for v in violations)
-            or any(v.violation_type == ViolationType.SECURITY_VIOLATION for v in violations)
+            or any(
+                v.violation_type == ViolationType.SECURITY_VIOLATION for v in violations
+            )
         )
 
     def execute_repair(self, operation: RepairOperation) -> bool:
@@ -451,7 +474,9 @@ class NamingGovernanceRepair:
         logger.info(f"é–‹å§‹åŸ·è¡Œä¿®å¾©æ“ä½œ: {operation.operation_id}")
 
         if operation.status != RepairStatus.PENDING:
-            logger.warning(f"æ“ä½œ {operation.operation_id} ç‹€æ…‹ä¸æ­£ç¢º: {operation.status}")
+            logger.warning(
+                f"æ“ä½œ {operation.operation_id} ç‹€æ…‹ä¸æ­£ç¢º: {operation.status}"
+            )
             return False
 
         operation.status = RepairStatus.IN_PROGRESS
@@ -552,7 +577,9 @@ class NamingGovernanceRepair:
                         logger.error(f"é‡å‘½åå¤±æ•—: {result.stderr}")
                         continue
 
-                logger.info(f"æˆåŠŸé‡å‘½å {resource_type}/{current_name} ç‚º {suggested_name}")
+                logger.info(
+                    f"æˆåŠŸé‡å‘½å {resource_type}/{current_name} ç‚º {suggested_name}"
+                )
 
             except Exception as e:
                 logger.error(f"ä¿®å¾©å‘½åæ¨¡å¼å¤±æ•—: {e}")
@@ -721,13 +748,19 @@ class NamingGovernanceRepair:
             current_violations = self.detect_violations(namespace)
 
             # æª¢æŸ¥ä¿®å¾©çš„é•è¦æ˜¯å¦å·²è§£æ±º
-            original_violation_ids = {v.resource_id for v in operation.violation_reports}
+            original_violation_ids = {
+                v.resource_id for v in operation.violation_reports
+            }
             current_violation_ids = {v.resource_id for v in current_violations}
 
-            remaining_violations = original_violation_ids.intersection(current_violation_ids)
+            remaining_violations = original_violation_ids.intersection(
+                current_violation_ids
+            )
 
             if not remaining_violations:
-                logger.info(f"ä¿®å¾©æ“ä½œ {operation.operation_id} é©—è­‰æˆåŠŸï¼šæ‰€æœ‰é•è¦å·²è§£æ±º")
+                logger.info(
+                    f"ä¿®å¾©æ“ä½œ {operation.operation_id} é©—è­‰æˆåŠŸï¼šæ‰€æœ‰é•è¦å·²è§£æ±º"
+                )
                 return True
             else:
                 logger.warning(
@@ -757,7 +790,9 @@ class NamingGovernanceRepair:
         except Exception as e:
             logger.error(f"ç™¼é€å®‰å…¨å‘Šè­¦å¤±æ•—: {e}")
 
-    def generate_repair_report(self, operations: List[RepairOperation]) -> Dict[str, Any]:
+    def generate_repair_report(
+        self, operations: List[RepairOperation]
+    ) -> Dict[str, Any]:
         """ç”Ÿæˆä¿®å¾©å ±å‘Š"""
         logger.info("ç”Ÿæˆä¿®å¾©å ±å‘Š")
 
@@ -822,12 +857,16 @@ class NamingGovernanceRepair:
 
 def main():
     """ä¸»å‡½æ•¸"""
-    parser = argparse.ArgumentParser(description="MachineNativeOps å‘½åæ²»ç†è‡ªå‹•ä¿®å¾©å·¥å…·")
+    parser = argparse.ArgumentParser(
+        description="MachineNativeOps å‘½åæ²»ç†è‡ªå‹•ä¿®å¾©å·¥å…·"
+    )
     parser.add_argument("--config", "-c", help="é…ç½®æ–‡ä»¶è·¯å¾‘")
     parser.add_argument(
         "--namespace", "-n", default="machine-native-ops", help="Kubernetes å‘½åç©ºé–“"
     )
-    parser.add_argument("--dry-run", action="store_true", help="è©¦é‹è¡Œæ¨¡å¼ï¼Œä¸åŸ·è¡Œå¯¦éš›ä¿®å¾©")
+    parser.add_argument(
+        "--dry-run", action="store_true", help="è©¦é‹è¡Œæ¨¡å¼ï¼Œä¸åŸ·è¡Œå¯¦éš›ä¿®å¾©"
+    )
     parser.add_argument("--output", "-o", help="å ±å‘Šè¼¸å‡ºè·¯å¾‘")
     parser.add_argument("--verbose", "-v", action="store_true", help="è©³ç´°è¼¸å‡º")
 
diff --git a/workspace/governance/naming-governance-v1.0.0/scripts/audit/change_manager.py b/workspace/governance/naming-governance-v1.0.0/scripts/audit/change_manager.py
index e276edb..b52e3db 100644
--- a/workspace/governance/naming-governance-v1.0.0/scripts/audit/change_manager.py
+++ b/workspace/governance/naming-governance-v1.0.0/scripts/audit/change_manager.py
@@ -84,7 +84,9 @@ class ChangeManager:
             print(f"éŒ¯èª¤: YAML è§£æå¤±æ•— - {e}")
             sys.exit(1)
 
-    def validate_change_type(self, change_type: ChangeType, risk_level: RiskLevel) -> bool:
+    def validate_change_type(
+        self, change_type: ChangeType, risk_level: RiskLevel
+    ) -> bool:
         """é©—è­‰è®Šæ›´é¡å‹èˆ‡é¢¨éšªç­‰ç´šçš„åŒ¹é…æ€§"""
         type_config = self.change_config.get("types", [])
 
@@ -130,7 +132,9 @@ class ChangeManager:
             }
         }
 
-        return yaml.dump(rfc_dict, allow_unicode=True, default_flow_style=False, sort_keys=False)
+        return yaml.dump(
+            rfc_dict, allow_unicode=True, default_flow_style=False, sort_keys=False
+        )
 
     def load_rfc(self, rfc_path: str) -> Optional[ChangeRequest]:
         """è¼‰å…¥ RFC è®Šæ›´è«‹æ±‚æ–‡æª”"""
@@ -150,11 +154,15 @@ class ChangeManager:
                 impact_assessment=ImpactAssessment(
                     services_affected=impact_data.get("services_affected", []),
                     downtime_expected=impact_data.get("downtime_expected", "0 min"),
-                    data_migration_required=impact_data.get("data_migration_required", False),
+                    data_migration_required=impact_data.get(
+                        "data_migration_required", False
+                    ),
                     rollback_complexity=impact_data.get("rollback_complexity", "low"),
                     user_impact=impact_data.get("user_impact", "none"),
                 ),
-                implementation_plan=cr_data.get("implementation_plan", {}).get("steps", []),
+                implementation_plan=cr_data.get("implementation_plan", {}).get(
+                    "steps", []
+                ),
                 rollback_plan=cr_data.get("rollback_plan", {}).get("steps", []),
                 approval_method=cr_data.get("approval", {}).get("method", "CAB"),
                 status=cr_data.get("status", "Pending"),
@@ -170,7 +178,9 @@ class ChangeManager:
             print(f"éŒ¯èª¤: ç„¡æ³•è¼‰å…¥ RFC - {e}")
             return None
 
-    def approve_change(self, change_request: ChangeRequest, approver: str) -> ChangeRequest:
+    def approve_change(
+        self, change_request: ChangeRequest, approver: str
+    ) -> ChangeRequest:
         """æ‰¹å‡†è®Šæ›´è«‹æ±‚"""
         change_request.status = "Approved"
         change_request.approved_by = approver
@@ -178,7 +188,9 @@ class ChangeManager:
 
         return change_request
 
-    def reject_change(self, change_request: ChangeRequest, reason: str) -> ChangeRequest:
+    def reject_change(
+        self, change_request: ChangeRequest, reason: str
+    ) -> ChangeRequest:
         """æ‹’çµ•è®Šæ›´è«‹æ±‚"""
         change_request.status = "Rejected"
         change_request.metrics["rejection_reason"] = reason
@@ -207,7 +219,9 @@ class ChangeManager:
                 errors.append(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {field}")
 
         # é©—è­‰è®Šæ›´é¡å‹èˆ‡é¢¨éšªç­‰ç´š
-        if not self.validate_change_type(change_request.type, change_request.risk_level):
+        if not self.validate_change_type(
+            change_request.type, change_request.risk_level
+        ):
             errors.append("è®Šæ›´é¡å‹èˆ‡é¢¨éšªç­‰ç´šä¸åŒ¹é…")
 
         # é©—è­‰å¯¦æ–½è¨ˆç•«
@@ -228,7 +242,9 @@ class ChangeManager:
 def main():
     """ä¸»å‡½æ•¸"""
     parser = argparse.ArgumentParser(description="è®Šæ›´ç®¡ç†å·¥å…· v1.0.0")
-    parser.add_argument("--spec", default="config/machine-spec.yaml", help="å‘½åè¦ç¯„æ–‡ä»¶è·¯å¾‘")
+    parser.add_argument(
+        "--spec", default="config/machine-spec.yaml", help="å‘½åè¦ç¯„æ–‡ä»¶è·¯å¾‘"
+    )
 
     subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
 
@@ -236,7 +252,10 @@ def main():
     create_parser = subparsers.add_parser("create", help="å‰µå»ºæ–°çš„è®Šæ›´è«‹æ±‚")
     create_parser.add_argument("--title", required=True, help="è®Šæ›´æ¨™é¡Œ")
     create_parser.add_argument(
-        "--type", required=True, choices=["standard", "normal", "emergency"], help="è®Šæ›´é¡å‹"
+        "--type",
+        required=True,
+        choices=["standard", "normal", "emergency"],
+        help="è®Šæ›´é¡å‹",
     )
     create_parser.add_argument("--requester", required=True, help="è«‹æ±‚äºº")
     create_parser.add_argument(
diff --git a/workspace/governance/naming-governance-v1.0.0/scripts/audit/exception_manager.py b/workspace/governance/naming-governance-v1.0.0/scripts/audit/exception_manager.py
index c428e0e..390df52 100644
--- a/workspace/governance/naming-governance-v1.0.0/scripts/audit/exception_manager.py
+++ b/workspace/governance/naming-governance-v1.0.0/scripts/audit/exception_manager.py
@@ -60,7 +60,9 @@ class ExceptionManager:
     """ä¾‹å¤–ç®¡ç†å™¨é¡åˆ¥"""
 
     def __init__(
-        self, spec_path: str = "config/machine-spec.yaml", exceptions_db: str = "exceptions-db.yaml"
+        self,
+        spec_path: str = "config/machine-spec.yaml",
+        exceptions_db: str = "exceptions-db.yaml",
     ):
         """åˆå§‹åŒ–ä¾‹å¤–ç®¡ç†å™¨"""
         self.spec_path = Path(spec_path)
@@ -103,9 +105,13 @@ class ExceptionManager:
         }
 
         with open(self.exceptions_db_path, "w", encoding="utf-8") as f:
-            yaml.dump(data, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
+            yaml.dump(
+                data, f, allow_unicode=True, default_flow_style=False, sort_keys=False
+            )
 
-    def validate_exception_request(self, exception: ComplianceException) -> Tuple[bool, List[str]]:
+    def validate_exception_request(
+        self, exception: ComplianceException
+    ) -> Tuple[bool, List[str]]:
         """é©—è­‰ä¾‹å¤–ç”³è«‹"""
         errors = []
 
@@ -131,7 +137,12 @@ class ExceptionManager:
             errors.append("åˆ°æœŸæ—¥æœŸæ ¼å¼ç„¡æ•ˆï¼Œæ‡‰ç‚º ISO 8601 æ ¼å¼")
 
         # é©—è­‰é¢¨éšªè©•ä¼°
-        if exception.risk_assessment.lower() not in ["low", "medium", "high", "critical"]:
+        if exception.risk_assessment.lower() not in [
+            "low",
+            "medium",
+            "high",
+            "critical",
+        ]:
             errors.append("é¢¨éšªè©•ä¼°å¿…é ˆç‚º: low, medium, high, æˆ– critical")
 
         # é©—è­‰ç·©è§£æªæ–½
@@ -239,26 +250,48 @@ class ExceptionManager:
         filtered_exceptions = self.exceptions
 
         if status_filter:
-            filtered_exceptions = [exc for exc in self.exceptions if exc["status"] == status_filter]
+            filtered_exceptions = [
+                exc for exc in self.exceptions if exc["status"] == status_filter
+            ]
 
         report = {
             "generated_at": datetime.now().isoformat(),
             "total_exceptions": len(self.exceptions),
             "by_status": {
                 "pending": len(
-                    [e for e in self.exceptions if e["status"] == ExceptionStatus.PENDING.value]
+                    [
+                        e
+                        for e in self.exceptions
+                        if e["status"] == ExceptionStatus.PENDING.value
+                    ]
                 ),
                 "approved": len(
-                    [e for e in self.exceptions if e["status"] == ExceptionStatus.APPROVED.value]
+                    [
+                        e
+                        for e in self.exceptions
+                        if e["status"] == ExceptionStatus.APPROVED.value
+                    ]
                 ),
                 "rejected": len(
-                    [e for e in self.exceptions if e["status"] == ExceptionStatus.REJECTED.value]
+                    [
+                        e
+                        for e in self.exceptions
+                        if e["status"] == ExceptionStatus.REJECTED.value
+                    ]
                 ),
                 "expired": len(
-                    [e for e in self.exceptions if e["status"] == ExceptionStatus.EXPIRED.value]
+                    [
+                        e
+                        for e in self.exceptions
+                        if e["status"] == ExceptionStatus.EXPIRED.value
+                    ]
                 ),
                 "revoked": len(
-                    [e for e in self.exceptions if e["status"] == ExceptionStatus.REVOKED.value]
+                    [
+                        e
+                        for e in self.exceptions
+                        if e["status"] == ExceptionStatus.REVOKED.value
+                    ]
                 ),
             },
             "exceptions": filtered_exceptions,
@@ -277,7 +310,10 @@ class ExceptionManager:
             if exc["id"] == exception_id:
                 if format == "yaml":
                     return yaml.dump(
-                        exc, allow_unicode=True, default_flow_style=False, sort_keys=False
+                        exc,
+                        allow_unicode=True,
+                        default_flow_style=False,
+                        sort_keys=False,
                     )
                 elif format == "json":
                     return json.dumps(exc, indent=2, ensure_ascii=False)
@@ -288,7 +324,9 @@ class ExceptionManager:
 def main():
     """ä¸»å‡½æ•¸"""
     parser = argparse.ArgumentParser(description="åˆè¦ä¾‹å¤–ç®¡ç†å·¥å…· v1.0.0")
-    parser.add_argument("--spec", default="config/machine-spec.yaml", help="å‘½åè¦ç¯„æ–‡ä»¶è·¯å¾‘")
+    parser.add_argument(
+        "--spec", default="config/machine-spec.yaml", help="å‘½åè¦ç¯„æ–‡ä»¶è·¯å¾‘"
+    )
     parser.add_argument("--db", default="exceptions-db.yaml", help="ä¾‹å¤–è³‡æ–™åº«æ–‡ä»¶è·¯å¾‘")
 
     subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
@@ -299,7 +337,10 @@ def main():
     create_parser.add_argument("--type", required=True, help="ä¾‹å¤–é¡å‹")
     create_parser.add_argument("--justification", required=True, help="ç”³è«‹ç†ç”±")
     create_parser.add_argument(
-        "--risk", required=True, choices=["low", "medium", "high", "critical"], help="é¢¨éšªè©•ä¼°"
+        "--risk",
+        required=True,
+        choices=["low", "medium", "high", "critical"],
+        help="é¢¨éšªè©•ä¼°",
     )
     create_parser.add_argument("--expiry", required=True, help="åˆ°æœŸæ—¥æœŸ (YYYY-MM-DD)")
     create_parser.add_argument("--resources", nargs="+", help="å—å½±éŸ¿çš„è³‡æº")
diff --git a/workspace/governance/naming-governance-v1.0.0/scripts/generation/naming_generator.py b/workspace/governance/naming-governance-v1.0.0/scripts/generation/naming_generator.py
index 278a580..75dbddd 100644
--- a/workspace/governance/naming-governance-v1.0.0/scripts/generation/naming_generator.py
+++ b/workspace/governance/naming-governance-v1.0.0/scripts/generation/naming_generator.py
@@ -125,7 +125,11 @@ class NamingGenerator:
 
             if "value_from" in label_spec:
                 # å¾åƒæ•¸æ˜ å°„å€¼
-                value_mapping = {"environment": environment, "app": app, "version": version}
+                value_mapping = {
+                    "environment": environment,
+                    "app": app,
+                    "version": version,
+                }
                 value = value_mapping.get(label_spec["value_from"], "")
             elif "default" in label_spec:
                 value = label_spec["default"]
@@ -165,7 +169,11 @@ class NamingGenerator:
                     "metadata": {"labels": labels},
                     "spec": {
                         "containers": [
-                            {"name": app, "image": image, "ports": [{"containerPort": 80}]}
+                            {
+                                "name": app,
+                                "image": image,
+                                "ports": [{"containerPort": 80}],
+                            }
                         ]
                     },
                 },
@@ -200,7 +208,9 @@ class NamingGenerator:
 def main():
     """ä¸»å‡½æ•¸"""
     parser = argparse.ArgumentParser(description="å‘½åç”Ÿæˆå™¨ v1.0.0")
-    parser.add_argument("--spec", default="config/machine-spec.yaml", help="å‘½åè¦ç¯„æ–‡ä»¶è·¯å¾‘")
+    parser.add_argument(
+        "--spec", default="config/machine-spec.yaml", help="å‘½åè¦ç¯„æ–‡ä»¶è·¯å¾‘"
+    )
     parser.add_argument(
         "--environment",
         required=True,
@@ -220,7 +230,9 @@ def main():
     parser.add_argument("--replicas", type=int, default=3, help="å‰¯æœ¬æ•¸é‡")
     parser.add_argument("--image", default="nginx:latest", help="å®¹å™¨é¡åƒ")
     parser.add_argument("--output", help="è¼¸å‡ºæ–‡ä»¶è·¯å¾‘")
-    parser.add_argument("--format", choices=["yaml", "json"], default="yaml", help="è¼¸å‡ºæ ¼å¼")
+    parser.add_argument(
+        "--format", choices=["yaml", "json"], default="yaml", help="è¼¸å‡ºæ ¼å¼"
+    )
 
     args = parser.parse_args()
 
diff --git a/workspace/governance/naming-governance-v1.0.0/scripts/validation/naming_validator.py b/workspace/governance/naming-governance-v1.0.0/scripts/validation/naming_validator.py
index 480c847..56aebb5 100644
--- a/workspace/governance/naming-governance-v1.0.0/scripts/validation/naming_validator.py
+++ b/workspace/governance/naming-governance-v1.0.0/scripts/validation/naming_validator.py
@@ -258,7 +258,9 @@ class NamingValidator:
 
         return len(all_violations) == 0, all_violations
 
-    def generate_report(self, violations: List[Violation], output_format: str = "text") -> str:
+    def generate_report(
+        self, violations: List[Violation], output_format: str = "text"
+    ) -> str:
         """ç”Ÿæˆç¨½æ ¸å ±å‘Š"""
         if not violations:
             return "âœ… æ‰€æœ‰è³‡æºå‡ç¬¦åˆå‘½åè¦ç¯„ï¼"
@@ -314,7 +316,9 @@ class NamingValidator:
             ]:
                 severity_violations = violations_by_severity[severity]
                 if severity_violations:
-                    report.append(f"\n{severity.value.upper()} ({len(severity_violations)}):")
+                    report.append(
+                        f"\n{severity.value.upper()} ({len(severity_violations)}):"
+                    )
                     report.append("")
 
                     for i, violation in enumerate(severity_violations, 1):
@@ -388,15 +392,24 @@ class NamingValidator:
 def main():
     """ä¸»å‡½æ•¸"""
     parser = argparse.ArgumentParser(description="å‘½åç¨½æ ¸å·¥å…· v1.0.0")
-    parser.add_argument("--spec", default="config/machine-spec.yaml", help="å‘½åè¦ç¯„æ–‡ä»¶è·¯å¾‘")
+    parser.add_argument(
+        "--spec", default="config/machine-spec.yaml", help="å‘½åè¦ç¯„æ–‡ä»¶è·¯å¾‘"
+    )
     parser.add_argument("--file", help="é©—è­‰å–®ä¸€ YAML æ–‡ä»¶")
     parser.add_argument("--directory", help="é©—è­‰ç›®éŒ„ä¸­çš„æ‰€æœ‰ YAML æ–‡ä»¶")
-    parser.add_argument("--pattern", default="*.yaml", help="ç›®éŒ„é©—è­‰çš„æ–‡ä»¶æ¨¡å¼ (é è¨­: *.yaml)")
+    parser.add_argument(
+        "--pattern", default="*.yaml", help="ç›®éŒ„é©—è­‰çš„æ–‡ä»¶æ¨¡å¼ (é è¨­: *.yaml)"
+    )
     parser.add_argument("--output", help="è¼¸å‡ºå ±å‘Šæ–‡ä»¶è·¯å¾‘")
     parser.add_argument(
-        "--format", choices=["text", "json", "yaml"], default="text", help="è¼¸å‡ºæ ¼å¼ (é è¨­: text)"
+        "--format",
+        choices=["text", "json", "yaml"],
+        default="text",
+        help="è¼¸å‡ºæ ¼å¼ (é è¨­: text)",
+    )
+    parser.add_argument(
+        "--strict", action="store_true", help="åš´æ ¼æ¨¡å¼ï¼Œä»»ä½•é•è¦éƒ½è¿”å›éé›¶é€€å‡ºç¢¼"
     )
-    parser.add_argument("--strict", action="store_true", help="åš´æ ¼æ¨¡å¼ï¼Œä»»ä½•é•è¦éƒ½è¿”å›éé›¶é€€å‡ºç¢¼")
 
     args = parser.parse_args()
 
@@ -410,7 +423,9 @@ def main():
         is_compliant, violations = validator.validate_k8s_manifest(args.file)
         all_violations.extend(violations)
     elif args.directory:
-        is_compliant, violations = validator.validate_directory(args.directory, args.pattern)
+        is_compliant, violations = validator.validate_directory(
+            args.directory, args.pattern
+        )
         all_violations.extend(violations)
     else:
         parser.print_help()
diff --git a/workspace/governance/tests/e2e/test_naming_workflow.py b/workspace/governance/tests/e2e/test_naming_workflow.py
index 49e2302..4d483d3 100644
--- a/workspace/governance/tests/e2e/test_naming_workflow.py
+++ b/workspace/governance/tests/e2e/test_naming_workflow.py
@@ -10,7 +10,9 @@ class TestNamingWorkflowE2E:
     """End-to-end test suite for naming workflow"""
 
     @pytest.mark.e2e
-    def test_complete_naming_workflow(self, mock_naming_generator, mock_naming_validator):
+    def test_complete_naming_workflow(
+        self, mock_naming_generator, mock_naming_validator
+    ):
         """Test complete naming workflow from generation to validation"""
         # Step 1: Generate name
         name = mock_naming_generator.generate("prod", "app", "service", "v1.0.0")
@@ -24,7 +26,9 @@ class TestNamingWorkflowE2E:
         assert mock_naming_generator.validate_pattern(name)
 
     @pytest.mark.e2e
-    def test_naming_workflow_with_invalid_input(self, mock_naming_generator, mock_naming_validator):
+    def test_naming_workflow_with_invalid_input(
+        self, mock_naming_generator, mock_naming_validator
+    ):
         """Test naming workflow with invalid input"""
         # Generate with uppercase (should be normalized)
         name = mock_naming_generator.generate("PROD", "APP", "SERVICE", "V1.0.0")
@@ -34,7 +38,9 @@ class TestNamingWorkflowE2E:
         assert result["valid"] is True or result["valid"] is False
 
     @pytest.mark.e2e
-    def test_naming_workflow_multiple_resources(self, mock_naming_generator, mock_naming_validator):
+    def test_naming_workflow_multiple_resources(
+        self, mock_naming_generator, mock_naming_validator
+    ):
         """Test naming workflow for multiple resources"""
         resources = [
             ("prod", "app", "service", "v1.0.0"),
@@ -49,7 +55,9 @@ class TestNamingWorkflowE2E:
 
     @pytest.mark.e2e
     @pytest.mark.slow
-    def test_naming_workflow_bulk_processing(self, mock_naming_generator, mock_naming_validator):
+    def test_naming_workflow_bulk_processing(
+        self, mock_naming_generator, mock_naming_validator
+    ):
         """Test naming workflow with bulk processing"""
         # Generate and validate 1000 names
         for i in range(1000):
@@ -62,12 +70,16 @@ class TestNamingWorkflowIntegration:
     """Integration tests for naming workflow"""
 
     @pytest.mark.e2e
-    def test_naming_workflow_with_ci_cd(self, mock_naming_generator, mock_naming_validator):
+    def test_naming_workflow_with_ci_cd(
+        self, mock_naming_generator, mock_naming_validator
+    ):
         """Test naming workflow integration with CI/CD"""
         # Simulate CI/CD pipeline
         names = []
         for i in range(10):
-            name = mock_naming_generator.generate("prod", "app", f"service-{i}", "v1.0.0")
+            name = mock_naming_generator.generate(
+                "prod", "app", f"service-{i}", "v1.0.0"
+            )
             names.append(name)
 
         # Validate all names
@@ -75,7 +87,9 @@ class TestNamingWorkflowIntegration:
         assert all(r["valid"] for r in results)
 
     @pytest.mark.e2e
-    def test_naming_workflow_with_monitoring(self, mock_naming_generator, mock_naming_validator):
+    def test_naming_workflow_with_monitoring(
+        self, mock_naming_generator, mock_naming_validator
+    ):
         """Test naming workflow with monitoring integration"""
         # Generate names and track metrics
         metrics = {"generated": 0, "validated": 0, "valid": 0, "invalid": 0}
diff --git a/workspace/governance/tests/e2e/test_quantum_workflow.py b/workspace/governance/tests/e2e/test_quantum_workflow.py
index 4c6edfc..13d7a0a 100644
--- a/workspace/governance/tests/e2e/test_quantum_workflow.py
+++ b/workspace/governance/tests/e2e/test_quantum_workflow.py
@@ -26,7 +26,11 @@ class TestQuantumWorkflowE2E:
         assert entanglement >= 0.95
 
         # Step 4: Observability injection
-        metrics = {"coherence": coherence, "entanglement": entanglement, "decoherence_rate": 0.0001}
+        metrics = {
+            "coherence": coherence,
+            "entanglement": entanglement,
+            "decoherence_rate": 0.0001,
+        }
         assert all(v is not None for v in metrics.values())
 
         # Step 5: Auto-repair
diff --git a/workspace/governance/tests/unit/test_naming_generator.py b/workspace/governance/tests/unit/test_naming_generator.py
index 558d730..6c0d6ac 100644
--- a/workspace/governance/tests/unit/test_naming_generator.py
+++ b/workspace/governance/tests/unit/test_naming_generator.py
@@ -23,15 +23,21 @@ class TestNamingGenerator:
         assert result == "staging-api-gateway-v2.1.3"
         assert mock_naming_generator.validate_pattern(result)
 
-    def test_validate_pattern_valid_names(self, mock_naming_generator, sample_resource_names):
+    def test_validate_pattern_valid_names(
+        self, mock_naming_generator, sample_resource_names
+    ):
         """Test pattern validation with valid names"""
         for name in sample_resource_names["valid"]:
             assert mock_naming_generator.validate_pattern(name), f"Failed for: {name}"
 
-    def test_validate_pattern_invalid_names(self, mock_naming_generator, sample_resource_names):
+    def test_validate_pattern_invalid_names(
+        self, mock_naming_generator, sample_resource_names
+    ):
         """Test pattern validation with invalid names"""
         for name in sample_resource_names["invalid"]:
-            assert not mock_naming_generator.validate_pattern(name), f"Should fail for: {name}"
+            assert not mock_naming_generator.validate_pattern(
+                name
+            ), f"Should fail for: {name}"
 
     def test_generate_lowercase_only(self, mock_naming_generator):
         """Test that generated names are lowercase only"""
diff --git a/workspace/governance/tests/unit/test_naming_validator.py b/workspace/governance/tests/unit/test_naming_validator.py
index fdead03..20a84cb 100644
--- a/workspace/governance/tests/unit/test_naming_validator.py
+++ b/workspace/governance/tests/unit/test_naming_validator.py
@@ -39,13 +39,17 @@ class TestNamingValidator:
         assert result["valid"] is False
         assert len(result["errors"]) > 0
 
-    def test_validate_multiple_valid_names(self, mock_naming_validator, sample_resource_names):
+    def test_validate_multiple_valid_names(
+        self, mock_naming_validator, sample_resource_names
+    ):
         """Test validation of multiple valid names"""
         for name in sample_resource_names["valid"]:
             result = mock_naming_validator.validate(name)
             assert result["valid"] is True, f"Failed for: {name}"
 
-    def test_validate_multiple_invalid_names(self, mock_naming_validator, sample_resource_names):
+    def test_validate_multiple_invalid_names(
+        self, mock_naming_validator, sample_resource_names
+    ):
         """Test validation of multiple invalid names"""
         for name in sample_resource_names["invalid"]:
             result = mock_naming_validator.validate(name)
diff --git a/workspace/guardrails_client.py b/workspace/guardrails_client.py
index 2c533b0..d054ddb 100644
--- a/workspace/guardrails_client.py
+++ b/workspace/guardrails_client.py
@@ -20,9 +20,13 @@ def _safe_import(module_name: str, attr: str) -> Tuple[Optional[Any], bool]:
         return None, False
 
 
-GuardrailsOpenAI, HAS_GUARDRAILS_CLIENT = _safe_import("guardrails.hub", "GuardrailsOpenAI")
+GuardrailsOpenAI, HAS_GUARDRAILS_CLIENT = _safe_import(
+    "guardrails.hub", "GuardrailsOpenAI"
+)
 if GuardrailsOpenAI is None:
-    GuardrailsOpenAI, HAS_GUARDRAILS_CLIENT = _safe_import("guardrails", "GuardrailsOpenAI")
+    GuardrailsOpenAI, HAS_GUARDRAILS_CLIENT = _safe_import(
+        "guardrails", "GuardrailsOpenAI"
+    )
 OpenAI, HAS_OPENAI_CLIENT = _safe_import("openai", "OpenAI")
 
 DEFAULT_MODEL = (
@@ -33,7 +37,9 @@ DEFAULT_MODEL = (
 
 
 def _get_api_key() -> Optional[str]:
-    return os.environ.get("AI_INTEGRATIONS_OPENAI_API_KEY") or os.environ.get("OPENAI_API_KEY")
+    return os.environ.get("AI_INTEGRATIONS_OPENAI_API_KEY") or os.environ.get(
+        "OPENAI_API_KEY"
+    )
 
 
 def get_api_key() -> Optional[str]:
@@ -42,7 +48,9 @@ def get_api_key() -> Optional[str]:
 
 
 def _get_base_url() -> Optional[str]:
-    return os.environ.get("AI_INTEGRATIONS_OPENAI_BASE_URL") or os.environ.get("OPENAI_BASE_URL")
+    return os.environ.get("AI_INTEGRATIONS_OPENAI_BASE_URL") or os.environ.get(
+        "OPENAI_BASE_URL"
+    )
 
 
 def client_available(api_key: Optional[str] = None) -> bool:
diff --git a/workspace/mcp/validation-mcp/tools/github_project_analyzer.py b/workspace/mcp/validation-mcp/tools/github_project_analyzer.py
index 799bf10..d6684a3 100644
--- a/workspace/mcp/validation-mcp/tools/github_project_analyzer.py
+++ b/workspace/mcp/validation-mcp/tools/github_project_analyzer.py
@@ -54,7 +54,9 @@ class GitHubAnalyzerConfig:
 class GitHubProjectAnalyzer:
     def __init__(self, config: GitHubAnalyzerConfig):
         self.config = config
-        self.base_url = f"https://api.github.com/repos/{config.repo_owner}/{config.repo_name}"
+        self.base_url = (
+            f"https://api.github.com/repos/{config.repo_owner}/{config.repo_name}"
+        )
         self.headers = {
             "Accept": "application/vnd.github.v3+json",
             "User-Agent": "namespace-mcp-Analyzer/2.1.0",
@@ -119,10 +121,14 @@ class GitHubProjectAnalyzer:
 
             # Scan for merge conflict markers using Python (safer than
             # subprocess)
-            results["merge_conflicts"] = self._scan_for_conflicts(local_path / "workspace")
+            results["merge_conflicts"] = self._scan_for_conflicts(
+                local_path / "workspace"
+            )
 
             # Scan governance scripts
-            governance_scripts_path = local_path / "workspace" / "src" / "governance" / "scripts"
+            governance_scripts_path = (
+                local_path / "workspace" / "src" / "governance" / "scripts"
+            )
             if governance_scripts_path.exists():
                 results["governance_scripts"] = [
                     f.name for f in governance_scripts_path.glob("*.py")
@@ -131,13 +137,17 @@ class GitHubProjectAnalyzer:
             # Scan workflows
             workflows_path = local_path / ".github" / "workflows"
             if workflows_path.exists():
-                results["workflows"] = [f.name for f in workflows_path.glob("*.yml")] + [
-                    f.name for f in workflows_path.glob("*.yaml")
-                ]
+                results["workflows"] = [
+                    f.name for f in workflows_path.glob("*.yml")
+                ] + [f.name for f in workflows_path.glob("*.yaml")]
 
             # Load pipeline config
             pipeline_path = (
-                local_path / "workspace" / "mcp" / "pipelines" / "unified-pipeline-config.yaml"
+                local_path
+                / "workspace"
+                / "mcp"
+                / "pipelines"
+                / "unified-pipeline-config.yaml"
             )
             if pipeline_path.exists() and yaml:
                 try:
@@ -166,7 +176,9 @@ class GitHubProjectAnalyzer:
             if response.ok:
                 self._repo_stats = response.json()
             else:
-                logger.warning("Failed to fetch repo stats (status %s)", response.status_code)
+                logger.warning(
+                    "Failed to fetch repo stats (status %s)", response.status_code
+                )
                 self._repo_stats = {}
         except Exception as exc:
             logger.warning("Error fetching repo stats: %s", exc)
@@ -187,7 +199,17 @@ class GitHubProjectAnalyzer:
         conflict_marker = "<<<<<<<".encode()
 
         # File extensions that are likely to have conflicts
-        text_extensions = {".md", ".yaml", ".yml", ".py", ".ts", ".js", ".json", ".txt", ".sh"}
+        text_extensions = {
+            ".md",
+            ".yaml",
+            ".yml",
+            ".py",
+            ".ts",
+            ".js",
+            ".json",
+            ".txt",
+            ".sh",
+        }
         # Patterns to skip (binary files, specific directories)
         skip_patterns = {
             "node_modules",
@@ -294,15 +316,30 @@ class GitHubProjectAnalyzer:
             ],
             "tech_stack": self._get_actual_tech_stack(),
             "module_relationships": {
-                "core": {"dependencies": ["utils", "config"], "dependents": ["api", "services"]},
-                "api": {"dependencies": ["core", "auth"], "dependents": ["gateway", "clients"]},
+                "core": {
+                    "dependencies": ["utils", "config"],
+                    "dependents": ["api", "services"],
+                },
+                "api": {
+                    "dependencies": ["core", "auth"],
+                    "dependents": ["gateway", "clients"],
+                },
                 "services": {
                     "dependencies": ["core", "db"],
                     "dependents": ["workers", "schedulers"],
                 },
-                "mcp-servers": {"dependencies": ["core"], "dependents": ["automation", "agents"]},
-                "governance": {"dependencies": ["config"], "dependents": ["ci-cd", "validation"]},
-                "shared": {"dependencies": [], "dependents": ["core", "mcp-servers", "services"]},
+                "mcp-servers": {
+                    "dependencies": ["core"],
+                    "dependents": ["automation", "agents"],
+                },
+                "governance": {
+                    "dependencies": ["config"],
+                    "dependents": ["ci-cd", "validation"],
+                },
+                "shared": {
+                    "dependencies": [],
+                    "dependents": ["core", "mcp-servers", "services"],
+                },
             },
             "scalability_considerations": [
                 (
@@ -357,9 +394,22 @@ class GitHubProjectAnalyzer:
         # available.
         performance_metrics = (
             {
-                "latency": {"current": "15ms", "p95": "15ms", "target": "<20ms", "status": "met"},
-                "throughput": {"current": "50k rpm", "target": "100k rpm", "status": "partial"},
-                "availability": {"current": "99.95%", "target": "99.99%", "status": "met"},
+                "latency": {
+                    "current": "15ms",
+                    "p95": "15ms",
+                    "target": "<20ms",
+                    "status": "met",
+                },
+                "throughput": {
+                    "current": "50k rpm",
+                    "target": "100k rpm",
+                    "status": "partial",
+                },
+                "availability": {
+                    "current": "99.95%",
+                    "target": "99.99%",
+                    "status": "met",
+                },
                 "error_rate": {
                     "current": "0.1%",
                     "target": "<0.05%",
@@ -419,7 +469,9 @@ class GitHubProjectAnalyzer:
 
         return {
             "core_features": features if self.config.include_code_samples else [],
-            "performance_metrics": performance_metrics if self.config.include_metrics else {},
+            "performance_metrics": (
+                performance_metrics if self.config.include_metrics else {}
+            ),
             "repository_stats": {
                 "stars": stats.get("stargazers_count", "N/A"),
                 "forks": stats.get("forks_count", "N/A"),
@@ -445,15 +497,25 @@ class GitHubProjectAnalyzer:
 
     def _get_pipeline_performance_metrics(self) -> Dict[str, Dict[str, Any]]:
         """Get actual performance metrics from pipeline config."""
-        if not self._local_scan_results or not self._local_scan_results.get("pipeline_config"):
+        if not self._local_scan_results or not self._local_scan_results.get(
+            "pipeline_config"
+        ):
             return {
-                "latency": {"current": "N/A", "target": "<=100ms (instant)", "status": "unknown"},
+                "latency": {
+                    "current": "N/A",
+                    "target": "<=100ms (instant)",
+                    "status": "unknown",
+                },
                 "throughput": {
                     "current": "N/A",
                     "target": "256 parallel agents",
                     "status": "unknown",
                 },
-                "availability": {"current": "N/A", "target": "99.99%", "status": "unknown"},
+                "availability": {
+                    "current": "N/A",
+                    "target": "99.99%",
+                    "status": "unknown",
+                },
             }
 
         config = self._local_scan_results["pipeline_config"]
@@ -494,7 +556,9 @@ class GitHubProjectAnalyzer:
             "typescript_files": self._local_scan_results.get("typescript_files", 0),
             "yaml_configs": self._local_scan_results.get("yaml_configs", 0),
             "mcp_servers": len(self._local_scan_results.get("mcp_servers", [])),
-            "governance_scripts": len(self._local_scan_results.get("governance_scripts", [])),
+            "governance_scripts": len(
+                self._local_scan_results.get("governance_scripts", [])
+            ),
             "workflows": len(self._local_scan_results.get("workflows", [])),
         }
 
@@ -522,9 +586,13 @@ class GitHubProjectAnalyzer:
             # Check governance validation status from pipeline config
             pipeline_config = self._local_scan_results.get("pipeline_config")
             if pipeline_config:
-                gov_validation = pipeline_config.get("spec", {}).get("governanceValidation", [])
+                gov_validation = pipeline_config.get("spec", {}).get(
+                    "governanceValidation", []
+                )
                 planned_validators = [
-                    v for v in gov_validation if v.get("implementationStatus") == "planned"
+                    v
+                    for v in gov_validation
+                    if v.get("implementationStatus") == "planned"
                 ]
                 if planned_validators:
                     high_priority.append(
@@ -534,7 +602,9 @@ class GitHubProjectAnalyzer:
                             "estimated_effort": "3-5 å¤©",
                             "dependencies": ["governance framework"],
                             "impact": "High - å•Ÿç”¨è‡ªå‹•åˆè¦é©—è­‰",
-                            "planned_validators": [v.get("validator") for v in planned_validators],
+                            "planned_validators": [
+                                v.get("validator") for v in planned_validators
+                            ],
                         }
                     )
 
@@ -623,7 +693,11 @@ class GitHubProjectAnalyzer:
 
         return {
             "code_quality": {
-                "best_practices": ["INSTANT execution", "Zero human intervention", "Event-driven"],
+                "best_practices": [
+                    "INSTANT execution",
+                    "Zero human intervention",
+                    "Event-driven",
+                ],
                 "quality_metrics": {
                     "python_files": local_stats.get("python_files", "N/A"),
                     "typescript_files": local_stats.get("typescript_files", "N/A"),
@@ -636,7 +710,9 @@ class GitHubProjectAnalyzer:
                 ],
             },
             "documentation": {
-                "completeness": "good" if local_stats.get("yaml_configs", 0) > 50 else "partial",
+                "completeness": (
+                    "good" if local_stats.get("yaml_configs", 0) > 50 else "partial"
+                ),
                 "readability": "bilingual (Chinese/English)",
                 "coverage_areas": ["architecture", "governance", "MCP servers"],
                 "missing_areas": ["performance tuning guide", "troubleshooting"],
@@ -737,7 +813,9 @@ class GitHubProjectAnalyzer:
         if analysis["metadata"].get("local_scan_enabled"):
             local_scan_note = "\n> âœ… å·²å•Ÿç”¨æœ¬åœ°å€‰åº«æƒæï¼Œæ•¸æ“šä¾†è‡ªå¯¦éš›æ–‡ä»¶åˆ†æã€‚\n"
         else:
-            local_scan_note = "\n> âš ï¸ æœªå•Ÿç”¨æœ¬åœ°æƒæã€‚ä½¿ç”¨ `--local-path` åƒæ•¸ç²å–æ›´æº–ç¢ºçš„åˆ†æã€‚\n"
+            local_scan_note = (
+                "\n> âš ï¸ æœªå•Ÿç”¨æœ¬åœ°æƒæã€‚ä½¿ç”¨ `--local-path` åƒæ•¸ç²å–æ›´æº–ç¢ºçš„åˆ†æã€‚\n"
+            )
 
         report = f"""# GitHub å°ˆæ¡ˆæ·±åº¦åˆ†æå ±å‘Š
 
@@ -917,7 +995,9 @@ namespace-mcp-cli prompt fix --input=inconsistent_prompt.md --output=fixed_promp
     def _format_capabilities(self, capabilities: List[Dict[str, Any]]) -> str:
         result = ""
         for cap in capabilities:
-            result += f"- **{cap['name']}** ({cap['status']}, æˆç†Ÿåº¦: {cap['maturity']})\n"
+            result += (
+                f"- **{cap['name']}** ({cap['status']}, æˆç†Ÿåº¦: {cap['maturity']})\n"
+            )
             result += f"  - {cap['description']}\n"
         return result
 
@@ -935,13 +1015,17 @@ namespace-mcp-cli prompt fix --input=inconsistent_prompt.md --output=fixed_promp
         )
 
     def _format_performance_metrics(self, metrics: Dict[str, Dict[str, Any]]) -> str:
-        result = "| æŒ‡æ¨™ | ç•¶å‰å€¼ | ç›®æ¨™å€¼ | ç‹€æ…‹ |\n|------|--------|--------|------|\n"
+        result = (
+            "| æŒ‡æ¨™ | ç•¶å‰å€¼ | ç›®æ¨™å€¼ | ç‹€æ…‹ |\n|------|--------|--------|------|\n"
+        )
         for metric, data in metrics.items():
             current_value = data.get("current")
             if current_value is None and "p95" in data:
                 current_value = data["p95"]
             status = data.get("status", "")
-            status_emoji = "âœ…" if status == "met" else "âš ï¸" if status == "partial" else "âŒ"
+            status_emoji = (
+                "âœ…" if status == "met" else "âš ï¸" if status == "partial" else "âŒ"
+            )
             target_val = data.get("target", "")
             result += f"| {metric} | {current_value or ''} | {target_val} | {status_emoji} |\n"
         return result
@@ -1043,7 +1127,8 @@ def _parse_args() -> argparse.Namespace:
     args = parser.parse_args()
     if not args.owner or not args.repo:
         parser.error(
-            "Repository owner and name are required via --owner/--repo " "or environment variables."
+            "Repository owner and name are required via --owner/--repo "
+            "or environment variables."
         )
     return args
 
diff --git a/workspace/mcp/validation-mcp/tools/github_project_analyzer_quantum.py b/workspace/mcp/validation-mcp/tools/github_project_analyzer_quantum.py
index ae7ae7c..76e5181 100644
--- a/workspace/mcp/validation-mcp/tools/github_project_analyzer_quantum.py
+++ b/workspace/mcp/validation-mcp/tools/github_project_analyzer_quantum.py
@@ -21,7 +21,9 @@ from typing import Any, Dict, List
 
 import yaml
 
-logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
+logging.basicConfig(
+    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
+)
 logger = logging.getLogger(__name__)
 
 
@@ -59,7 +61,11 @@ class QuantumComputeEngine:
         }
 
     def _qaoa(self, p):
-        return {"algo": "QAOA", "opt": random.random(), "fidelity": random.uniform(0.90, 0.98)}
+        return {
+            "algo": "QAOA",
+            "opt": random.random(),
+            "fidelity": random.uniform(0.90, 0.98),
+        }
 
     def _qml(self, p):
         return {
@@ -277,18 +283,28 @@ class WorkspaceValidator:
             # æª¢æŸ¥é‡è¤‡å®šç¾©
             import re
 
-            const_declarations = re.findall(r"^const\s+(\w+)\s*[=:]", content, re.MULTILINE)
+            const_declarations = re.findall(
+                r"^const\s+(\w+)\s*[=:]", content, re.MULTILINE
+            )
             if len(const_declarations) != len(set(const_declarations)):
-                result["warnings"].append("Potential duplicate const declarations found")
+                result["warnings"].append(
+                    "Potential duplicate const declarations found"
+                )
 
-            interface_declarations = re.findall(r"^interface\s+(\w+)", content, re.MULTILINE)
+            interface_declarations = re.findall(
+                r"^interface\s+(\w+)", content, re.MULTILINE
+            )
             if len(interface_declarations) != len(set(interface_declarations)):
-                result["warnings"].append("Potential duplicate interface declarations found")
+                result["warnings"].append(
+                    "Potential duplicate interface declarations found"
+                )
 
             # æª¢æŸ¥é‡è¤‡çš„ import èªå¥
             # ä¸€èˆ¬ importï¼ˆæ’é™¤ type-only importï¼‰
             imports = re.findall(
-                r'^import\s+(?!type\b).*from\s+["\']([^"\']+)["\']', content, re.MULTILINE
+                r'^import\s+(?!type\b).*from\s+["\']([^"\']+)["\']',
+                content,
+                re.MULTILINE,
             )
             # type-only import
             type_imports = re.findall(
@@ -306,7 +322,9 @@ class WorkspaceValidator:
             seen_type_imports = set()
             for imp in type_imports:
                 if imp in seen_type_imports:
-                    result["warnings"].append(f"Duplicate type import from module: {imp}")
+                    result["warnings"].append(
+                        f"Duplicate type import from module: {imp}"
+                    )
                 else:
                     seen_type_imports.add(imp)
         except Exception as e:
@@ -414,12 +432,18 @@ class WorkspaceValidator:
             "typescript_files": len(ts_files),
             "python_files": len(py_files),
             "markdown_files": len(md_files),
-            "yaml_valid": sum(1 for r in self.validation_results["yaml_files"] if r["valid"]),
-            "json_valid": sum(1 for r in self.validation_results["json_files"] if r["valid"]),
+            "yaml_valid": sum(
+                1 for r in self.validation_results["yaml_files"] if r["valid"]
+            ),
+            "json_valid": sum(
+                1 for r in self.validation_results["json_files"] if r["valid"]
+            ),
             "typescript_valid": sum(
                 1 for r in self.validation_results["typescript_files"] if r["valid"]
             ),
-            "python_valid": sum(1 for r in self.validation_results["python_files"] if r["valid"]),
+            "python_valid": sum(
+                1 for r in self.validation_results["python_files"] if r["valid"]
+            ),
             "total_errors": len(self.validation_results["errors"]),
             "total_warnings": len(self.validation_results["warnings"]),
         }
@@ -430,7 +454,9 @@ class WorkspaceValidator:
 class GitHubProjectAnalyzer:
     def __init__(self, config: GitHubAnalyzerConfig):
         self.config = config
-        self.base_url = f"https://api.github.com/repos/{config.repo_owner}/{config.repo_name}"
+        self.base_url = (
+            f"https://api.github.com/repos/{config.repo_owner}/{config.repo_name}"
+        )
         self.headers = {
             "Accept": "application/vnd.github.v3+json",
             "User-Agent": "namespace-mcp-Analyzer/3.0.0",
@@ -456,7 +482,9 @@ class GitHubProjectAnalyzer:
         analysis_result["sections"]["todo_list"] = self._analyze_todo_list()
         analysis_result["sections"]["diagnostics"] = self._analyze_diagnostics()
         analysis_result["sections"]["deep_details"] = self._analyze_deep_details()
-        analysis_result["sections"]["quantum_analysis"] = self._analyze_quantum_potential()
+        analysis_result["sections"][
+            "quantum_analysis"
+        ] = self._analyze_quantum_potential()
 
         return analysis_result
 
@@ -485,7 +513,9 @@ class GitHubProjectAnalyzer:
             "algorithms_tested": ["VQE", "QAOA", "QML"],
             "results": {"VQE": vqe_result, "QAOA": qaoa_result, "QML": qml_result},
             "average_fidelity": (
-                vqe_result["fidelity"] + qaoa_result["fidelity"] + qml_result["fidelity"]
+                vqe_result["fidelity"]
+                + qaoa_result["fidelity"]
+                + qml_result["fidelity"]
             )
             / 3,
         }
@@ -524,7 +554,10 @@ class GitHubProjectAnalyzer:
                     "dependencies": ["mcp-servers", "schemas"],
                     "dependents": ["governance", "ci-cd"],
                 },
-                "tools": {"dependencies": ["types"], "dependents": ["mcp-servers", "validation"]},
+                "tools": {
+                    "dependencies": ["types"],
+                    "dependents": ["mcp-servers", "validation"],
+                },
             },
         }
 
@@ -559,8 +592,16 @@ class GitHubProjectAnalyzer:
             ],
             "performance_metrics": {
                 "latency": {"current": "8ms", "target": "<10ms", "status": "met"},
-                "throughput": {"current": "100k rpm", "target": "200k rpm", "status": "met"},
-                "availability": {"current": "99.99%", "target": "99.999%", "status": "met"},
+                "throughput": {
+                    "current": "100k rpm",
+                    "target": "200k rpm",
+                    "status": "met",
+                },
+                "availability": {
+                    "current": "99.99%",
+                    "target": "99.999%",
+                    "status": "met",
+                },
                 "mcp_tools": {"current": "59", "target": "59", "status": "met"},
             },
         }
@@ -623,7 +664,11 @@ class GitHubProjectAnalyzer:
         """æ·±åº¦ç´°ç¯€åˆ†æ"""
         return {
             "code_quality": {
-                "best_practices": ["SOLID principles", "DRY", "MCP Protocol compliance"],
+                "best_practices": [
+                    "SOLID principles",
+                    "DRY",
+                    "MCP Protocol compliance",
+                ],
                 "quality_metrics": {
                     "test_coverage": "70%",
                     "code_complexity": "low",
@@ -632,7 +677,12 @@ class GitHubProjectAnalyzer:
             },
             "documentation": {
                 "completeness": "excellent",
-                "coverage_areas": ["API docs", "architecture", "deployment", "MCP tools"],
+                "coverage_areas": [
+                    "API docs",
+                    "architecture",
+                    "deployment",
+                    "MCP tools",
+                ],
             },
         }
 
@@ -778,12 +828,16 @@ class GitHubProjectAnalyzer:
     def _format_capabilities(self, capabilities: List[Dict]) -> str:
         result = ""
         for cap in capabilities:
-            result += f"- **{cap['name']}** ({cap['status']}, æˆç†Ÿåº¦: {cap['maturity']})\n"
+            result += (
+                f"- **{cap['name']}** ({cap['status']}, æˆç†Ÿåº¦: {cap['maturity']})\n"
+            )
             result += f"  - {cap['description']}\n"
         return result
 
     def _format_performance_metrics(self, metrics: Dict) -> str:
-        result = "| æŒ‡æ¨™ | ç•¶å‰å€¼ | ç›®æ¨™å€¼ | ç‹€æ…‹ |\n|------|--------|--------|------|\n"
+        result = (
+            "| æŒ‡æ¨™ | ç•¶å‰å€¼ | ç›®æ¨™å€¼ | ç‹€æ…‹ |\n|------|--------|--------|------|\n"
+        )
         for metric, data in metrics.items():
             status_emoji = "âœ…" if data["status"] == "met" else "âš ï¸"
             result += f"| {metric} | {data['current']} | {data['target']} | {status_emoji} |\n"
@@ -814,8 +868,12 @@ def main():
     parser.add_argument("--owner", default="namespace-mcp", help="å€‰åº«æ“æœ‰è€…")
     parser.add_argument("--repo", default="namespace-mcp", help="å€‰åº«åç¨±")
     parser.add_argument("--scope", default="entire", help="åˆ†æç¯„åœ")
-    parser.add_argument("--output", default="workspace_mcp_validation_report.md", help="è¼¸å‡ºæ–‡ä»¶")
-    parser.add_argument("--quantum", action="store_true", default=True, help="å•Ÿç”¨é‡å­åˆ†æ")
+    parser.add_argument(
+        "--output", default="workspace_mcp_validation_report.md", help="è¼¸å‡ºæ–‡ä»¶"
+    )
+    parser.add_argument(
+        "--quantum", action="store_true", default=True, help="å•Ÿç”¨é‡å­åˆ†æ"
+    )
 
     args = parser.parse_args()
 
diff --git a/workspace/mcp/validation-mcp/tools/github_project_analyzer_v2.py b/workspace/mcp/validation-mcp/tools/github_project_analyzer_v2.py
index a8e0f47..5d19452 100644
--- a/workspace/mcp/validation-mcp/tools/github_project_analyzer_v2.py
+++ b/workspace/mcp/validation-mcp/tools/github_project_analyzer_v2.py
@@ -32,7 +32,9 @@ class GitHubAnalyzerConfig:
 class GitHubProjectAnalyzer:
     def __init__(self, config: GitHubAnalyzerConfig):
         self.config = config
-        self.base_url = f"https://api.github.com/repos/{config.repo_owner}/{config.repo_name}"
+        self.base_url = (
+            f"https://api.github.com/repos/{config.repo_owner}/{config.repo_name}"
+        )
         self.headers = {
             "Accept": "application/vnd.github.v3+json",
             "User-Agent": "namespace-mcp-Analyzer/2.0.0",
@@ -91,8 +93,14 @@ class GitHubProjectAnalyzer:
                 "monitoring": ["Prometheus", "Grafana", "Jaeger"],
             },
             "module_relationships": {
-                "core": {"dependencies": ["utils", "config"], "dependents": ["api", "services"]},
-                "api": {"dependencies": ["core", "auth"], "dependents": ["gateway", "clients"]},
+                "core": {
+                    "dependencies": ["utils", "config"],
+                    "dependents": ["api", "services"],
+                },
+                "api": {
+                    "dependencies": ["core", "auth"],
+                    "dependents": ["gateway", "clients"],
+                },
                 "services": {
                     "dependencies": ["core", "db"],
                     "dependents": ["workers", "schedulers"],
@@ -137,8 +145,16 @@ class GitHubProjectAnalyzer:
             ],
             "performance_metrics": {
                 "latency": {"p95": "15ms", "target": "<20ms", "status": "met"},
-                "throughput": {"current": "50k rpm", "target": "100k rpm", "status": "partial"},
-                "availability": {"current": "99.95%", "target": "99.99%", "status": "met"},
+                "throughput": {
+                    "current": "50k rpm",
+                    "target": "100k rpm",
+                    "status": "partial",
+                },
+                "availability": {
+                    "current": "99.95%",
+                    "target": "99.99%",
+                    "status": "met",
+                },
                 "error_rate": {
                     "current": "0.1%",
                     "target": "<0.05%",
@@ -482,12 +498,16 @@ namespace-mcp-cli prompt fix --input=inconsistent_prompt.md --output=fixed_promp
     def _format_capabilities(self, capabilities: List[Dict]) -> str:
         result = ""
         for cap in capabilities:
-            result += f"- **{cap['name']}** ({cap['status']}, æˆç†Ÿåº¦: {cap['maturity']})\n"
+            result += (
+                f"- **{cap['name']}** ({cap['status']}, æˆç†Ÿåº¦: {cap['maturity']})\n"
+            )
             result += f"  - {cap['description']}\n"
         return result
 
     def _format_performance_metrics(self, metrics: Dict) -> str:
-        result = "| æŒ‡æ¨™ | ç•¶å‰å€¼ | ç›®æ¨™å€¼ | ç‹€æ…‹ |\n|------|--------|--------|------|\n"
+        result = (
+            "| æŒ‡æ¨™ | ç•¶å‰å€¼ | ç›®æ¨™å€¼ | ç‹€æ…‹ |\n|------|--------|--------|------|\n"
+        )
         for metric, data in metrics.items():
             status_emoji = (
                 "âœ…"
diff --git a/workspace/mcp/validation-mcp/tools/load_unified_pipeline.py b/workspace/mcp/validation-mcp/tools/load_unified_pipeline.py
index ce11d9f..79c1042 100644
--- a/workspace/mcp/validation-mcp/tools/load_unified_pipeline.py
+++ b/workspace/mcp/validation-mcp/tools/load_unified_pipeline.py
@@ -26,7 +26,9 @@ import yaml
 logger = logging.getLogger(__name__)
 
 
-MANIFEST_PATH = Path("00-namespaces/namespaces-mcp/pipelines/unified-pipeline-config.yaml")
+MANIFEST_PATH = Path(
+    "00-namespaces/namespaces-mcp/pipelines/unified-pipeline-config.yaml"
+)
 SCHEMA_PATH = Path("00-namespaces/namespaces-mcp/schemas/unified-pipeline.schema.json")
 
 
@@ -393,7 +395,9 @@ def _parse_auto_healing(spec: Dict[str, Any]) -> Optional[AutoHealing]:
     )
 
 
-def _parse_governance_validation(spec: Dict[str, Any]) -> Optional[List[GovernanceValidationRule]]:
+def _parse_governance_validation(
+    spec: Dict[str, Any],
+) -> Optional[List[GovernanceValidationRule]]:
     """Parse governance validation rules from spec data."""
     if "governanceValidation" not in spec:
         return None
@@ -403,7 +407,8 @@ def _parse_governance_validation(spec: Dict[str, Any]) -> Optional[List[Governan
         return None
 
     return [
-        _safe_construct(GovernanceValidationRule, g, "governanceValidation[*]") for g in gv_data
+        _safe_construct(GovernanceValidationRule, g, "governanceValidation[*]")
+        for g in gv_data
     ]
 
 
@@ -472,7 +477,8 @@ def _parse_mcp_integration(spec: Dict[str, Any]) -> McpIntegration:
     if not isinstance(adapters_data, list):
         raise ValueError("spec.mcpIntegration.toolAdapters must be a list")
     adapters = [
-        _safe_construct(ToolAdapter, t, "mcpIntegration.toolAdapters[*]") for t in adapters_data
+        _safe_construct(ToolAdapter, t, "mcpIntegration.toolAdapters[*]")
+        for t in adapters_data
     ]
 
     return McpIntegration(
@@ -516,7 +522,9 @@ def load_manifest(path: Path = MANIFEST_PATH) -> UnifiedPipelineManifest:
     # Parse optional configurations
     auto_scaling = _parse_auto_scaling(spec)
     latency_thresholds = (
-        _safe_construct(LatencyThresholds, spec["latencyThresholds"], "latencyThresholds")
+        _safe_construct(
+            LatencyThresholds, spec["latencyThresholds"], "latencyThresholds"
+        )
         if "latencyThresholds" in spec
         else None
     )
@@ -578,7 +586,9 @@ def _safe_construct(cls, data: dict, label: str):
     try:
         return cls(**filtered_data)
     except (TypeError, KeyError, ValueError) as exc:
-        raise ValueError(f"Failed constructing {label} for {cls.__name__}: {exc}") from exc
+        raise ValueError(
+            f"Failed constructing {label} for {cls.__name__}: {exc}"
+        ) from exc
 
 
 # ========================================
diff --git a/workspace/namespace-converter.py b/workspace/namespace-converter.py
index ade3dd8..00db32d 100755
--- a/workspace/namespace-converter.py
+++ b/workspace/namespace-converter.py
@@ -85,9 +85,13 @@ class NamespaceConverter:
                     with open(file_path, "w", encoding="utf-8") as f:
                         f.write(converted_content)
                     if self.verbose:
-                        print(f"âœ… Updated {file_path}: {file_conversions} conversion(s)")
+                        print(
+                            f"âœ… Updated {file_path}: {file_conversions} conversion(s)"
+                        )
                 else:
-                    print(f"ğŸ” Would update {file_path}: {file_conversions} conversion(s)")
+                    print(
+                        f"ğŸ” Would update {file_path}: {file_conversions} conversion(s)"
+                    )
             elif self.verbose:
                 print(f"â­ï¸  No changes needed: {file_path}")
 
@@ -142,7 +146,9 @@ class NamespaceConverter:
         if self.stats["conversions_by_rule"]:
             report += "ğŸ”§ Conversions by Rule:\n"
             for pattern, count in sorted(
-                self.stats["conversions_by_rule"].items(), key=lambda x: x[1], reverse=True
+                self.stats["conversions_by_rule"].items(),
+                key=lambda x: x[1],
+                reverse=True,
             ):
                 report += f"  {pattern[:40]:40} â†’ {count:4} conversion(s)\n"
         else:
@@ -182,7 +188,9 @@ Examples:
     parser.add_argument(
         "--dry-run", action="store_true", help="Preview changes without applying them"
     )
-    parser.add_argument("--verbose", action="store_true", help="Show detailed output for all files")
+    parser.add_argument(
+        "--verbose", action="store_true", help="Show detailed output for all files"
+    )
     parser.add_argument("--report", help="Save conversion report to file")
 
     args = parser.parse_args()
diff --git a/workspace/namespace-validator.py b/workspace/namespace-validator.py
index 199616f..7f2c07b 100755
--- a/workspace/namespace-validator.py
+++ b/workspace/namespace-validator.py
@@ -144,7 +144,14 @@ class NamespaceValidator:
         for file_path in directory.rglob("*"):
             if file_path.is_file() and file_path.suffix in extensions:
                 # Skip certain directories
-                skip_dirs = {".git", "node_modules", "__pycache__", "dist", "build", "archive"}
+                skip_dirs = {
+                    ".git",
+                    "node_modules",
+                    "__pycache__",
+                    "dist",
+                    "build",
+                    "archive",
+                }
                 if any(skip_dir in file_path.parts for skip_dir in skip_dirs):
                     continue
 
@@ -187,7 +194,9 @@ class NamespaceValidator:
 """
 
         if compliance_rate == 100:
-            report += "âœ… **All files are 100% compliant with MachineNativeOps namespace!**\n"
+            report += (
+                "âœ… **All files are 100% compliant with MachineNativeOps namespace!**\n"
+            )
         elif compliance_rate >= 90:
             report += "âš ï¸  Most files are compliant, but some violations found.\n"
         else:
@@ -212,7 +221,9 @@ class NamespaceValidator:
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Validate MachineNativeOps namespace compliance")
+    parser = argparse.ArgumentParser(
+        description="Validate MachineNativeOps namespace compliance"
+    )
     parser.add_argument(
         "directory",
         nargs="?",
@@ -220,7 +231,9 @@ def main():
         help="Directory to validate (default: current directory)",
     )
     parser.add_argument(
-        "--verbose", action="store_true", help="Show all checked files, not just violations"
+        "--verbose",
+        action="store_true",
+        help="Show all checked files, not just violations",
     )
     parser.add_argument("--output", help="Output report to file")
 
diff --git a/workspace/original_dev/original_axiom_backup/core/config_manager.py b/workspace/original_dev/original_axiom_backup/core/config_manager.py
index 5576ce5..b5f2506 100644
--- a/workspace/original_dev/original_axiom_backup/core/config_manager.py
+++ b/workspace/original_dev/original_axiom_backup/core/config_manager.py
@@ -74,10 +74,14 @@ class ConfigurationManager:
 
         # Setup file watching
         self.observer = Observer()
-        self.observer.schedule(ConfigurationFileHandler(self), str(self.config_dir), recursive=True)
+        self.observer.schedule(
+            ConfigurationFileHandler(self), str(self.config_dir), recursive=True
+        )
         self.observer.start()
 
-        logger.info(f"Configuration manager initialized for environment: {self.environment}")
+        logger.info(
+            f"Configuration manager initialized for environment: {self.environment}"
+        )
 
     def load_configuration(
         self,
@@ -104,7 +108,9 @@ class ConfigurationManager:
                 config_file = Path(config_file)
 
             if not config_file.exists():
-                raise ConfigValidationError(f"Configuration file not found: {config_file}")
+                raise ConfigValidationError(
+                    f"Configuration file not found: {config_file}"
+                )
 
             # Load base configuration
             try:
@@ -117,7 +123,9 @@ class ConfigurationManager:
                 raise ConfigValidationError(f"Failed to load configuration: {e}")
 
             # Apply environment-specific overrides
-            environment_config = self._load_environment_overrides(config_name, config_file)
+            environment_config = self._load_environment_overrides(
+                config_name, config_file
+            )
             merged_config = self._merge_configurations(base_config, environment_config)
 
             # Apply environment variable overrides
@@ -148,7 +156,9 @@ class ConfigurationManager:
             logger.info(f"Configuration '{config_name}' loaded successfully")
             return final_config
 
-    def get_configuration(self, config_name: str, section: Optional[str] = None) -> Dict[str, Any]:
+    def get_configuration(
+        self, config_name: str, section: Optional[str] = None
+    ) -> Dict[str, Any]:
         """
         Get configuration or specific section.
 
@@ -167,7 +177,9 @@ class ConfigurationManager:
 
             if section:
                 if section not in config:
-                    raise ConfigValidationError(f"Section '{section}' not found in '{config_name}'")
+                    raise ConfigValidationError(
+                        f"Section '{section}' not found in '{config_name}'"
+                    )
                 return config[section]
 
             return copy.deepcopy(config)
@@ -235,11 +247,15 @@ class ConfigurationManager:
             if config_name in self.callbacks:
                 try:
                     self.callbacks[config_name].remove(callback)
-                    logger.debug(f"Callback unregistered for configuration '{config_name}'")
+                    logger.debug(
+                        f"Callback unregistered for configuration '{config_name}'"
+                    )
                 except ValueError:
                     pass
 
-    def _load_environment_overrides(self, config_name: str, config_file: Path) -> Dict[str, Any]:
+    def _load_environment_overrides(
+        self, config_name: str, config_file: Path
+    ) -> Dict[str, Any]:
         """Load environment-specific configuration overrides"""
         env_config_file = config_file.parent / f"{config_name}.{self.environment}.yaml"
         env_alternative = config_file.parent / self.environment / f"{config_name}.yaml"
@@ -290,14 +306,20 @@ class ConfigurationManager:
         result = copy.deepcopy(base)
 
         for key, value in override.items():
-            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
+            if (
+                key in result
+                and isinstance(result[key], dict)
+                and isinstance(value, dict)
+            ):
                 result[key] = self._merge_configurations(result[key], value)
             else:
                 result[key] = value
 
         return result
 
-    def _set_nested_value(self, config: Dict[str, Any], keys: List[str], value: Any) -> None:
+    def _set_nested_value(
+        self, config: Dict[str, Any], keys: List[str], value: Any
+    ) -> None:
         """Set nested value in configuration dictionary"""
         current = config
         for key in keys[:-1]:
@@ -306,7 +328,9 @@ class ConfigurationManager:
             current = current[key]
         current[keys[-1]] = value
 
-    def _validate_configuration(self, config: Dict[str, Any], schema: Dict[str, Any]) -> None:
+    def _validate_configuration(
+        self, config: Dict[str, Any], schema: Dict[str, Any]
+    ) -> None:
         """Validate configuration against schema"""
         try:
             # Simple validation - in production, use jsonschema or similar
@@ -320,7 +344,9 @@ class ConfigurationManager:
                 for field, field_schema in schema["properties"].items():
                     if field in config:
                         expected_type = field_schema.get("type")
-                        if expected_type and not self._check_type(config[field], expected_type):
+                        if expected_type and not self._check_type(
+                            config[field], expected_type
+                        ):
                             raise ConfigValidationError(
                                 f"Invalid type for {field}: expected {expected_type}"
                             )
@@ -366,7 +392,9 @@ class ConfigurationManager:
                     # Reload configuration
                     schema = self.schemas.get(config_name)
                     self.load_configuration(config_name, str(file_path), schema)
-                    logger.info(f"Reloaded configuration '{config_name}' from file change")
+                    logger.info(
+                        f"Reloaded configuration '{config_name}' from file change"
+                    )
                 except Exception as e:
                     logger.error(f"Failed to reload configuration '{config_name}': {e}")
                 break
diff --git a/workspace/original_dev/original_axiom_backup/core/plugin_manager.py b/workspace/original_dev/original_axiom_backup/core/plugin_manager.py
index b8a0366..0f9e805 100644
--- a/workspace/original_dev/original_axiom_backup/core/plugin_manager.py
+++ b/workspace/original_dev/original_axiom_backup/core/plugin_manager.py
@@ -84,7 +84,9 @@ class AxiomPluginManager:
 
     def _load_interface_spec(self) -> dict:
         """Load plugin interface specification"""
-        spec_path = Path(__file__).parent.parent / "standards" / "plugin_interface_v1.yaml"
+        spec_path = (
+            Path(__file__).parent.parent / "standards" / "plugin_interface_v1.yaml"
+        )
         try:
             with open(spec_path, "r") as f:
                 return yaml.safe_load(f)
@@ -158,7 +160,9 @@ class AxiomPluginManager:
                 self._update_dependency_graph(plugin_id, metadata.dependencies)
 
                 load_time = time.time() - start_time
-                logger.info(f"Plugin {plugin_id} loaded successfully in {load_time:.3f}s")
+                logger.info(
+                    f"Plugin {plugin_id} loaded successfully in {load_time:.3f}s"
+                )
 
                 return True
 
@@ -291,7 +295,9 @@ class AxiomPluginManager:
                 plugin_id=plugin_id,
                 status="FAILED",
                 result={},
-                execution_time=time.time() - start_time if "start_time" in locals() else 0.0,
+                execution_time=(
+                    time.time() - start_time if "start_time" in locals() else 0.0
+                ),
                 error=str(e),
             )
 
@@ -319,7 +325,9 @@ class AxiomPluginManager:
                 # Parallel execution for independent plugins
                 futures = {}
                 for plugin_id in execution_order[0]:
-                    future = self.executor.submit(self.execute_plugin, plugin_id, context.copy())
+                    future = self.executor.submit(
+                        self.execute_plugin, plugin_id, context.copy()
+                    )
                     futures[plugin_id] = future
 
                 for plugin_id, future in futures.items():
@@ -335,7 +343,9 @@ class AxiomPluginManager:
 
                         # Stop on failure
                         if result.status == "FAILED":
-                            logger.error(f"Stopping execution chain due to failure in {plugin_id}")
+                            logger.error(
+                                f"Stopping execution chain due to failure in {plugin_id}"
+                            )
                             break
 
             return results
@@ -452,7 +462,9 @@ class AxiomPluginManager:
         # Validate version format
         version = config["version"]
         if not isinstance(version, str) or not self._is_valid_semver(version):
-            raise PluginValidationError("Invalid version format, expected semver (x.y.z)")
+            raise PluginValidationError(
+                "Invalid version format, expected semver (x.y.z)"
+            )
 
         # Validate priority range
         priority = config["priority"]
@@ -568,7 +580,9 @@ class AxiomPluginManager:
 
         # Check for circular dependencies
         if in_degree:
-            raise PluginValidationError(f"Circular dependency detected: {list(in_degree.keys())}")
+            raise PluginValidationError(
+                f"Circular dependency detected: {list(in_degree.keys())}"
+            )
 
         return execution_levels
 
@@ -579,7 +593,9 @@ class AxiomPluginManager:
         with self.lock:
             # Unload all plugins in reverse dependency order
             try:
-                execution_order = self._resolve_execution_order(list(self.plugins.keys()))
+                execution_order = self._resolve_execution_order(
+                    list(self.plugins.keys())
+                )
                 for level in reversed(execution_order):
                     for plugin_id in level:
                         self._unload_plugin_internal(plugin_id)
diff --git a/workspace/original_dev/original_axiom_backup/core/plugin_orchestrator.py b/workspace/original_dev/original_axiom_backup/core/plugin_orchestrator.py
index 5f1eb79..e909815 100644
--- a/workspace/original_dev/original_axiom_backup/core/plugin_orchestrator.py
+++ b/workspace/original_dev/original_axiom_backup/core/plugin_orchestrator.py
@@ -104,7 +104,9 @@ class PluginOrchestrator:
             # Build execution graph for this workflow
             self._build_workflow_graph(workflow)
 
-            logger.info(f"Loaded workflow: {workflow.name} with {len(workflow.plugins)} plugins")
+            logger.info(
+                f"Loaded workflow: {workflow.name} with {len(workflow.plugins)} plugins"
+            )
             return True
 
         except Exception as e:
@@ -209,7 +211,9 @@ class PluginOrchestrator:
         Returns:
             List[PluginExecutionResult]: Execution results
         """
-        logger.info(f"Executing {len(plugin_ids)} plugins in {execution_mode.value} mode")
+        logger.info(
+            f"Executing {len(plugin_ids)} plugins in {execution_mode.value} mode"
+        )
 
         # Build execution plan
         execution_plan = self._build_execution_plan(plugin_ids)
@@ -249,7 +253,9 @@ class PluginOrchestrator:
 
         # Calculate statistics
         total_executions = len(self.execution_history)
-        successful_executions = sum(1 for e in self.execution_history if e["status"] == "SUCCESS")
+        successful_executions = sum(
+            1 for e in self.execution_history if e["status"] == "SUCCESS"
+        )
 
         avg_execution_time = (
             sum(e["execution_time"] for e in self.execution_history) / total_executions
@@ -332,7 +338,10 @@ class PluginOrchestrator:
         for level_plugins in execution_plan:
             level_results = []
 
-            if context.execution_mode == ExecutionMode.PARALLEL and len(level_plugins) > 1:
+            if (
+                context.execution_mode == ExecutionMode.PARALLEL
+                and len(level_plugins) > 1
+            ):
                 # Execute level in parallel
                 level_results = self._execute_level_parallel(level_plugins, context)
             elif context.execution_mode == ExecutionMode.SEQUENTIAL:
@@ -366,7 +375,9 @@ class PluginOrchestrator:
 
         for plugin_id in plugins:
             if self._should_execute_plugin(plugin_id, context):
-                future = self.executor.submit(self._execute_plugin_with_retry, plugin_id, context)
+                future = self.executor.submit(
+                    self._execute_plugin_with_retry, plugin_id, context
+                )
                 futures[future] = plugin_id
 
         results = []
@@ -461,7 +472,9 @@ class PluginOrchestrator:
 
                 # Execute plugin
                 plugin_context = context.global_context.copy()
-                result = plugin_manager.execute_plugin(plugin_id, plugin_context, context.timeout)
+                result = plugin_manager.execute_plugin(
+                    plugin_id, plugin_context, context.timeout
+                )
 
                 # Update circuit breaker
                 self._update_circuit_breaker(plugin_id, result)
@@ -473,13 +486,17 @@ class PluginOrchestrator:
 
                     # Check if we should retry
                     if attempt < max_retries:
-                        wait_time = self._calculate_backoff_time(attempt, backoff_strategy)
+                        wait_time = self._calculate_backoff_time(
+                            attempt, backoff_strategy
+                        )
                         logger.warning(
                             f"Plugin {plugin_id} failed (attempt {attempt + 1}), retrying in {wait_time}s"
                         )
                         time.sleep(wait_time)
                     else:
-                        logger.error(f"Plugin {plugin_id} failed after {max_retries + 1} attempts")
+                        logger.error(
+                            f"Plugin {plugin_id} failed after {max_retries + 1} attempts"
+                        )
 
             except Exception as e:
                 last_result = PluginExecutionResult(
@@ -557,7 +574,9 @@ class PluginOrchestrator:
                 levels.append(current_level)
             else:
                 # Circular dependency or unresolved dependencies
-                raise PluginValidationError(f"Cannot resolve execution order for: {remaining}")
+                raise PluginValidationError(
+                    f"Cannot resolve execution order for: {remaining}"
+                )
 
         return levels
 
@@ -611,7 +630,9 @@ class PluginOrchestrator:
 
         return breaker["state"] == "OPEN"
 
-    def _update_circuit_breaker(self, plugin_id: str, result: PluginExecutionResult) -> None:
+    def _update_circuit_breaker(
+        self, plugin_id: str, result: PluginExecutionResult
+    ) -> None:
         """Update circuit breaker state based on execution result"""
         if plugin_id not in self.circuit_breakers:
             self.circuit_breakers[plugin_id] = {
@@ -658,7 +679,9 @@ class PluginOrchestrator:
             if len(self.execution_history) > 1000:
                 self.execution_history = self.execution_history[-1000:]
 
-    def _update_performance_metrics(self, workflow_name: str, result: Dict[str, Any]) -> None:
+    def _update_performance_metrics(
+        self, workflow_name: str, result: Dict[str, Any]
+    ) -> None:
         """Update performance metrics"""
         with self._lock:
             for plugin_result in result.get("results", []):
diff --git a/workspace/original_dev/original_axiom_backup/demo_system.py b/workspace/original_dev/original_axiom_backup/demo_system.py
index 225422d..6edee43 100644
--- a/workspace/original_dev/original_axiom_backup/demo_system.py
+++ b/workspace/original_dev/original_axiom_backup/demo_system.py
@@ -12,9 +12,6 @@ Features demonstrated:
 - Hot-reload configuration management
 """
 
-from core.plugin_orchestrator import ErrorHandlingStrategy, ExecutionMode, orchestrator
-from core.plugin_manager import plugin_manager
-from core.config_manager import config_manager
 import json
 import logging
 import os
@@ -26,6 +23,10 @@ import time
 from pathlib import Path
 from typing import Any, Dict, List
 
+from core.config_manager import config_manager
+from core.plugin_manager import plugin_manager
+from core.plugin_orchestrator import ErrorHandlingStrategy, ExecutionMode, orchestrator
+
 # Add project to path
 project_root = Path(__file__).parent
 sys.path.insert(0, str(project_root))
@@ -73,7 +74,10 @@ class AxiomSystemDemo:
     def _create_demo_files(self):
         """Create demonstration data files"""
         demo_files = [
-            ("document.txt", "This is a sample document for backup demonstration.\n" * 100),
+            (
+                "document.txt",
+                "This is a sample document for backup demonstration.\n" * 100,
+            ),
             (
                 "config.json",
                 json.dumps(
@@ -87,7 +91,8 @@ class AxiomSystemDemo:
             ),
             (
                 "data.csv",
-                "id,name,value\n" + "\n".join([f"{i},item_{i},{i*10}" for i in range(1, 101)]),
+                "id,name,value\n"
+                + "\n".join([f"{i},item_{i},{i*10}" for i in range(1, 101)]),
             ),
             ("secret.txt", "This is sensitive data that should be encrypted."),
             # 1MB file for compression testing
@@ -180,7 +185,9 @@ class AxiomSystemDemo:
                 "loaded_plugins": loaded_plugins,
             }
 
-            logger.info(f"âœ… Loaded {len(loaded_plugins)} plugins (avg: {avg_load_time:.3f}s)")
+            logger.info(
+                f"âœ… Loaded {len(loaded_plugins)} plugins (avg: {avg_load_time:.3f}s)"
+            )
 
         except Exception as e:
             logger.error(f"âŒ Plugin loading demo failed: {e}")
@@ -223,7 +230,12 @@ class AxiomSystemDemo:
 
             # Create multiple concurrent tasks
             threads = []
-            plugins = ["compression_zstd", "encryption_aes", "backup_incremental", "storage_s3"]
+            plugins = [
+                "compression_zstd",
+                "encryption_aes",
+                "backup_incremental",
+                "storage_s3",
+            ]
 
             for i, plugin in enumerate(plugins):
                 for j in range(3):  # 3 tasks per plugin
@@ -247,7 +259,9 @@ class AxiomSystemDemo:
             successful_tasks = len(results)
             failed_tasks = len(errors)
             avg_execution_time = (
-                sum(r["execution_time"] for r in results) / len(results) if results else 0
+                sum(r["execution_time"] for r in results) / len(results)
+                if results
+                else 0
             )
             concurrency_ratio = len(threads) / total_time if total_time > 0 else 0
 
@@ -322,11 +336,14 @@ class AxiomSystemDemo:
             self.results["error_handling"] = {
                 "success": all(r["success"] for r in results),
                 "scenarios_tested": len(results),
-                "avg_handling_time": sum(r["handling_time"] for r in results) / len(results),
+                "avg_handling_time": sum(r["handling_time"] for r in results)
+                / len(results),
                 "results": results,
             }
 
-            logger.info(f"âœ… Error handling: {len(results)} scenarios tested successfully")
+            logger.info(
+                f"âœ… Error handling: {len(results)} scenarios tested successfully"
+            )
 
         except Exception as e:
             logger.error(f"âŒ Error handling demo failed: {e}")
@@ -376,10 +393,14 @@ class AxiomSystemDemo:
             plugin_scores = []
             for plugin, data in metrics["plugin_performance"].items():
                 # Simple scoring based on execution time and success rate
-                score = (100 - data["avg_execution_time"] * 100) * (data["success_rate"] / 100)
+                score = (100 - data["avg_execution_time"] * 100) * (
+                    data["success_rate"] / 100
+                )
                 plugin_scores.append(score)
 
-            overall_score = sum(plugin_scores) / len(plugin_scores) if plugin_scores else 0
+            overall_score = (
+                sum(plugin_scores) / len(plugin_scores) if plugin_scores else 0
+            )
 
             self.results["performance_monitoring"] = {
                 "success": True,
@@ -404,7 +425,11 @@ class AxiomSystemDemo:
 
         try:
             swap_operations = [
-                {"operation": "Load new plugin version", "downtime": 0.0, "success": True},
+                {
+                    "operation": "Load new plugin version",
+                    "downtime": 0.0,
+                    "success": True,
+                },
                 {
                     "operation": "Update plugin configuration",
                     "downtime": 0.001,  # 1ms for config reload
@@ -430,7 +455,9 @@ class AxiomSystemDemo:
             }
 
             logger.info(f"âœ… Hot-swap demonstration completed")
-            logger.info(f"   {successful_swaps}/{len(swap_operations)} operations successful")
+            logger.info(
+                f"   {successful_swaps}/{len(swap_operations)} operations successful"
+            )
             logger.info(f"   Total downtime: {total_downtime:.3f}s (target: <0.01s)")
 
         except Exception as e:
@@ -538,14 +565,20 @@ class AxiomSystemDemo:
                 f"   Success rate: {report['performance_analysis']['overall_success_rate']:.1%}"
             )
 
-            success_count = sum(1 for r in self.results.values() if r.get("success", False))
-            logger.info(f"   Successful demonstrations: {success_count}/{len(self.results)}")
+            success_count = sum(
+                1 for r in self.results.values() if r.get("success", False)
+            )
+            logger.info(
+                f"   Successful demonstrations: {success_count}/{len(self.results)}"
+            )
 
             logger.info("\nğŸ† Key Achievements:")
             for achievement in report["performance_analysis"]["key_achievements"]:
                 logger.info(f"   âœ… {achievement}")
 
-            logger.info(f"\nğŸ“Š Report available at: {self.temp_dir}/demonstration_report.json")
+            logger.info(
+                f"\nğŸ“Š Report available at: {self.temp_dir}/demonstration_report.json"
+            )
 
             return report
 
@@ -579,7 +612,9 @@ def main():
         print(
             f"   Key Features Demonstrated: {len(report['performance_analysis']['key_achievements'])}"
         )
-        print(f"   Competitive Advantages: {len(report['competitive_advantages'])} platforms")
+        print(
+            f"   Competitive Advantages: {len(report['competitive_advantages'])} platforms"
+        )
 
         print("\nâœ¨ AXIOM successfully demonstrates superior capabilities")
         print("   compared to Replit, Claude, and GPT platforms!")
diff --git a/workspace/original_dev/original_axiom_backup/examples/complete_integration.py b/workspace/original_dev/original_axiom_backup/examples/complete_integration.py
index 840b0fa..062498d 100644
--- a/workspace/original_dev/original_axiom_backup/examples/complete_integration.py
+++ b/workspace/original_dev/original_axiom_backup/examples/complete_integration.py
@@ -3,13 +3,6 @@ AXIOM Backup System - Complete Integration Example
 Demonstrates the full power of the hot-swappable plugin architecture.
 """
 
-from core.plugin_orchestrator import ErrorHandlingStrategy, ExecutionMode, orchestrator
-from core.plugin_manager import PluginManagerContext, plugin_manager
-from core.config_manager import config_manager
-from plugins.storage_s3 import PLUGIN_METADATA as STORAGE_METADATA
-from plugins.encryption_aes import PLUGIN_METADATA as ENCRYPTION_METADATA
-from plugins.compression_zstd import PLUGIN_METADATA as COMPRESSION_METADATA
-from plugins.backup_incremental import PLUGIN_METADATA as BACKUP_METADATA
 import json
 import logging
 import os
@@ -20,6 +13,14 @@ import time
 from pathlib import Path
 from typing import Any, Dict, List
 
+from core.config_manager import config_manager
+from core.plugin_manager import PluginManagerContext, plugin_manager
+from core.plugin_orchestrator import ErrorHandlingStrategy, ExecutionMode, orchestrator
+from plugins.backup_incremental import PLUGIN_METADATA as BACKUP_METADATA
+from plugins.compression_zstd import PLUGIN_METADATA as COMPRESSION_METADATA
+from plugins.encryption_aes import PLUGIN_METADATA as ENCRYPTION_METADATA
+from plugins.storage_s3 import PLUGIN_METADATA as STORAGE_METADATA
+
 # Add the project root to Python path
 project_root = Path(__file__).parent.parent
 sys.path.insert(0, str(project_root))
@@ -214,7 +215,9 @@ class AxiomBackupSystem:
             "timestamp": time.time(),
         }
 
-        compression_result = plugin_manager.execute_plugin("compression_zstd", compression_context)
+        compression_result = plugin_manager.execute_plugin(
+            "compression_zstd", compression_context
+        )
         results["compression"] = compression_result._asdict()
 
         if compression_result.status == "SUCCESS":
@@ -237,7 +240,9 @@ class AxiomBackupSystem:
             "timestamp": time.time(),
         }
 
-        encryption_result = plugin_manager.execute_plugin("encryption_aes", encryption_context)
+        encryption_result = plugin_manager.execute_plugin(
+            "encryption_aes", encryption_context
+        )
         results["encryption"] = encryption_result._asdict()
 
         if encryption_result.status == "SUCCESS":
@@ -254,7 +259,9 @@ class AxiomBackupSystem:
             "timestamp": time.time(),
         }
 
-        backup_result = plugin_manager.execute_plugin("backup_incremental", backup_context)
+        backup_result = plugin_manager.execute_plugin(
+            "backup_incremental", backup_context
+        )
         results["backup"] = backup_result._asdict()
 
         if backup_result.status == "SUCCESS":
@@ -295,7 +302,9 @@ class AxiomBackupSystem:
                 f"    ğŸ“Š {workflow_result['plugins_successful']}/{workflow_result['plugins_executed']} plugins successful"
             )
         else:
-            logger.error(f"    âŒ Quick backup workflow failed: {workflow_result.get('error')}")
+            logger.error(
+                f"    âŒ Quick backup workflow failed: {workflow_result.get('error')}"
+            )
 
         # Demonstrate parallel execution
         logger.info("  âš¡ Demonstrating parallel execution...")
@@ -329,7 +338,9 @@ class AxiomBackupSystem:
 
         # Show current plugins
         current_plugins = plugin_manager.list_plugins()
-        logger.info(f"  ğŸ“‹ Currently loaded plugins: {[p['plugin_id'] for p in current_plugins]}")
+        logger.info(
+            f"  ğŸ“‹ Currently loaded plugins: {[p['plugin_id'] for p in current_plugins]}"
+        )
 
         # Test plugin validation
         logger.info("  ğŸ” Validating all plugins...")
@@ -377,7 +388,9 @@ class AxiomBackupSystem:
         reload_success = plugin_manager.unload_plugin("backup_incremental")
         if reload_success:
             plugin_path = project_root / "plugins" / "backup_incremental.py"
-            reload_success = plugin_manager.load_plugin(str(plugin_path), backup_plugin_config)
+            reload_success = plugin_manager.load_plugin(
+                str(plugin_path), backup_plugin_config
+            )
 
         results["hot_swap"] = {"success": reload_success}
 
@@ -404,7 +417,9 @@ class AxiomBackupSystem:
             "timestamp": time.time(),
         }
 
-        error_result = plugin_manager.execute_plugin("compression_zstd", invalid_context)
+        error_result = plugin_manager.execute_plugin(
+            "compression_zstd", invalid_context
+        )
         results["invalid_path"] = error_result._asdict()
 
         if error_result.status == "FAILED":
@@ -429,11 +444,15 @@ class AxiomBackupSystem:
         }
 
         retry_results = orchestrator.execute_plugins(
-            ["compression_zstd"], retry_context["global_context"], ExecutionMode.SEQUENTIAL
+            ["compression_zstd"],
+            retry_context["global_context"],
+            ExecutionMode.SEQUENTIAL,
         )
         results["retry_test"] = [r._asdict() for r in retry_results]
 
-        logger.info(f"    âœ… Retry mechanism tested: {len(retry_results)} attempts made")
+        logger.info(
+            f"    âœ… Retry mechanism tested: {len(retry_results)} attempts made"
+        )
 
         return results
 
@@ -448,7 +467,9 @@ class AxiomBackupSystem:
         if "total_executions" in perf_analysis:
             logger.info(f"    Total executions: {perf_analysis['total_executions']}")
             logger.info(f"    Success rate: {perf_analysis['success_rate']:.1f}%")
-            logger.info(f"    Avg execution time: {perf_analysis['avg_execution_time']:.3f}s")
+            logger.info(
+                f"    Avg execution time: {perf_analysis['avg_execution_time']:.3f}s"
+            )
 
         # Plugin performance breakdown
         if "plugin_performance" in perf_analysis:
@@ -499,27 +520,43 @@ class AxiomBackupSystem:
             self.create_demo_data()
 
             # Run all demonstrations
-            results = {"status": "SUCCESS", "demo_start_time": time.time(), "demonstrations": {}}
+            results = {
+                "status": "SUCCESS",
+                "demo_start_time": time.time(),
+                "demonstrations": {},
+            }
 
             # Basic operations
-            results["demonstrations"]["basic_operations"] = self.demonstrate_basic_operations()
+            results["demonstrations"][
+                "basic_operations"
+            ] = self.demonstrate_basic_operations()
 
             # Workflow execution
-            results["demonstrations"]["workflow_execution"] = self.demonstrate_workflow_execution()
+            results["demonstrations"][
+                "workflow_execution"
+            ] = self.demonstrate_workflow_execution()
 
             # Hot swapping
             results["demonstrations"]["hot_swap"] = self.demonstrate_hot_swap()
 
             # Error handling
-            results["demonstrations"]["error_handling"] = self.demonstrate_error_handling()
+            results["demonstrations"][
+                "error_handling"
+            ] = self.demonstrate_error_handling()
 
             # Performance analysis
-            results["demonstrations"]["performance_analysis"] = self.performance_analysis()
+            results["demonstrations"][
+                "performance_analysis"
+            ] = self.performance_analysis()
 
             results["demo_end_time"] = time.time()
-            results["total_demo_time"] = results["demo_end_time"] - results["demo_start_time"]
+            results["total_demo_time"] = (
+                results["demo_end_time"] - results["demo_start_time"]
+            )
 
-            logger.info(f"ğŸ‰ Complete demonstration finished in {results['total_demo_time']:.3f}s")
+            logger.info(
+                f"ğŸ‰ Complete demonstration finished in {results['total_demo_time']:.3f}s"
+            )
 
             return results
 
diff --git a/workspace/original_dev/original_axiom_backup/plugins/backup_incremental.py b/workspace/original_dev/original_axiom_backup/plugins/backup_incremental.py
index be2f1bb..0c8df63 100644
--- a/workspace/original_dev/original_axiom_backup/plugins/backup_incremental.py
+++ b/workspace/original_dev/original_axiom_backup/plugins/backup_incremental.py
@@ -121,7 +121,9 @@ class Plugin:
             self.last_cleanup = time.time()
 
             # Backup scheduling
-            self.full_backup_interval = config.get("full_backup_interval", 7 * 24 * 3600)  # 7 days
+            self.full_backup_interval = config.get(
+                "full_backup_interval", 7 * 24 * 3600
+            )  # 7 days
             self.incremental_backup_interval = config.get(
                 "incremental_backup_interval", 3600
             )  # 1 hour
@@ -146,7 +148,11 @@ class Plugin:
             dict: Execution result with backup metrics
         """
         if not self.initialized:
-            return {"status": "FAILED", "error": "Plugin not initialized", "timestamp": time.time()}
+            return {
+                "status": "FAILED",
+                "error": "Plugin not initialized",
+                "timestamp": time.time(),
+            }
 
         try:
             start_time = time.time()
@@ -378,7 +384,8 @@ class Plugin:
             # Get current file state
             current_files = self._scan_directory(source_path)
             current_metadata = {
-                str(path): self._get_file_metadata(path, backup_id) for path in current_files
+                str(path): self._get_file_metadata(path, backup_id)
+                for path in current_files
             }
 
             # Get previous backup state
@@ -492,11 +499,14 @@ class Plugin:
             # Get current file state
             current_files = self._scan_directory(source_path)
             current_metadata = {
-                str(path): self._get_file_metadata(path, backup_id) for path in current_files
+                str(path): self._get_file_metadata(path, backup_id)
+                for path in current_files
             }
 
             # Get full backup state
-            full_backup_metadata = self._get_backup_metadata(last_full_backup["backup_id"])
+            full_backup_metadata = self._get_backup_metadata(
+                last_full_backup["backup_id"]
+            )
 
             # Find new and modified files
             for file_path, metadata in current_metadata.items():
@@ -558,7 +568,9 @@ class Plugin:
                 shutil.rmtree(backup_dir)
             raise e
 
-    def _backup_file(self, source_file: Path, backup_dir: Path) -> Optional[Dict[str, Any]]:
+    def _backup_file(
+        self, source_file: Path, backup_dir: Path
+    ) -> Optional[Dict[str, Any]]:
         """Backup a single file"""
         try:
             # Calculate file hash
@@ -933,8 +945,12 @@ class Plugin:
                     shutil.rmtree(backup_dir)
 
                 # Delete from database
-                cursor.execute("DELETE FROM backup_sessions WHERE backup_id = ?", (backup_id,))
-                cursor.execute("DELETE FROM file_metadata WHERE backup_id = ?", (backup_id,))
+                cursor.execute(
+                    "DELETE FROM backup_sessions WHERE backup_id = ?", (backup_id,)
+                )
+                cursor.execute(
+                    "DELETE FROM file_metadata WHERE backup_id = ?", (backup_id,)
+                )
 
                 deleted_count += 1
                 logger.info(f"Deleted backup: {backup_id}")
@@ -1054,8 +1070,12 @@ class Plugin:
 
             # Remove from database
             cursor = self.db_connection.cursor()
-            cursor.execute("DELETE FROM backup_sessions WHERE backup_id = ?", (backup_id,))
-            cursor.execute("DELETE FROM file_metadata WHERE backup_id = ?", (backup_id,))
+            cursor.execute(
+                "DELETE FROM backup_sessions WHERE backup_id = ?", (backup_id,)
+            )
+            cursor.execute(
+                "DELETE FROM file_metadata WHERE backup_id = ?", (backup_id,)
+            )
             self.db_connection.commit()
 
         except Exception as e:
diff --git a/workspace/original_dev/original_axiom_backup/plugins/compression_zstd.py b/workspace/original_dev/original_axiom_backup/plugins/compression_zstd.py
index 4056176..d209ede 100644
--- a/workspace/original_dev/original_axiom_backup/plugins/compression_zstd.py
+++ b/workspace/original_dev/original_axiom_backup/plugins/compression_zstd.py
@@ -63,8 +63,12 @@ class Plugin:
             threads = config.get("threads", min(8, os.cpu_count() or 1))
 
             # Validate compression level (1-22 for ZSTD)
-            if not isinstance(compression_level, int) or not (1 <= compression_level <= 22):
-                logger.error(f"Invalid compression level: {compression_level}. Must be 1-22")
+            if not isinstance(compression_level, int) or not (
+                1 <= compression_level <= 22
+            ):
+                logger.error(
+                    f"Invalid compression level: {compression_level}. Must be 1-22"
+                )
                 return False
 
             # Initialize compressor with optimized settings
@@ -77,7 +81,9 @@ class Plugin:
                 min_match=config.get("min_match", 3),
                 target_length=config.get("target_length", 16),
                 strategy=(
-                    zstd.STRATEGY_BTULTRA2 if compression_level >= 19 else zstd.STRATEGY_BTULTRA
+                    zstd.STRATEGY_BTULTRA2
+                    if compression_level >= 19
+                    else zstd.STRATEGY_BTULTRA
                 ),
                 threads=threads,
             )
@@ -96,7 +102,9 @@ class Plugin:
 
             # Streaming configuration
             self.chunk_size = chunk_size
-            self.stream_buffer_size = config.get("stream_buffer_size", 1024 * 1024)  # 1MB
+            self.stream_buffer_size = config.get(
+                "stream_buffer_size", 1024 * 1024
+            )  # 1MB
 
             self.initialized = True
             logger.info(
@@ -120,7 +128,11 @@ class Plugin:
             dict: Execution result with metrics
         """
         if not self.initialized:
-            return {"status": "FAILED", "error": "Plugin not initialized", "timestamp": time.time()}
+            return {
+                "status": "FAILED",
+                "error": "Plugin not initialized",
+                "timestamp": time.time(),
+            }
 
         try:
             start_time = time.time()
@@ -276,7 +288,8 @@ class Plugin:
             "compression_ratio": compression_ratio,
             "files_processed": 1,
             # MB/s
-            "throughput": (original_size / (1024 * 1024)) / (time.time() - time.time() or 0.001),
+            "throughput": (original_size / (1024 * 1024))
+            / (time.time() - time.time() or 0.001),
         }
 
     def _compress_directory(self, source: Path, target: Path) -> Dict[str, Any]:
@@ -300,7 +313,10 @@ class Plugin:
             # Compress the tar archive
             result = self._compress_file(tar_path, target)
             result.update(
-                {"original_size": total_original_size, "files_processed": files_processed}
+                {
+                    "original_size": total_original_size,
+                    "files_processed": files_processed,
+                }
             )
 
             return result
@@ -331,14 +347,17 @@ class Plugin:
             dst_file.write(remaining)
 
         decompressed_size = target.stat().st_size
-        compression_ratio = compressed_size / decompressed_size if decompressed_size > 0 else 0
+        compression_ratio = (
+            compressed_size / decompressed_size if decompressed_size > 0 else 0
+        )
 
         return {
             "original_size": decompressed_size,
             "compressed_size": compressed_size,
             "compression_ratio": compression_ratio,
             "files_processed": 1,
-            "throughput": (compressed_size / (1024 * 1024)) / (time.time() - time.time() or 0.001),
+            "throughput": (compressed_size / (1024 * 1024))
+            / (time.time() - time.time() or 0.001),
         }
 
     def _estimate_compression(self, source: Path) -> Dict[str, Any]:
@@ -391,7 +410,9 @@ class Plugin:
             total_original = source.stat().st_size
             files_processed = 1
         else:
-            total_original = sum(f.stat().st_size for f in source.rglob("*") if f.is_file())
+            total_original = sum(
+                f.stat().st_size for f in source.rglob("*") if f.is_file()
+            )
             files_processed = len([f for f in source.rglob("*") if f.is_file()])
 
         estimated_compressed = int(total_original * estimated_ratio)
diff --git a/workspace/original_dev/original_axiom_backup/plugins/encryption_aes.py b/workspace/original_dev/original_axiom_backup/plugins/encryption_aes.py
index e9b4f55..3944bad 100644
--- a/workspace/original_dev/original_axiom_backup/plugins/encryption_aes.py
+++ b/workspace/original_dev/original_axiom_backup/plugins/encryption_aes.py
@@ -80,12 +80,19 @@ class Plugin:
 
             # Encryption configuration
             algorithm = config.get("algorithm", "AES-256-GCM")
-            key_rotation_interval = config.get("key_rotation_interval", 86400)  # 24 hours
+            key_rotation_interval = config.get(
+                "key_rotation_interval", 86400
+            )  # 24 hours
             max_keys = config.get("max_keys", 100)
             key_derivation_iterations = config.get("key_derivation_iterations", 100000)
 
             # Validate algorithm
-            supported_algorithms = ["AES-256-GCM", "AES-256-CBC", "AES-256-CTR", "FERNET"]
+            supported_algorithms = [
+                "AES-256-GCM",
+                "AES-256-CBC",
+                "AES-256-CTR",
+                "FERNET",
+            ]
             if algorithm not in supported_algorithms:
                 logger.error(f"Unsupported encryption algorithm: {algorithm}")
                 return False
@@ -112,7 +119,9 @@ class Plugin:
             self.parallel_encryption = config.get("parallel_encryption", True)
 
             self.initialized = True
-            logger.info(f"AES encryption plugin initialized with algorithm: {algorithm}")
+            logger.info(
+                f"AES encryption plugin initialized with algorithm: {algorithm}"
+            )
 
             return True
 
@@ -131,7 +140,11 @@ class Plugin:
             dict: Execution result with encryption metadata
         """
         if not self.initialized:
-            return {"status": "FAILED", "error": "Plugin not initialized", "timestamp": time.time()}
+            return {
+                "status": "FAILED",
+                "error": "Plugin not initialized",
+                "timestamp": time.time(),
+            }
 
         try:
             start_time = time.time()
@@ -358,10 +371,14 @@ class Plugin:
                             with open(file_path, "rb") as f:
                                 file_data = f.read()
 
-                            encrypted_data, metadata = self._encrypt_data(file_data, key_id)
+                            encrypted_data, metadata = self._encrypt_data(
+                                file_data, key_id
+                            )
 
                             # Add encrypted file to zip
-                            zip_info = zipfile.ZipInfo(str(file_path.relative_to(source)))
+                            zip_info = zipfile.ZipInfo(
+                                str(file_path.relative_to(source))
+                            )
                             zip_file.writestr(zip_info, encrypted_data)
 
                             files_processed += 1
@@ -411,14 +428,18 @@ class Plugin:
             encrypted_data = src_file.read()
 
         if metadata:
-            decrypted_data, verify_metadata = self._decrypt_data(encrypted_data, metadata, key)
+            decrypted_data, verify_metadata = self._decrypt_data(
+                encrypted_data, metadata, key
+            )
         else:
             # Legacy decryption
             if self.algorithm == "FERNET":
                 fernet = Fernet(base64.urlsafe_b64encode(key))
                 decrypted_data = fernet.decrypt(encrypted_data)
             else:
-                raise ValueError("Cannot decrypt without metadata for non-FERNET algorithms")
+                raise ValueError(
+                    "Cannot decrypt without metadata for non-FERNET algorithms"
+                )
 
         # Write decrypted file
         with open(target, "wb") as dst_file:
@@ -430,7 +451,9 @@ class Plugin:
             "artifacts": [str(target)],
         }
 
-    def _encrypt_data(self, data: bytes, key_id: str) -> Tuple[bytes, EncryptionMetadata]:
+    def _encrypt_data(
+        self, data: bytes, key_id: str
+    ) -> Tuple[bytes, EncryptionMetadata]:
         """Encrypt data using configured algorithm"""
         key = self.encryption_keys[key_id]
 
@@ -466,7 +489,9 @@ class Plugin:
 
         return encrypted_data, metadata
 
-    def _encrypt_aes_gcm(self, data: bytes, key_id: str) -> Tuple[bytes, EncryptionMetadata]:
+    def _encrypt_aes_gcm(
+        self, data: bytes, key_id: str
+    ) -> Tuple[bytes, EncryptionMetadata]:
         """Encrypt using AES-256-GCM"""
         salt = os.urandom(16)
         iv = os.urandom(12)  # 96-bit IV for GCM
@@ -482,7 +507,9 @@ class Plugin:
         derived_key = kdf.derive(self.encryption_keys[key_id])
 
         # Encrypt
-        cipher = Cipher(algorithms.AES(derived_key), modes.GCM(iv), backend=self.backend)
+        cipher = Cipher(
+            algorithms.AES(derived_key), modes.GCM(iv), backend=self.backend
+        )
         encryptor = cipher.encryptor()
 
         encrypted_data = encryptor.update(data) + encryptor.finalize()
@@ -504,7 +531,9 @@ class Plugin:
 
         return result, metadata
 
-    def _encrypt_aes_cbc(self, data: bytes, key_id: str) -> Tuple[bytes, EncryptionMetadata]:
+    def _encrypt_aes_cbc(
+        self, data: bytes, key_id: str
+    ) -> Tuple[bytes, EncryptionMetadata]:
         """Encrypt using AES-256-CBC"""
         salt = os.urandom(16)
         iv = os.urandom(16)
@@ -524,7 +553,9 @@ class Plugin:
         padded_data = padder.update(data) + padder.finalize()
 
         # Encrypt
-        cipher = Cipher(algorithms.AES(derived_key), modes.CBC(iv), backend=self.backend)
+        cipher = Cipher(
+            algorithms.AES(derived_key), modes.CBC(iv), backend=self.backend
+        )
         encryptor = cipher.encryptor()
         encrypted_data = encryptor.update(padded_data) + encryptor.finalize()
 
@@ -544,7 +575,9 @@ class Plugin:
 
         return result, metadata
 
-    def _encrypt_aes_ctr(self, data: bytes, key_id: str) -> Tuple[bytes, EncryptionMetadata]:
+    def _encrypt_aes_ctr(
+        self, data: bytes, key_id: str
+    ) -> Tuple[bytes, EncryptionMetadata]:
         """Encrypt using AES-256-CTR"""
         salt = os.urandom(16)
         iv = os.urandom(16)
@@ -560,7 +593,9 @@ class Plugin:
         derived_key = kdf.derive(self.encryption_keys[key_id])
 
         # Encrypt
-        cipher = Cipher(algorithms.AES(derived_key), modes.CTR(iv), backend=self.backend)
+        cipher = Cipher(
+            algorithms.AES(derived_key), modes.CTR(iv), backend=self.backend
+        )
         encryptor = cipher.encryptor()
         encrypted_data = encryptor.update(data) + encryptor.finalize()
 
@@ -609,7 +644,9 @@ class Plugin:
             derived_key = kdf.derive(key)
 
             # Decrypt
-            cipher = Cipher(algorithms.AES(derived_key), modes.GCM(iv, tag), backend=self.backend)
+            cipher = Cipher(
+                algorithms.AES(derived_key), modes.GCM(iv, tag), backend=self.backend
+            )
             decryptor = cipher.decryptor()
             decrypted_data = decryptor.update(ciphertext) + decryptor.finalize()
 
@@ -634,7 +671,9 @@ class Plugin:
             derived_key = kdf.derive(key)
 
             # Decrypt
-            cipher = Cipher(algorithms.AES(derived_key), modes.CBC(iv), backend=self.backend)
+            cipher = Cipher(
+                algorithms.AES(derived_key), modes.CBC(iv), backend=self.backend
+            )
             decryptor = cipher.decryptor()
             padded_data = decryptor.update(ciphertext) + decryptor.finalize()
 
@@ -663,7 +702,9 @@ class Plugin:
             derived_key = kdf.derive(key)
 
             # Decrypt
-            cipher = Cipher(algorithms.AES(derived_key), modes.CTR(iv), backend=self.backend)
+            cipher = Cipher(
+                algorithms.AES(derived_key), modes.CTR(iv), backend=self.backend
+            )
             decryptor = cipher.decryptor()
             decrypted_data = decryptor.update(ciphertext) + decryptor.finalize()
 
@@ -698,7 +739,11 @@ class Plugin:
         # Save key
         self._save_key(key_id, key)
 
-        return {"key_id": key_id, "algorithm": self.algorithm, "created_at": key_info.created_at}
+        return {
+            "key_id": key_id,
+            "algorithm": self.algorithm,
+            "created_at": key_info.created_at,
+        }
 
     def _rotate_key(self) -> Dict[str, Any]:
         """Rotate encryption keys"""
@@ -810,7 +855,9 @@ class Plugin:
 
     def _get_active_key_id(self) -> Optional[str]:
         """Get the most recently active key"""
-        active_keys = [k_id for k_id, info in self.key_metadata.items() if info.is_active]
+        active_keys = [
+            k_id for k_id, info in self.key_metadata.items() if info.is_active
+        ]
         if not active_keys:
             return None
 
diff --git a/workspace/original_dev/original_axiom_backup/plugins/storage_s3.py b/workspace/original_dev/original_axiom_backup/plugins/storage_s3.py
index 1b102c2..e789d0c 100644
--- a/workspace/original_dev/original_axiom_backup/plugins/storage_s3.py
+++ b/workspace/original_dev/original_axiom_backup/plugins/storage_s3.py
@@ -154,13 +154,19 @@ class Plugin:
             # Upload configuration
             self.upload_config = {
                 # 64MB
-                "multipart_threshold": config.get("multipart_threshold", 64 * 1024 * 1024),
+                "multipart_threshold": config.get(
+                    "multipart_threshold", 64 * 1024 * 1024
+                ),
                 # 16MB
-                "multipart_chunksize": config.get("multipart_chunksize", 16 * 1024 * 1024),
+                "multipart_chunksize": config.get(
+                    "multipart_chunksize", 16 * 1024 * 1024
+                ),
                 "max_concurrency": config.get("max_concurrency", 8),
                 "use_threads": config.get("use_threads", True),
                 "storage_class": config.get("storage_class", "STANDARD"),
-                "server_side_encryption": config.get("server_side_encryption", "AES256"),
+                "server_side_encryption": config.get(
+                    "server_side_encryption", "AES256"
+                ),
                 "metadata": config.get("default_metadata", {}),
                 "tags": config.get("default_tags", {}),
                 "content_type_detection": config.get("content_type_detection", True),
@@ -175,7 +181,9 @@ class Plugin:
                 self._create_bucket()
 
             self.initialized = True
-            logger.info(f"S3 storage plugin initialized for bucket: {s3_config.bucket_name}")
+            logger.info(
+                f"S3 storage plugin initialized for bucket: {s3_config.bucket_name}"
+            )
 
             return True
 
@@ -194,7 +202,11 @@ class Plugin:
             dict: Execution result with storage metrics
         """
         if not self.initialized:
-            return {"status": "FAILED", "error": "Plugin not initialized", "timestamp": time.time()}
+            return {
+                "status": "FAILED",
+                "error": "Plugin not initialized",
+                "timestamp": time.time(),
+            }
 
         try:
             start_time = time.time()
@@ -215,7 +227,9 @@ class Plugin:
             if operation_mode == "UPLOAD":
                 result = self._upload_to_s3(source_path, context)
             elif operation_mode == "DOWNLOAD":
-                result = self._download_from_s3(source_path, Path(context["target_path"]))
+                result = self._download_from_s3(
+                    source_path, Path(context["target_path"])
+                )
             elif operation_mode == "LIST":
                 result = self._list_s3_objects(context)
             elif operation_mode == "DELETE":
@@ -282,11 +296,16 @@ class Plugin:
 
                 # Upload test file
                 self.s3_client.put_object(
-                    Bucket=self.bucket.name, Key=test_key, Body=test_data, Metadata={"test": "true"}
+                    Bucket=self.bucket.name,
+                    Key=test_key,
+                    Body=test_data,
+                    Metadata={"test": "true"},
                 )
 
                 # Download and verify
-                response = self.s3_client.get_object(Bucket=self.bucket.name, Key=test_key)
+                response = self.s3_client.get_object(
+                    Bucket=self.bucket.name, Key=test_key
+                )
                 downloaded_data = response["Body"].read()
 
                 if downloaded_data == test_data:
@@ -379,8 +398,12 @@ class Plugin:
             futures = []
 
             for file_path, relative_path in files_to_upload:
-                s3_key = f"{s3_prefix}/{relative_path}" if s3_prefix else str(relative_path)
-                future = self.executor.submit(self._upload_file_internal, file_path, s3_key)
+                s3_key = (
+                    f"{s3_prefix}/{relative_path}" if s3_prefix else str(relative_path)
+                )
+                future = self.executor.submit(
+                    self._upload_file_internal, file_path, s3_key
+                )
                 futures.append((future, s3_key))
 
             for future, s3_key in futures:
@@ -395,7 +418,9 @@ class Plugin:
         else:
             # Sequential upload
             for file_path, relative_path in files_to_upload:
-                s3_key = f"{s3_prefix}/{relative_path}" if s3_prefix else str(relative_path)
+                s3_key = (
+                    f"{s3_prefix}/{relative_path}" if s3_prefix else str(relative_path)
+                )
                 try:
                     result = self._upload_file_internal(file_path, s3_key)
                     files_uploaded += 1
@@ -408,7 +433,9 @@ class Plugin:
         return {
             "files_processed": files_uploaded,
             "bytes_transferred": bytes_uploaded,
-            "transfer_speed": bytes_uploaded / (time.time() - time.time() or 0.001) / (1024 * 1024),
+            "transfer_speed": bytes_uploaded
+            / (time.time() - time.time() or 0.001)
+            / (1024 * 1024),
             "s3_objects": s3_objects,
             "artifacts": artifacts,
         }
@@ -434,7 +461,9 @@ class Plugin:
         }
 
         if self.upload_config["server_side_encryption"]:
-            upload_args["ServerSideEncryption"] = self.upload_config["server_side_encryption"]
+            upload_args["ServerSideEncryption"] = self.upload_config[
+                "server_side_encryption"
+            ]
 
         # Add metadata
         metadata = self.upload_config["metadata"].copy()
@@ -458,7 +487,9 @@ class Plugin:
 
         upload_time = time.time() - start_time
         file_size = local_file.stat().st_size
-        upload_speed = (file_size / (1024 * 1024)) / upload_time if upload_time > 0 else 0
+        upload_speed = (
+            (file_size / (1024 * 1024)) / upload_time if upload_time > 0 else 0
+        )
 
         s3_object = {
             "key": s3_key,
@@ -467,7 +498,11 @@ class Plugin:
             "storage_class": self.upload_config["storage_class"],
         }
 
-        return {"s3_object": s3_object, "bytes_uploaded": file_size, "upload_speed": upload_speed}
+        return {
+            "s3_object": s3_object,
+            "bytes_uploaded": file_size,
+            "upload_speed": upload_speed,
+        }
 
     def _multipart_upload(self, local_file: Path, s3_key: str) -> Dict[str, Any]:
         """Multipart upload for large files"""
@@ -481,7 +516,9 @@ class Plugin:
         }
 
         if self.upload_config["server_side_encryption"]:
-            initiate_args["ServerSideEncryption"] = self.upload_config["server_side_encryption"]
+            initiate_args["ServerSideEncryption"] = self.upload_config[
+                "server_side_encryption"
+            ]
 
         # Add metadata
         metadata = self.upload_config["metadata"].copy()
@@ -522,7 +559,9 @@ class Plugin:
                         Body=chunk,
                     )
 
-                    parts.append({"ETag": part_response["ETag"], "PartNumber": part_number})
+                    parts.append(
+                        {"ETag": part_response["ETag"], "PartNumber": part_number}
+                    )
 
                     bytes_uploaded += len(chunk)
                     part_number += 1
@@ -535,7 +574,9 @@ class Plugin:
                 "MultipartUpload": {"Parts": parts},
             }
 
-            complete_response = self.s3_client.complete_multipart_upload(**complete_args)
+            complete_response = self.s3_client.complete_multipart_upload(
+                **complete_args
+            )
 
         except Exception as e:
             # Abort multipart upload on error
@@ -549,7 +590,9 @@ class Plugin:
 
         upload_time = time.time() - start_time
         file_size = local_file.stat().st_size
-        upload_speed = (file_size / (1024 * 1024)) / upload_time if upload_time > 0 else 0
+        upload_speed = (
+            (file_size / (1024 * 1024)) / upload_time if upload_time > 0 else 0
+        )
 
         s3_object = {
             "key": s3_key,
@@ -588,7 +631,9 @@ class Plugin:
 
             download_time = time.time() - start_time
             file_size = local_file.stat().st_size
-            download_speed = (file_size / (1024 * 1024)) / download_time if download_time > 0 else 0
+            download_speed = (
+                (file_size / (1024 * 1024)) / download_time if download_time > 0 else 0
+            )
 
             return {
                 "files_processed": 1,
@@ -647,7 +692,9 @@ class Plugin:
         objects = []
         paginator = self.s3_client.get_paginator("list_objects_v2")
         pages = paginator.paginate(
-            Bucket=self.bucket.name, Prefix=prefix, PaginationConfig={"MaxItems": max_keys}
+            Bucket=self.bucket.name,
+            Prefix=prefix,
+            PaginationConfig={"MaxItems": max_keys},
         )
 
         for page in pages:
@@ -689,7 +736,9 @@ class Plugin:
                 if "Errors" in response:
                     failed_count += len(response["Errors"])
                     for error in response["Errors"]:
-                        logger.error(f"Failed to delete {error['Key']}: {error['Message']}")
+                        logger.error(
+                            f"Failed to delete {error['Key']}: {error['Message']}"
+                        )
 
             except Exception as e:
                 logger.error(f"Batch delete failed: {e}")
@@ -707,7 +756,9 @@ class Plugin:
         for file_path in local_path.rglob("*"):
             if file_path.is_file():
                 relative_path = file_path.relative_to(local_path)
-                s3_key = f"{s3_prefix}/{relative_path}" if s3_prefix else str(relative_path)
+                s3_key = (
+                    f"{s3_prefix}/{relative_path}" if s3_prefix else str(relative_path)
+                )
                 local_files.add((s3_key, file_path))
 
         # Get S3 files
@@ -745,7 +796,9 @@ class Plugin:
         if delete_removed:
             s3_files_to_delete = s3_files - {s3_key for s3_key, _ in local_files}
             if s3_files_to_delete:
-                delete_result = self._delete_from_s3({"s3_keys": list(s3_files_to_delete)})
+                delete_result = self._delete_from_s3(
+                    {"s3_keys": list(s3_files_to_delete)}
+                )
                 deleted_count = delete_result["deleted_count"]
 
         return {
@@ -767,7 +820,9 @@ class Plugin:
         for s3_key in s3_keys:
             try:
                 # Get object metadata
-                response = self.s3_client.head_object(Bucket=self.bucket.name, Key=s3_key)
+                response = self.s3_client.head_object(
+                    Bucket=self.bucket.name, Key=s3_key
+                )
 
                 # Get local file hash if available
                 original_hash = response.get("Metadata", {}).get("file_hash")
diff --git a/workspace/original_dev/original_axiom_backup/tests/test_plugin_system.py b/workspace/original_dev/original_axiom_backup/tests/test_plugin_system.py
index 4ffa1a6..dbdaf8e 100644
--- a/workspace/original_dev/original_axiom_backup/tests/test_plugin_system.py
+++ b/workspace/original_dev/original_axiom_backup/tests/test_plugin_system.py
@@ -3,9 +3,6 @@ AXIOM Plugin System - Comprehensive Test Suite
 Tests all components of the hot-swappable plugin architecture.
 """
 
-from core.plugin_orchestrator import ErrorHandlingStrategy, ExecutionMode, orchestrator
-from core.plugin_manager import PluginExecutionResult, PluginMetadata, plugin_manager
-from core.config_manager import config_manager
 import json
 import os
 import shutil
@@ -16,6 +13,10 @@ import unittest
 from pathlib import Path
 from unittest.mock import MagicMock, Mock, patch
 
+from core.config_manager import config_manager
+from core.plugin_manager import PluginExecutionResult, PluginMetadata, plugin_manager
+from core.plugin_orchestrator import ErrorHandlingStrategy, ExecutionMode, orchestrator
+
 # Add project root to path
 project_root = Path(__file__).parent.parent
 sys.path.insert(0, str(project_root))
@@ -43,11 +44,17 @@ class TestPluginInterface(unittest.TestCase):
     def test_plugin_metadata_validation(self):
         """Test plugin metadata validation"""
         valid_metadata = PluginMetadata(
-            plugin_id="test_plugin", version="1.0.0", priority=50, enabled=True, dependencies=[]
+            plugin_id="test_plugin",
+            version="1.0.0",
+            priority=50,
+            enabled=True,
+            dependencies=[],
         )
 
         # Test plugin ID validation
-        self.assertTrue(valid_metadata.plugin_id.replace("_", "").replace("-", "").isalnum())
+        self.assertTrue(
+            valid_metadata.plugin_id.replace("_", "").replace("-", "").isalnum()
+        )
         self.assertGreaterEqual(valid_metadata.priority, 1)
         self.assertLessEqual(valid_metadata.priority, 100)
 
@@ -240,7 +247,10 @@ class TestPluginOrchestrator(unittest.TestCase):
             "name": "dependency_test",
             "description": "Test dependency resolution",
             "plugins": ["plugin_a", "plugin_b", "plugin_c"],
-            "dependencies": {"plugin_c": ["plugin_a", "plugin_b"], "plugin_b": ["plugin_a"]},
+            "dependencies": {
+                "plugin_c": ["plugin_a", "plugin_b"],
+                "plugin_b": ["plugin_a"],
+            },
         }
 
         success = self.orchestrator.load_workflow(workflow_config)
@@ -252,8 +262,12 @@ class TestPluginOrchestrator(unittest.TestCase):
         self.assertIn("plugin_c", self.orchestrator.execution_graph.nodes)
 
         # Check dependency edges
-        self.assertTrue(self.orchestrator.execution_graph.has_edge("plugin_a", "plugin_b"))
-        self.assertTrue(self.orchestrator.execution_graph.has_edge("plugin_b", "plugin_c"))
+        self.assertTrue(
+            self.orchestrator.execution_graph.has_edge("plugin_a", "plugin_b")
+        )
+        self.assertTrue(
+            self.orchestrator.execution_graph.has_edge("plugin_b", "plugin_c")
+        )
 
     def test_execution_modes(self):
         """Test different execution modes"""
diff --git a/workspace/restructure_project.py b/workspace/restructure_project.py
index 41c4f11..d215622 100644
--- a/workspace/restructure_project.py
+++ b/workspace/restructure_project.py
@@ -136,7 +136,9 @@ class ProjectRestructurer:
                     # Create placeholder files
                     if isinstance(contents, list):
                         for content in contents:
-                            if content.endswith((".md", ".yaml", ".yml", ".json", ".py", ".sh")):
+                            if content.endswith(
+                                (".md", ".yaml", ".yml", ".json", ".py", ".sh")
+                            ):
                                 file_path = subdir_path / content
                                 if not file_path.exists():
                                     file_path.touch()
@@ -215,7 +217,10 @@ class ProjectRestructurer:
                 "environment": "development",
                 "namespace": "machinenativenops",
                 "services": {
-                    "machinenativenops.instant_generation": {"enabled": True, "debug": True},
+                    "machinenativenops.instant_generation": {
+                        "enabled": True,
+                        "debug": True,
+                    },
                     "phase4": {"enabled": True, "debug": True},
                 },
             },
@@ -223,14 +228,20 @@ class ProjectRestructurer:
                 "environment": "production",
                 "namespace": "machinenativenops",
                 "services": {
-                    "machinenativenops.instant_generation": {"enabled": True, "debug": False},
+                    "machinenativenops.instant_generation": {
+                        "enabled": True,
+                        "debug": False,
+                    },
                     "phase4": {"enabled": True, "debug": False},
                 },
             },
             "config/ci-cd/github-actions/main.yml": {
                 "name": "MachineNativeOps CI/CD",
                 "namespace": "machinenativenops",
-                "on": {"push": {"branches": ["main"]}, "pull_request": {"branches": ["main"]}},
+                "on": {
+                    "push": {"branches": ["main"]},
+                    "pull_request": {"branches": ["main"]},
+                },
                 "jobs": {
                     "build": {
                         "runs-on": "ubuntu-latest",
diff --git a/workspace/root/teams/default-team/orchestrator/services/github_integration.py b/workspace/root/teams/default-team/orchestrator/services/github_integration.py
index e2488d9..9995a97 100644
--- a/workspace/root/teams/default-team/orchestrator/services/github_integration.py
+++ b/workspace/root/teams/default-team/orchestrator/services/github_integration.py
@@ -239,7 +239,9 @@ class GitHubIntegration:
         description: Optional[str] = None,
     ) -> Dict[str, Any]:
         """Create a deployment status."""
-        endpoint = f"/repos/{self._owner}/{self._repo}/deployments/{deployment_id}/statuses"
+        endpoint = (
+            f"/repos/{self._owner}/{self._repo}/deployments/{deployment_id}/statuses"
+        )
 
         data: Dict[str, Any] = {
             "state": state,
@@ -379,10 +381,14 @@ class GitHubEventHandler:
     def map_event(cls, github_event: str, action: Optional[str] = None) -> str:
         """Map GitHub event to team event type."""
         key = f"{github_event}.{action}" if action else github_event
-        return cls.EVENT_MAPPING.get(key, cls.EVENT_MAPPING.get(github_event, "UNKNOWN_EVENT"))
+        return cls.EVENT_MAPPING.get(
+            key, cls.EVENT_MAPPING.get(github_event, "UNKNOWN_EVENT")
+        )
 
     @classmethod
-    def parse_webhook(cls, headers: Dict[str, str], payload: Dict[str, Any]) -> Dict[str, Any]:
+    def parse_webhook(
+        cls, headers: Dict[str, str], payload: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Parse GitHub webhook payload into team event."""
         event_type = headers.get("X-GitHub-Event", "unknown")
         action = payload.get("action")
diff --git a/workspace/root/teams/default-team/orchestrator/services/playbook_runner.py b/workspace/root/teams/default-team/orchestrator/services/playbook_runner.py
index 9e17b82..9c2ad36 100644
--- a/workspace/root/teams/default-team/orchestrator/services/playbook_runner.py
+++ b/workspace/root/teams/default-team/orchestrator/services/playbook_runner.py
@@ -161,7 +161,9 @@ class PlaybookRunner:
                     break
 
             condition = stage.get("condition")
-            if condition and not self._evaluate_condition(condition, stage_results, context):
+            if condition and not self._evaluate_condition(
+                condition, stage_results, context
+            ):
                 should_skip = True
 
             if should_skip:
@@ -188,9 +190,12 @@ class PlaybookRunner:
         result.duration_seconds = (end_time - start_time).total_seconds()
 
         all_success = all(
-            s.status in [StageStatus.SUCCESS, StageStatus.SKIPPED] for s in result.stages
+            s.status in [StageStatus.SUCCESS, StageStatus.SKIPPED]
+            for s in result.stages
+        )
+        result.status = (
+            PlaybookStatus.SUCCESS if all_success else PlaybookStatus.FAILURE
         )
-        result.status = PlaybookStatus.SUCCESS if all_success else PlaybookStatus.FAILURE
 
         result.quality_gates_passed = await self._check_quality_gates(
             playbook.get("quality_gates", []),
@@ -231,7 +236,9 @@ class PlaybookRunner:
                 action = step.get("action")
                 params = step.get("params", {})
 
-                params = self._interpolate_params(params, context, previous_results, step_outputs)
+                params = self._interpolate_params(
+                    params, context, previous_results, step_outputs
+                )
 
                 handler = self._action_handlers.get(action)
                 if handler:
diff --git a/workspace/scripts/automation/automation_launcher.py b/workspace/scripts/automation/automation_launcher.py
index 128ea4a..511132b 100644
--- a/workspace/scripts/automation/automation_launcher.py
+++ b/workspace/scripts/automation/automation_launcher.py
@@ -132,7 +132,9 @@ class AutomationLauncher:
         if show_banner:
             print(BANNER)
 
-        print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸš€ å•Ÿå‹• SynergyMesh è‡ªå‹•åŒ–ç³»çµ±...")
+        print(
+            f"[{datetime.now().strftime('%H:%M:%S')}] ğŸš€ å•Ÿå‹• SynergyMesh è‡ªå‹•åŒ–ç³»çµ±..."
+        )
         print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“‹ æ¨¡å¼: {self.config['mode']}")
         print()
 
@@ -166,7 +168,9 @@ class AutomationLauncher:
                 print("=" * 70)
                 print(f"âœ… SynergyMesh è‡ªå‹•åŒ–ç³»çµ±å•Ÿå‹•æˆåŠŸ")
                 print(f"   é‹è¡Œæ¨¡å¼: {self.config['mode']}")
-                print(f"   å¼•æ“æ•¸é‡: {len(self.orchestrator.registry.get_all_engines())}")
+                print(
+                    f"   å¼•æ“æ•¸é‡: {len(self.orchestrator.registry.get_all_engines())}"
+                )
                 print(f"   ğŸ’“ Heartbeat: Active (Phoenix-ready)")
                 print("=" * 70)
                 print()
@@ -215,7 +219,11 @@ class AutomationLauncher:
                 heartbeat = {
                     "timestamp": datetime.now().isoformat(),
                     "status": "running",
-                    "uptime": str(datetime.now() - self._start_time) if self._start_time else "0",
+                    "uptime": (
+                        str(datetime.now() - self._start_time)
+                        if self._start_time
+                        else "0"
+                    ),
                     "pid": os.getpid(),
                 }
 
@@ -247,7 +255,9 @@ class AutomationLauncher:
         status = self.orchestrator.get_status()
         status["launcher"] = {
             "mode": self.config["mode"],
-            "uptime": str(datetime.now() - self._start_time) if self._start_time else "N/A",
+            "uptime": (
+                str(datetime.now() - self._start_time) if self._start_time else "N/A"
+            ),
         }
         return status
 
diff --git a/workspace/scripts/config-generation/generate-etc-config.py b/workspace/scripts/config-generation/generate-etc-config.py
index 6c914d6..724c672 100755
--- a/workspace/scripts/config-generation/generate-etc-config.py
+++ b/workspace/scripts/config-generation/generate-etc-config.py
@@ -51,7 +51,9 @@ class AAPSConfigGenerator:
         """å„²å­˜ YAML æ–‡ä»¶"""
         try:
             with open(file_path, "w", encoding="utf-8") as f:
-                yaml.dump(data, f, default_flow_style=False, allow_unicode=True, indent=2)
+                yaml.dump(
+                    data, f, default_flow_style=False, allow_unicode=True, indent=2
+                )
             print(f"âœ… Generated: {file_path.relative_to(self.root_dir)}")
         except Exception as e:
             print(f"âŒ Error saving {file_path}: {e}")
@@ -61,7 +63,9 @@ class AAPSConfigGenerator:
         print("ğŸ”§ Generating main configuration...")
 
         # è¼‰å…¥æ¬Šå¨é…ç½®
-        config_spec = self.load_yaml(self.root_config_dir / "policy" / "root.config.yaml")
+        config_spec = self.load_yaml(
+            self.root_config_dir / "policy" / "root.config.yaml"
+        )
         engine_config = self.load_yaml(self.root_config_dir / "engine" / "engine.yaml")
 
         # ç”Ÿæˆéƒ¨ç½²é…ç½®
@@ -90,7 +94,9 @@ class AAPSConfigGenerator:
                 },
                 # å¼•æ“é…ç½®
                 "engine": {
-                    "name": engine_config.get("spec", {}).get("engine", {}).get("name", "AAPS"),
+                    "name": engine_config.get("spec", {})
+                    .get("engine", {})
+                    .get("name", "AAPS"),
                     "version": engine_config.get("spec", {})
                     .get("engine", {})
                     .get("version", "1.0.0"),
@@ -118,7 +124,9 @@ class AAPSConfigGenerator:
                     "authorization": engine_config.get("spec", {})
                     .get("security", {})
                     .get("authorization", {}),
-                    "secrets": engine_config.get("spec", {}).get("security", {}).get("secrets", {}),
+                    "secrets": engine_config.get("spec", {})
+                    .get("security", {})
+                    .get("secrets", {}),
                 },
             },
         }
@@ -130,8 +138,12 @@ class AAPSConfigGenerator:
         print("ğŸ›¡ï¸  Generating governance configuration...")
 
         # è¼‰å…¥æ¬Šå¨é…ç½®
-        governance_spec = self.load_yaml(self.root_config_dir / "policy" / "root.governance.yaml")
-        naming_policy = self.load_yaml(self.root_config_dir / "policy" / "root.naming-policy.yaml")
+        governance_spec = self.load_yaml(
+            self.root_config_dir / "policy" / "root.governance.yaml"
+        )
+        naming_policy = self.load_yaml(
+            self.root_config_dir / "policy" / "root.naming-policy.yaml"
+        )
 
         # ç”Ÿæˆæ²»ç†é…ç½®
         governance_config = {
@@ -201,7 +213,9 @@ class AAPSConfigGenerator:
         print("ğŸ”’ Generating integrity configuration...")
 
         # è¼‰å…¥æ¬Šå¨é…ç½®
-        integrity_spec = self.load_yaml(self.root_config_dir / "evidence" / "root.integrity.yaml")
+        integrity_spec = self.load_yaml(
+            self.root_config_dir / "evidence" / "root.integrity.yaml"
+        )
 
         # ç”Ÿæˆå®Œæ•´æ€§é…ç½®
         integrity_config = {
@@ -222,7 +236,9 @@ class AAPSConfigGenerator:
                 # é©—è­‰é…ç½®
                 "verification": integrity_spec.get("spec", {}).get("verification", {}),
                 # åç§»æª¢æ¸¬
-                "driftDetection": integrity_spec.get("spec", {}).get("driftDetection", {}),
+                "driftDetection": integrity_spec.get("spec", {}).get(
+                    "driftDetection", {}
+                ),
             },
         }
 
@@ -233,7 +249,9 @@ class AAPSConfigGenerator:
         modules = modules_registry.get("spec", {}).get("modules", [])
         return sorted(modules, key=lambda x: x.get("priority", 999))
 
-    def _extract_dependencies(self, modules_registry: Dict[str, Any]) -> Dict[str, List[str]]:
+    def _extract_dependencies(
+        self, modules_registry: Dict[str, Any]
+    ) -> Dict[str, List[str]]:
         """æå–ä¾è³´é—œä¿‚"""
         modules = modules_registry.get("spec", {}).get("modules", [])
         dependencies = {}
@@ -241,11 +259,15 @@ class AAPSConfigGenerator:
         for module in modules:
             name = module.get("name", "")
             deps = module.get("dependencies", [])
-            dependencies[name] = [dep.get("name", "") for dep in deps if dep.get("name")]
+            dependencies[name] = [
+                dep.get("name", "") for dep in deps if dep.get("name")
+            ]
 
         return dependencies
 
-    def _extract_resources(self, modules_registry: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
+    def _extract_resources(
+        self, modules_registry: Dict[str, Any]
+    ) -> Dict[str, Dict[str, Any]]:
         """æå–è³‡æºé…ç½®"""
         modules = modules_registry.get("spec", {}).get("modules", [])
         resources = {}
diff --git a/workspace/scripts/github/fix-actions-sha.py b/workspace/scripts/github/fix-actions-sha.py
index 02e425a..a1d8cc6 100644
--- a/workspace/scripts/github/fix-actions-sha.py
+++ b/workspace/scripts/github/fix-actions-sha.py
@@ -94,7 +94,9 @@ def main():
 
     # Find all workflow files
     workflow_dir = Path(".github/workflows")
-    workflow_files = list(workflow_dir.glob("*.yml")) + list(workflow_dir.glob("*.yaml"))
+    workflow_files = list(workflow_dir.glob("*.yml")) + list(
+        workflow_dir.glob("*.yaml")
+    )
 
     print(f"ğŸ“ Found {len(workflow_files)} workflow files")
 
diff --git a/workspace/scripts/maintenance/brand-replacer.py b/workspace/scripts/maintenance/brand-replacer.py
index c56b6bf..84741a0 100644
--- a/workspace/scripts/maintenance/brand-replacer.py
+++ b/workspace/scripts/maintenance/brand-replacer.py
@@ -120,7 +120,17 @@ class BrandReplacer:
 
     def process_all_files(self) -> dict[str, Any]:
         """è™•ç†æ‰€æœ‰æª”æ¡ˆ"""
-        extensions = {".md", ".yml", ".yaml", ".json", ".sh", ".txt", ".py", ".ts", ".js"}
+        extensions = {
+            ".md",
+            ".yml",
+            ".yaml",
+            ".json",
+            ".sh",
+            ".txt",
+            ".py",
+            ".ts",
+            ".js",
+        }
         exclude_dirs = {".git", "node_modules", "dist", "build", "__pycache__", ".venv"}
 
         processed = 0
diff --git a/workspace/scripts/maintenance/emergency_recovery.py b/workspace/scripts/maintenance/emergency_recovery.py
index be3c931..d8eecdd 100644
--- a/workspace/scripts/maintenance/emergency_recovery.py
+++ b/workspace/scripts/maintenance/emergency_recovery.py
@@ -155,7 +155,11 @@ class EmergencyRecovery:
             if not path.exists():
                 self.log(f"   âŒ Missing directory: {directory}", "ERROR")
                 self.issues_found.append(
-                    {"type": "missing_directory", "directory": directory, "path": str(path)}
+                    {
+                        "type": "missing_directory",
+                        "directory": directory,
+                        "path": str(path),
+                    }
                 )
             else:
                 self.log(f"   âœ… Directory exists: {directory}")
@@ -181,7 +185,9 @@ class EmergencyRecovery:
     def check_processes(self):
         """Check if critical processes are running"""
         try:
-            result = subprocess.run(["ps", "aux"], capture_output=True, text=True, timeout=10)
+            result = subprocess.run(
+                ["ps", "aux"], capture_output=True, text=True, timeout=10
+            )
 
             processes = result.stdout
 
@@ -244,7 +250,10 @@ class EmergencyRecovery:
             if issue_type == "missing_directory":
                 self.repair_missing_directory(issue)
             elif issue_type == "missing_file":
-                self.log(f"   âš ï¸  Cannot auto-fix missing file: {issue['component']}", "WARNING")
+                self.log(
+                    f"   âš ï¸  Cannot auto-fix missing file: {issue['component']}",
+                    "WARNING",
+                )
             elif issue_type == "missing_module":
                 self.repair_missing_module(issue)
             elif issue_type == "process_not_running":
@@ -293,12 +302,22 @@ class EmergencyRecovery:
         except subprocess.CalledProcessError as e:
             self.log(f"   âŒ Failed to install {module}: {e}", "ERROR")
             self.fixes_applied.append(
-                {"type": "installed_module", "module": module, "success": False, "error": str(e)}
+                {
+                    "type": "installed_module",
+                    "module": module,
+                    "success": False,
+                    "error": str(e),
+                }
             )
         except Exception as e:
             self.log(f"   âŒ Error installing {module}: {e}", "ERROR")
             self.fixes_applied.append(
-                {"type": "installed_module", "module": module, "success": False, "error": str(e)}
+                {
+                    "type": "installed_module",
+                    "module": module,
+                    "success": False,
+                    "error": str(e),
+                }
             )
 
     def recover_services(self):
@@ -307,7 +326,8 @@ class EmergencyRecovery:
 
         # Try to start automation_launcher
         if any(
-            issue["type"] == "process_not_running" and issue["process"] == "automation_launcher.py"
+            issue["type"] == "process_not_running"
+            and issue["process"] == "automation_launcher.py"
             for issue in self.issues_found
         ):
             self.start_automation_launcher()
@@ -317,7 +337,8 @@ class EmergencyRecovery:
 
         # Try to start watchdog
         if any(
-            issue["type"] == "process_not_running" and issue["process"] == "system_watchdog.py"
+            issue["type"] == "process_not_running"
+            and issue["process"] == "system_watchdog.py"
             for issue in self.issues_found
         ):
             self.start_watchdog()
@@ -327,7 +348,9 @@ class EmergencyRecovery:
         launcher_path = self.base_path / "automation_launcher.py"
 
         if not launcher_path.exists():
-            self.log("   âŒ Cannot start automation_launcher.py - file not found", "ERROR")
+            self.log(
+                "   âŒ Cannot start automation_launcher.py - file not found", "ERROR"
+            )
             return
 
         self.log("   ğŸ”„ Starting automation_launcher.py...")
@@ -342,7 +365,11 @@ class EmergencyRecovery:
             )
             self.log("   âœ… Started automation_launcher.py")
             self.fixes_applied.append(
-                {"type": "started_service", "service": "automation_launcher.py", "success": True}
+                {
+                    "type": "started_service",
+                    "service": "automation_launcher.py",
+                    "success": True,
+                }
             )
         except Exception as e:
             self.log(f"   âŒ Failed to start automation_launcher.py: {e}", "ERROR")
@@ -375,7 +402,11 @@ class EmergencyRecovery:
             )
             self.log("   âœ… Started system_watchdog.py")
             self.fixes_applied.append(
-                {"type": "started_service", "service": "system_watchdog.py", "success": True}
+                {
+                    "type": "started_service",
+                    "service": "system_watchdog.py",
+                    "success": True,
+                }
             )
         except Exception as e:
             self.log(f"   âŒ Failed to start system_watchdog.py: {e}", "ERROR")
@@ -456,7 +487,9 @@ class EmergencyRecovery:
 
     def save_report(self, success: bool):
         """Save recovery report"""
-        report_path = self.base_path / ".automation_logs" / "emergency_recovery_report.json"
+        report_path = (
+            self.base_path / ".automation_logs" / "emergency_recovery_report.json"
+        )
 
         report = {
             "timestamp": datetime.now().isoformat(),
diff --git a/workspace/scripts/migrate.py b/workspace/scripts/migrate.py
index 33fd138..669b69a 100755
--- a/workspace/scripts/migrate.py
+++ b/workspace/scripts/migrate.py
@@ -4,12 +4,12 @@ MachineNativeOps Database Migration Script
 æ•¸æ“šåº«é·ç§»è…³æœ¬
 """
 
-from src.new.config import load_config
 import asyncio
 import sys
 from pathlib import Path
 
 import asyncpg
+from src.new.config import load_config
 
 # æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent))
@@ -31,7 +31,9 @@ async def create_database():
 
     try:
         # æª¢æŸ¥æ•¸æ“šåº«æ˜¯å¦å­˜åœ¨
-        exists = await conn.fetchval("SELECT 1 FROM pg_database WHERE datname = $1", db_config.name)
+        exists = await conn.fetchval(
+            "SELECT 1 FROM pg_database WHERE datname = $1", db_config.name
+        )
 
         if not exists:
             # å‰µå»ºæ•¸æ“šåº«
@@ -164,17 +166,29 @@ async def create_tables():
         print("ğŸ”§ å‰µå»ºç´¢å¼•...")
 
         # é …ç›®ç´¢å¼•
-        await conn.execute("CREATE INDEX IF NOT EXISTS idx_projects_owner ON projects(owner)")
-        await conn.execute("CREATE INDEX IF NOT EXISTS idx_projects_status ON projects(status)")
+        await conn.execute(
+            "CREATE INDEX IF NOT EXISTS idx_projects_owner ON projects(owner)"
+        )
+        await conn.execute(
+            "CREATE INDEX IF NOT EXISTS idx_projects_status ON projects(status)"
+        )
         await conn.execute(
             "CREATE INDEX IF NOT EXISTS idx_projects_created_at ON projects(created_at)"
         )
 
         # ä»»å‹™ç´¢å¼•
-        await conn.execute("CREATE INDEX IF NOT EXISTS idx_tasks_project_id ON tasks(project_id)")
-        await conn.execute("CREATE INDEX IF NOT EXISTS idx_tasks_assignee ON tasks(assignee)")
-        await conn.execute("CREATE INDEX IF NOT EXISTS idx_tasks_status ON tasks(status)")
-        await conn.execute("CREATE INDEX IF NOT EXISTS idx_tasks_priority ON tasks(priority)")
+        await conn.execute(
+            "CREATE INDEX IF NOT EXISTS idx_tasks_project_id ON tasks(project_id)"
+        )
+        await conn.execute(
+            "CREATE INDEX IF NOT EXISTS idx_tasks_assignee ON tasks(assignee)"
+        )
+        await conn.execute(
+            "CREATE INDEX IF NOT EXISTS idx_tasks_status ON tasks(status)"
+        )
+        await conn.execute(
+            "CREATE INDEX IF NOT EXISTS idx_tasks_priority ON tasks(priority)"
+        )
 
         # å·¥ä½œæµåŸ·è¡Œç´¢å¼•
         await conn.execute(
@@ -185,7 +199,9 @@ async def create_tables():
         )
 
         # ç”¨æˆ¶ç´¢å¼•
-        await conn.execute("CREATE INDEX IF NOT EXISTS idx_users_username ON users(username)")
+        await conn.execute(
+            "CREATE INDEX IF NOT EXISTS idx_users_username ON users(username)"
+        )
         await conn.execute("CREATE INDEX IF NOT EXISTS idx_users_email ON users(email)")
 
         print("âœ… æ•¸æ“šè¡¨å‰µå»ºæˆåŠŸ")
@@ -212,7 +228,9 @@ async def insert_default_data():
         print("ğŸ”§ æ’å…¥é»˜èªæ•¸æ“š...")
 
         # æ’å…¥é»˜èªç”¨æˆ¶ (admin/admin123)
-        admin_exists = await conn.fetchval("SELECT 1 FROM users WHERE username = 'admin'")
+        admin_exists = await conn.fetchval(
+            "SELECT 1 FROM users WHERE username = 'admin'"
+        )
 
         if not admin_exists:
             # å¯¦éš›æ‡‰ç”¨ä¸­æ‡‰ä½¿ç”¨ bcrypt å“ˆå¸Œå¯†ç¢¼
diff --git a/workspace/scripts/migration/fhs-structure-validator.py b/workspace/scripts/migration/fhs-structure-validator.py
index 02dc94e..39963aa 100755
--- a/workspace/scripts/migration/fhs-structure-validator.py
+++ b/workspace/scripts/migration/fhs-structure-validator.py
@@ -40,7 +40,11 @@ class FHSStructureValidator:
             "home": {"description": "ç”¨æˆ¶ä¸»ç›®éŒ„", "required": True},
             "tmp": {"description": "è‡¨æ™‚æª”æ¡ˆ", "required": True},
             "opt": {"description": "å¯é¸æ‡‰ç”¨ç¨‹å¼", "required": True},
-            "srv": {"description": "æœå‹™è³‡æ–™", "required": True, "subdirs": ["www", "ftp", "git"]},
+            "srv": {
+                "description": "æœå‹™è³‡æ–™",
+                "required": True,
+                "subdirs": ["www", "ftp", "git"],
+            },
             "init.d": {"description": "åˆå§‹åŒ–è…³æœ¬", "required": True},
         }
 
@@ -114,7 +118,8 @@ def main():
 
     structure_results = validator.validate_directory_structure()
     compliance_score = (
-        structure_results["summary"]["valid_fhs"] / structure_results["summary"]["total_fhs"]
+        structure_results["summary"]["valid_fhs"]
+        / structure_results["summary"]["total_fhs"]
     ) * 100
 
     if compliance_score >= 90:
diff --git a/workspace/scripts/migration/namespace-converter.py b/workspace/scripts/migration/namespace-converter.py
index 81caf3d..49994e2 100644
--- a/workspace/scripts/migration/namespace-converter.py
+++ b/workspace/scripts/migration/namespace-converter.py
@@ -93,7 +93,10 @@ class NamespaceConverter:
                     # è½‰æ› kind
                     if "kind" in doc:
                         old_kind = doc["kind"]
-                        if "GlobalBaseline" in old_kind and old_kind != self.TARGET_KIND:
+                        if (
+                            "GlobalBaseline" in old_kind
+                            and old_kind != self.TARGET_KIND
+                        ):
                             doc["kind"] = self.TARGET_KIND
                             self.stats.kind_updates += 1
                             modified = True
@@ -115,8 +118,12 @@ class NamespaceConverter:
                                 for key, value in labels.items():
                                     if not key.startswith(self.TARGET_LABEL_PREFIX):
                                         # æå– key çš„å¾ŒåŠéƒ¨åˆ†
-                                        key_suffix = key.split("/")[-1] if "/" in key else key
-                                        new_key = f"{self.TARGET_LABEL_PREFIX}{key_suffix}"
+                                        key_suffix = (
+                                            key.split("/")[-1] if "/" in key else key
+                                        )
+                                        new_key = (
+                                            f"{self.TARGET_LABEL_PREFIX}{key_suffix}"
+                                        )
                                         new_labels[new_key] = value
                                         self.stats.label_updates += 1
                                         modified = True
@@ -136,8 +143,9 @@ class NamespaceConverter:
                                             # æå– URN çš„å¾ŒåŠéƒ¨åˆ†
                                             urn_parts = value.split(":")
                                             if len(urn_parts) > 2:
-                                                new_value = self.TARGET_URN_PREFIX + ":".join(
-                                                    urn_parts[2:]
+                                                new_value = (
+                                                    self.TARGET_URN_PREFIX
+                                                    + ":".join(urn_parts[2:])
                                                 )
                                                 new_annotations[key] = new_value
                                                 self.stats.urn_updates += 1
@@ -148,8 +156,12 @@ class NamespaceConverter:
                                             new_annotations[key] = value
                                     # è½‰æ› annotation key
                                     elif not key.startswith(self.TARGET_LABEL_PREFIX):
-                                        key_suffix = key.split("/")[-1] if "/" in key else key
-                                        new_key = f"{self.TARGET_LABEL_PREFIX}{key_suffix}"
+                                        key_suffix = (
+                                            key.split("/")[-1] if "/" in key else key
+                                        )
+                                        new_key = (
+                                            f"{self.TARGET_LABEL_PREFIX}{key_suffix}"
+                                        )
                                         new_annotations[new_key] = value
                                         self.stats.label_updates += 1
                                         modified = True
@@ -160,7 +172,10 @@ class NamespaceConverter:
                 if modified:
                     # é‡æ–°åºåˆ—åŒ– YAML
                     new_content = yaml.dump_all(
-                        docs, default_flow_style=False, sort_keys=False, allow_unicode=True
+                        docs,
+                        default_flow_style=False,
+                        sort_keys=False,
+                        allow_unicode=True,
                     )
 
                     if not self.dry_run:
@@ -168,7 +183,9 @@ class NamespaceConverter:
                             f.write(new_content)
 
                     new_hash = self.calculate_file_hash(new_content)
-                    self.stats.hash_changes.append((str(file_path), original_hash, new_hash))
+                    self.stats.hash_changes.append(
+                        (str(file_path), original_hash, new_hash)
+                    )
                     self.stats.files_modified += 1
                     return True
 
@@ -195,7 +212,9 @@ class NamespaceConverter:
 
         # éæ¿¾æ’é™¤ç›®éŒ„
         yaml_files = [
-            f for f in yaml_files if not any(excluded in f.parts for excluded in self.exclude_dirs)
+            f
+            for f in yaml_files
+            if not any(excluded in f.parts for excluded in self.exclude_dirs)
         ]
 
         print(f"ğŸ“ æ‰¾åˆ° {len(yaml_files)} å€‹ YAML æ–‡ä»¶")
@@ -254,7 +273,9 @@ def main():
 
     parser = argparse.ArgumentParser(description="MachineNativeOps å‘½åç©ºé–“è½‰æ›å·¥å…·")
     parser.add_argument("directory", help="è¦è½‰æ›çš„ç›®éŒ„è·¯å¾‘")
-    parser.add_argument("--dry-run", action="store_true", help="ä¹¾è·‘æ¨¡å¼ï¼ˆä¸å¯¦éš›ä¿®æ”¹æ–‡ä»¶ï¼‰")
+    parser.add_argument(
+        "--dry-run", action="store_true", help="ä¹¾è·‘æ¨¡å¼ï¼ˆä¸å¯¦éš›ä¿®æ”¹æ–‡ä»¶ï¼‰"
+    )
 
     args = parser.parse_args()
 
diff --git a/workspace/scripts/migration/namespace-validator.py b/workspace/scripts/migration/namespace-validator.py
index bc69198..004e3eb 100644
--- a/workspace/scripts/migration/namespace-validator.py
+++ b/workspace/scripts/migration/namespace-validator.py
@@ -21,7 +21,9 @@ class ValidationResult:
     valid_files: int = 0
     invalid_files: int = 0
     errors: List[Tuple[str, str]] = field(default_factory=list)  # (file, error_message)
-    warnings: List[Tuple[str, str]] = field(default_factory=list)  # (file, warning_message)
+    warnings: List[Tuple[str, str]] = field(
+        default_factory=list
+    )  # (file, warning_message)
 
 
 class NamespaceValidator:
@@ -66,7 +68,9 @@ class NamespaceValidator:
             # æª¢æŸ¥ç¦æ­¢çš„æ¨¡å¼
             for pattern in self.FORBIDDEN_PATTERNS:
                 if pattern in content.lower():
-                    self.result.errors.append((str(file_path), "æª¢æ¸¬åˆ°ç¦æ­¢çš„èˆŠå‘½åç©ºé–“å¼•ç”¨"))
+                    self.result.errors.append(
+                        (str(file_path), "æª¢æ¸¬åˆ°ç¦æ­¢çš„èˆŠå‘½åç©ºé–“å¼•ç”¨")
+                    )
                     return False
 
             # å˜—è©¦è§£æ YAML
@@ -91,7 +95,10 @@ class NamespaceValidator:
 
                     # æª¢æŸ¥ kind
                     if "kind" in doc:
-                        if "GlobalBaseline" in doc["kind"] and doc["kind"] != self.REQUIRED_KIND:
+                        if (
+                            "GlobalBaseline" in doc["kind"]
+                            and doc["kind"] != self.REQUIRED_KIND
+                        ):
                             self.result.errors.append(
                                 (
                                     str(file_path),
@@ -116,9 +123,13 @@ class NamespaceValidator:
                                 file_valid = False
 
                         # æª¢æŸ¥ labels
-                        if "labels" in metadata and isinstance(metadata["labels"], dict):
+                        if "labels" in metadata and isinstance(
+                            metadata["labels"], dict
+                        ):
                             for key in metadata["labels"].keys():
-                                if "/" in key and not key.startswith(self.REQUIRED_LABEL_PREFIX):
+                                if "/" in key and not key.startswith(
+                                    self.REQUIRED_LABEL_PREFIX
+                                ):
                                     self.result.warnings.append(
                                         (
                                             str(file_path),
@@ -127,11 +138,15 @@ class NamespaceValidator:
                                     )
 
                         # æª¢æŸ¥ annotations
-                        if "annotations" in metadata and isinstance(metadata["annotations"], dict):
+                        if "annotations" in metadata and isinstance(
+                            metadata["annotations"], dict
+                        ):
                             for key, value in metadata["annotations"].items():
                                 # æª¢æŸ¥ URN
                                 if "urn" in key.lower() and isinstance(value, str):
-                                    if value.startswith("urn:") and not value.startswith(
+                                    if value.startswith(
+                                        "urn:"
+                                    ) and not value.startswith(
                                         self.REQUIRED_URN_PREFIX
                                     ):
                                         self.result.errors.append(
@@ -143,7 +158,9 @@ class NamespaceValidator:
                                         file_valid = False
 
                                 # æª¢æŸ¥ annotation key
-                                if "/" in key and not key.startswith(self.REQUIRED_LABEL_PREFIX):
+                                if "/" in key and not key.startswith(
+                                    self.REQUIRED_LABEL_PREFIX
+                                ):
                                     self.result.warnings.append(
                                         (
                                             str(file_path),
@@ -174,7 +191,9 @@ class NamespaceValidator:
 
         # éæ¿¾æ’é™¤ç›®éŒ„
         yaml_files = [
-            f for f in yaml_files if not any(excluded in f.parts for excluded in self.exclude_dirs)
+            f
+            for f in yaml_files
+            if not any(excluded in f.parts for excluded in self.exclude_dirs)
         ]
 
         print(f"ğŸ“ æ‰¾åˆ° {len(yaml_files)} å€‹ YAML æ–‡ä»¶")
diff --git a/workspace/scripts/namespace-renamer.py b/workspace/scripts/namespace-renamer.py
index 91cdd10..9157e07 100644
--- a/workspace/scripts/namespace-renamer.py
+++ b/workspace/scripts/namespace-renamer.py
@@ -46,7 +46,9 @@ def rename_axm_to_mno(content):
     }
 
     # æŒ‰é•·åº¦æ’åºï¼Œå…ˆæ›¿æ›è¼ƒé•·çš„å­—ç¬¦ä¸²
-    sorted_replacements = sorted(replacements.items(), key=lambda x: len(x[0]), reverse=True)
+    sorted_replacements = sorted(
+        replacements.items(), key=lambda x: len(x[0]), reverse=True
+    )
 
     new_content = content
     for old, new in sorted_replacements:
diff --git a/workspace/scripts/ops/migration/migrator.py b/workspace/scripts/ops/migration/migrator.py
index f795eea..b1ddc7c 100644
--- a/workspace/scripts/ops/migration/migrator.py
+++ b/workspace/scripts/ops/migration/migrator.py
@@ -92,20 +92,28 @@ class Migrator:
             "v1_exists": self.v1_path.exists(),
             "v2_exists": self.v2_path.exists(),
             "drone_config_exists": (self._project_root / "drone-config.yml").exists(),
-            "island_config_exists": (self._project_root / "island-control.yml").exists(),
+            "island_config_exists": (
+                self._project_root / "island-control.yml"
+            ).exists(),
             "can_migrate_v1_to_v2": False,
             "can_migrate_v2_to_v1": False,
         }
 
-        result["can_migrate_v1_to_v2"] = result["v1_exists"] and result["drone_config_exists"]
-        result["can_migrate_v2_to_v1"] = result["v2_exists"] and result["island_config_exists"]
+        result["can_migrate_v1_to_v2"] = (
+            result["v1_exists"] and result["drone_config_exists"]
+        )
+        result["can_migrate_v2_to_v1"] = (
+            result["v2_exists"] and result["island_config_exists"]
+        )
 
         # é¡¯ç¤ºæª¢æŸ¥çµæœ
         print("\nğŸ“‹ é·ç§»å‰æª¢æŸ¥çµæœ:")
         print(f"  v1-python-drones: {'âœ…' if result['v1_exists'] else 'âŒ'}")
         print(f"  v2-multi-islands: {'âœ…' if result['v2_exists'] else 'âŒ'}")
         print(f"  drone-config.yml: {'âœ…' if result['drone_config_exists'] else 'âŒ'}")
-        print(f"  island-control.yml: {'âœ…' if result['island_config_exists'] else 'âŒ'}")
+        print(
+            f"  island-control.yml: {'âœ…' if result['island_config_exists'] else 'âŒ'}"
+        )
         print(f"  å¯åŸ·è¡Œ v1 â†’ v2: {'âœ…' if result['can_migrate_v1_to_v2'] else 'âŒ'}")
         print(f"  å¯åŸ·è¡Œ v2 â†’ v1: {'âœ…' if result['can_migrate_v2_to_v1'] else 'âŒ'}")
         print()
@@ -323,7 +331,11 @@ def main() -> int:
     parser = argparse.ArgumentParser(description="SynergyMesh ç‰ˆæœ¬é·ç§»å·¥å…·")
 
     parser.add_argument(
-        "--direction", "-d", choices=["v1-to-v2", "v2-to-v1"], required=True, help="é·ç§»æ–¹å‘"
+        "--direction",
+        "-d",
+        choices=["v1-to-v2", "v2-to-v1"],
+        required=True,
+        help="é·ç§»æ–¹å‘",
     )
 
     parser.add_argument("--dry-run", action="store_true", help="ä¹¾è·‘æ¨¡å¼ï¼ˆä¸å¯¦éš›åŸ·è¡Œï¼‰")
diff --git a/workspace/scripts/ops/migration/scripts/v1_to_v2.py b/workspace/scripts/ops/migration/scripts/v1_to_v2.py
index d5ccd7c..2fa3770 100644
--- a/workspace/scripts/ops/migration/scripts/v1_to_v2.py
+++ b/workspace/scripts/ops/migration/scripts/v1_to_v2.py
@@ -5,10 +5,11 @@ v1 â†’ v2 é·ç§»è…³æœ¬
 å°‡ v1-python-drones é·ç§»è‡³ v2-multi-islands æ¶æ§‹ã€‚
 """
 
-from migration.migrator import Migrator
 import sys
 from pathlib import Path
 
+from migration.migrator import Migrator
+
 # æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))
 
diff --git a/workspace/scripts/ops/migration/scripts/v2_to_v1.py b/workspace/scripts/ops/migration/scripts/v2_to_v1.py
index 738b9dd..5093e76 100644
--- a/workspace/scripts/ops/migration/scripts/v2_to_v1.py
+++ b/workspace/scripts/ops/migration/scripts/v2_to_v1.py
@@ -5,10 +5,11 @@ v2 â†’ v1 é™ç´šé·ç§»è…³æœ¬
 å°‡ v2-multi-islands é™ç´šè‡³ v1-python-drones æ¶æ§‹ã€‚
 """
 
-from migration.migrator import Migrator
 import sys
 from pathlib import Path
 
+from migration.migrator import Migrator
+
 # æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))
 
diff --git a/workspace/scripts/pre-deploy-test.py b/workspace/scripts/pre-deploy-test.py
index 0110e71..9fa2fc4 100755
--- a/workspace/scripts/pre-deploy-test.py
+++ b/workspace/scripts/pre-deploy-test.py
@@ -43,11 +43,17 @@ class PreDeployTester:
             else:
                 logger.error(f"âŒ æ¸¬è©¦å¤±æ•—: {test_name}")
                 self.test_results.append(
-                    {"name": test_name, "status": "FAIL", "reason": "Test returned False"}
+                    {
+                        "name": test_name,
+                        "status": "FAIL",
+                        "reason": "Test returned False",
+                    }
                 )
         except Exception as e:
             logger.error(f"âŒ æ¸¬è©¦ç•°å¸¸: {test_name} - {str(e)}")
-            self.test_results.append({"name": test_name, "status": "ERROR", "reason": str(e)})
+            self.test_results.append(
+                {"name": test_name, "status": "ERROR", "reason": str(e)}
+            )
 
     def test_core_imports(self):
         """æ¸¬è©¦æ ¸å¿ƒæ¨¡çµ„å°å…¥"""
@@ -94,7 +100,9 @@ class PreDeployTester:
             task = Task(id="task-123", project_id="test-123", name="Test Task")
 
             # æ¸¬è©¦æ¥­å‹™æŒ‡æ¨™
-            metrics = BusinessMetrics(total_projects=1, active_projects=1, total_tasks=1)
+            metrics = BusinessMetrics(
+                total_projects=1, active_projects=1, total_tasks=1
+            )
 
             return (
                 project.id == "test-123"
@@ -171,7 +179,10 @@ class PreDeployTester:
             with open("docker-compose.prod.yml", "r") as f:
                 compose_config = yaml.safe_load(f)
 
-            return "services" in compose_config and "mno-business" in compose_config["services"]
+            return (
+                "services" in compose_config
+                and "mno-business" in compose_config["services"]
+            )
         except Exception as e:
             logger.error(f"Docker æ–‡ä»¶æ¸¬è©¦å¤±æ•—: {e}")
             return False
@@ -277,7 +288,9 @@ class PreDeployTester:
                 "passed_tests": self.passed_tests,
                 "failed_tests": self.total_tests - self.passed_tests,
                 "success_rate": (
-                    (self.passed_tests / self.total_tests * 100) if self.total_tests > 0 else 0
+                    (self.passed_tests / self.total_tests * 100)
+                    if self.total_tests > 0
+                    else 0
                 ),
             },
             "results": self.test_results,
@@ -334,7 +347,9 @@ class PreDeployTester:
         if failed_tests:
             logger.error("å¤±æ•—çš„æ¸¬è©¦:")
             for test in failed_tests:
-                logger.error(f"  âŒ {test['name']}: {test.get('reason', 'Unknown error')}")
+                logger.error(
+                    f"  âŒ {test['name']}: {test.get('reason', 'Unknown error')}"
+                )
 
         logger.info(f"ğŸ“Š è©³ç´°å ±å‘Šå·²ä¿å­˜åˆ°: test-results.json")
 
@@ -350,7 +365,9 @@ def main():
         logger.info("\nğŸ¯ ä¸‹ä¸€æ­¥:")
         logger.info("1. è¤‡è£½ .env.example åˆ° .env ä¸¦é…ç½®ç’°å¢ƒè®Šé‡")
         logger.info("2. é‹è¡Œéƒ¨ç½²è…³æœ¬: ./scripts/deploy.sh")
-        logger.info("3. ç›£æ§éƒ¨ç½²æ—¥èªŒ: docker-compose -f docker-compose.prod.yml logs -f")
+        logger.info(
+            "3. ç›£æ§éƒ¨ç½²æ—¥èªŒ: docker-compose -f docker-compose.prod.yml logs -f"
+        )
         sys.exit(0)
     else:
         logger.error("\nğŸ› ï¸  è«‹ä¿®å¾©å¤±æ•—çš„æ¸¬è©¦å¾Œé‡æ–°é‹è¡Œ")
diff --git a/workspace/scripts/validate-instant-execution.py b/workspace/scripts/validate-instant-execution.py
index 23854c0..22b1eb8 100755
--- a/workspace/scripts/validate-instant-execution.py
+++ b/workspace/scripts/validate-instant-execution.py
@@ -154,7 +154,9 @@ class InstantExecutionValidator:
         print_header("é©—è­‰ä¸¦è¡Œåº¦é…ç½®")
 
         parallelism = (
-            self.manifest.get("spec", {}).get("execution_standards", {}).get("parallelism", {})
+            self.manifest.get("spec", {})
+            .get("execution_standards", {})
+            .get("parallelism", {})
         )
 
         all_passed = True
@@ -186,7 +188,11 @@ class InstantExecutionValidator:
         """é©—è­‰è‡ªæ²»åº¦é…ç½®"""
         print_header("é©—è­‰è‡ªæ²»åº¦é…ç½®")
 
-        autonomy = self.manifest.get("spec", {}).get("execution_standards", {}).get("autonomy", {})
+        autonomy = (
+            self.manifest.get("spec", {})
+            .get("execution_standards", {})
+            .get("autonomy", {})
+        )
 
         all_passed = True
 
@@ -354,12 +360,18 @@ class InstantExecutionValidator:
 
         all_passed = True
 
-        required_validators = ["INSTANT_EXECUTION", "AUTONOMY_LEVEL", "LATENCY_COMPLIANCE"]
+        required_validators = [
+            "INSTANT_EXECUTION",
+            "AUTONOMY_LEVEL",
+            "LATENCY_COMPLIANCE",
+        ]
 
         self.results["total_checks"] += len(required_validators)
 
         for validator_name in required_validators:
-            validator_found = any(v.get("standard") == validator_name for v in validators)
+            validator_found = any(
+                v.get("standard") == validator_name for v in validators
+            )
             if validator_found:
                 self.results["passed"] += 1
                 print_success(f"å¿…è¦é©—è­‰å™¨å­˜åœ¨: {validator_name}")
@@ -488,7 +500,9 @@ def main():
         default="contracts/INSTANT-EXECUTION-MANIFEST.yaml",
         help="Path to the instant execution manifest file",
     )
-    parser.add_argument("--report", help="Path to save the validation report (JSON format)")
+    parser.add_argument(
+        "--report", help="Path to save the validation report (JSON format)"
+    )
     parser.add_argument("--verbose", action="store_true", help="Enable verbose output")
 
     args = parser.parse_args()
diff --git a/workspace/scripts/validation/validate-root-specs.py b/workspace/scripts/validation/validate-root-specs.py
index 0dd2524..4239e1e 100755
--- a/workspace/scripts/validation/validate-root-specs.py
+++ b/workspace/scripts/validation/validate-root-specs.py
@@ -71,9 +71,9 @@ class RootSpecsValidator:
     def load_root_files(self):
         """Load all root.*.yaml files"""
         for file_path in self.repo_root.glob("root.*.yaml"):
-            if not file_path.name.startswith("root.specs.") and not file_path.name.startswith(
-                "root.registry."
-            ):
+            if not file_path.name.startswith(
+                "root.specs."
+            ) and not file_path.name.startswith("root.registry."):
                 self.root_files[file_path.name] = self.load_yaml(file_path)
 
     def validate_naming_spec(self) -> List[str]:
@@ -91,18 +91,24 @@ class RootSpecsValidator:
             # Check file name format
             file_pattern = naming_rules.get("file_names", {}).get("pattern", "")
             if file_pattern and not re.match(file_pattern, file_name):
-                errors.append(f"File name '{file_name}' does not match pattern: {file_pattern}")
+                errors.append(
+                    f"File name '{file_name}' does not match pattern: {file_pattern}"
+                )
 
             # Check YAML keys
             if content and isinstance(content, dict):
-                errors.extend(self._validate_yaml_keys(content, file_name, naming_rules))
+                errors.extend(
+                    self._validate_yaml_keys(content, file_name, naming_rules)
+                )
 
             # Check apiVersion format
             api_version = content.get("apiVersion", "")
             if api_version:
                 api_pattern = naming_rules.get("api_version", {}).get("pattern", "")
                 if api_pattern and not re.match(api_pattern, api_version):
-                    errors.append(f"{file_name}: apiVersion '{api_version}' does not match pattern")
+                    errors.append(
+                        f"{file_name}: apiVersion '{api_version}' does not match pattern"
+                    )
 
             # Check kind format
             kind = content.get("kind", "")
@@ -159,13 +165,17 @@ class RootSpecsValidator:
 
                 # Recurse into nested structures
                 errors.extend(
-                    self._validate_yaml_keys(value, file_name, naming_rules, current_path)
+                    self._validate_yaml_keys(
+                        value, file_name, naming_rules, current_path
+                    )
                 )
 
         elif isinstance(data, list):
             for i, item in enumerate(data):
                 errors.extend(
-                    self._validate_yaml_keys(item, file_name, naming_rules, f"{path}[{i}]")
+                    self._validate_yaml_keys(
+                        item, file_name, naming_rules, f"{path}[{i}]"
+                    )
                 )
 
         return errors
@@ -195,7 +205,9 @@ class RootSpecsValidator:
                 for urn_entry in urns:
                     urn = urn_entry.get("urn", "")
                     if urn and urn_pattern and not re.match(urn_pattern, urn):
-                        errors.append(f"URN '{urn}' does not match pattern: {urn_pattern}")
+                        errors.append(
+                            f"URN '{urn}' does not match pattern: {urn_pattern}"
+                        )
 
         # Check for duplicate URNs
         all_urns = []
@@ -258,7 +270,9 @@ class RootSpecsValidator:
             for module in modules:
                 module_id = module.get("id", "")
                 dependencies = module.get("dependencies", [])
-                dependency_graph[module_id] = [dep.get("module_id", "") for dep in dependencies]
+                dependency_graph[module_id] = [
+                    dep.get("module_id", "") for dep in dependencies
+                ]
 
             # Detect cycles using DFS
             cycles = self._detect_cycles(dependency_graph)
@@ -357,7 +371,9 @@ class RootSpecsValidator:
         report.append("## Summary\n")
         report.append(f"- **Total Errors:** {len(self.errors)}\n")
         report.append(f"- **Total Warnings:** {len(self.warnings)}\n")
-        report.append(f"- **Status:** {'âŒ FAILED' if self.errors else 'âœ… PASSED'}\n\n")
+        report.append(
+            f"- **Status:** {'âŒ FAILED' if self.errors else 'âœ… PASSED'}\n\n"
+        )
 
         # Errors
         if self.errors:
diff --git a/workspace/scripts/verification/basic-verification.py b/workspace/scripts/verification/basic-verification.py
index 45c7aab..b3f0753 100755
--- a/workspace/scripts/verification/basic-verification.py
+++ b/workspace/scripts/verification/basic-verification.py
@@ -85,7 +85,9 @@ class BasicVerification:
                 if "kind" in doc:
                     kind = doc["kind"]
                     # é€™è£¡å¯ä»¥æ·»åŠ æ›´å¤šé©—è­‰é‚è¼¯
-                    if kind not in standard_kinds and not kind.startswith("MachineNativeOps"):
+                    if kind not in standard_kinds and not kind.startswith(
+                        "MachineNativeOps"
+                    ):
                         self.warnings.append(f"{file_path}: éæ¨™æº–è³‡æºé¡å‹ '{kind}'")
 
             return True
@@ -95,12 +97,24 @@ class BasicVerification:
 
     def verify_yaml_files(self) -> bool:
         """é©—è­‰æ‰€æœ‰ YAML æ–‡ä»¶"""
-        yaml_files = list(self.root_dir.rglob("*.yaml")) + list(self.root_dir.rglob("*.yml"))
+        yaml_files = list(self.root_dir.rglob("*.yaml")) + list(
+            self.root_dir.rglob("*.yml")
+        )
 
         # éæ¿¾æ’é™¤ç›®éŒ„
-        exclude_dirs = {".git", "node_modules", "__pycache__", "dist", "build", ".venv", "archive"}
+        exclude_dirs = {
+            ".git",
+            "node_modules",
+            "__pycache__",
+            "dist",
+            "build",
+            ".venv",
+            "archive",
+        }
         yaml_files = [
-            f for f in yaml_files if not any(excluded in f.parts for excluded in exclude_dirs)
+            f
+            for f in yaml_files
+            if not any(excluded in f.parts for excluded in exclude_dirs)
         ]
 
         if not yaml_files:
@@ -140,9 +154,19 @@ class BasicVerification:
         python_files = list(self.root_dir.rglob("*.py"))
 
         # éæ¿¾æ’é™¤ç›®éŒ„
-        exclude_dirs = {".git", "node_modules", "__pycache__", "dist", "build", ".venv", "archive"}
+        exclude_dirs = {
+            ".git",
+            "node_modules",
+            "__pycache__",
+            "dist",
+            "build",
+            ".venv",
+            "archive",
+        }
         python_files = [
-            f for f in python_files if not any(excluded in f.parts for excluded in exclude_dirs)
+            f
+            for f in python_files
+            if not any(excluded in f.parts for excluded in exclude_dirs)
         ]
 
         if not python_files:
@@ -191,7 +215,9 @@ class BasicVerification:
         )
 
         # è³‡æºé¡å‹æ¨™æº–åŒ–ï¼ˆå·²åŒ…å«åœ¨ YAML é©—è­‰ä¸­ï¼‰
-        results.append(("è³‡æºé¡å‹æ¨™æº–åŒ–å®Œæˆ", not any("è³‡æºé¡å‹" in e for e in self.errors)))
+        results.append(
+            ("è³‡æºé¡å‹æ¨™æº–åŒ–å®Œæˆ", not any("è³‡æºé¡å‹" in e for e in self.errors))
+        )
 
         # è¼¸å‡ºçµæœ
         print()
diff --git a/workspace/scripts/verification/production-verification.py b/workspace/scripts/verification/production-verification.py
index ccf2594..91a622a 100755
--- a/workspace/scripts/verification/production-verification.py
+++ b/workspace/scripts/verification/production-verification.py
@@ -60,8 +60,13 @@ class ProductionVerification:
                     for pattern in sensitive_patterns:
                         if f"{pattern} =" in content or f"{pattern}=" in content:
                             # æª¢æŸ¥æ˜¯å¦æ˜¯ç¡¬ç·¨ç¢¼çš„å€¼
-                            if f'"{pattern}"' not in content and f"'{pattern}'" not in content:
-                                self.warnings.append(f"å¯èƒ½åŒ…å«æ•æ„Ÿä¿¡æ¯: {py_file} ({pattern})")
+                            if (
+                                f'"{pattern}"' not in content
+                                and f"'{pattern}'" not in content
+                            ):
+                                self.warnings.append(
+                                    f"å¯èƒ½åŒ…å«æ•æ„Ÿä¿¡æ¯: {py_file} ({pattern})"
+                                )
 
             except Exception as e:
                 self.errors.append(f"å®‰å…¨æƒæå¤±æ•— {py_file}: {e}")
@@ -91,7 +96,9 @@ class ProductionVerification:
                     # æª¢æŸ¥æª”æ¡ˆå¤§å°åˆç†æ€§
                     size_kb = full_path.stat().st_size / 1024
                     if size_kb > 1000:  # 1MB
-                        self.warnings.append(f"æ¨¡çµ„éå¤§: {module_path} ({size_kb:.1f}KB)")
+                        self.warnings.append(
+                            f"æ¨¡çµ„éå¤§: {module_path} ({size_kb:.1f}KB)"
+                        )
 
             return True
 
diff --git a/workspace/scripts/verification/run-all-verifications.py b/workspace/scripts/verification/run-all-verifications.py
index 2290c2c..e1b0d85 100755
--- a/workspace/scripts/verification/run-all-verifications.py
+++ b/workspace/scripts/verification/run-all-verifications.py
@@ -15,7 +15,9 @@ def run_verification_stage(script_name: str, directory: str) -> bool:
 
     try:
         result = subprocess.run(
-            [sys.executable, str(script_path), directory], capture_output=False, text=True
+            [sys.executable, str(script_path), directory],
+            capture_output=False,
+            text=True,
         )
         return result.returncode == 0
     except Exception as e:
diff --git a/workspace/setup.py b/workspace/setup.py
index 6454076..8150c0c 100644
--- a/workspace/setup.py
+++ b/workspace/setup.py
@@ -13,7 +13,9 @@ from setuptools import find_packages, setup
 
 # Read README for long description
 readme_path = Path(__file__).parent / "README.md"
-long_description = readme_path.read_text(encoding="utf-8") if readme_path.exists() else ""
+long_description = (
+    readme_path.read_text(encoding="utf-8") if readme_path.exists() else ""
+)
 
 # Read requirements
 requirements_path = Path(__file__).parent / "requirements-workflow.txt"
diff --git a/workspace/src/ai/agents/dependency-manager/src/analyzers/base_analyzer.py b/workspace/src/ai/agents/dependency-manager/src/analyzers/base_analyzer.py
index 531b10a..08d0d93 100644
--- a/workspace/src/ai/agents/dependency-manager/src/analyzers/base_analyzer.py
+++ b/workspace/src/ai/agents/dependency-manager/src/analyzers/base_analyzer.py
@@ -85,7 +85,9 @@ class BaseAnalyzer(ABC):
         logger.warning(f"åœ¨ {project_path} ä¸­æœªæ‰¾åˆ° {self.ecosystem.value} æ¸…å–®æ–‡ä»¶")
         return None
 
-    async def analyze(self, project_path: Path, analysis_id: str) -> Optional[DependencyAnalysis]:
+    async def analyze(
+        self, project_path: Path, analysis_id: str
+    ) -> Optional[DependencyAnalysis]:
         """
         åˆ†æå°ˆæ¡ˆä¾è³´
 
diff --git a/workspace/src/ai/agents/dependency-manager/src/analyzers/npm_analyzer.py b/workspace/src/ai/agents/dependency-manager/src/analyzers/npm_analyzer.py
index 1861336..339ebdb 100644
--- a/workspace/src/ai/agents/dependency-manager/src/analyzers/npm_analyzer.py
+++ b/workspace/src/ai/agents/dependency-manager/src/analyzers/npm_analyzer.py
@@ -67,7 +67,9 @@ class NpmAnalyzer(BaseAnalyzer):
             # è§£æå¯é¸ä¾è³´
             if "optionalDependencies" in package_data:
                 for name, version in package_data["optionalDependencies"].items():
-                    dep = self._create_dependency(name, version, DependencyType.OPTIONAL)
+                    dep = self._create_dependency(
+                        name, version, DependencyType.OPTIONAL
+                    )
                     dependencies.append(dep)
 
             logger.info(f"å¾ {manifest_path} è§£æå‡º {len(dependencies)} å€‹ä¾è³´é …")
@@ -97,7 +99,10 @@ class NpmAnalyzer(BaseAnalyzer):
         version = self._clean_version(version_spec)
 
         return Dependency(
-            name=name, current_version=version, ecosystem=Ecosystem.NPM, dep_type=dep_type
+            name=name,
+            current_version=version,
+            ecosystem=Ecosystem.NPM,
+            dep_type=dep_type,
         )
 
     def _clean_version(self, version_spec: str) -> str:
@@ -216,7 +221,9 @@ class NpmAnalyzer(BaseAnalyzer):
                 name=name,
                 current_version=version,
                 ecosystem=Ecosystem.NPM,
-                dep_type=DependencyType.DIRECT if depth == 0 else DependencyType.TRANSITIVE,
+                dep_type=(
+                    DependencyType.DIRECT if depth == 0 else DependencyType.TRANSITIVE
+                ),
             )
             result.append(dep)
 
diff --git a/workspace/src/ai/agents/dependency-manager/src/combination/combination_templates.py b/workspace/src/ai/agents/dependency-manager/src/combination/combination_templates.py
index 6504197..0f84df3 100644
--- a/workspace/src/ai/agents/dependency-manager/src/combination/combination_templates.py
+++ b/workspace/src/ai/agents/dependency-manager/src/combination/combination_templates.py
@@ -94,7 +94,9 @@ class CombinationTemplateManager:
             for t in self._templates.values()
         ]
 
-    def recommend_template(self, stage: CompanyStage, priority: str) -> CombinationTemplate:
+    def recommend_template(
+        self, stage: CompanyStage, priority: str
+    ) -> CombinationTemplate:
         for t in self._templates.values():
             if stage in t.suitable_stages:
                 return t
diff --git a/workspace/src/ai/agents/dependency-manager/src/combination/core_satellite.py b/workspace/src/ai/agents/dependency-manager/src/combination/core_satellite.py
index c44d2d5..781c468 100644
--- a/workspace/src/ai/agents/dependency-manager/src/combination/core_satellite.py
+++ b/workspace/src/ai/agents/dependency-manager/src/combination/core_satellite.py
@@ -76,14 +76,23 @@ class CoreSatelliteArchitecture:
             ),
             satellite_allocations=[
                 PromptAllocation(
-                    PromptCategory.PROFESSIONAL, AllocationRole.SATELLITE, 15.0, "å°ˆæ¥­ç´šé–‹ç™¼"
+                    PromptCategory.PROFESSIONAL,
+                    AllocationRole.SATELLITE,
+                    15.0,
+                    "å°ˆæ¥­ç´šé–‹ç™¼",
                 ),
                 PromptAllocation(
-                    PromptCategory.HIGH_VALUE, AllocationRole.SATELLITE, 10.0, "é«˜åƒ¹å€¼æ‡‰ç”¨"
+                    PromptCategory.HIGH_VALUE,
+                    AllocationRole.SATELLITE,
+                    10.0,
+                    "é«˜åƒ¹å€¼æ‡‰ç”¨",
                 ),
             ],
             exploration_allocation=PromptAllocation(
-                PromptCategory.INTELLIGENT, AllocationRole.EXPLORATION, 5.0, "æ™ºèƒ½åŒ–æ¢ç´¢"
+                PromptCategory.INTELLIGENT,
+                AllocationRole.EXPLORATION,
+                5.0,
+                "æ™ºèƒ½åŒ–æ¢ç´¢",
             ),
         )
 
@@ -96,7 +105,10 @@ class CoreSatelliteArchitecture:
             ),
             satellite_allocations=[
                 PromptAllocation(
-                    PromptCategory.BUSINESS_ORIENTED, AllocationRole.SATELLITE, 20.0, "å•†æ¥­å°å‘"
+                    PromptCategory.BUSINESS_ORIENTED,
+                    AllocationRole.SATELLITE,
+                    20.0,
+                    "å•†æ¥­å°å‘",
                 ),
                 PromptAllocation(
                     PromptCategory.ENTERPRISE, AllocationRole.SATELLITE, 5.0, "ä¼æ¥­åŸºç¤"
@@ -118,7 +130,9 @@ class CoreSatelliteArchitecture:
                 PromptAllocation(
                     PromptCategory.INTELLIGENT, AllocationRole.SATELLITE, 15.0, "æ™ºèƒ½åŒ–"
                 ),
-                PromptAllocation(PromptCategory.NEXT_GEN, AllocationRole.SATELLITE, 10.0, "ä¸‹ä¸–ä»£"),
+                PromptAllocation(
+                    PromptCategory.NEXT_GEN, AllocationRole.SATELLITE, 10.0, "ä¸‹ä¸–ä»£"
+                ),
             ],
             exploration_allocation=PromptAllocation(
                 PromptCategory.HIGH_VALUE, AllocationRole.EXPLORATION, 5.0, "æ–°èˆˆç ”ç©¶"
diff --git a/workspace/src/ai/agents/dependency-manager/src/combination/quarterly_review.py b/workspace/src/ai/agents/dependency-manager/src/combination/quarterly_review.py
index 1a2d1b3..ecf1d4c 100644
--- a/workspace/src/ai/agents/dependency-manager/src/combination/quarterly_review.py
+++ b/workspace/src/ai/agents/dependency-manager/src/combination/quarterly_review.py
@@ -86,7 +86,10 @@ class QuarterlyReviewEngine:
         end_date = datetime(year, end_month, 28)
 
         review = QuarterlyReview(
-            quarter=quarter, start_date=start_date, end_date=end_date, status=ReviewStatus.SCHEDULED
+            quarter=quarter,
+            start_date=start_date,
+            end_date=end_date,
+            status=ReviewStatus.SCHEDULED,
         )
         self._reviews[quarter] = review
         return review
@@ -147,7 +150,11 @@ class QuarterlyReviewEngine:
 
     def list_reviews(self) -> List[Dict]:
         return [
-            {"quarter": r.quarter, "status": r.status.value, "items_count": len(r.items)}
+            {
+                "quarter": r.quarter,
+                "status": r.status.value,
+                "items_count": len(r.items),
+            }
             for r in self._reviews.values()
         ]
 
diff --git a/workspace/src/ai/agents/dependency-manager/src/crossplatform/__init__.py b/workspace/src/ai/agents/dependency-manager/src/crossplatform/__init__.py
index 2066e5b..bd1da89 100644
--- a/workspace/src/ai/agents/dependency-manager/src/crossplatform/__init__.py
+++ b/workspace/src/ai/agents/dependency-manager/src/crossplatform/__init__.py
@@ -5,12 +5,27 @@ Cross-platform Integration Module
 Phase 9: Web3ã€IoTã€AR/VR æ•´åˆä»¥åŠé¢¨éšªç®¡æ§ç³»çµ±
 """
 
-from .arvr_integration import ARVRIntegration, ImmersiveExperience, MetaversePlatform, MixedReality
+from .arvr_integration import (
+    ARVRIntegration,
+    ImmersiveExperience,
+    MetaversePlatform,
+    MixedReality,
+)
 from .emergency_response import EmergencyResponse, PlanType, TriggerCondition
-from .iot_integration import DeviceInterconnection, EdgeComputing, Industry40, IoTIntegration
+from .iot_integration import (
+    DeviceInterconnection,
+    EdgeComputing,
+    Industry40,
+    IoTIntegration,
+)
 from .risk_assessment import MitigationStrategy, RiskAssessment, RiskCategory
 from .tech_stack_matrix import StackRecommendation, TechStackMatrix
-from .web3_integration import DAppAssessment, NFTStrategy, SmartContractDev, Web3Integration
+from .web3_integration import (
+    DAppAssessment,
+    NFTStrategy,
+    SmartContractDev,
+    Web3Integration,
+)
 
 __all__ = [
     "Web3Integration",
diff --git a/workspace/src/ai/agents/dependency-manager/src/crossplatform/arvr_integration.py b/workspace/src/ai/agents/dependency-manager/src/crossplatform/arvr_integration.py
index 0ceee78..db6197e 100644
--- a/workspace/src/ai/agents/dependency-manager/src/crossplatform/arvr_integration.py
+++ b/workspace/src/ai/agents/dependency-manager/src/crossplatform/arvr_integration.py
@@ -176,7 +176,9 @@ class ARVRIntegration:
         self.mixed_reality_strategies: List[MixedReality] = []
         self.metaverse_platforms: List[MetaversePlatform] = []
 
-    def evaluate_immersive_experience(self, experience: ImmersiveExperience) -> ImmersiveExperience:
+    def evaluate_immersive_experience(
+        self, experience: ImmersiveExperience
+    ) -> ImmersiveExperience:
         """è©•ä¼°æ²‰æµ¸å¼é«”é©—"""
         specs = self.HARDWARE_SPECS.get(experience.hardware_requirement, {})
         score = 0.0
@@ -201,14 +203,20 @@ class ARVRIntegration:
         score += xr_bonus.get(experience.xr_type, 10)
 
         experience.immersion_score = min(100, score)
-        experience.hardware_recommendations = self._get_hardware_recommendations(experience)
-        experience.development_frameworks = self.DEVELOPMENT_FRAMEWORKS.get(experience.xr_type, [])
+        experience.hardware_recommendations = self._get_hardware_recommendations(
+            experience
+        )
+        experience.development_frameworks = self.DEVELOPMENT_FRAMEWORKS.get(
+            experience.xr_type, []
+        )
         experience.user_experience_tips.extend(self._generate_ux_tips(experience))
 
         self.immersive_experiences.append(experience)
         return experience
 
-    def _get_hardware_recommendations(self, experience: ImmersiveExperience) -> List[str]:
+    def _get_hardware_recommendations(
+        self, experience: ImmersiveExperience
+    ) -> List[str]:
         """ç²å–ç¡¬é«”å»ºè­°"""
         recommendations = []
 
@@ -224,10 +232,17 @@ class ARVRIntegration:
             recommendations.extend(["Meta Quest 3", "Pico 4", "HTC Vive XR Elite"])
         elif experience.hardware_requirement == HardwareRequirement.PC_TETHERED:
             recommendations.extend(
-                ["Valve Index", "HP Reverb G2", "HTC Vive Pro 2", "æœ€ä½éœ€æ±‚ï¼šRTX 3060, 16GB RAM"]
+                [
+                    "Valve Index",
+                    "HP Reverb G2",
+                    "HTC Vive Pro 2",
+                    "æœ€ä½éœ€æ±‚ï¼šRTX 3060, 16GB RAM",
+                ]
             )
         elif experience.hardware_requirement == HardwareRequirement.ENTERPRISE:
-            recommendations.extend(["Microsoft HoloLens 2", "Magic Leap 2", "Varjo XR-3"])
+            recommendations.extend(
+                ["Microsoft HoloLens 2", "Magic Leap 2", "Varjo XR-3"]
+            )
 
         return recommendations
 
@@ -244,7 +259,9 @@ class ARVRIntegration:
                 ]
             )
         elif experience.xr_type == XRType.AR:
-            tips.extend(["ç¢ºä¿è‰¯å¥½çš„å…‰ç·šè¿½è¹¤", "æä¾›æ¸…æ™°çš„ AR ç‰©ä»¶æ”¾ç½®å¼•å°", "è€ƒæ…®æˆ¶å¤–ä½¿ç”¨å ´æ™¯"])
+            tips.extend(
+                ["ç¢ºä¿è‰¯å¥½çš„å…‰ç·šè¿½è¹¤", "æä¾›æ¸…æ™°çš„ AR ç‰©ä»¶æ”¾ç½®å¼•å°", "è€ƒæ…®æˆ¶å¤–ä½¿ç”¨å ´æ™¯"]
+            )
         elif experience.xr_type in [XRType.MR, XRType.XR]:
             tips.extend(["å¹³è¡¡è™›æ“¬å’Œç¾å¯¦å…ƒç´ ", "è€ƒæ…®ç’°å¢ƒé®æ“‹æ•ˆæœ", "è¨­è¨ˆé©æ‡‰æ€§ UI"])
 
@@ -363,7 +380,9 @@ class ARVRIntegration:
         platform.key_components = self._identify_key_components(platform)
 
         # è®Šç¾ç­–ç•¥
-        platform.monetization_strategies = self._generate_monetization_strategies(platform)
+        platform.monetization_strategies = self._generate_monetization_strategies(
+            platform
+        )
 
         self.metaverse_platforms.append(platform)
         return platform
@@ -391,7 +410,9 @@ class ARVRIntegration:
 
         return components
 
-    def _generate_monetization_strategies(self, platform: MetaversePlatform) -> List[str]:
+    def _generate_monetization_strategies(
+        self, platform: MetaversePlatform
+    ) -> List[str]:
         """ç”Ÿæˆè®Šç¾ç­–ç•¥"""
         strategies = []
 
@@ -414,7 +435,9 @@ class ARVRIntegration:
         return {
             "generated_at": datetime.now().isoformat(),
             "immersive_experiences": [e.to_dict() for e in self.immersive_experiences],
-            "mixed_reality_strategies": [m.to_dict() for m in self.mixed_reality_strategies],
+            "mixed_reality_strategies": [
+                m.to_dict() for m in self.mixed_reality_strategies
+            ],
             "metaverse_platforms": [p.to_dict() for p in self.metaverse_platforms],
             "summary": {
                 "total_experiences": len(self.immersive_experiences),
diff --git a/workspace/src/ai/agents/dependency-manager/src/crossplatform/emergency_response.py b/workspace/src/ai/agents/dependency-manager/src/crossplatform/emergency_response.py
index 6ff3c98..81f37b5 100644
--- a/workspace/src/ai/agents/dependency-manager/src/crossplatform/emergency_response.py
+++ b/workspace/src/ai/agents/dependency-manager/src/crossplatform/emergency_response.py
@@ -145,7 +145,11 @@ class EmergencyResponse:
                 "marketing": 0.15,
                 "reserve": 0.15,
             },
-            success_metrics={"revenue_growth": 0.15, "user_retention": 0.85, "nps_score": 50},
+            success_metrics={
+                "revenue_growth": 0.15,
+                "user_retention": 0.85,
+                "nps_score": 50,
+            },
             rollback_plan="ç„¡éœ€å›æ»¾ï¼ŒæŒçºŒç›£æ§é—œéµæŒ‡æ¨™",
         )
 
@@ -494,5 +498,7 @@ class EmergencyResponse:
             "active_plan": self.active_plan.value,
             "plans": {k.value: v.to_dict() for k, v in self.plans.items()},
             "triggers": {k: v.to_dict() for k, v in self.triggers.items()},
-            "triggered_count": len([t for t in self.triggers.values() if t.is_triggered]),
+            "triggered_count": len(
+                [t for t in self.triggers.values() if t.is_triggered]
+            ),
         }
diff --git a/workspace/src/ai/agents/dependency-manager/src/crossplatform/iot_integration.py b/workspace/src/ai/agents/dependency-manager/src/crossplatform/iot_integration.py
index 6f410f7..5e88dc0 100644
--- a/workspace/src/ai/agents/dependency-manager/src/crossplatform/iot_integration.py
+++ b/workspace/src/ai/agents/dependency-manager/src/crossplatform/iot_integration.py
@@ -68,7 +68,9 @@ class EdgeComputing:
             "local_processing_percentage": self.local_processing_percentage,
             "data_privacy_requirement": self.data_privacy_requirement,
             "suitability_score": self.suitability_score,
-            "recommended_type": self.recommended_type.value if self.recommended_type else None,
+            "recommended_type": (
+                self.recommended_type.value if self.recommended_type else None
+            ),
             "hardware_recommendations": self.hardware_recommendations,
             "deployment_considerations": self.deployment_considerations,
         }
@@ -256,12 +258,20 @@ class IoTIntegration:
 
         if edge.computing_type == EdgeComputingType.MULTI_ACCESS_EDGE:
             recommendations.extend(
-                ["NVIDIA Jetson AGX Xavier æˆ–åŒç´š", "Intel Xeon è™•ç†å™¨é‚Šç·£æœå‹™å™¨", "é«˜é€Ÿ NVMe å­˜å„²"]
+                [
+                    "NVIDIA Jetson AGX Xavier æˆ–åŒç´š",
+                    "Intel Xeon è™•ç†å™¨é‚Šç·£æœå‹™å™¨",
+                    "é«˜é€Ÿ NVMe å­˜å„²",
+                ]
             )
         elif edge.computing_type == EdgeComputingType.FOG_COMPUTING:
-            recommendations.extend(["Raspberry Pi 4 é›†ç¾¤", "Intel NUC é‚Šç·£è¨­å‚™", "å·¥æ¥­ç´šé‚Šç·£ç¶²é—œ"])
+            recommendations.extend(
+                ["Raspberry Pi 4 é›†ç¾¤", "Intel NUC é‚Šç·£è¨­å‚™", "å·¥æ¥­ç´šé‚Šç·£ç¶²é—œ"]
+            )
         else:
-            recommendations.extend(["ARM æ¶æ§‹é‚Šç·£è¨­å‚™", "å·¥æ¥­ IoT ç¶²é—œ", "ä½åŠŸè€—é‚Šç·£è™•ç†å™¨"])
+            recommendations.extend(
+                ["ARM æ¶æ§‹é‚Šç·£è¨­å‚™", "å·¥æ¥­ IoT ç¶²é—œ", "ä½åŠŸè€—é‚Šç·£è™•ç†å™¨"]
+            )
 
         return recommendations
 
@@ -314,7 +324,9 @@ class IoTIntegration:
         if device.security_level == "standard":
             measures.extend(["è¨ªå•æ§åˆ¶åˆ—è¡¨ (ACL)", "æ¶ˆæ¯å®Œæ•´æ€§é©—è­‰"])
         elif device.security_level == "advanced":
-            measures.extend(["è¨­å‚™è­‰æ›¸ç®¡ç† (PKI)", "ç«¯åˆ°ç«¯åŠ å¯†", "å…¥ä¾µæª¢æ¸¬ç³»çµ±", "å®‰å…¨å•Ÿå‹•é©—è­‰"])
+            measures.extend(
+                ["è¨­å‚™è­‰æ›¸ç®¡ç† (PKI)", "ç«¯åˆ°ç«¯åŠ å¯†", "å…¥ä¾µæª¢æ¸¬ç³»çµ±", "å®‰å…¨å•Ÿå‹•é©—è­‰"]
+            )
 
         return measures
 
@@ -415,7 +427,9 @@ class IoTIntegration:
         return {
             "generated_at": datetime.now().isoformat(),
             "edge_computing_assessments": [e.to_dict() for e in self.edge_assessments],
-            "device_interconnection_strategies": [d.to_dict() for d in self.device_strategies],
+            "device_interconnection_strategies": [
+                d.to_dict() for d in self.device_strategies
+            ],
             "industry40_plans": [p.to_dict() for p in self.industry40_plans],
             "summary": {
                 "total_edge_assessments": len(self.edge_assessments),
@@ -428,7 +442,8 @@ class IoTIntegration:
                     else 0
                 ),
                 "avg_estimated_roi": (
-                    sum(p.estimated_roi for p in self.industry40_plans) / len(self.industry40_plans)
+                    sum(p.estimated_roi for p in self.industry40_plans)
+                    / len(self.industry40_plans)
                     if self.industry40_plans
                     else 0
                 ),
diff --git a/workspace/src/ai/agents/dependency-manager/src/crossplatform/risk_assessment.py b/workspace/src/ai/agents/dependency-manager/src/crossplatform/risk_assessment.py
index 8d87a3c..62452f5 100644
--- a/workspace/src/ai/agents/dependency-manager/src/crossplatform/risk_assessment.py
+++ b/workspace/src/ai/agents/dependency-manager/src/crossplatform/risk_assessment.py
@@ -330,7 +330,11 @@ class RiskAssessment:
         experience_risk = {"low": (8, 8), "medium": (5, 6), "high": (3, 4)}
         prob, imp = experience_risk.get(team_experience, (5, 5))
         risk = self.add_risk(
-            RiskType.TALENT_SCARCITY, "åœ˜éšŠç¶“é©—é¢¨éšª", f"åœ˜éšŠç¶“é©—ç­‰ç´š: {team_experience}", prob, imp
+            RiskType.TALENT_SCARCITY,
+            "åœ˜éšŠç¶“é©—é¢¨éšª",
+            f"åœ˜éšŠç¶“é©—ç­‰ç´š: {team_experience}",
+            prob,
+            imp,
         )
         assessed_risks.append(risk)
 
@@ -382,7 +386,9 @@ class RiskAssessment:
 
         # åŠ æ¬Šå¹³å‡ï¼Œé«˜é¢¨éšªæ¬Šé‡æ›´é«˜
         weights = {RiskCategory.HIGH: 3, RiskCategory.MEDIUM: 2, RiskCategory.LOW: 1}
-        total_weighted_score = sum(r.risk_score * weights[r.category] for r in self.risks)
+        total_weighted_score = sum(
+            r.risk_score * weights[r.category] for r in self.risks
+        )
         total_weights = sum(weights[r.category] for r in self.risks)
 
         return total_weighted_score / total_weights if total_weights > 0 else 0.0
@@ -461,7 +467,9 @@ class RiskAssessment:
             "summary": {
                 "total": len(self.risks),
                 "high": len([r for r in self.risks if r.category == RiskCategory.HIGH]),
-                "medium": len([r for r in self.risks if r.category == RiskCategory.MEDIUM]),
+                "medium": len(
+                    [r for r in self.risks if r.category == RiskCategory.MEDIUM]
+                ),
                 "low": len([r for r in self.risks if r.category == RiskCategory.LOW]),
             },
         }
diff --git a/workspace/src/ai/agents/dependency-manager/src/crossplatform/tech_stack_matrix.py b/workspace/src/ai/agents/dependency-manager/src/crossplatform/tech_stack_matrix.py
index c241c61..a5f5d1a 100644
--- a/workspace/src/ai/agents/dependency-manager/src/crossplatform/tech_stack_matrix.py
+++ b/workspace/src/ai/agents/dependency-manager/src/crossplatform/tech_stack_matrix.py
@@ -124,13 +124,33 @@ class TechStackMatrix:
         FrontendTech.NEXTJS: ["Prisma", "NextAuth", "Vercel", "tRPC"],
         FrontendTech.FLUTTER: ["Provider", "Riverpod", "Firebase", "Hive"],
         BackendArch.MICROSERVICES: ["Kubernetes", "Docker", "Istio", "gRPC"],
-        BackendArch.SERVERLESS: ["AWS Lambda", "Azure Functions", "Vercel", "Cloudflare Workers"],
+        BackendArch.SERVERLESS: [
+            "AWS Lambda",
+            "Azure Functions",
+            "Vercel",
+            "Cloudflare Workers",
+        ],
         BackendArch.MONOLITH: ["Django", "Rails", "Spring Boot", "Express"],
-        DataProcessing.REALTIME: ["Apache Kafka", "Redis Streams", "WebSocket", "Socket.io"],
-        DataProcessing.STREAMING: ["Apache Flink", "Spark Streaming", "Kinesis", "Pulsar"],
+        DataProcessing.REALTIME: [
+            "Apache Kafka",
+            "Redis Streams",
+            "WebSocket",
+            "Socket.io",
+        ],
+        DataProcessing.STREAMING: [
+            "Apache Flink",
+            "Spark Streaming",
+            "Kinesis",
+            "Pulsar",
+        ],
         DataProcessing.BATCH: ["Apache Spark", "Hadoop", "Airflow", "dbt"],
         DeploymentStrategy.CLOUD_NATIVE: ["Kubernetes", "Helm", "ArgoCD", "Prometheus"],
-        DeploymentStrategy.EDGE: ["Cloudflare Workers", "Lambda@Edge", "Fly.io", "Deno Deploy"],
+        DeploymentStrategy.EDGE: [
+            "Cloudflare Workers",
+            "Lambda@Edge",
+            "Fly.io",
+            "Deno Deploy",
+        ],
     }
 
     # è¤‡é›œåº¦è©•ç´š
@@ -178,14 +198,24 @@ class TechStackMatrix:
         )
 
         # è¨ˆç®—ç›¸å®¹æ€§åˆ†æ•¸
-        frontend_backend = self.COMPATIBILITY_MATRIX.get((frontend, backend), 75)  # é è¨­åˆ†æ•¸
-        data_deploy = self.DATA_DEPLOY_COMPATIBILITY.get((data_processing, deployment), 75)
+        frontend_backend = self.COMPATIBILITY_MATRIX.get(
+            (frontend, backend), 75
+        )  # é è¨­åˆ†æ•¸
+        data_deploy = self.DATA_DEPLOY_COMPATIBILITY.get(
+            (data_processing, deployment), 75
+        )
         recommendation.compatibility_score = (frontend_backend + data_deploy) / 2
 
         # è¨­å®šè©•ç´š
-        recommendation.complexity_rating = self.COMPLEXITY_RATINGS.get(backend, "medium")
-        recommendation.scalability_rating = self.SCALABILITY_RATINGS.get(backend, "medium")
-        recommendation.cost_estimate = self.COST_ESTIMATES.get((backend, deployment), "medium")
+        recommendation.complexity_rating = self.COMPLEXITY_RATINGS.get(
+            backend, "medium"
+        )
+        recommendation.scalability_rating = self.SCALABILITY_RATINGS.get(
+            backend, "medium"
+        )
+        recommendation.cost_estimate = self.COST_ESTIMATES.get(
+            (backend, deployment), "medium"
+        )
 
         # æ¨è–¦å·¥å…·
         recommendation.recommended_tools = {
@@ -206,10 +236,16 @@ class TechStackMatrix:
         considerations = []
 
         # å‰å¾Œç«¯è€ƒé‡
-        if rec.frontend == FrontendTech.NEXTJS and rec.backend == BackendArch.MICROSERVICES:
+        if (
+            rec.frontend == FrontendTech.NEXTJS
+            and rec.backend == BackendArch.MICROSERVICES
+        ):
             considerations.append("Next.js çš„ API Routes å¯ç°¡åŒ–éƒ¨åˆ†å¾Œç«¯é‚è¼¯")
 
-        if rec.frontend == FrontendTech.FLUTTER and rec.backend == BackendArch.SERVERLESS:
+        if (
+            rec.frontend == FrontendTech.FLUTTER
+            and rec.backend == BackendArch.SERVERLESS
+        ):
             considerations.append("è€ƒæ…®ä½¿ç”¨ Firebase ä½œç‚ºå¾Œç«¯æœå‹™")
 
         # æ•¸æ“šè™•ç†è€ƒé‡
@@ -226,7 +262,9 @@ class TechStackMatrix:
 
         # çµ„åˆç‰¹å®šè€ƒé‡
         if rec.backend == BackendArch.MICROSERVICES:
-            considerations.extend(["éœ€è¦å®Œå–„çš„æœå‹™ç™¼ç¾æ©Ÿåˆ¶", "è€ƒæ…®åˆ†ä½ˆå¼è¿½è¹¤å’Œæ—¥èªŒèšåˆ"])
+            considerations.extend(
+                ["éœ€è¦å®Œå–„çš„æœå‹™ç™¼ç¾æ©Ÿåˆ¶", "è€ƒæ…®åˆ†ä½ˆå¼è¿½è¹¤å’Œæ—¥èªŒèšåˆ"]
+            )
 
         if rec.compatibility_score < 80:
             considerations.append("âš ï¸ æ­¤çµ„åˆç›¸å®¹æ€§è¼ƒä½ï¼Œå»ºè­°é‡æ–°è©•ä¼°")
@@ -234,7 +272,11 @@ class TechStackMatrix:
         return considerations
 
     def recommend_optimal_stack(
-        self, project_type: str, team_size: int, scalability_need: str, budget_level: str
+        self,
+        project_type: str,
+        team_size: int,
+        scalability_need: str,
+        budget_level: str,
     ) -> StackRecommendation:
         """æ¨è–¦æœ€ä½³æŠ€è¡“æ£§"""
         # åŸºæ–¼é …ç›®é¡å‹é¸æ“‡å‰ç«¯
@@ -252,7 +294,9 @@ class TechStackMatrix:
             backend = BackendArch.MONOLITH
         elif team_size < 15:
             backend = (
-                BackendArch.MODULAR_MONOLITH if budget_level == "low" else BackendArch.SERVERLESS
+                BackendArch.MODULAR_MONOLITH
+                if budget_level == "low"
+                else BackendArch.SERVERLESS
             )
         else:
             backend = BackendArch.MICROSERVICES
@@ -284,7 +328,9 @@ class TechStackMatrix:
 
         comparison = {
             "stacks": [s.to_dict() for s in stacks],
-            "best_compatibility": max(stacks, key=lambda s: s.compatibility_score).to_dict(),
+            "best_compatibility": max(
+                stacks, key=lambda s: s.compatibility_score
+            ).to_dict(),
             "lowest_complexity": min(
                 stacks, key=lambda s: self._complexity_to_score(s.complexity_rating)
             ).to_dict(),
@@ -306,7 +352,9 @@ class TechStackMatrix:
         scores = {"low": 1, "medium": 2, "high": 3, "very_high": 4}
         return scores.get(rating, 2)
 
-    def _create_comparison_matrix(self, stacks: List[StackRecommendation]) -> List[Dict[str, Any]]:
+    def _create_comparison_matrix(
+        self, stacks: List[StackRecommendation]
+    ) -> List[Dict[str, Any]]:
         """å‰µå»ºæ¯”è¼ƒçŸ©é™£"""
         matrix = []
         for stack in stacks:
diff --git a/workspace/src/ai/agents/dependency-manager/src/crossplatform/web3_integration.py b/workspace/src/ai/agents/dependency-manager/src/crossplatform/web3_integration.py
index 53b2a51..4d75769 100644
--- a/workspace/src/ai/agents/dependency-manager/src/crossplatform/web3_integration.py
+++ b/workspace/src/ai/agents/dependency-manager/src/crossplatform/web3_integration.py
@@ -76,7 +76,9 @@ class DAppAssessment:
             "estimated_tps_requirement": self.estimated_tps_requirement,
             "feasibility_score": self.feasibility_score,
             "recommended_blockchain": (
-                self.recommended_blockchain.value if self.recommended_blockchain else None
+                self.recommended_blockchain.value
+                if self.recommended_blockchain
+                else None
             ),
             "risks": self.risks,
             "recommendations": self.recommendations,
@@ -345,7 +347,9 @@ class Web3Integration:
         risks = []
 
         if contract.contract_type == "defi":
-            risks.extend(["é‡å…¥æ”»æ“Šé¢¨éšª", "é–ƒé›»è²¸æ”»æ“Šé¢¨éšª", "é è¨€æ©Ÿæ“ç¸±é¢¨éšª", "å‰ç«¯é‹è¡Œé¢¨éšª"])
+            risks.extend(
+                ["é‡å…¥æ”»æ“Šé¢¨éšª", "é–ƒé›»è²¸æ”»æ“Šé¢¨éšª", "é è¨€æ©Ÿæ“ç¸±é¢¨éšª", "å‰ç«¯é‹è¡Œé¢¨éšª"]
+            )
         elif contract.contract_type == "token":
             risks.extend(["ç„¡é™é‘„é€ æ¼æ´", "è½‰å¸³é‚è¼¯éŒ¯èª¤", "æˆæ¬Šç®¡ç†ä¸ç•¶"])
         elif contract.contract_type == "nft":
@@ -391,7 +395,8 @@ class Web3Integration:
                 "total_nft_strategies": len(self.nft_strategies),
                 "total_contracts": len(self.contracts),
                 "avg_feasibility_score": (
-                    sum(a.feasibility_score for a in self.assessments) / len(self.assessments)
+                    sum(a.feasibility_score for a in self.assessments)
+                    / len(self.assessments)
                     if self.assessments
                     else 0
                 ),
diff --git a/workspace/src/ai/agents/dependency-manager/src/engine.py b/workspace/src/ai/agents/dependency-manager/src/engine.py
index 679833a..1677ce1 100644
--- a/workspace/src/ai/agents/dependency-manager/src/engine.py
+++ b/workspace/src/ai/agents/dependency-manager/src/engine.py
@@ -99,7 +99,9 @@ class DependencyManager:
                     enabled=yaml_config.get("enabled", True),
                     parallel=yaml_config.get("parallel", True),
                     max_workers=yaml_config.get("max_workers", 8),
-                    ecosystems=[Ecosystem(e) for e in yaml_config.get("ecosystems", ["npm"])],
+                    ecosystems=[
+                        Ecosystem(e) for e in yaml_config.get("ecosystems", ["npm"])
+                    ],
                 )
             except Exception as e:
                 logger.warning(f"è¼‰å…¥é…ç½®å¤±æ•—: {e}ï¼Œä½¿ç”¨é»˜èªé…ç½®")
@@ -151,7 +153,9 @@ class DependencyManager:
 
         return results
 
-    async def scan_vulnerabilities(self, analysis: DependencyAnalysis) -> VulnerabilityScanResult:
+    async def scan_vulnerabilities(
+        self, analysis: DependencyAnalysis
+    ) -> VulnerabilityScanResult:
         """
         æƒææ¼æ´
 
@@ -218,7 +222,12 @@ class DependencyManager:
         """
         logger.info(f"é–‹å§‹å®Œæ•´æƒæ: {project_path}")
 
-        result = {"project": project_path, "analyses": {}, "vulnerabilities": {}, "licenses": {}}
+        result = {
+            "project": project_path,
+            "analyses": {},
+            "vulnerabilities": {},
+            "licenses": {},
+        }
 
         # åˆ†æå„ç”Ÿæ…‹ç³»çµ±
         analyses = await self.analyze_project(project_path)
@@ -262,9 +271,15 @@ class DependencyManager:
             summary["ecosystems"].append(eco_name)
 
             if "summary" in analysis:
-                summary["total_dependencies"] += analysis["summary"].get("total_dependencies", 0)
-                summary["outdated_dependencies"] += analysis["summary"].get("outdated", 0)
-                summary["vulnerable_dependencies"] += analysis["summary"].get("vulnerable", 0)
+                summary["total_dependencies"] += analysis["summary"].get(
+                    "total_dependencies", 0
+                )
+                summary["outdated_dependencies"] += analysis["summary"].get(
+                    "outdated", 0
+                )
+                summary["vulnerable_dependencies"] += analysis["summary"].get(
+                    "vulnerable", 0
+                )
 
         for eco_name, licenses in scan_result.get("licenses", {}).items():
             if "summary" in licenses:
@@ -281,7 +296,9 @@ async def main():
 
     parser = argparse.ArgumentParser(description="ä¾è³´ç®¡ç†ä»£ç† - SynergyMesh")
     parser.add_argument("--project", "-p", required=True, help="å°ˆæ¡ˆè·¯å¾‘")
-    parser.add_argument("--scan-type", choices=["full", "quick"], default="full", help="æƒæé¡å‹")
+    parser.add_argument(
+        "--scan-type", choices=["full", "quick"], default="full", help="æƒæé¡å‹"
+    )
     parser.add_argument("--output", "-o", help="è¼¸å‡ºæ–‡ä»¶è·¯å¾‘")
     parser.add_argument("--config", "-c", help="é…ç½®æ–‡ä»¶è·¯å¾‘")
 
diff --git a/workspace/src/ai/agents/dependency-manager/src/enterprise/analytics.py b/workspace/src/ai/agents/dependency-manager/src/enterprise/analytics.py
index 7c4a345..af682cf 100644
--- a/workspace/src/ai/agents/dependency-manager/src/enterprise/analytics.py
+++ b/workspace/src/ai/agents/dependency-manager/src/enterprise/analytics.py
@@ -298,7 +298,8 @@ class CommercialAnalytics:
             costs.append(
                 CostItem(
                     category=CostCategory.SECURITY,
-                    amount=has_vulnerabilities * self.DEFAULT_COSTS[CostCategory.SECURITY],
+                    amount=has_vulnerabilities
+                    * self.DEFAULT_COSTS[CostCategory.SECURITY],
                     period="one-time",
                     description=f"{dependency_name} å®‰å…¨ä¿®å¾©æˆæœ¬ ({has_vulnerabilities} å€‹æ¼æ´)",
                     confidence=0.8,
@@ -354,7 +355,9 @@ class CommercialAnalytics:
                 type_key = item.debt_type.value
                 by_type[type_key] = by_type.get(type_key, 0) + item.total_debt
 
-                by_severity[item.severity] = by_severity.get(item.severity, 0) + item.total_debt
+                by_severity[item.severity] = (
+                    by_severity.get(item.severity, 0) + item.total_debt
+                )
 
         return {
             "total_principal": total_principal,
@@ -527,7 +530,9 @@ class CommercialAnalytics:
                     debt_items.append(debt)
 
                 if dep.get("vulnerabilities", 0) > 0:
-                    severity = "critical" if dep.get("vulnerabilities", 0) >= 3 else "high"
+                    severity = (
+                        "critical" if dep.get("vulnerabilities", 0) >= 3 else "high"
+                    )
                     debt = TechDebtItem(
                         debt_type=TechDebtType.SECURITY_VULNERABILITY,
                         dependency_name=dep.get("name", "unknown"),
@@ -555,7 +560,8 @@ class CommercialAnalytics:
 
         # åˆ†æè‡ªå‹•åŒ–åƒ¹å€¼
         automation_values = self.analyze_automation_value(
-            dependencies_count=len(dependencies), monthly_manual_hours=automation_hours_saved
+            dependencies_count=len(dependencies),
+            monthly_manual_hours=automation_hours_saved,
         )
         total_values.extend(automation_values)
 
diff --git a/workspace/src/ai/agents/dependency-manager/src/enterprise/integration.py b/workspace/src/ai/agents/dependency-manager/src/enterprise/integration.py
index 9f0d930..fe97742 100644
--- a/workspace/src/ai/agents/dependency-manager/src/enterprise/integration.py
+++ b/workspace/src/ai/agents/dependency-manager/src/enterprise/integration.py
@@ -146,7 +146,9 @@ class EnterpriseIntegration:
         return self._integrations.get(name)
 
     def list_integrations(
-        self, integration_type: Optional[IntegrationType] = None, enabled_only: bool = False
+        self,
+        integration_type: Optional[IntegrationType] = None,
+        enabled_only: bool = False,
     ) -> List[IntegrationConfig]:
         """
         åˆ—å‡ºæ•´åˆ
@@ -217,7 +219,10 @@ class EnterpriseIntegration:
 
         # å»ºç«‹äº‹ä»¶
         event = WebhookEvent(
-            event_type=event_type, payload=payload, timestamp=datetime.now(), signature=signature
+            event_type=event_type,
+            payload=payload,
+            timestamp=datetime.now(),
+            signature=signature,
         )
 
         self._event_history.append(event)
@@ -251,10 +256,14 @@ class EnterpriseIntegration:
             duration_ms=duration,
         )
 
-    def _verify_signature(self, payload: Dict[str, Any], signature: str, secret: str) -> bool:
+    def _verify_signature(
+        self, payload: Dict[str, Any], signature: str, secret: str
+    ) -> bool:
         """é©—è­‰ Webhook ç°½å"""
         payload_str = json.dumps(payload, sort_keys=True)
-        expected = hmac.new(secret.encode(), payload_str.encode(), hashlib.sha256).hexdigest()
+        expected = hmac.new(
+            secret.encode(), payload_str.encode(), hashlib.sha256
+        ).hexdigest()
         return hmac.compare_digest(signature, expected)
 
     # ==================== è¨Šæ¯é€šçŸ¥ ====================
@@ -358,7 +367,9 @@ class EnterpriseIntegration:
 
         # æ¸…ç†èˆŠè¨˜éŒ„
         self._rate_limiters[integration_name] = [
-            t for t in self._rate_limiters[integration_name] if t.timestamp() > window_start
+            t
+            for t in self._rate_limiters[integration_name]
+            if t.timestamp() > window_start
         ]
 
         # æª¢æŸ¥æ˜¯å¦è¶…éé™åˆ¶
@@ -461,7 +472,11 @@ class EnterpriseIntegration:
                 error=f"æ•´åˆ '{integration_name}' ä¸å­˜åœ¨",
             )
 
-        issue_types = [IntegrationType.GITHUB, IntegrationType.GITLAB, IntegrationType.JIRA]
+        issue_types = [
+            IntegrationType.GITHUB,
+            IntegrationType.GITLAB,
+            IntegrationType.JIRA,
+        ]
 
         if config.type not in issue_types:
             return IntegrationResult(
@@ -523,7 +538,9 @@ class EnterpriseIntegration:
         report = {
             "generated_at": datetime.now().isoformat(),
             "total_integrations": len(self._integrations),
-            "enabled_integrations": len([i for i in self._integrations.values() if i.enabled]),
+            "enabled_integrations": len(
+                [i for i in self._integrations.values() if i.enabled]
+            ),
             "integrations_by_type": {},
             "webhook_handlers": {},
             "recent_events": [],
diff --git a/workspace/src/ai/agents/dependency-manager/src/enterprise/recommendation.py b/workspace/src/ai/agents/dependency-manager/src/enterprise/recommendation.py
index a0f5c37..c7b7118 100644
--- a/workspace/src/ai/agents/dependency-manager/src/enterprise/recommendation.py
+++ b/workspace/src/ai/agents/dependency-manager/src/enterprise/recommendation.py
@@ -147,13 +147,19 @@ class IntelligentRecommendation:
     KNOWN_PACKAGES = {
         # npm
         "lodash": {"alternatives": ["ramda", "underscore"], "category": "utility"},
-        "moment": {"alternatives": ["dayjs", "date-fns", "luxon"], "category": "datetime"},
+        "moment": {
+            "alternatives": ["dayjs", "date-fns", "luxon"],
+            "category": "datetime",
+        },
         "request": {"alternatives": ["axios", "got", "node-fetch"], "category": "http"},
         "express": {"alternatives": ["fastify", "koa", "hapi"], "category": "web"},
         "jquery": {"alternatives": ["vanilla-js", "cash-dom"], "category": "dom"},
         # python
         "requests": {"alternatives": ["httpx", "aiohttp"], "category": "http"},
-        "django": {"alternatives": ["flask", "fastapi", "starlette"], "category": "web"},
+        "django": {
+            "alternatives": ["flask", "fastapi", "starlette"],
+            "category": "web",
+        },
         "pandas": {"alternatives": ["polars", "vaex"], "category": "data"},
         "numpy": {"alternatives": ["jax", "cupy"], "category": "numeric"},
     }
@@ -174,7 +180,10 @@ class IntelligentRecommendation:
     # ==================== å¥åº·åº¦è©•ä¼° ====================
 
     def calculate_health_score(
-        self, dependency_name: str, version: str, metadata: Optional[Dict[str, Any]] = None
+        self,
+        dependency_name: str,
+        version: str,
+        metadata: Optional[Dict[str, Any]] = None,
     ) -> HealthScore:
         """
         è¨ˆç®—ä¾è³´é …å¥åº·åº¦è©•åˆ†
@@ -316,7 +325,9 @@ class IntelligentRecommendation:
                 {"stars": 5000, "weekly_downloads": 500000, "has_documentation": True},
             )
 
-            migration_effort = self._estimate_migration_effort(dependency_name, alt_name)
+            migration_effort = self._estimate_migration_effort(
+                dependency_name, alt_name
+            )
 
             compatibility = self._estimate_compatibility(dependency_name, alt_name)
 
@@ -478,7 +489,11 @@ class IntelligentRecommendation:
                         risk_type="deprecation",
                         probability=0.9,
                         impact_level=RiskLevel.HIGH,
-                        mitigation_actions=[f"è€ƒæ…®æ›¿æ› {name}", "æª¢è¦–æ›¿ä»£æ–¹æ¡ˆ", "è¦åŠƒé·ç§»æ™‚ç¨‹"],
+                        mitigation_actions=[
+                            f"è€ƒæ…®æ›¿æ› {name}",
+                            "æª¢è¦–æ›¿ä»£æ–¹æ¡ˆ",
+                            "è¦åŠƒé·ç§»æ™‚ç¨‹",
+                        ],
                     )
                 )
 
@@ -491,7 +506,11 @@ class IntelligentRecommendation:
                         risk_type="stability",
                         probability=0.6,
                         impact_level=RiskLevel.MEDIUM,
-                        mitigation_actions=["ç›£æ§ç‰ˆæœ¬æ›´æ–°", "æº–å‚™å‡ç´šè¨ˆç•«", "å¢åŠ æ¸¬è©¦è¦†è“‹"],
+                        mitigation_actions=[
+                            "ç›£æ§ç‰ˆæœ¬æ›´æ–°",
+                            "æº–å‚™å‡ç´šè¨ˆç•«",
+                            "å¢åŠ æ¸¬è©¦è¦†è“‹",
+                        ],
                     )
                 )
 
@@ -503,8 +522,14 @@ class IntelligentRecommendation:
                         dependency_name=name,
                         risk_type="security",
                         probability=0.95,
-                        impact_level=RiskLevel.CRITICAL if vuln_count >= 3 else RiskLevel.HIGH,
-                        mitigation_actions=["ç«‹å³ä¿®è£œæ¼æ´", "å‡ç´šè‡³å®‰å…¨ç‰ˆæœ¬", "è©•ä¼°å½±éŸ¿ç¯„åœ"],
+                        impact_level=(
+                            RiskLevel.CRITICAL if vuln_count >= 3 else RiskLevel.HIGH
+                        ),
+                        mitigation_actions=[
+                            "ç«‹å³ä¿®è£œæ¼æ´",
+                            "å‡ç´šè‡³å®‰å…¨ç‰ˆæœ¬",
+                            "è©•ä¼°å½±éŸ¿ç¯„åœ",
+                        ],
                     )
                 )
 
@@ -513,7 +538,9 @@ class IntelligentRecommendation:
 
     # ==================== å»ºè­°ç”Ÿæˆ ====================
 
-    def generate_recommendations(self, dependencies: List[Dict[str, Any]]) -> List[Recommendation]:
+    def generate_recommendations(
+        self, dependencies: List[Dict[str, Any]]
+    ) -> List[Recommendation]:
         """
         ç”Ÿæˆå»ºè­°
 
@@ -538,7 +565,11 @@ class IntelligentRecommendation:
                         priority=10,
                         title=f"ä¿®å¾© {name} çš„å®‰å…¨æ¼æ´",
                         description=f"ç™¼ç¾ {dep.get('vulnerabilities', 0)} å€‹å®‰å…¨æ¼æ´",
-                        actions=[f"å‡ç´š {name} è‡³æœ€æ–°ç‰ˆæœ¬", "åŸ·è¡Œå®‰å…¨æƒæç¢ºèª", "æ›´æ–°ç›¸é—œæ¸¬è©¦"],
+                        actions=[
+                            f"å‡ç´š {name} è‡³æœ€æ–°ç‰ˆæœ¬",
+                            "åŸ·è¡Œå®‰å…¨æƒæç¢ºèª",
+                            "æ›´æ–°ç›¸é—œæ¸¬è©¦",
+                        ],
                         estimated_effort_hours=2.0,
                         confidence=0.95,
                     )
@@ -590,7 +621,9 @@ class IntelligentRecommendation:
 
     # ==================== å ±å‘Šç”Ÿæˆ ====================
 
-    def generate_insight_report(self, dependencies: List[Dict[str, Any]]) -> Dict[str, Any]:
+    def generate_insight_report(
+        self, dependencies: List[Dict[str, Any]]
+    ) -> Dict[str, Any]:
         """
         ç”Ÿæˆæ´å¯Ÿå ±å‘Š
 
@@ -607,7 +640,11 @@ class IntelligentRecommendation:
                 dep.get("name", "unknown"), dep.get("version", "0.0.0"), dep
             )
             health_scores.append(
-                {"name": dep.get("name"), "score": score.overall_score, "grade": score.grade}
+                {
+                    "name": dep.get("name"),
+                    "score": score.overall_score,
+                    "grade": score.grade,
+                }
             )
 
         # é æ¸¬é¢¨éšª
@@ -618,7 +655,9 @@ class IntelligentRecommendation:
 
         # çµ±è¨ˆ
         avg_health = (
-            sum(h["score"] for h in health_scores) / len(health_scores) if health_scores else 0
+            sum(h["score"] for h in health_scores) / len(health_scores)
+            if health_scores
+            else 0
         )
         critical_risks = len([r for r in risks if r.impact_level == RiskLevel.CRITICAL])
         high_priority_recs = len([r for r in recommendations if r.priority >= 8])
@@ -681,7 +720,9 @@ class IntelligentRecommendation:
         ]
 
         # å¥åº·åº¦æ’è¡Œ
-        sorted_health = sorted(report["health_scores"], key=lambda x: x["score"], reverse=True)
+        sorted_health = sorted(
+            report["health_scores"], key=lambda x: x["score"], reverse=True
+        )
         for h in sorted_health[:10]:
             grade_emoji = {"A": "ğŸŒŸ", "B": "âœ…", "C": "âš ï¸", "D": "ğŸ”¶", "F": "ğŸ”´"}
             emoji = grade_emoji.get(h["grade"], "â“")
diff --git a/workspace/src/ai/agents/dependency-manager/src/enterprise/security.py b/workspace/src/ai/agents/dependency-manager/src/enterprise/security.py
index 9787690..61ca218 100644
--- a/workspace/src/ai/agents/dependency-manager/src/enterprise/security.py
+++ b/workspace/src/ai/agents/dependency-manager/src/enterprise/security.py
@@ -332,7 +332,11 @@ class NextGenSecurity:
             "metadata": {
                 "timestamp": sbom.created_at.isoformat(),
                 "tools": [sbom.metadata.get("tool", "unknown")],
-                "component": {"type": "application", "name": sbom.name, "version": sbom.version},
+                "component": {
+                    "type": "application",
+                    "name": sbom.name,
+                    "version": sbom.version,
+                },
             },
             "components": [
                 {
@@ -392,7 +396,12 @@ class NextGenSecurity:
                 "project_version": sbom.version,
                 "created": sbom.created_at.isoformat(),
                 "components": [
-                    {"name": c.name, "version": c.version, "purl": c.purl, "license": c.license}
+                    {
+                        "name": c.name,
+                        "version": c.version,
+                        "purl": c.purl,
+                        "license": c.license,
+                    }
                     for c in sbom.components
                 ],
             },
@@ -482,7 +491,9 @@ class NextGenSecurity:
 
         elif "è®Šæ›´" in req_name or "change" in req_name.lower():
             # æª¢æŸ¥æ˜¯å¦æœ‰ç‰ˆæœ¬é–å®š
-            pinned = len([d for d in dependencies if not d.get("version", "").startswith("^")])
+            pinned = len(
+                [d for d in dependencies if not d.get("version", "").startswith("^")]
+            )
             if pinned < len(dependencies) * 0.8:
                 status = "partial"
                 evidence.append(f"{pinned}/{len(dependencies)} ç‰ˆæœ¬å·²é–å®š")
@@ -492,7 +503,9 @@ class NextGenSecurity:
 
         elif "æƒ¡æ„" in req_name or "malicious" in req_name.lower():
             malicious = [
-                d for d in dependencies if d.get("name", "").lower() in self.KNOWN_MALICIOUS
+                d
+                for d in dependencies
+                if d.get("name", "").lower() in self.KNOWN_MALICIOUS
             ]
             if malicious:
                 status = "fail"
@@ -516,7 +529,9 @@ class NextGenSecurity:
 
     # ==================== ä¾›æ‡‰éˆå®‰å…¨ ====================
 
-    def analyze_supply_chain(self, dependencies: List[Dict[str, Any]]) -> List[SupplyChainAlert]:
+    def analyze_supply_chain(
+        self, dependencies: List[Dict[str, Any]]
+    ) -> List[SupplyChainAlert]:
         """
         åˆ†æä¾›æ‡‰éˆå®‰å…¨
 
@@ -736,8 +751,12 @@ class NextGenSecurity:
                 compliance_reports.append(report)
 
         # çµ±è¨ˆ
-        critical_alerts = len([a for a in supply_chain_alerts if a.severity == "critical"])
-        untrusted = len([t for t in trust_assessments if t.trust_level == TrustLevel.UNTRUSTED])
+        critical_alerts = len(
+            [a for a in supply_chain_alerts if a.severity == "critical"]
+        )
+        untrusted = len(
+            [t for t in trust_assessments if t.trust_level == TrustLevel.UNTRUSTED]
+        )
         avg_trust = (
             sum(t.score for t in trust_assessments) / len(trust_assessments)
             if trust_assessments
@@ -763,7 +782,11 @@ class NextGenSecurity:
                 for a in supply_chain_alerts
             ],
             "trust_assessments": [
-                {"package": t.package_name, "trust_level": t.trust_level.value, "score": t.score}
+                {
+                    "package": t.package_name,
+                    "trust_level": t.trust_level.value,
+                    "score": t.score,
+                }
                 for t in trust_assessments
             ],
             "compliance": [
@@ -840,7 +863,9 @@ class NextGenSecurity:
             report["trust_assessments"], key=lambda x: x["score"], reverse=True
         )[:10]:
             emoji = trust_emoji.get(assessment["trust_level"], "â“")
-            lines.append(f"  {emoji} {assessment['package']}: {assessment['score']:.0f}")
+            lines.append(
+                f"  {emoji} {assessment['package']}: {assessment['score']:.0f}"
+            )
 
         if report["compliance"]:
             lines.extend(
@@ -851,8 +876,14 @@ class NextGenSecurity:
                 ]
             )
             for comp in report["compliance"]:
-                status = "âœ…" if comp["score"] >= 80 else "âš ï¸" if comp["score"] >= 60 else "âŒ"
-                lines.append(f"  {status} {comp['framework'].upper()}: {comp['score']:.1f}%")
+                status = (
+                    "âœ…"
+                    if comp["score"] >= 80
+                    else "âš ï¸" if comp["score"] >= 60 else "âŒ"
+                )
+                lines.append(
+                    f"  {status} {comp['framework'].upper()}: {comp['score']:.1f}%"
+                )
                 lines.append(f"     é€šéï¼š{comp['passed']} | å¤±æ•—ï¼š{comp['failed']}")
 
         lines.extend(["", "=" * 60])
diff --git a/workspace/src/ai/agents/dependency-manager/src/evaluation/evaluation_report.py b/workspace/src/ai/agents/dependency-manager/src/evaluation/evaluation_report.py
index 323a1a1..40ec675 100644
--- a/workspace/src/ai/agents/dependency-manager/src/evaluation/evaluation_report.py
+++ b/workspace/src/ai/agents/dependency-manager/src/evaluation/evaluation_report.py
@@ -87,7 +87,9 @@ class EvaluationReportGenerator:
 
     def _get_dimension_name(self, dim: str) -> str:
         """ç²å–ç¶­åº¦åç¨±"""
-        names = self.DIMENSION_NAMES.get(self.config.language, self.DIMENSION_NAMES["zh-TW"])
+        names = self.DIMENSION_NAMES.get(
+            self.config.language, self.DIMENSION_NAMES["zh-TW"]
+        )
         return names.get(dim, dim)
 
     def _generate_markdown(self, result: SMARTVResult) -> str:
@@ -141,7 +143,9 @@ class EvaluationReportGenerator:
 
                 lines.append(f"### {indicator} {dim_name}")
                 lines.append("")
-                lines.append(f"- **åˆ†æ•¸**: {score.score:.1f} / 10.0 ({score.percentage:.1f}%)")
+                lines.append(
+                    f"- **åˆ†æ•¸**: {score.score:.1f} / 10.0 ({score.percentage:.1f}%)"
+                )
                 lines.append(f"- **ç­‰ç´š**: {score.level.value}")
                 lines.append("")
 
@@ -166,7 +170,9 @@ class EvaluationReportGenerator:
             lines.append("")
             lines.append("```json")
             chart_data = {
-                "labels": [self._get_dimension_name(d.value) for d in result.scores.keys()],
+                "labels": [
+                    self._get_dimension_name(d.value) for d in result.scores.keys()
+                ],
                 "values": [s.score for s in result.scores.values()],
             }
             lines.append(json.dumps(chart_data, ensure_ascii=False, indent=2))
@@ -354,7 +360,9 @@ class EvaluationReportGenerator:
             lines.append(f"### {result.project_name}")
 
             # æ‰¾å‡ºæœ€é«˜å’Œæœ€ä½åˆ†ç¶­åº¦
-            sorted_dims = sorted(result.scores.items(), key=lambda x: x[1].score, reverse=True)
+            sorted_dims = sorted(
+                result.scores.items(), key=lambda x: x[1].score, reverse=True
+            )
 
             best = sorted_dims[0]
             worst = sorted_dims[-1]
@@ -374,7 +382,9 @@ class EvaluationReportGenerator:
         emoji = self.GRADE_EMOJIS.get(result.overall_grade, "ğŸ“Š")
 
         # æ‰¾å‡ºå„ªå‹¢å’ŒåŠ£å‹¢
-        sorted_dims = sorted(result.scores.items(), key=lambda x: x[1].score, reverse=True)
+        sorted_dims = sorted(
+            result.scores.items(), key=lambda x: x[1].score, reverse=True
+        )
 
         strengths = [d for d in sorted_dims[:2] if d[1].score >= 7]
         weaknesses = [d for d in sorted_dims[-2:] if d[1].score < 6]
@@ -391,13 +401,17 @@ class EvaluationReportGenerator:
         if strengths:
             summary += "**å„ªå‹¢é ˜åŸŸ**:\n"
             for dim, score in strengths:
-                summary += f"- {self._get_dimension_name(dim.value)}: {score.score:.1f}\n"
+                summary += (
+                    f"- {self._get_dimension_name(dim.value)}: {score.score:.1f}\n"
+                )
             summary += "\n"
 
         if weaknesses:
             summary += "**éœ€è¦é—œæ³¨**:\n"
             for dim, score in weaknesses:
-                summary += f"- {self._get_dimension_name(dim.value)}: {score.score:.1f}\n"
+                summary += (
+                    f"- {self._get_dimension_name(dim.value)}: {score.score:.1f}\n"
+                )
             summary += "\n"
 
         if result.recommendations:
diff --git a/workspace/src/ai/agents/dependency-manager/src/evaluation/smartv_framework.py b/workspace/src/ai/agents/dependency-manager/src/evaluation/smartv_framework.py
index 4db617c..17c35a6 100644
--- a/workspace/src/ai/agents/dependency-manager/src/evaluation/smartv_framework.py
+++ b/workspace/src/ai/agents/dependency-manager/src/evaluation/smartv_framework.py
@@ -168,7 +168,9 @@ class BaseEvaluator:
             evidences=evidences,
         )
 
-    def _evaluate_criterion(self, criterion: EvaluationCriteria, data: Dict[str, Any]) -> float:
+    def _evaluate_criterion(
+        self, criterion: EvaluationCriteria, data: Dict[str, Any]
+    ) -> float:
         """Evaluate a single criterion - override in subclass for custom logic
 
         Args:
@@ -188,7 +190,9 @@ class BaseEvaluator:
         if total_weight == 0:
             return sum(sub_scores.values()) / len(sub_scores)
         weighted_sum = sum(
-            sub_scores.get(c.name, 0) * c.weight for c in self.criteria if c.name in sub_scores
+            sub_scores.get(c.name, 0) * c.weight
+            for c in self.criteria
+            if c.name in sub_scores
         )
         return weighted_sum / total_weight
 
@@ -211,13 +215,19 @@ class ScalabilityEvaluator(BaseEvaluator):
     def _get_criteria(self) -> List[EvaluationCriteria]:
         return [
             EvaluationCriteria(
-                name="architecture_scalability", description="æŠ€è¡“æ¶æ§‹å¯æ“´å±•æ€§", weight=0.35
+                name="architecture_scalability",
+                description="æŠ€è¡“æ¶æ§‹å¯æ“´å±•æ€§",
+                weight=0.35,
             ),
             EvaluationCriteria(
                 name="user_growth_potential", description="ç”¨æˆ¶å¢é•·æ½›åŠ›", weight=0.30
             ),
-            EvaluationCriteria(name="load_capacity", description="ç³»çµ±è² è¼‰æ‰¿å—èƒ½åŠ›", weight=0.20),
-            EvaluationCriteria(name="horizontal_scaling", description="æ°´å¹³æ“´å±•èƒ½åŠ›", weight=0.15),
+            EvaluationCriteria(
+                name="load_capacity", description="ç³»çµ±è² è¼‰æ‰¿å—èƒ½åŠ›", weight=0.20
+            ),
+            EvaluationCriteria(
+                name="horizontal_scaling", description="æ°´å¹³æ“´å±•èƒ½åŠ›", weight=0.15
+            ),
         ]
 
     def evaluate(self, data: Dict[str, Any]) -> DimensionScore:
@@ -293,11 +303,15 @@ class MarketFitEvaluator(BaseEvaluator):
             EvaluationCriteria(
                 name="user_needs_match", description="ç›®æ¨™ç”¨æˆ¶éœ€æ±‚åŒ¹é…åº¦", weight=0.35
             ),
-            EvaluationCriteria(name="market_timing", description="å¸‚å ´æ™‚æ©Ÿæˆç†Ÿåº¦", weight=0.25),
+            EvaluationCriteria(
+                name="market_timing", description="å¸‚å ´æ™‚æ©Ÿæˆç†Ÿåº¦", weight=0.25
+            ),
             EvaluationCriteria(
                 name="competitive_analysis", description="ç«¶çˆ­ç’°å¢ƒåˆ†æ", weight=0.25
             ),
-            EvaluationCriteria(name="market_size", description="å¸‚å ´è¦æ¨¡æ½›åŠ›", weight=0.15),
+            EvaluationCriteria(
+                name="market_size", description="å¸‚å ´è¦æ¨¡æ½›åŠ›", weight=0.15
+            ),
         ]
 
     def evaluate(self, data: Dict[str, Any]) -> DimensionScore:
@@ -355,9 +369,15 @@ class AchievabilityEvaluator(BaseEvaluator):
             EvaluationCriteria(
                 name="team_capability", description="åœ˜éšŠæŠ€è¡“èƒ½åŠ›åŒ¹é…åº¦", weight=0.35
             ),
-            EvaluationCriteria(name="budget_timeline", description="é ç®—èˆ‡æ™‚ç¨‹åˆç†æ€§", weight=0.30),
-            EvaluationCriteria(name="technical_risk", description="æŠ€è¡“é¢¨éšªè©•ä¼°", weight=0.20),
-            EvaluationCriteria(name="resource_availability", description="è³‡æºå¯ç”¨æ€§", weight=0.15),
+            EvaluationCriteria(
+                name="budget_timeline", description="é ç®—èˆ‡æ™‚ç¨‹åˆç†æ€§", weight=0.30
+            ),
+            EvaluationCriteria(
+                name="technical_risk", description="æŠ€è¡“é¢¨éšªè©•ä¼°", weight=0.20
+            ),
+            EvaluationCriteria(
+                name="resource_availability", description="è³‡æºå¯ç”¨æ€§", weight=0.15
+            ),
         ]
 
     def evaluate(self, data: Dict[str, Any]) -> DimensionScore:
@@ -365,7 +385,9 @@ class AchievabilityEvaluator(BaseEvaluator):
             "team_capability": self._eval_team(data),
             "budget_timeline": self._eval_budget(data),
             "technical_risk": self._eval_risk(data),
-            "resource_availability": min(data.get("resource_availability_score", 5), 10),
+            "resource_availability": min(
+                data.get("resource_availability_score", 5), 10
+            ),
         }
         return DimensionScore(
             dimension=self.dimension,
@@ -401,7 +423,13 @@ class AchievabilityEvaluator(BaseEvaluator):
 
     def _eval_risk(self, data: Dict[str, Any]) -> float:
         risk = data.get("risk_level", "medium")
-        scores = {"very_low": 10.0, "low": 8.0, "medium": 6.0, "high": 4.0, "very_high": 2.0}
+        scores = {
+            "very_low": 10.0,
+            "low": 8.0,
+            "medium": 6.0,
+            "high": 4.0,
+            "very_high": 2.0,
+        }
         base = scores.get(risk, 5.0)
         mitigation = min(len(data.get("mitigation_plans", [])) * 0.5, 2.0)
         return min(base + mitigation, 10.0)
@@ -414,9 +442,15 @@ class ROIEvaluator(BaseEvaluator):
 
     def _get_criteria(self) -> List[EvaluationCriteria]:
         return [
-            EvaluationCriteria(name="financial_return", description="é æœŸè²¡å‹™å›å ±", weight=0.40),
-            EvaluationCriteria(name="cost_benefit", description="æˆæœ¬æ•ˆç›Šåˆ†æ", weight=0.35),
-            EvaluationCriteria(name="resource_efficiency", description="è³‡æºåˆ©ç”¨æ•ˆç‡", weight=0.25),
+            EvaluationCriteria(
+                name="financial_return", description="é æœŸè²¡å‹™å›å ±", weight=0.40
+            ),
+            EvaluationCriteria(
+                name="cost_benefit", description="æˆæœ¬æ•ˆç›Šåˆ†æ", weight=0.35
+            ),
+            EvaluationCriteria(
+                name="resource_efficiency", description="è³‡æºåˆ©ç”¨æ•ˆç‡", weight=0.25
+            ),
         ]
 
     def evaluate(self, data: Dict[str, Any]) -> DimensionScore:
@@ -443,7 +477,11 @@ class ROIEvaluator(BaseEvaluator):
         payback_score = (
             10.0
             if payback <= 6
-            else 8.0 if payback <= 12 else 6.0 if payback <= 24 else 4.0 if payback <= 36 else 2.0
+            else (
+                8.0
+                if payback <= 12
+                else 6.0 if payback <= 24 else 4.0 if payback <= 36 else 2.0
+            )
         )
         return roi_score * 0.6 + payback_score * 0.4
 
@@ -474,9 +512,15 @@ class TechnologyMaturityEvaluator(BaseEvaluator):
 
     def _get_criteria(self) -> List[EvaluationCriteria]:
         return [
-            EvaluationCriteria(name="tech_stability", description="ç›¸é—œæŠ€è¡“ç©©å®šç¨‹åº¦", weight=0.35),
-            EvaluationCriteria(name="ecosystem", description="ç”Ÿæ…‹ç³»çµ±å®Œæ•´æ€§", weight=0.35),
-            EvaluationCriteria(name="learning_curve", description="å­¸ç¿’æ›²ç·šé™¡å³­ç¨‹åº¦", weight=0.30),
+            EvaluationCriteria(
+                name="tech_stability", description="ç›¸é—œæŠ€è¡“ç©©å®šç¨‹åº¦", weight=0.35
+            ),
+            EvaluationCriteria(
+                name="ecosystem", description="ç”Ÿæ…‹ç³»çµ±å®Œæ•´æ€§", weight=0.35
+            ),
+            EvaluationCriteria(
+                name="learning_curve", description="å­¸ç¿’æ›²ç·šé™¡å³­ç¨‹åº¦", weight=0.30
+            ),
         ]
 
     def evaluate(self, data: Dict[str, Any]) -> DimensionScore:
@@ -550,8 +594,12 @@ class ValueCreationEvaluator(BaseEvaluator):
             EvaluationCriteria(
                 name="competitive_advantage", description="é•·æœŸç«¶çˆ­å„ªå‹¢", weight=0.35
             ),
-            EvaluationCriteria(name="brand_value", description="å“ç‰Œåƒ¹å€¼æå‡", weight=0.30),
-            EvaluationCriteria(name="innovation_impact", description="å‰µæ–°å½±éŸ¿åŠ›", weight=0.35),
+            EvaluationCriteria(
+                name="brand_value", description="å“ç‰Œåƒ¹å€¼æå‡", weight=0.30
+            ),
+            EvaluationCriteria(
+                name="innovation_impact", description="å‰µæ–°å½±éŸ¿åŠ›", weight=0.35
+            ),
         ]
 
     def evaluate(self, data: Dict[str, Any]) -> DimensionScore:
diff --git a/workspace/src/ai/agents/dependency-manager/src/evaluation/weight_config.py b/workspace/src/ai/agents/dependency-manager/src/evaluation/weight_config.py
index 7860439..c76ba5c 100644
--- a/workspace/src/ai/agents/dependency-manager/src/evaluation/weight_config.py
+++ b/workspace/src/ai/agents/dependency-manager/src/evaluation/weight_config.py
@@ -162,7 +162,9 @@ class WeightConfigManager:
             return {k: 1.0 / n for k in weights}
         return {k: v / total for k, v in weights.items()}
 
-    def suggest_weights(self, priorities: Dict[str, int]) -> Dict[str, float]:  # 1-5 çš„å„ªå…ˆç´š
+    def suggest_weights(
+        self, priorities: Dict[str, int]
+    ) -> Dict[str, float]:  # 1-5 çš„å„ªå…ˆç´š
         """æ ¹æ“šå„ªå…ˆç´šå»ºè­°æ¬Šé‡"""
         # å°‡å„ªå…ˆç´šè½‰æ›ç‚ºæ¬Šé‡
         weights = {}
diff --git a/workspace/src/ai/agents/dependency-manager/src/future/development_tracker.py b/workspace/src/ai/agents/dependency-manager/src/future/development_tracker.py
index c8876ad..99031a8 100644
--- a/workspace/src/ai/agents/dependency-manager/src/future/development_tracker.py
+++ b/workspace/src/ai/agents/dependency-manager/src/future/development_tracker.py
@@ -103,7 +103,9 @@ class Strategy321:
     # ç­–ç•¥é …ç›®
     current_strategies: List[StrategyItem] = field(default_factory=list)  # æœ€å¤š 3 å€‹
     preparing_strategies: List[StrategyItem] = field(default_factory=list)  # æœ€å¤š 2 å€‹
-    researching_strategies: List[StrategyItem] = field(default_factory=list)  # æœ€å¤š 1 å€‹
+    researching_strategies: List[StrategyItem] = field(
+        default_factory=list
+    )  # æœ€å¤š 1 å€‹
 
     # æ­·å²è¨˜éŒ„
     strategy_history: List[Dict[str, Any]] = field(default_factory=list)
@@ -163,7 +165,9 @@ class Strategy321:
                 s.priority = StrategyPriority.PREPARING
                 self.preparing_strategies.append(s)
                 self.researching_strategies.pop(i)
-                self._record_history(strategy_id, "promoted", "researching -> preparing")
+                self._record_history(
+                    strategy_id, "promoted", "researching -> preparing"
+                )
                 return True, "ç­–ç•¥å·²æå‡åˆ°æº–å‚™ä¸­"
 
         # å¾æº–å‚™ä¸­æå‡åˆ°ç•¶å‰
@@ -181,7 +185,9 @@ class Strategy321:
 
         return False, "æ‰¾ä¸åˆ°æŒ‡å®šç­–ç•¥"
 
-    def complete_strategy(self, strategy_id: str, actual_roi: float = 0.0) -> Tuple[bool, str]:
+    def complete_strategy(
+        self, strategy_id: str, actual_roi: float = 0.0
+    ) -> Tuple[bool, str]:
         """
         å®Œæˆç­–ç•¥
 
@@ -198,7 +204,9 @@ class Strategy321:
                 s.completed_at = datetime.now()
                 s.progress = 100
                 self.current_strategies.pop(i)
-                self._record_history(strategy_id, "completed", f"actual_roi: {actual_roi}")
+                self._record_history(
+                    strategy_id, "completed", f"actual_roi: {actual_roi}"
+                )
                 return True, "ç­–ç•¥å·²å®Œæˆ"
 
         return False, "æ‰¾ä¸åˆ°æŒ‡å®šç­–ç•¥æˆ–ç­–ç•¥ä¸åœ¨ç•¶å‰åŸ·è¡Œä¸­"
@@ -219,14 +227,20 @@ class Strategy321:
         return {
             "organization_id": self.organization_id,
             "current_strategies": [
-                {"id": s.strategy_id, "name": s.name, "progress": s.progress, "status": s.status}
+                {
+                    "id": s.strategy_id,
+                    "name": s.name,
+                    "progress": s.progress,
+                    "status": s.status,
+                }
                 for s in self.current_strategies
             ],
             "preparing_strategies": [
                 {"id": s.strategy_id, "name": s.name} for s in self.preparing_strategies
             ],
             "researching_strategies": [
-                {"id": s.strategy_id, "name": s.name} for s in self.researching_strategies
+                {"id": s.strategy_id, "name": s.name}
+                for s in self.researching_strategies
             ],
             "slots": {
                 "current": f"{len(self.current_strategies)}/{self.max_current}",
@@ -266,7 +280,9 @@ class TeamCapability:
     team_size: int
 
     # æŠ€èƒ½è©•ä¼°
-    skill_assessments: Dict[SkillCategory, TeamSkillAssessment] = field(default_factory=dict)
+    skill_assessments: Dict[SkillCategory, TeamSkillAssessment] = field(
+        default_factory=dict
+    )
 
     # åŸ¹è¨“è¨ˆåŠƒ
     training_plans: List[Dict[str, Any]] = field(default_factory=list)
@@ -560,7 +576,10 @@ class ContinuousOptimization:
         return "\n".join(report_lines)
 
     def set_alert(
-        self, metric_name: str, threshold: float, comparison: str = "below"  # below, above
+        self,
+        metric_name: str,
+        threshold: float,
+        comparison: str = "below",  # below, above
     ) -> None:
         """
         è¨­ç½®è­¦å ±
@@ -641,7 +660,10 @@ class DevelopmentTracker:
     """
 
     def __init__(
-        self, organization_id: str, team_name: str = "Development Team", team_size: int = 10
+        self,
+        organization_id: str,
+        team_name: str = "Development Team",
+        team_size: int = 10,
     ):
         self.strategy_321 = Strategy321(organization_id=organization_id)
         self.team_capability = TeamCapability(
@@ -650,11 +672,20 @@ class DevelopmentTracker:
         self.continuous_optimization = ContinuousOptimization()
 
     def add_strategy(
-        self, strategy_id: str, name: str, description: str, priority: StrategyPriority, **kwargs
+        self,
+        strategy_id: str,
+        name: str,
+        description: str,
+        priority: StrategyPriority,
+        **kwargs,
     ) -> Tuple[bool, str]:
         """æ·»åŠ ç­–ç•¥"""
         strategy = StrategyItem(
-            strategy_id=strategy_id, name=name, description=description, priority=priority, **kwargs
+            strategy_id=strategy_id,
+            name=name,
+            description=description,
+            priority=priority,
+            **kwargs,
         )
         return self.strategy_321.add_strategy(strategy)
 
@@ -673,7 +704,9 @@ class DevelopmentTracker:
     def conduct_quarterly_review(self) -> OptimizationReview:
         """åŸ·è¡Œå­£åº¦å¯©æŸ¥"""
         self.strategy_321.review_cycle = ReviewCycle.QUARTERLY
-        return self.continuous_optimization.conduct_review(self.strategy_321, self.team_capability)
+        return self.continuous_optimization.conduct_review(
+            self.strategy_321, self.team_capability
+        )
 
     def generate_full_report(self) -> str:
         """ç”Ÿæˆå®Œæ•´å ±å‘Š"""
diff --git a/workspace/src/ai/agents/dependency-manager/src/future/lowcode_integration.py b/workspace/src/ai/agents/dependency-manager/src/future/lowcode_integration.py
index e925637..086d750 100644
--- a/workspace/src/ai/agents/dependency-manager/src/future/lowcode_integration.py
+++ b/workspace/src/ai/agents/dependency-manager/src/future/lowcode_integration.py
@@ -159,12 +159,16 @@ class VisualWorkflow:
         errors = []
 
         # æª¢æŸ¥æ˜¯å¦æœ‰è§¸ç™¼å™¨
-        triggers = [n for n in self.nodes.values() if n.node_type == WorkflowNodeType.TRIGGER]
+        triggers = [
+            n for n in self.nodes.values() if n.node_type == WorkflowNodeType.TRIGGER
+        ]
         if not triggers:
             errors.append("å·¥ä½œæµå¿…é ˆæœ‰è‡³å°‘ä¸€å€‹è§¸ç™¼å™¨")
 
         # æª¢æŸ¥æ˜¯å¦æœ‰è¼¸å‡º
-        outputs = [n for n in self.nodes.values() if n.node_type == WorkflowNodeType.OUTPUT]
+        outputs = [
+            n for n in self.nodes.values() if n.node_type == WorkflowNodeType.OUTPUT
+        ]
         if not outputs:
             errors.append("å·¥ä½œæµå¿…é ˆæœ‰è‡³å°‘ä¸€å€‹è¼¸å‡ºç¯€é»")
 
@@ -255,9 +259,7 @@ class AutoGenerator:
             config, default_flow_style=False, allow_unicode=True, sort_keys=False
         )
 
-        return (
-            f"# è‡ªå‹•ç”Ÿæˆçš„ä¾è³´ç®¡ç†é…ç½®\n# ç”Ÿæˆæ™‚é–“: {datetime.now().isoformat()}\n\n{yaml_content}"
-        )
+        return f"# è‡ªå‹•ç”Ÿæˆçš„ä¾è³´ç®¡ç†é…ç½®\n# ç”Ÿæˆæ™‚é–“: {datetime.now().isoformat()}\n\n{yaml_content}"
 
     def _generate_json(self, config: Dict[str, Any]) -> str:
         """ç”Ÿæˆ JSON é…ç½®"""
@@ -363,7 +365,9 @@ if __name__ == '__main__':
 
         # æ ¹æ“šç”Ÿæ…‹ç³»çµ±æ·»åŠ ä¾è³´å®‰è£
         if ecosystem == "npm":
-            dockerfile_lines.extend(["COPY package*.json ./", "RUN npm ci --only=production", ""])
+            dockerfile_lines.extend(
+                ["COPY package*.json ./", "RUN npm ci --only=production", ""]
+            )
         elif ecosystem == "pip":
             dockerfile_lines.extend(
                 [
@@ -373,7 +377,9 @@ if __name__ == '__main__':
                 ]
             )
         elif ecosystem == "go":
-            dockerfile_lines.extend(["COPY go.mod go.sum ./", "RUN go mod download", ""])
+            dockerfile_lines.extend(
+                ["COPY go.mod go.sum ./", "RUN go mod download", ""]
+            )
 
         dockerfile_lines.extend(["COPY . .", "", 'CMD ["npm", "start"]'])
 
@@ -415,7 +421,10 @@ if __name__ == '__main__':
         elif ecosystem == "pip":
             steps.extend(
                 [
-                    {"uses": "actions/setup-python@v4", "with": {"python-version": "3.11"}},
+                    {
+                        "uses": "actions/setup-python@v4",
+                        "with": {"python-version": "3.11"},
+                    },
                     {"run": "pip install -r requirements.txt"},
                     {"run": "pip-audit"},
                 ]
@@ -552,7 +561,10 @@ class LowCodeIntegration:
             CitizenDeveloper: æ–°å‰µå»ºçš„å…¬æ°‘é–‹ç™¼è€…
         """
         user = CitizenDeveloper(
-            user_id=user_id, name=name, skill_level=skill_level, last_activity=datetime.now()
+            user_id=user_id,
+            name=name,
+            skill_level=skill_level,
+            last_activity=datetime.now(),
         )
 
         # æ ¹æ“šæŠ€èƒ½ç­‰ç´šè¨­ç½®æ¬Šé™
@@ -577,7 +589,10 @@ class LowCodeIntegration:
             VisualWorkflow: æ–°å‰µå»ºçš„å·¥ä½œæµ
         """
         workflow = VisualWorkflow(
-            workflow_id=workflow_id, name=name, description=description, created_by=created_by
+            workflow_id=workflow_id,
+            name=name,
+            description=description,
+            created_by=created_by,
         )
 
         self.workflows[workflow_id] = workflow
@@ -590,7 +605,10 @@ class LowCodeIntegration:
         return workflow
 
     def apply_template(
-        self, template_id: str, workflow_id: str, customizations: Optional[Dict[str, Any]] = None
+        self,
+        template_id: str,
+        workflow_id: str,
+        customizations: Optional[Dict[str, Any]] = None,
     ) -> VisualWorkflow:
         """
         æ‡‰ç”¨æ¨¡æ¿å‰µå»ºå·¥ä½œæµ
@@ -624,7 +642,10 @@ class LowCodeIntegration:
         # å‰µå»ºè§¸ç™¼å™¨ç¯€é»
         trigger = definition.get("trigger", {})
         trigger_node = WorkflowNode(
-            node_id="trigger_1", node_type=WorkflowNodeType.TRIGGER, name="è§¸ç™¼å™¨", config=trigger
+            node_id="trigger_1",
+            node_type=WorkflowNodeType.TRIGGER,
+            name="è§¸ç™¼å™¨",
+            config=trigger,
         )
         workflow.add_node(trigger_node)
 
@@ -645,7 +666,10 @@ class LowCodeIntegration:
 
         # æ·»åŠ è¼¸å‡ºç¯€é»
         output_node = WorkflowNode(
-            node_id="output_1", node_type=WorkflowNodeType.OUTPUT, name="è¼¸å‡º", config={}
+            node_id="output_1",
+            node_type=WorkflowNodeType.OUTPUT,
+            name="è¼¸å‡º",
+            config={},
         )
         workflow.add_node(output_node)
         workflow.connect_nodes(prev_node_id, "output_1")
@@ -774,8 +798,12 @@ class LowCodeIntegration:
 
         if reqs:
             progress = {
-                "workflows_progress": min(100, user.workflows_created / reqs["workflows"] * 100),
-                "templates_progress": min(100, user.templates_used / reqs["templates"] * 100),
+                "workflows_progress": min(
+                    100, user.workflows_created / reqs["workflows"] * 100
+                ),
+                "templates_progress": min(
+                    100, user.templates_used / reqs["templates"] * 100
+                ),
             }
 
         return {
@@ -787,5 +815,7 @@ class LowCodeIntegration:
             "tutorials_completed": user.tutorials_completed,
             "achievements": user.achievements,
             "next_level_progress": progress,
-            "last_activity": user.last_activity.isoformat() if user.last_activity else None,
+            "last_activity": (
+                user.last_activity.isoformat() if user.last_activity else None
+            ),
         }
diff --git a/workspace/src/ai/agents/dependency-manager/src/future/privacy_framework.py b/workspace/src/ai/agents/dependency-manager/src/future/privacy_framework.py
index b23eac4..3b2ae23 100644
--- a/workspace/src/ai/agents/dependency-manager/src/future/privacy_framework.py
+++ b/workspace/src/ai/agents/dependency-manager/src/future/privacy_framework.py
@@ -131,16 +131,22 @@ class PrivacyByDesign:
         pii_count = sum(1 for f in self.data_fields.values() if f.is_pii)
         encrypted_count = sum(1 for f in self.data_fields.values() if f.is_encrypted)
         anonymized_count = sum(1 for f in self.data_fields.values() if f.is_anonymized)
-        consent_required = sum(1 for f in self.data_fields.values() if f.requires_consent)
+        consent_required = sum(
+            1 for f in self.data_fields.values() if f.requires_consent
+        )
 
         total_fields = len(self.data_fields)
 
         # é é˜²æ€§åˆ†æ•¸ï¼ˆPII ä¿è­·æ¯”ä¾‹ï¼‰
-        self.proactive_score = (1 - pii_count / total_fields) * 100 if total_fields > 0 else 100
+        self.proactive_score = (
+            (1 - pii_count / total_fields) * 100 if total_fields > 0 else 100
+        )
 
         # é»˜èªéš±ç§åˆ†æ•¸ï¼ˆåŠ å¯†å’ŒåŒ¿ååŒ–æ¯”ä¾‹ï¼‰
         protected = encrypted_count + anonymized_count
-        self.default_privacy_score = (protected / total_fields) * 100 if total_fields > 0 else 0
+        self.default_privacy_score = (
+            (protected / total_fields) * 100 if total_fields > 0 else 0
+        )
 
         # åµŒå…¥å¼è¨­è¨ˆåˆ†æ•¸
         self.embedded_score = 70  # åŸºç¤åˆ†æ•¸ï¼Œå¯æ ¹æ“šæ¶æ§‹è©•ä¼°èª¿æ•´
@@ -149,10 +155,14 @@ class PrivacyByDesign:
         self.positive_sum_score = 75  # åŸºç¤åˆ†æ•¸
 
         # ç«¯åˆ°ç«¯å®‰å…¨åˆ†æ•¸
-        self.e2e_security_score = (encrypted_count / total_fields) * 100 if total_fields > 0 else 0
+        self.e2e_security_score = (
+            (encrypted_count / total_fields) * 100 if total_fields > 0 else 0
+        )
 
         # å¯è¦‹æ€§åˆ†æ•¸ï¼ˆåŒæ„éœ€æ±‚è¦†è“‹ç‡ï¼‰
-        self.visibility_score = (consent_required / pii_count) * 100 if pii_count > 0 else 100
+        self.visibility_score = (
+            (consent_required / pii_count) * 100 if pii_count > 0 else 100
+        )
 
         # ä»¥ç”¨æˆ¶ç‚ºä¸­å¿ƒåˆ†æ•¸
         self.user_centric_score = (
@@ -213,7 +223,9 @@ class DataSovereignty:
     organization_id: str
 
     # æ•¸æ“šä½ç½®
-    data_locations: Dict[str, str] = field(default_factory=dict)  # data_type -> location
+    data_locations: Dict[str, str] = field(
+        default_factory=dict
+    )  # data_type -> location
 
     # ç®¡è½„æ¬Šæ˜ å°„
     jurisdiction_mapping: Dict[str, List[str]] = field(default_factory=dict)
@@ -224,7 +236,9 @@ class DataSovereignty:
     # æœ¬åœ°åŒ–è¦æ±‚
     localization_requirements: List[Dict[str, Any]] = field(default_factory=list)
 
-    def register_data_location(self, data_type: str, location: str, jurisdiction: str) -> None:
+    def register_data_location(
+        self, data_type: str, location: str, jurisdiction: str
+    ) -> None:
         """è¨»å†Šæ•¸æ“šä½ç½®"""
         self.data_locations[data_type] = location
 
@@ -387,7 +401,9 @@ class ConsentManager:
         consent_id = self._generate_consent_id(user_id, purpose)
 
         # å“ˆå¸Œ IP åœ°å€ä»¥ä¿è­·éš±ç§
-        hashed_ip = hashlib.sha256(ip_address.encode()).hexdigest()[:12] if ip_address else ""
+        hashed_ip = (
+            hashlib.sha256(ip_address.encode()).hexdigest()[:12] if ip_address else ""
+        )
 
         consent = ConsentRecord(
             consent_id=consent_id,
@@ -434,7 +450,9 @@ class ConsentManager:
 
         return count
 
-    def check_consent(self, user_id: str, purpose: str, data_category: DataCategory) -> bool:
+    def check_consent(
+        self, user_id: str, purpose: str, data_category: DataCategory
+    ) -> bool:
         """
         æª¢æŸ¥ç”¨æˆ¶æ˜¯å¦å·²åŒæ„ç‰¹å®šç›®çš„å’Œæ•¸æ“šé¡åˆ¥
 
@@ -452,7 +470,10 @@ class ConsentManager:
         for consent_id in self.user_consents[user_id]:
             consent = self.consents.get(consent_id)
             if consent and consent.is_valid():
-                if consent.purpose == purpose and data_category in consent.data_categories:
+                if (
+                    consent.purpose == purpose
+                    and data_category in consent.data_categories
+                ):
                     return True
 
         return False
@@ -462,7 +483,11 @@ class ConsentManager:
         if user_id not in self.user_consents:
             return []
 
-        return [self.consents[cid] for cid in self.user_consents[user_id] if cid in self.consents]
+        return [
+            self.consents[cid]
+            for cid in self.user_consents[user_id]
+            if cid in self.consents
+        ]
 
     def generate_consent_report(self, user_id: str) -> Dict[str, Any]:
         """ç”Ÿæˆç”¨æˆ¶åŒæ„å ±å‘Š"""
@@ -585,7 +610,9 @@ class PrivacyFramework:
             **kwargs,
         )
 
-    def check_consent(self, user_id: str, purpose: str, data_category: DataCategory) -> bool:
+    def check_consent(
+        self, user_id: str, purpose: str, data_category: DataCategory
+    ) -> bool:
         """æª¢æŸ¥åŒæ„"""
         return self.consent_manager.check_consent(user_id, purpose, data_category)
 
@@ -618,7 +645,9 @@ class PrivacyFramework:
 
         if requirements.get("data_minimization"):
             # æª¢æŸ¥æ•¸æ“šæœ€å°åŒ–
-            pii_ratio = sum(1 for f in self.privacy_design.data_fields.values() if f.is_pii)
+            pii_ratio = sum(
+                1 for f in self.privacy_design.data_fields.values() if f.is_pii
+            )
             total = len(self.privacy_design.data_fields)
             minimization_score = (1 - pii_ratio / total) * 100 if total > 0 else 100
             results["data_minimization"] = minimization_score >= 70
@@ -627,7 +656,9 @@ class PrivacyFramework:
 
         if requirements.get("encryption_required"):
             # æª¢æŸ¥åŠ å¯†
-            encrypted = sum(1 for f in self.privacy_design.data_fields.values() if f.is_encrypted)
+            encrypted = sum(
+                1 for f in self.privacy_design.data_fields.values() if f.is_encrypted
+            )
             total = len(self.privacy_design.data_fields)
             encryption_rate = (encrypted / total) * 100 if total > 0 else 0
             results["encryption"] = encryption_rate >= 80
@@ -636,7 +667,9 @@ class PrivacyFramework:
 
         if requirements.get("right_to_erasure") or requirements.get("right_to_delete"):
             # æª¢æŸ¥åˆªé™¤æ¬Š
-            has_deletion = any(f.deletion_policy for f in self.privacy_design.data_fields.values())
+            has_deletion = any(
+                f.deletion_policy for f in self.privacy_design.data_fields.values()
+            )
             results["right_to_deletion"] = has_deletion
             if not has_deletion:
                 issues.append("ç¼ºå°‘æ•¸æ“šåˆªé™¤æ”¿ç­–")
@@ -699,7 +732,9 @@ class PrivacyFramework:
 
         # æœªåŠ å¯† PII é¢¨éšª
         unencrypted_pii = sum(
-            1 for f in self.privacy_design.data_fields.values() if f.is_pii and not f.is_encrypted
+            1
+            for f in self.privacy_design.data_fields.values()
+            if f.is_pii and not f.is_encrypted
         )
         if unencrypted_pii > 0:
             risk_factors.append(f"{unencrypted_pii} å€‹ PII æ¬„ä½æœªåŠ å¯†")
@@ -742,7 +777,9 @@ class PrivacyFramework:
             "mitigation_measures": self._generate_mitigation_measures(risk_factors),
         }
 
-    def _generate_mitigation_measures(self, risk_factors: List[str]) -> List[Dict[str, str]]:
+    def _generate_mitigation_measures(
+        self, risk_factors: List[str]
+    ) -> List[Dict[str, str]]:
         """ç”Ÿæˆé¢¨éšªç·©è§£æªæ–½"""
         measures = []
 
@@ -775,7 +812,11 @@ class PrivacyFramework:
 
         if not measures:
             measures.append(
-                {"risk": "ç„¡é‡å¤§é¢¨éšª", "measure": "ç¹¼çºŒç¶­æŒç¾æœ‰éš±ç§ä¿è­·æªæ–½", "priority": "LOW"}
+                {
+                    "risk": "ç„¡é‡å¤§é¢¨éšª",
+                    "measure": "ç¹¼çºŒç¶­æŒç¾æœ‰éš±ç§ä¿è­·æªæ–½",
+                    "priority": "LOW",
+                }
             )
 
         return measures
diff --git a/workspace/src/ai/agents/dependency-manager/src/future/sustainable_analyzer.py b/workspace/src/ai/agents/dependency-manager/src/future/sustainable_analyzer.py
index 5e36af1..684be5f 100644
--- a/workspace/src/ai/agents/dependency-manager/src/future/sustainable_analyzer.py
+++ b/workspace/src/ai/agents/dependency-manager/src/future/sustainable_analyzer.py
@@ -246,7 +246,9 @@ class SustainableAnalyzer:
 
         # è¨ˆç®—å„é …æ’æ”¾
         build_emissions = (
-            factors["base"] + factors["per_mb"] * size_mb + factors["per_dep"] * dependencies_count
+            factors["base"]
+            + factors["per_mb"] * size_mb
+            + factors["per_dep"] * dependencies_count
         )
 
         # é‹è¡Œæ™‚æ’æ”¾ï¼ˆåŸºæ–¼ CPU å’Œè¨˜æ†¶é«”ä¼°ç®—ï¼‰
@@ -356,20 +358,28 @@ class SustainableAnalyzer:
         else:
             return EnergyGrade.F
 
-    def _generate_efficiency_recommendations(self, scores: Dict[str, float]) -> List[str]:
+    def _generate_efficiency_recommendations(
+        self, scores: Dict[str, float]
+    ) -> List[str]:
         """ç”Ÿæˆæ•ˆç‡å„ªåŒ–å»ºè­°"""
         recommendations = []
 
         if scores["cpu"] < 70:
             recommendations.append("ğŸ”§ å„ªåŒ– CPU ä½¿ç”¨ï¼šè€ƒæ…®ä½¿ç”¨æ›´é«˜æ•ˆçš„ç®—æ³•æˆ–éåŒæ­¥è™•ç†")
         if scores["memory"] < 70:
-            recommendations.append("ğŸ”§ å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨ï¼šæª¢æŸ¥è¨˜æ†¶é«”æ´©æ¼ï¼Œä½¿ç”¨ä¸²æµè™•ç†å¤§æ•¸æ“š")
+            recommendations.append(
+                "ğŸ”§ å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨ï¼šæª¢æŸ¥è¨˜æ†¶é«”æ´©æ¼ï¼Œä½¿ç”¨ä¸²æµè™•ç†å¤§æ•¸æ“š"
+            )
         if scores["network"] < 70:
             recommendations.append("ğŸ”§ æ¸›å°‘ç¶²è·¯ä½¿ç”¨ï¼šå•Ÿç”¨å£“ç¸®ï¼Œä½¿ç”¨å¿«å–ï¼Œæ‰¹é‡è™•ç†è«‹æ±‚")
         if scores["storage"] < 70:
-            recommendations.append("ğŸ”§ å„ªåŒ–å­˜å„²ä½¿ç”¨ï¼šæ¸…ç†ä¸å¿…è¦çš„ä¾è³´ï¼Œä½¿ç”¨æ›´å°çš„æ›¿ä»£æ–¹æ¡ˆ")
+            recommendations.append(
+                "ğŸ”§ å„ªåŒ–å­˜å„²ä½¿ç”¨ï¼šæ¸…ç†ä¸å¿…è¦çš„ä¾è³´ï¼Œä½¿ç”¨æ›´å°çš„æ›¿ä»£æ–¹æ¡ˆ"
+            )
         if scores["lifecycle"] < 70:
-            recommendations.append("ğŸ”§ æ”¹å–„ç”Ÿå‘½é€±æœŸç®¡ç†ï¼šæ›´æ–°éæ™‚ä¾è³´ï¼Œç§»é™¤æœªä½¿ç”¨çš„ä¾è³´")
+            recommendations.append(
+                "ğŸ”§ æ”¹å–„ç”Ÿå‘½é€±æœŸç®¡ç†ï¼šæ›´æ–°éæ™‚ä¾è³´ï¼Œç§»é™¤æœªä½¿ç”¨çš„ä¾è³´"
+            )
 
         if not recommendations:
             recommendations.append("âœ… èƒ½æºæ•ˆç‡è‰¯å¥½ï¼Œç¹¼çºŒä¿æŒï¼")
@@ -405,9 +415,9 @@ class SustainableAnalyzer:
 
         # è¨ˆç®—èƒ½æºåˆ†æ•¸ï¼ˆå¦‚æœæœ‰è©•ä¼°ï¼‰
         if self.energy_assessments:
-            energy_score = sum(ea.efficiency_score for ea in self.energy_assessments) / len(
-                self.energy_assessments
-            )
+            energy_score = sum(
+                ea.efficiency_score for ea in self.energy_assessments
+            ) / len(self.energy_assessments)
         else:
             energy_score = 70  # é»˜èªå€¼
 
@@ -420,7 +430,10 @@ class SustainableAnalyzer:
 
         # è¨ˆç®—ç¸½åˆ†
         overall_score = (
-            carbon_score * 0.3 + energy_score * 0.3 + resource_score * 0.2 + lifecycle_score * 0.2
+            carbon_score * 0.3
+            + energy_score * 0.3
+            + resource_score * 0.2
+            + lifecycle_score * 0.2
         )
 
         # ESG åˆè¦è©•ä¼°
@@ -466,7 +479,9 @@ class SustainableAnalyzer:
                 ]
             )
         elif score >= 80:
-            certifications.extend(["ğŸ¥ˆ Sustainable Software Badge", "ğŸ¥ˆ Energy Star Partner Ready"])
+            certifications.extend(
+                ["ğŸ¥ˆ Sustainable Software Badge", "ğŸ¥ˆ Energy Star Partner Ready"]
+            )
         elif score >= 70:
             certifications.append("ğŸ¥‰ Green Coding Initiative Member")
 
@@ -512,9 +527,11 @@ class SustainableAnalyzer:
             f"  ç”Ÿå‘½é€±æœŸè©•åˆ†: {gs.lifecycle_score:.1f}",
             "",
             "ğŸ“ˆ è¶¨å‹¢: "
-            + {"improving": "ğŸ“ˆ æ”¹å–„ä¸­", "stable": "ğŸ“Š ç©©å®š", "declining": "ğŸ“‰ ä¸‹é™ä¸­"}.get(
-                gs.trend, "ğŸ“Š ç©©å®š"
-            ),
+            + {
+                "improving": "ğŸ“ˆ æ”¹å–„ä¸­",
+                "stable": "ğŸ“Š ç©©å®š",
+                "declining": "ğŸ“‰ ä¸‹é™ä¸­",
+            }.get(gs.trend, "ğŸ“Š ç©©å®š"),
             "",
             "ğŸ” ESG åˆè¦ç‹€æ…‹",
             "-" * 40,
diff --git a/workspace/src/ai/agents/dependency-manager/src/implementation/action_guide.py b/workspace/src/ai/agents/dependency-manager/src/implementation/action_guide.py
index 8c9af0e..b88df7e 100644
--- a/workspace/src/ai/agents/dependency-manager/src/implementation/action_guide.py
+++ b/workspace/src/ai/agents/dependency-manager/src/implementation/action_guide.py
@@ -135,8 +135,16 @@ class StrategyEvaluator:
             "description": "æ¡ç”¨æ ¸å¿ƒ-è¡›æ˜Ÿæ¨¡å¼åˆ†æ•£é¢¨éšª",
             "weight": 0.2,
         },
-        "agility": {"name": "å‹•æ…‹èª¿æ•´", "description": "å»ºç«‹æ•æ·çš„ç­–ç•¥èª¿æ•´æ©Ÿåˆ¶", "weight": 0.2},
-        "risk_control": {"name": "é¢¨éšªç®¡æ§", "description": "åˆ¶å®šå®Œå–„çš„æ‡‰æ€¥é æ¡ˆ", "weight": 0.2},
+        "agility": {
+            "name": "å‹•æ…‹èª¿æ•´",
+            "description": "å»ºç«‹æ•æ·çš„ç­–ç•¥èª¿æ•´æ©Ÿåˆ¶",
+            "weight": 0.2,
+        },
+        "risk_control": {
+            "name": "é¢¨éšªç®¡æ§",
+            "description": "åˆ¶å®šå®Œå–„çš„æ‡‰æ€¥é æ¡ˆ",
+            "weight": 0.2,
+        },
     }
 
     def __init__(self):
@@ -284,13 +292,21 @@ class ActionGuide:
             "id": "agility",
             "name": "å‹•æ…‹èª¿æ•´",
             "description": "å»ºç«‹æ•æ·çš„ç­–ç•¥èª¿æ•´æ©Ÿåˆ¶",
-            "actions": ["è¨­å®šé—œéµç¸¾æ•ˆæŒ‡æ¨™", "å»ºç«‹ç›£æ§å’Œé è­¦ç³»çµ±", "åˆ¶å®šèª¿æ•´è§¸ç™¼æ¢ä»¶å’Œæµç¨‹"],
+            "actions": [
+                "è¨­å®šé—œéµç¸¾æ•ˆæŒ‡æ¨™",
+                "å»ºç«‹ç›£æ§å’Œé è­¦ç³»çµ±",
+                "åˆ¶å®šèª¿æ•´è§¸ç™¼æ¢ä»¶å’Œæµç¨‹",
+            ],
         },
         {
             "id": "risk_control",
             "name": "é¢¨éšªç®¡æ§",
             "description": "åˆ¶å®šå®Œå–„çš„æ‡‰æ€¥é æ¡ˆ",
-            "actions": ["è­˜åˆ¥æ½›åœ¨é¢¨éšª", "åˆ¶å®š Plan A/B/C æ‡‰æ€¥ç­–ç•¥", "å®šæœŸæ¼”ç·´å’Œæ›´æ–°é æ¡ˆ"],
+            "actions": [
+                "è­˜åˆ¥æ½›åœ¨é¢¨éšª",
+                "åˆ¶å®š Plan A/B/C æ‡‰æ€¥ç­–ç•¥",
+                "å®šæœŸæ¼”ç·´å’Œæ›´æ–°é æ¡ˆ",
+            ],
         },
     ]
 
@@ -466,11 +482,15 @@ class ActionGuide:
         """æ·»åŠ è¡Œå‹•é …ç›®"""
         self.action_items.append(action)
 
-    def get_recommendations_by_type(self, rec_type: RecommendationType) -> List[Recommendation]:
+    def get_recommendations_by_type(
+        self, rec_type: RecommendationType
+    ) -> List[Recommendation]:
         """æ ¹æ“šé¡å‹ç²å–å»ºè­°"""
         return [r for r in self.recommendations if r.type == rec_type]
 
-    def get_recommendations_by_priority(self, priority: ActionPriority) -> List[Recommendation]:
+    def get_recommendations_by_priority(
+        self, priority: ActionPriority
+    ) -> List[Recommendation]:
         """æ ¹æ“šå„ªå…ˆç´šç²å–å»ºè­°"""
         return [r for r in self.recommendations if r.priority == priority]
 
@@ -534,9 +554,12 @@ class ActionGuide:
         lines.extend(["---", "", "## æ ¸å¿ƒå»ºè­°", ""])
 
         for rec in self.recommendations:
-            priority_icon = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}[
-                rec.priority.value
-            ]
+            priority_icon = {
+                "critical": "ğŸ”´",
+                "high": "ğŸŸ ",
+                "medium": "ğŸŸ¡",
+                "low": "ğŸŸ¢",
+            }[rec.priority.value]
 
             lines.append(f"### {priority_icon} {rec.title}")
             lines.append(f"**é¡å‹ï¼š** {rec.type.value}")
diff --git a/workspace/src/ai/agents/dependency-manager/src/implementation/implementation_plan.py b/workspace/src/ai/agents/dependency-manager/src/implementation/implementation_plan.py
index 1fe604d..80a5bb5 100644
--- a/workspace/src/ai/agents/dependency-manager/src/implementation/implementation_plan.py
+++ b/workspace/src/ai/agents/dependency-manager/src/implementation/implementation_plan.py
@@ -85,7 +85,9 @@ class Task:
             "dependencies": self.dependencies,
             "start_date": self.start_date.isoformat() if self.start_date else None,
             "end_date": self.end_date.isoformat() if self.end_date else None,
-            "completed_date": self.completed_date.isoformat() if self.completed_date else None,
+            "completed_date": (
+                self.completed_date.isoformat() if self.completed_date else None
+            ),
             "progress": self.progress_percentage(),
             "is_overdue": self.is_overdue(),
         }
@@ -140,7 +142,9 @@ class Milestone:
             "description": self.description,
             "target_date": self.target_date.isoformat(),
             "completed": self.completed,
-            "completed_date": self.completed_date.isoformat() if self.completed_date else None,
+            "completed_date": (
+                self.completed_date.isoformat() if self.completed_date else None
+            ),
             "progress": self.progress_percentage(),
             "is_on_track": self.is_on_track(),
             "deliverables": self.deliverables,
@@ -173,7 +177,9 @@ class Phase:
         """è¨ˆç®—éšæ®µé€²åº¦"""
         if not self.milestones:
             return 0.0
-        return sum(m.progress_percentage() for m in self.milestones) / len(self.milestones)
+        return sum(m.progress_percentage() for m in self.milestones) / len(
+            self.milestones
+        )
 
     def is_current(self, current_month: int) -> bool:
         """æª¢æŸ¥æ˜¯å¦ç‚ºç•¶å‰éšæ®µ"""
@@ -316,7 +322,11 @@ class ImplementationPlan:
             description="è©•ä¼°ç­–ç•¥æˆæ•ˆã€èª¿æ•´ç™¼å±•æ–¹å‘ã€æº–å‚™ä¸‹ä¸€å¹´åº¦è¦åŠƒ",
             start_month=10,
             end_month=12,
-            objectives=["è©•ä¼°å„æç¤ºè©ç­–ç•¥æˆæ•ˆ", "èª¿æ•´æœªä¾†ç™¼å±•æ–¹å‘", "æº–å‚™ä¸‹ä¸€å¹´åº¦çš„æŠ€è¡“è·¯ç·šåœ–"],
+            objectives=[
+                "è©•ä¼°å„æç¤ºè©ç­–ç•¥æˆæ•ˆ",
+                "èª¿æ•´æœªä¾†ç™¼å±•æ–¹å‘",
+                "æº–å‚™ä¸‹ä¸€å¹´åº¦çš„æŠ€è¡“è·¯ç·šåœ–",
+            ],
             key_activities=[
                 "æ”¶é›†ä¸¦åˆ†æå„é …æŒ‡æ¨™æ•¸æ“š",
                 "é€²è¡Œç­–ç•¥æˆæ•ˆè©•ä¼°",
@@ -428,7 +438,9 @@ class ImplementationPlan:
         ]
 
         for phase in self.phases:
-            lines.append(f"## {phase.name} (ç¬¬ {phase.start_month}-{phase.end_month} æœˆ)")
+            lines.append(
+                f"## {phase.name} (ç¬¬ {phase.start_month}-{phase.end_month} æœˆ)"
+            )
             lines.append("")
             lines.append(f"**éšæ®µé¡å‹ï¼š** {phase.phase_type.value}")
             lines.append(f"**é€²åº¦ï¼š** {phase.progress_percentage():.1f}%")
diff --git a/workspace/src/ai/agents/dependency-manager/src/implementation/success_metrics.py b/workspace/src/ai/agents/dependency-manager/src/implementation/success_metrics.py
index 9a514c8..1ec4557 100644
--- a/workspace/src/ai/agents/dependency-manager/src/implementation/success_metrics.py
+++ b/workspace/src/ai/agents/dependency-manager/src/implementation/success_metrics.py
@@ -61,7 +61,9 @@ class TechnicalMetric:
 
     def add_data_point(self, value: float, notes: str = "") -> None:
         """æ·»åŠ æ•¸æ“šé»"""
-        self.data_points.append(MetricDataPoint(value=value, timestamp=datetime.now(), notes=notes))
+        self.data_points.append(
+            MetricDataPoint(value=value, timestamp=datetime.now(), notes=notes)
+        )
 
     def current_value(self) -> Optional[float]:
         """ç²å–ç•¶å‰å€¼"""
@@ -155,7 +157,9 @@ class BusinessMetric:
 
     def add_data_point(self, value: float, notes: str = "") -> None:
         """æ·»åŠ æ•¸æ“šé»"""
-        self.data_points.append(MetricDataPoint(value=value, timestamp=datetime.now(), notes=notes))
+        self.data_points.append(
+            MetricDataPoint(value=value, timestamp=datetime.now(), notes=notes)
+        )
 
     def current_value(self) -> Optional[float]:
         """ç²å–ç•¶å‰å€¼"""
@@ -246,7 +250,9 @@ class OrganizationalMetric:
 
     def add_data_point(self, value: float, notes: str = "") -> None:
         """æ·»åŠ æ•¸æ“šé»"""
-        self.data_points.append(MetricDataPoint(value=value, timestamp=datetime.now(), notes=notes))
+        self.data_points.append(
+            MetricDataPoint(value=value, timestamp=datetime.now(), notes=notes)
+        )
 
     def current_value(self) -> Optional[float]:
         """ç²å–ç•¶å‰å€¼"""
diff --git a/workspace/src/ai/agents/dependency-manager/src/models/vulnerability.py b/workspace/src/ai/agents/dependency-manager/src/models/vulnerability.py
index 048c7aa..e4d247e 100644
--- a/workspace/src/ai/agents/dependency-manager/src/models/vulnerability.py
+++ b/workspace/src/ai/agents/dependency-manager/src/models/vulnerability.py
@@ -101,7 +101,9 @@ class Vulnerability:
             "cvss_score": self.cvss_score,
             "source": self.source.value,
             "references": self.references,
-            "published_at": self.published_at.isoformat() if self.published_at else None,
+            "published_at": (
+                self.published_at.isoformat() if self.published_at else None
+            ),
         }
 
     def __str__(self) -> str:
diff --git a/workspace/src/ai/agents/dependency-manager/src/scanners/license_scanner.py b/workspace/src/ai/agents/dependency-manager/src/scanners/license_scanner.py
index 653887e..710ba76 100644
--- a/workspace/src/ai/agents/dependency-manager/src/scanners/license_scanner.py
+++ b/workspace/src/ai/agents/dependency-manager/src/scanners/license_scanner.py
@@ -53,7 +53,13 @@ class LicensePolicy:
         }
     )
     warning: Set[str] = field(
-        default_factory=lambda: {"LGPL-2.1", "LGPL-3.0", "MPL-2.0", "EPL-1.0", "EPL-2.0"}
+        default_factory=lambda: {
+            "LGPL-2.1",
+            "LGPL-3.0",
+            "MPL-2.0",
+            "EPL-1.0",
+            "EPL-2.0",
+        }
     )
     blocked: Set[str] = field(
         default_factory=lambda: {"GPL-2.0", "GPL-3.0", "AGPL-3.0", "SSPL-1.0"}
@@ -254,7 +260,9 @@ class LicenseScanner:
             package=dep.name, license_id=license_id, category=category, status=status
         )
 
-    async def _get_license(self, package_name: str, ecosystem: Ecosystem) -> Optional[str]:
+    async def _get_license(
+        self, package_name: str, ecosystem: Ecosystem
+    ) -> Optional[str]:
         """
         ç²å–å¥—ä»¶çš„è¨±å¯è­‰
 
diff --git a/workspace/src/ai/agents/dependency-manager/src/scanners/vulnerability_scanner.py b/workspace/src/ai/agents/dependency-manager/src/scanners/vulnerability_scanner.py
index aa103aa..4aa4cdd 100644
--- a/workspace/src/ai/agents/dependency-manager/src/scanners/vulnerability_scanner.py
+++ b/workspace/src/ai/agents/dependency-manager/src/scanners/vulnerability_scanner.py
@@ -47,9 +47,15 @@ class VulnerabilityScanner:
             config: æƒæé…ç½®ï¼Œå¦‚æœªæä¾›å‰‡ä½¿ç”¨é»˜èªé…ç½®
         """
         self.config = config or ScanConfig(
-            sources=[VulnerabilitySource.NVD, VulnerabilitySource.GHSA, VulnerabilitySource.OSV]
+            sources=[
+                VulnerabilitySource.NVD,
+                VulnerabilitySource.GHSA,
+                VulnerabilitySource.OSV,
+            ]
+        )
+        logger.info(
+            f"æ¼æ´æƒæå™¨åˆå§‹åŒ–å®Œæˆï¼Œæ•¸æ“šæº: {[s.value for s in self.config.sources]}"
         )
-        logger.info(f"æ¼æ´æƒæå™¨åˆå§‹åŒ–å®Œæˆï¼Œæ•¸æ“šæº: {[s.value for s in self.config.sources]}")
 
     async def scan(self, dependencies: List[Dependency]) -> VulnerabilityScanResult:
         """
@@ -77,7 +83,9 @@ class VulnerabilityScanner:
             scanned.add(package_key)
 
             # æƒææ¯å€‹æ•¸æ“šæº
-            vulnerabilities = await self._scan_package(dep.name, dep.current_version, dep.ecosystem)
+            vulnerabilities = await self._scan_package(
+                dep.name, dep.current_version, dep.ecosystem
+            )
 
             for vuln in vulnerabilities:
                 # æª¢æŸ¥æ˜¯å¦ç¬¦åˆåš´é‡ç¨‹åº¦é–¾å€¼
@@ -111,7 +119,9 @@ class VulnerabilityScanner:
 
         for source in self.config.sources:
             try:
-                source_vulns = await self._query_source(source, package_name, version, ecosystem)
+                source_vulns = await self._query_source(
+                    source, package_name, version, ecosystem
+                )
                 vulnerabilities.extend(source_vulns)
             except Exception as e:
                 logger.warning(f"æŸ¥è©¢ {source.value} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
@@ -122,7 +132,11 @@ class VulnerabilityScanner:
         return unique_vulns
 
     async def _query_source(
-        self, source: VulnerabilitySource, package_name: str, version: str, ecosystem: Ecosystem
+        self,
+        source: VulnerabilitySource,
+        package_name: str,
+        version: str,
+        ecosystem: Ecosystem,
     ) -> List[Vulnerability]:
         """
         æŸ¥è©¢æŒ‡å®šæ•¸æ“šæº
diff --git a/workspace/src/ai/agents/dependency-manager/src/strategy/__init__.py b/workspace/src/ai/agents/dependency-manager/src/strategy/__init__.py
index 275cf74..0415045 100644
--- a/workspace/src/ai/agents/dependency-manager/src/strategy/__init__.py
+++ b/workspace/src/ai/agents/dependency-manager/src/strategy/__init__.py
@@ -13,7 +13,12 @@ MIT License
 """
 
 from .case_study_engine import CaseStudy, CaseStudyEngine, EvolutionPhase, LessonLearned
-from .evolution_tracker import EvolutionTracker, MaturityLevel, PhaseTransition, ProjectMaturity
+from .evolution_tracker import (
+    EvolutionTracker,
+    MaturityLevel,
+    PhaseTransition,
+    ProjectMaturity,
+)
 from .resource_optimizer import (
     BudgetAllocation,
     OptimizationResult,
diff --git a/workspace/src/ai/agents/dependency-manager/src/strategy/case_study_engine.py b/workspace/src/ai/agents/dependency-manager/src/strategy/case_study_engine.py
index 7a53c74..3709eac 100644
--- a/workspace/src/ai/agents/dependency-manager/src/strategy/case_study_engine.py
+++ b/workspace/src/ai/agents/dependency-manager/src/strategy/case_study_engine.py
@@ -182,7 +182,12 @@ class CaseStudyEngine:
                     phase_type=PhaseType.GROWTH,
                     strategy=DevelopmentStrategy.HIGH_MARKET_RETURN,
                     description="å¤§é‡æŠ•è³‡å…§å®¹æˆæ¬Šï¼Œå¿«é€Ÿæ“´å±•ç”¨æˆ¶åŸºæ•¸",
-                    key_actions=["æ“´å¤§å…§å®¹åº«", "å„ªåŒ–æ¨è–¦ç³»çµ±", "åœ‹éš›åŒ–æ“´å±•", "æå‡ä¸²æµå“è³ª"],
+                    key_actions=[
+                        "æ“´å¤§å…§å®¹åº«",
+                        "å„ªåŒ–æ¨è–¦ç³»çµ±",
+                        "åœ‹éš›åŒ–æ“´å±•",
+                        "æå‡ä¸²æµå“è³ª",
+                    ],
                     success_metrics={
                         "ç”¨æˆ¶å¢é•·": "å¹´å¢é•· > 30%",
                         "è§€çœ‹æ™‚é•·": "æœˆå‡ > 40 å°æ™‚",
@@ -196,7 +201,12 @@ class CaseStudyEngine:
                     phase_type=PhaseType.MATURITY,
                     strategy=DevelopmentStrategy.HIGH_VALUE,
                     description="é–‹ç™¼åŸå‰µå…§å®¹ï¼Œå»ºç«‹å“ç‰Œè­·åŸæ²³",
-                    key_actions=["æŠ•è³‡åŸå‰µå…§å®¹", "å»ºç«‹è£½ä½œèƒ½åŠ›", "å…¨çƒåŒ–å…§å®¹ç­–ç•¥", "å»ºç«‹ IP è³‡ç”¢"],
+                    key_actions=[
+                        "æŠ•è³‡åŸå‰µå…§å®¹",
+                        "å»ºç«‹è£½ä½œèƒ½åŠ›",
+                        "å…¨çƒåŒ–å…§å®¹ç­–ç•¥",
+                        "å»ºç«‹ IP è³‡ç”¢",
+                    ],
                     success_metrics={
                         "åŸå‰µå…§å®¹ä½”æ¯”": "> 50%",
                         "ç²çæ•¸é‡": "è‰¾ç¾ç > 100",
@@ -237,15 +247,27 @@ class CaseStudyEngine:
                         "è¨­ç«‹ç¨ç«‹åœ˜éšŠæ¢ç´¢æ–°æ¥­å‹™",
                         "è¨­å®šæ˜ç¢ºçš„è½‰æ›é‡Œç¨‹ç¢‘",
                     ],
-                    common_mistakes=["éæ—©æ”¾æ£„ç¾æœ‰æ¥­å‹™", "è³‡æºåˆ†é…å¤±è¡¡", "å¿½è¦–ç¾æœ‰å®¢æˆ¶éœ€æ±‚"],
+                    common_mistakes=[
+                        "éæ—©æ”¾æ£„ç¾æœ‰æ¥­å‹™",
+                        "è³‡æºåˆ†é…å¤±è¡¡",
+                        "å¿½è¦–ç¾æœ‰å®¢æˆ¶éœ€æ±‚",
+                    ],
                 ),
                 LessonLearned(
                     category="æŠ€è¡“æŠ•è³‡",
                     title="æ¨è–¦ç³»çµ±æ˜¯æ ¸å¿ƒç«¶çˆ­åŠ›",
                     description="å€‹äººåŒ–æ¨è–¦æ¸›å°‘ç”¨æˆ¶æ±ºç­–ç–²å‹ï¼Œæé«˜é»è‘—åº¦",
                     applicability=["å…§å®¹å¹³å°", "é›»å•†", "SaaS"],
-                    implementation_tips=["å¾ç°¡å–®è¦å‰‡é–‹å§‹", "æŒçºŒæ”¶é›†ç”¨æˆ¶åé¥‹", "A/B æ¸¬è©¦é©—è­‰æ•ˆæœ"],
-                    common_mistakes=["éåº¦ä¾è³´è¤‡é›œæ¼”ç®—æ³•", "å¿½è¦–å†·å•Ÿå‹•å•é¡Œ", "æ¨è–¦åŒè³ªåŒ–"],
+                    implementation_tips=[
+                        "å¾ç°¡å–®è¦å‰‡é–‹å§‹",
+                        "æŒçºŒæ”¶é›†ç”¨æˆ¶åé¥‹",
+                        "A/B æ¸¬è©¦é©—è­‰æ•ˆæœ",
+                    ],
+                    common_mistakes=[
+                        "éåº¦ä¾è³´è¤‡é›œæ¼”ç®—æ³•",
+                        "å¿½è¦–å†·å•Ÿå‹•å•é¡Œ",
+                        "æ¨è–¦åŒè³ªåŒ–",
+                    ],
                 ),
                 LessonLearned(
                     category="å…§å®¹ç­–ç•¥",
@@ -257,7 +279,11 @@ class CaseStudyEngine:
                         "èˆ‡å„ªç§€å‰µä½œè€…åˆä½œ",
                         "å»ºç«‹æ•¸æ“šé©…å‹•çš„è£½ä½œæµç¨‹",
                     ],
-                    common_mistakes=["ç›²ç›®è¿½æ±‚æ•¸é‡", "å¿½è¦–æœ¬åœ°åŒ–éœ€æ±‚", "éåº¦ä¾è³´æ˜æ˜Ÿæ•ˆæ‡‰"],
+                    common_mistakes=[
+                        "ç›²ç›®è¿½æ±‚æ•¸é‡",
+                        "å¿½è¦–æœ¬åœ°åŒ–éœ€æ±‚",
+                        "éåº¦ä¾è³´æ˜æ˜Ÿæ•ˆæ‡‰",
+                    ],
                 ),
             ],
             key_success_factors=[
@@ -340,7 +366,12 @@ class CaseStudyEngine:
                     phase_type=PhaseType.INNOVATION,
                     strategy=DevelopmentStrategy.INTELLIGENT,
                     description="æ•´åˆ AI é©…å‹•çš„åº«å­˜ç®¡ç†å’ŒéŠ·å”®é æ¸¬",
-                    key_actions=["AI åº«å­˜å„ªåŒ–", "æ™ºèƒ½å®šåƒ¹å»ºè­°", "éŠ·å”®é æ¸¬æ¨¡å‹", "æ™ºèƒ½åº—é¢è¨­è¨ˆ"],
+                    key_actions=[
+                        "AI åº«å­˜å„ªåŒ–",
+                        "æ™ºèƒ½å®šåƒ¹å»ºè­°",
+                        "éŠ·å”®é æ¸¬æ¨¡å‹",
+                        "æ™ºèƒ½åº—é¢è¨­è¨ˆ",
+                    ],
                     success_metrics={
                         "é æ¸¬æº–ç¢ºåº¦": "> 85%",
                         "åº«å­˜é€±è½‰ç‡": "æå‡ > 20%",
@@ -374,14 +405,22 @@ class CaseStudyEngine:
                         "æä¾›é–‹ç™¼è€…æ¿€å‹µè¨ˆç•«",
                         "å»ºç«‹å“è³ªå¯©æ ¸æ©Ÿåˆ¶",
                     ],
-                    common_mistakes=["API è¨­è¨ˆä¸ä¸€è‡´", "ç¼ºä¹é–‹ç™¼è€…æ”¯æ´", "å¹³å°æŠ½æˆéé«˜"],
+                    common_mistakes=[
+                        "API è¨­è¨ˆä¸ä¸€è‡´",
+                        "ç¼ºä¹é–‹ç™¼è€…æ”¯æ´",
+                        "å¹³å°æŠ½æˆéé«˜",
+                    ],
                 ),
                 LessonLearned(
                     category="è®Šç¾ç­–ç•¥",
                     title="æ”¯ä»˜æ•´åˆæ˜¯é‡è¦æ”¶å…¥ä¾†æº",
                     description="Shopify Payments å‰µé€ å¯é æ¸¬çš„æ”¶å…¥æµ",
                     applicability=["é›»å•†å¹³å°", "å¸‚é›†", "é‡‘èç§‘æŠ€"],
-                    implementation_tips=["ç°¡åŒ–æ”¯ä»˜æµç¨‹", "æä¾›æœ‰ç«¶çˆ­åŠ›çš„è²»ç‡", "ç¢ºä¿åˆè¦æ€§"],
+                    implementation_tips=[
+                        "ç°¡åŒ–æ”¯ä»˜æµç¨‹",
+                        "æä¾›æœ‰ç«¶çˆ­åŠ›çš„è²»ç‡",
+                        "ç¢ºä¿åˆè¦æ€§",
+                    ],
                     common_mistakes=["å¿½è¦–åˆè¦è¦æ±‚", "è²»ç‡ä¸é€æ˜", "æ”¯ä»˜é«”é©—å·®"],
                 ),
             ],
@@ -408,7 +447,12 @@ class CaseStudyEngine:
                     phase_type=PhaseType.INITIAL,
                     strategy=DevelopmentStrategy.ADVANCED,
                     description="ç‚ºé–‹ç™¼è€…æ‰“é€ æœ€ç°¡å–®çš„æ”¯ä»˜ API",
-                    key_actions=["è¨­è¨ˆç›´è§€çš„ API", "å„ªè³ªæ–‡æª”æ’°å¯«", "ç°¡åŒ–æ•´åˆæµç¨‹", "æä¾›æ¸¬è©¦æ²™ç®±"],
+                    key_actions=[
+                        "è¨­è¨ˆç›´è§€çš„ API",
+                        "å„ªè³ªæ–‡æª”æ’°å¯«",
+                        "ç°¡åŒ–æ•´åˆæµç¨‹",
+                        "æä¾›æ¸¬è©¦æ²™ç®±",
+                    ],
                     success_metrics={
                         "æ•´åˆæ™‚é–“": "< 1 å°æ™‚",
                         "é–‹ç™¼è€…æ»¿æ„åº¦": "> 4.5/5",
@@ -422,7 +466,12 @@ class CaseStudyEngine:
                     phase_type=PhaseType.GROWTH,
                     strategy=DevelopmentStrategy.ENTERPRISE_GRADE,
                     description="æ“´å±•åˆ°ä¼æ¥­ç´šåŠŸèƒ½ï¼Œæ”¯æ´è¤‡é›œæ”¯ä»˜å ´æ™¯",
-                    key_actions=["å¤šå¹£ç¨®æ”¯æ´", "è¨‚é–±ç®¡ç†åŠŸèƒ½", "æ¬ºè©æª¢æ¸¬ç³»çµ±", "åˆè¦å·¥å…·"],
+                    key_actions=[
+                        "å¤šå¹£ç¨®æ”¯æ´",
+                        "è¨‚é–±ç®¡ç†åŠŸèƒ½",
+                        "æ¬ºè©æª¢æ¸¬ç³»çµ±",
+                        "åˆè¦å·¥å…·",
+                    ],
                     success_metrics={
                         "æ”¯æ´è²¨å¹£æ•¸": "> 135",
                         "æ¬ºè©é˜»æ“‹ç‡": "> 99%",
@@ -455,7 +504,12 @@ class CaseStudyEngine:
                     phase_type=PhaseType.INNOVATION,
                     strategy=DevelopmentStrategy.NEXT_GEN,
                     description="æ¢ç´¢ä¸‹ä¸–ä»£é‡‘èæŠ€è¡“å’Œå…¨çƒæ“´å±•",
-                    key_actions=["åŠ å¯†è²¨å¹£æ”¯æ´", "åµŒå…¥å¼é‡‘è", "å…¨çƒéŠ€è¡Œé€£æ¥", "å³æ™‚æ”¯ä»˜ç¶²çµ¡"],
+                    key_actions=[
+                        "åŠ å¯†è²¨å¹£æ”¯æ´",
+                        "åµŒå…¥å¼é‡‘è",
+                        "å…¨çƒéŠ€è¡Œé€£æ¥",
+                        "å³æ™‚æ”¯ä»˜ç¶²çµ¡",
+                    ],
                     success_metrics={
                         "æ–°å¸‚å ´é€²å…¥": "> 10 åœ‹å®¶/å¹´",
                         "æ–°ç”¢å“æ”¶å…¥": "> 20%",
@@ -477,7 +531,11 @@ class CaseStudyEngine:
                         "æä¾›å¤šèªè¨€ SDK",
                         "ç¶­è­·äº’å‹•å¼æ–‡æª”",
                     ],
-                    common_mistakes=["API ç‰ˆæœ¬ç®¡ç†æ··äº‚", "æ–‡æª”èˆ‡ä»£ç¢¼ä¸åŒæ­¥", "éŒ¯èª¤è¨Šæ¯ä¸æ¸…æ¥š"],
+                    common_mistakes=[
+                        "API ç‰ˆæœ¬ç®¡ç†æ··äº‚",
+                        "æ–‡æª”èˆ‡ä»£ç¢¼ä¸åŒæ­¥",
+                        "éŒ¯èª¤è¨Šæ¯ä¸æ¸…æ¥š",
+                    ],
                 ),
                 LessonLearned(
                     category="ç”¢å“æ“´å±•",
@@ -492,7 +550,13 @@ class CaseStudyEngine:
                     common_mistakes=["éæ—©å¤šå…ƒåŒ–", "å¿½è¦–æ ¸å¿ƒç”¢å“", "æ•´åˆä¸å¤ ç·Šå¯†"],
                 ),
             ],
-            key_success_factors=["é–‹ç™¼è€…å„ªå…ˆ", "å“è¶Šçš„æ–‡æª”", "æŒçºŒå‰µæ–°", "åˆè¦å…ˆè¡Œ", "å…¨çƒåŒ–æ€ç¶­"],
+            key_success_factors=[
+                "é–‹ç™¼è€…å„ªå…ˆ",
+                "å“è¶Šçš„æ–‡æª”",
+                "æŒçºŒå‰µæ–°",
+                "åˆè¦å…ˆè¡Œ",
+                "å…¨çƒåŒ–æ€ç¶­",
+            ],
             technology_stack=["Ruby", "Scala", "Go", "React", "AWS"],
             business_model="äº¤æ˜“æŠ½æˆ + æœå‹™è²»",
             market_position="å…¨çƒé ˜å…ˆæ”¯ä»˜åŸºç¤è¨­æ–½",
diff --git a/workspace/src/ai/agents/dependency-manager/src/strategy/evolution_tracker.py b/workspace/src/ai/agents/dependency-manager/src/strategy/evolution_tracker.py
index 04acb3b..e74e5c7 100644
--- a/workspace/src/ai/agents/dependency-manager/src/strategy/evolution_tracker.py
+++ b/workspace/src/ai/agents/dependency-manager/src/strategy/evolution_tracker.py
@@ -251,7 +251,9 @@ class EvolutionTracker:
         current_phase = self._determine_phase(project_data, overall_score)
 
         # è¨ˆç®—éšæ®µé€²åº¦
-        phase_progress = self._calculate_phase_progress(current_phase, project_data, dimensions)
+        phase_progress = self._calculate_phase_progress(
+            current_phase, project_data, dimensions
+        )
 
         # è­˜åˆ¥é˜»ç¤™å› ç´ 
         blockers = self._identify_blockers(dimensions, project_data)
@@ -313,7 +315,9 @@ class EvolutionTracker:
         else:
             return MaturityLevel.INITIAL
 
-    def _determine_phase(self, data: Dict[str, Any], overall_score: float) -> DevelopmentPhase:
+    def _determine_phase(
+        self, data: Dict[str, Any], overall_score: float
+    ) -> DevelopmentPhase:
         """åˆ¤æ–·ç•¶å‰ç™¼å±•éšæ®µ"""
         # æ ¹æ“šé—œéµæŒ‡æ¨™åˆ¤æ–·
         revenue = data.get("revenue", 0)
@@ -528,7 +532,10 @@ class EvolutionTracker:
             return base * 2
 
     def _identify_transition_risks(
-        self, maturity: ProjectMaturity, from_phase: DevelopmentPhase, to_phase: DevelopmentPhase
+        self,
+        maturity: ProjectMaturity,
+        from_phase: DevelopmentPhase,
+        to_phase: DevelopmentPhase,
     ) -> List[str]:
         """è­˜åˆ¥è½‰æ›é¢¨éšª"""
         risks = []
@@ -541,7 +548,10 @@ class EvolutionTracker:
         weakest = maturity.get_weakest_dimension()
         strongest = maturity.get_strongest_dimension()
         if maturity.dimensions:
-            score_diff = maturity.dimensions[strongest].score - maturity.dimensions[weakest].score
+            score_diff = (
+                maturity.dimensions[strongest].score
+                - maturity.dimensions[weakest].score
+            )
             if score_diff > 30:
                 risks.append(f"ç¶­åº¦ç™¼å±•ä¸å¹³è¡¡ï¼š{weakest} æ˜é¡¯è½å¾Œ")
 
@@ -828,7 +838,9 @@ class EvolutionTracker:
 
             report.append("\n### é‡Œç¨‹ç¢‘")
             for milestone in roadmap.milestones:
-                report.append(f"\n**{milestone['phase']}** (ç¬¬ {milestone['target_date']} å€‹æœˆ)")
+                report.append(
+                    f"\n**{milestone['phase']}** (ç¬¬ {milestone['target_date']} å€‹æœˆ)"
+                )
                 for metric, value in milestone["key_metrics"].items():
                     report.append(f"- {metric}: {value}")
 
diff --git a/workspace/src/ai/agents/dependency-manager/src/strategy/resource_optimizer.py b/workspace/src/ai/agents/dependency-manager/src/strategy/resource_optimizer.py
index 1b54c69..9cd3570 100644
--- a/workspace/src/ai/agents/dependency-manager/src/strategy/resource_optimizer.py
+++ b/workspace/src/ai/agents/dependency-manager/src/strategy/resource_optimizer.py
@@ -70,7 +70,9 @@ class BudgetAllocation:
 
     def get_by_priority(self, priority: int) -> List[str]:
         """æ ¹æ“šå„ªå…ˆç´šç²å–é¡åˆ¥"""
-        return [name for name, cat in self.allocations.items() if cat.priority == priority]
+        return [
+            name for name, cat in self.allocations.items() if cat.priority == priority
+        ]
 
     def to_dict(self) -> Dict[str, Any]:
         """è½‰æ›ç‚ºå­—å…¸"""
@@ -120,7 +122,9 @@ class TeamAllocation:
 
     def get_by_criticality(self, criticality: str) -> List[str]:
         """æ ¹æ“šé—œéµåº¦ç²å–è§’è‰²"""
-        return [name for name, role in self.roles.items() if role.criticality == criticality]
+        return [
+            name for name, role in self.roles.items() if role.criticality == criticality
+        ]
 
     def to_dict(self) -> Dict[str, Any]:
         """è½‰æ›ç‚ºå­—å…¸"""
@@ -235,7 +239,11 @@ class ResourceOptimizer:
             "marketing": {"ratio": 0.15, "criticality": "critical", "cost": 100000},
             "sales": {"ratio": 0.20, "criticality": "critical", "cost": 110000},
             "operations": {"ratio": 0.10, "criticality": "important", "cost": 85000},
-            "customer_success": {"ratio": 0.05, "criticality": "important", "cost": 75000},
+            "customer_success": {
+                "ratio": 0.05,
+                "criticality": "important",
+                "cost": 75000,
+            },
         },
         "enterprise": {
             "engineering": {"ratio": 0.30, "criticality": "critical", "cost": 150000},
@@ -243,7 +251,11 @@ class ResourceOptimizer:
             "marketing": {"ratio": 0.10, "criticality": "important", "cost": 110000},
             "sales": {"ratio": 0.20, "criticality": "critical", "cost": 130000},
             "operations": {"ratio": 0.15, "criticality": "important", "cost": 90000},
-            "customer_success": {"ratio": 0.10, "criticality": "critical", "cost": 85000},
+            "customer_success": {
+                "ratio": 0.10,
+                "criticality": "critical",
+                "cost": 85000,
+            },
             "finance": {"ratio": 0.05, "criticality": "important", "cost": 120000},
         },
     }
@@ -314,7 +326,9 @@ class ResourceOptimizer:
                 cat.amount *= adjustment_ratio
 
         # è¨ˆç®—å„ªåŒ–åˆ†æ•¸
-        optimization_score = self._calculate_budget_optimization_score(allocations, strategy)
+        optimization_score = self._calculate_budget_optimization_score(
+            allocations, strategy
+        )
 
         return BudgetAllocation(
             total_budget=total_budget,
@@ -329,7 +343,9 @@ class ResourceOptimizer:
     ) -> float:
         """è¨ˆç®—é ç®—å„ªåŒ–åˆ†æ•¸"""
         # åŸºæ–¼æœ‰æ•ˆåƒ¹å€¼è¨ˆç®—åˆ†æ•¸
-        total_effective_value = sum(cat.get_effective_value() for cat in allocations.values())
+        total_effective_value = sum(
+            cat.get_effective_value() for cat in allocations.values()
+        )
         total_amount = sum(cat.amount for cat in allocations.values())
 
         if total_amount == 0:
@@ -342,8 +358,12 @@ class ResourceOptimizer:
         strategy_bonus = {
             AllocationStrategy.BALANCED: 10,
             AllocationStrategy.GROWTH_FOCUSED: 15 if "marketing" in allocations else 5,
-            AllocationStrategy.EFFICIENCY_FOCUSED: 15 if "operations" in allocations else 5,
-            AllocationStrategy.INNOVATION_FOCUSED: 15 if "r_and_d" in allocations else 5,
+            AllocationStrategy.EFFICIENCY_FOCUSED: (
+                15 if "operations" in allocations else 5
+            ),
+            AllocationStrategy.INNOVATION_FOCUSED: (
+                15 if "r_and_d" in allocations else 5
+            ),
             AllocationStrategy.RISK_AVERSE: 10,
         }
         score += strategy_bonus.get(strategy, 0)
@@ -411,7 +431,9 @@ class ResourceOptimizer:
                                 if config["criticality"] == "critical"
                                 else 2 if config["criticality"] == "important" else 3
                             ),
-                            "timeline_months": 1 if config["criticality"] == "critical" else 3,
+                            "timeline_months": (
+                                1 if config["criticality"] == "critical" else 3
+                            ),
                         }
                     )
 
@@ -504,7 +526,9 @@ class ResourceOptimizer:
         payback_months = self._calculate_payback_period(total_budget, projected_roi)
 
         # é¢¨éšªè©•ä¼°
-        risk_score = self._calculate_risk_score(budget_allocation, team_allocation, strategy)
+        risk_score = self._calculate_risk_score(
+            budget_allocation, team_allocation, strategy
+        )
 
         # æ•æ„Ÿåº¦åˆ†æ
         sensitivity = self._perform_sensitivity_analysis(
@@ -565,7 +589,10 @@ class ResourceOptimizer:
         return min(120, max(1, round(months)))
 
     def _calculate_risk_score(
-        self, budget: BudgetAllocation, team: TeamAllocation, strategy: AllocationStrategy
+        self,
+        budget: BudgetAllocation,
+        team: TeamAllocation,
+        strategy: AllocationStrategy,
     ) -> float:
         """è¨ˆç®—é¢¨éšªåˆ†æ•¸ (0-100, è¶Šé«˜è¶Šå±éšª)"""
         score = 20.0  # åŸºç¤é¢¨éšª
@@ -581,7 +608,9 @@ class ResourceOptimizer:
         score += strategy_risk.get(strategy, 0)
 
         # é ç®—é›†ä¸­åº¦é¢¨éšª
-        max_ratio = max(cat.amount / budget.total_budget for cat in budget.allocations.values())
+        max_ratio = max(
+            cat.amount / budget.total_budget for cat in budget.allocations.values()
+        )
         if max_ratio > 0.4:
             score += 15
 
@@ -650,7 +679,8 @@ class ResourceOptimizer:
             if "growth" in [g.lower() for g in goals]:
                 if (
                     "marketing" not in budget.allocations
-                    or budget.allocations["marketing"].amount < budget.total_budget * 0.15
+                    or budget.allocations["marketing"].amount
+                    < budget.total_budget * 0.15
                 ):
                     recommendations.append("å¢é•·ç›®æ¨™éœ€è¦æ›´å¤šè¡ŒéŠ·æŠ•è³‡")
 
@@ -676,7 +706,9 @@ class ResourceOptimizer:
         report.append("\n## ä¸€ã€é ç®—åˆ†é…")
         report.append(f"\n**ç¸½é ç®—**: ${result.budget_allocation.total_budget:,.0f}")
         report.append(f"**åˆ†é…ç­–ç•¥**: {result.budget_allocation.strategy.value}")
-        report.append(f"**å„ªåŒ–åˆ†æ•¸**: {result.budget_allocation.optimization_score:.1f}/100")
+        report.append(
+            f"**å„ªåŒ–åˆ†æ•¸**: {result.budget_allocation.optimization_score:.1f}/100"
+        )
 
         report.append("\n| é¡åˆ¥ | é‡‘é¡ | ä½”æ¯” | å„ªå…ˆç´š | é æœŸ ROI |")
         report.append("|------|------|------|--------|----------|")
@@ -692,7 +724,9 @@ class ResourceOptimizer:
         report.append(f"\n**ç¸½äººæ•¸**: {result.team_allocation.total_headcount}")
         report.append(f"**å¹´åº¦æˆæœ¬**: ${result.team_allocation.total_cost:,.0f}")
         report.append(f"**çµ„ç¹”çµæ§‹**: {result.team_allocation.structure}")
-        report.append(f"**å„ªåŒ–åˆ†æ•¸**: {result.team_allocation.optimization_score:.1f}/100")
+        report.append(
+            f"**å„ªåŒ–åˆ†æ•¸**: {result.team_allocation.optimization_score:.1f}/100"
+        )
 
         report.append("\n| è§’è‰² | äººæ•¸ | å¹´è–ª | ç¸½æˆæœ¬ | é—œéµåº¦ |")
         report.append("|------|------|------|--------|--------|")
diff --git a/workspace/src/ai/agents/dependency-manager/src/strategy/strategy_advisor.py b/workspace/src/ai/agents/dependency-manager/src/strategy/strategy_advisor.py
index 4eadf05..493b35f 100644
--- a/workspace/src/ai/agents/dependency-manager/src/strategy/strategy_advisor.py
+++ b/workspace/src/ai/agents/dependency-manager/src/strategy/strategy_advisor.py
@@ -105,7 +105,9 @@ class TechCapabilityAssessment:
         if not self.capabilities:
             return 0.0
 
-        cap_avg = sum(c.get_score() for c in self.capabilities.values()) / len(self.capabilities)
+        cap_avg = sum(c.get_score() for c in self.capabilities.values()) / len(
+            self.capabilities
+        )
 
         weighted = (
             cap_avg * 0.5
@@ -118,7 +120,9 @@ class TechCapabilityAssessment:
 
     def get_strengths(self) -> List[str]:
         """ç²å–å„ªå‹¢é ˜åŸŸ"""
-        return [name for name, cap in self.capabilities.items() if cap.get_score() >= 70]
+        return [
+            name for name, cap in self.capabilities.items() if cap.get_score() >= 70
+        ]
 
     def get_gaps(self) -> List[str]:
         """ç²å–èƒ½åŠ›ç¼ºå£"""
@@ -256,7 +260,13 @@ class StrategyAdvisor:
                 "security",
                 "testing",
             ],
-            "data": ["analytics", "ml_ai", "data_engineering", "visualization", "governance"],
+            "data": [
+                "analytics",
+                "ml_ai",
+                "data_engineering",
+                "visualization",
+                "governance",
+            ],
             "business": [
                 "product_management",
                 "ux_design",
@@ -565,7 +575,9 @@ class StrategyAdvisor:
         if overall_score >= 70 and timing_score >= 60:
             # é«˜èƒ½åŠ› + å¥½æ™‚æ©Ÿ â†’ ç©æ¥µæ“´å¼µ
             recommendations.append(
-                self._create_expansion_strategy(capability_assessment, market_analysis, constraints)
+                self._create_expansion_strategy(
+                    capability_assessment, market_analysis, constraints
+                )
             )
 
         if overall_score < 50:
@@ -576,7 +588,9 @@ class StrategyAdvisor:
 
         if "growth" in [g.lower() for g in business_goals]:
             # è¿½æ±‚å¢é•· â†’ å¸‚å ´æ“´å¼µç­–ç•¥
-            recommendations.append(self._create_growth_strategy(market_analysis, constraints))
+            recommendations.append(
+                self._create_growth_strategy(market_analysis, constraints)
+            )
 
         if "innovation" in [g.lower() for g in business_goals]:
             # è¿½æ±‚å‰µæ–° â†’ æŠ€è¡“å‰µæ–°ç­–ç•¥
@@ -592,13 +606,19 @@ class StrategyAdvisor:
 
         # æŒ‰å„ªå…ˆç´šå’Œä¿¡å¿ƒåˆ†æ•¸æ’åº
         recommendations.sort(
-            key=lambda r: (list(StrategicPriority).index(r.priority), -r.confidence_score)
+            key=lambda r: (
+                list(StrategicPriority).index(r.priority),
+                -r.confidence_score,
+            )
         )
 
         return recommendations
 
     def _create_expansion_strategy(
-        self, cap: TechCapabilityAssessment, market: MarketTimingAnalysis, constraints: Dict
+        self,
+        cap: TechCapabilityAssessment,
+        market: MarketTimingAnalysis,
+        constraints: Dict,
     ) -> StrategyRecommendation:
         """å‰µå»ºæ“´å¼µç­–ç•¥"""
         budget = constraints.get("budget", 1000000)
@@ -640,7 +660,11 @@ class StrategyAdvisor:
             strategy_name="æŠ€è¡“èƒ½åŠ›å»ºè¨­",
             priority=StrategicPriority.CRITICAL,
             rationale=f"åœ˜éšŠèƒ½åŠ›å­˜åœ¨ç¼ºå£: {', '.join(gaps[:3])}",
-            prerequisites=["ç®¡ç†å±¤èªåŒæŠ•è³‡éœ€æ±‚", "ç¢ºå®šé‡é»ç™¼å±•é ˜åŸŸ", "å»ºç«‹äººæ‰æ‹›å‹Ÿç®¡é“"],
+            prerequisites=[
+                "ç®¡ç†å±¤èªåŒæŠ•è³‡éœ€æ±‚",
+                "ç¢ºå®šé‡é»ç™¼å±•é ˜åŸŸ",
+                "å»ºç«‹äººæ‰æ‹›å‹Ÿç®¡é“",
+            ],
             expected_outcomes=["æŠ€è¡“èƒ½åŠ›æå‡ 30%", "é™ä½æŠ€è¡“å‚µå‹™", "æå‡äº¤ä»˜æ•ˆç‡"],
             estimated_timeline_months=12,
             estimated_investment={
diff --git a/workspace/src/ai/agents/dependency-manager/src/updaters/auto_updater.py b/workspace/src/ai/agents/dependency-manager/src/updaters/auto_updater.py
index 85b5400..cf143f8 100644
--- a/workspace/src/ai/agents/dependency-manager/src/updaters/auto_updater.py
+++ b/workspace/src/ai/agents/dependency-manager/src/updaters/auto_updater.py
@@ -198,7 +198,9 @@ class AutoUpdater:
         except (ValueError, IndexError):
             return VersionParts()
 
-    def _get_policy(self, update_type: UpdateType, is_security_fix: bool) -> UpdatePolicy:
+    def _get_policy(
+        self, update_type: UpdateType, is_security_fix: bool
+    ) -> UpdatePolicy:
         """
         ç²å–æ›´æ–°ç­–ç•¥
 
diff --git a/workspace/src/ai/agents/dependency-manager/src/utils/audit_logger.py b/workspace/src/ai/agents/dependency-manager/src/utils/audit_logger.py
index 57e990b..33b4d46 100644
--- a/workspace/src/ai/agents/dependency-manager/src/utils/audit_logger.py
+++ b/workspace/src/ai/agents/dependency-manager/src/utils/audit_logger.py
@@ -231,17 +231,24 @@ class AuditLogger:
         self, package: str, vulnerability_id: str, severity: str
     ) -> AuditEvent:
         """è¨˜éŒ„ç™¼ç¾æ¼æ´"""
-        audit_severity = AuditSeverity.CRITICAL if severity == "CRITICAL" else AuditSeverity.WARNING
+        audit_severity = (
+            AuditSeverity.CRITICAL if severity == "CRITICAL" else AuditSeverity.WARNING
+        )
 
         return self.log(
             event_type=AuditEventType.VULNERABILITY_DETECTED,
             target=package,
             details=f"ç™¼ç¾æ¼æ´ {vulnerability_id} (åš´é‡ç¨‹åº¦: {severity})",
             severity=audit_severity,
-            metadata={"vulnerability_id": vulnerability_id, "vulnerability_severity": severity},
+            metadata={
+                "vulnerability_id": vulnerability_id,
+                "vulnerability_severity": severity,
+            },
         )
 
-    def log_update_started(self, package: str, from_version: str, to_version: str) -> AuditEvent:
+    def log_update_started(
+        self, package: str, from_version: str, to_version: str
+    ) -> AuditEvent:
         """è¨˜éŒ„æ›´æ–°é–‹å§‹"""
         return self.log(
             event_type=AuditEventType.UPDATE_STARTED,
@@ -250,7 +257,9 @@ class AuditLogger:
             metadata={"from_version": from_version, "to_version": to_version},
         )
 
-    def log_update_completed(self, package: str, from_version: str, to_version: str) -> AuditEvent:
+    def log_update_completed(
+        self, package: str, from_version: str, to_version: str
+    ) -> AuditEvent:
         """è¨˜éŒ„æ›´æ–°å®Œæˆ"""
         return self.log(
             event_type=AuditEventType.UPDATE_COMPLETED,
@@ -364,7 +373,10 @@ class AuditLogger:
                 or event.timestamp < summary["time_range"]["start"]
             ):
                 summary["time_range"]["start"] = event.timestamp
-            if not summary["time_range"]["end"] or event.timestamp > summary["time_range"]["end"]:
+            if (
+                not summary["time_range"]["end"]
+                or event.timestamp > summary["time_range"]["end"]
+            ):
                 summary["time_range"]["end"] = event.timestamp
 
         # è½‰æ›æ™‚é–“æ ¼å¼
diff --git a/workspace/src/ai/agents/dependency-manager/src/utils/dependency_tree.py b/workspace/src/ai/agents/dependency-manager/src/utils/dependency_tree.py
index c038ff2..abec007 100644
--- a/workspace/src/ai/agents/dependency-manager/src/utils/dependency_tree.py
+++ b/workspace/src/ai/agents/dependency-manager/src/utils/dependency_tree.py
@@ -83,7 +83,9 @@ class DependencyTree:
         logger.info(f"åˆå§‹åŒ–ä¾è³´æ¨¹: {project_name}")
 
     def build_tree(
-        self, dependencies: List[Dependency], parent_map: Optional[Dict[str, List[str]]] = None
+        self,
+        dependencies: List[Dependency],
+        parent_map: Optional[Dict[str, List[str]]] = None,
     ) -> None:
         """
         å»ºæ§‹ä¾è³´æ¨¹
@@ -211,7 +213,9 @@ class DependencyTree:
         child_prefix = prefix + ("    " if is_last else "â”‚   ")
         for i, child in enumerate(node.children):
             child_is_last = i == len(node.children) - 1
-            lines.extend(self._render_node(child, child_prefix, child_is_last, show_risk))
+            lines.extend(
+                self._render_node(child, child_prefix, child_is_last, show_risk)
+            )
 
         return lines
 
diff --git a/workspace/src/ai/agents/dependency-manager/src/utils/language_boundary.py b/workspace/src/ai/agents/dependency-manager/src/utils/language_boundary.py
index 8fb02fc..93b0be8 100644
--- a/workspace/src/ai/agents/dependency-manager/src/utils/language_boundary.py
+++ b/workspace/src/ai/agents/dependency-manager/src/utils/language_boundary.py
@@ -51,7 +51,9 @@ class LanguageRegistry:
     TERMS = {
         # ä¾è³´ç›¸é—œ
         "dependency": TranslationEntry("dependency", "ä¾è³´é …", "Dependency", "ä¾èµ–é¡¹"),
-        "dependencies": TranslationEntry("dependencies", "ä¾è³´é …", "Dependencies", "ä¾èµ–é¡¹"),
+        "dependencies": TranslationEntry(
+            "dependencies", "ä¾è³´é …", "Dependencies", "ä¾èµ–é¡¹"
+        ),
         "direct_dependency": TranslationEntry(
             "direct_dependency", "ç›´æ¥ä¾è³´", "Direct Dependency", "ç›´æ¥ä¾èµ–"
         ),
@@ -75,15 +77,21 @@ class LanguageRegistry:
         "minor": TranslationEntry("minor", "æ¬¡ç‰ˆæœ¬", "Minor", "æ¬¡ç‰ˆæœ¬"),
         "patch": TranslationEntry("patch", "ä¿®è£œç‰ˆæœ¬", "Patch", "ä¿®è¡¥ç‰ˆæœ¬"),
         # æ¼æ´ç›¸é—œ
-        "vulnerability": TranslationEntry("vulnerability", "æ¼æ´", "Vulnerability", "æ¼æ´"),
-        "vulnerabilities": TranslationEntry("vulnerabilities", "æ¼æ´", "Vulnerabilities", "æ¼æ´"),
+        "vulnerability": TranslationEntry(
+            "vulnerability", "æ¼æ´", "Vulnerability", "æ¼æ´"
+        ),
+        "vulnerabilities": TranslationEntry(
+            "vulnerabilities", "æ¼æ´", "Vulnerabilities", "æ¼æ´"
+        ),
         "critical": TranslationEntry("critical", "åš´é‡", "Critical", "ä¸¥é‡"),
         "high": TranslationEntry("high", "é«˜", "High", "é«˜"),
         "medium": TranslationEntry("medium", "ä¸­", "Medium", "ä¸­"),
         "low": TranslationEntry("low", "ä½", "Low", "ä½"),
         "severity": TranslationEntry("severity", "åš´é‡ç¨‹åº¦", "Severity", "ä¸¥é‡ç¨‹åº¦"),
         "cve": TranslationEntry("cve", "æ¼æ´ç·¨è™Ÿ", "CVE", "æ¼æ´ç¼–å·"),
-        "fixed_version": TranslationEntry("fixed_version", "ä¿®å¾©ç‰ˆæœ¬", "Fixed Version", "ä¿®å¤ç‰ˆæœ¬"),
+        "fixed_version": TranslationEntry(
+            "fixed_version", "ä¿®å¾©ç‰ˆæœ¬", "Fixed Version", "ä¿®å¤ç‰ˆæœ¬"
+        ),
         # è¨±å¯è­‰ç›¸é—œ
         "license": TranslationEntry("license", "è¨±å¯è­‰", "License", "è®¸å¯è¯"),
         "allowed": TranslationEntry("allowed", "å…è¨±", "Allowed", "å…è®¸"),
@@ -93,9 +101,15 @@ class LanguageRegistry:
         # æ›´æ–°ç›¸é—œ
         "update": TranslationEntry("update", "æ›´æ–°", "Update", "æ›´æ–°"),
         "updates": TranslationEntry("updates", "æ›´æ–°", "Updates", "æ›´æ–°"),
-        "auto_update": TranslationEntry("auto_update", "è‡ªå‹•æ›´æ–°", "Auto Update", "è‡ªåŠ¨æ›´æ–°"),
-        "manual_review": TranslationEntry("manual_review", "äººå·¥å¯©æŸ¥", "Manual Review", "äººå·¥å®¡æŸ¥"),
-        "pull_request": TranslationEntry("pull_request", "æ‹‰å–è«‹æ±‚", "Pull Request", "æ‹‰å–è¯·æ±‚"),
+        "auto_update": TranslationEntry(
+            "auto_update", "è‡ªå‹•æ›´æ–°", "Auto Update", "è‡ªåŠ¨æ›´æ–°"
+        ),
+        "manual_review": TranslationEntry(
+            "manual_review", "äººå·¥å¯©æŸ¥", "Manual Review", "äººå·¥å®¡æŸ¥"
+        ),
+        "pull_request": TranslationEntry(
+            "pull_request", "æ‹‰å–è«‹æ±‚", "Pull Request", "æ‹‰å–è¯·æ±‚"
+        ),
         "rollback": TranslationEntry("rollback", "å›æ»¾", "Rollback", "å›æ»š"),
         # æ“ä½œç›¸é—œ
         "analysis": TranslationEntry("analysis", "åˆ†æ", "Analysis", "åˆ†æ"),
@@ -107,7 +121,9 @@ class LanguageRegistry:
         "skipped": TranslationEntry("skipped", "è·³é", "Skipped", "è·³è¿‡"),
         # é¢¨éšªç›¸é—œ
         "risk": TranslationEntry("risk", "é¢¨éšª", "Risk", "é£é™©"),
-        "risk_level": TranslationEntry("risk_level", "é¢¨éšªç­‰ç´š", "Risk Level", "é£é™©ç­‰çº§"),
+        "risk_level": TranslationEntry(
+            "risk_level", "é¢¨éšªç­‰ç´š", "Risk Level", "é£é™©ç­‰çº§"
+        ),
         "breaking_change": TranslationEntry(
             "breaking_change", "ç ´å£æ€§è®Šæ›´", "Breaking Change", "ç ´åæ€§å˜æ›´"
         ),
@@ -125,7 +141,9 @@ class LanguageRegistry:
         "minutes": TranslationEntry("minutes", "åˆ†é˜", "Minutes", "åˆ†é’Ÿ"),
         # ç­–ç•¥ç›¸é—œ
         "policy": TranslationEntry("policy", "ç­–ç•¥", "Policy", "ç­–ç•¥"),
-        "conservative": TranslationEntry("conservative", "ä¿å®ˆ", "Conservative", "ä¿å®ˆ"),
+        "conservative": TranslationEntry(
+            "conservative", "ä¿å®ˆ", "Conservative", "ä¿å®ˆ"
+        ),
         "balanced": TranslationEntry("balanced", "å¹³è¡¡", "Balanced", "å¹³è¡¡"),
         "aggressive": TranslationEntry("aggressive", "ç©æ¥µ", "Aggressive", "ç§¯æ"),
         "security_first": TranslationEntry(
@@ -378,7 +396,8 @@ class LanguageBoundary:
                     result[local_key] = localize_dict(value)
                 elif isinstance(value, list):
                     result[local_key] = [
-                        localize_dict(item) if isinstance(item, dict) else item for item in value
+                        localize_dict(item) if isinstance(item, dict) else item
+                        for item in value
                     ]
                 else:
                     result[local_key] = value
diff --git a/workspace/src/ai/agents/dependency-manager/src/utils/policy_simulator.py b/workspace/src/ai/agents/dependency-manager/src/utils/policy_simulator.py
index 2be3554..c938409 100644
--- a/workspace/src/ai/agents/dependency-manager/src/utils/policy_simulator.py
+++ b/workspace/src/ai/agents/dependency-manager/src/utils/policy_simulator.py
@@ -204,7 +204,9 @@ class PolicySimulator:
         """
         logger.info(f"é–‹å§‹æ¨¡æ“¬: {scenario.name}")
 
-        result = SimulationResult(scenario=scenario, total_dependencies=analysis.total_count)
+        result = SimulationResult(
+            scenario=scenario, total_dependencies=analysis.total_count
+        )
 
         # æ¨¡æ“¬æ¯å€‹éæ™‚ä¾è³´çš„æ›´æ–°
         for dep in analysis.dependencies:
@@ -297,7 +299,9 @@ class PolicySimulator:
 
         return comparison
 
-    def _simulate_update(self, dep: Dependency, scenario: SimulationScenario) -> Optional[Update]:
+    def _simulate_update(
+        self, dep: Dependency, scenario: SimulationScenario
+    ) -> Optional[Update]:
         """
         æ¨¡æ“¬å–®å€‹ä¾è³´çš„æ›´æ–°
 
@@ -312,7 +316,9 @@ class PolicySimulator:
             return None
 
         # åˆ¤æ–·æ›´æ–°é¡å‹
-        update_type = self._classify_update_type(dep.current_version, dep.latest_version)
+        update_type = self._classify_update_type(
+            dep.current_version, dep.latest_version
+        )
 
         # å®‰å…¨å„ªå…ˆæ¨¡å¼ç‰¹æ®Šè™•ç†
         if scenario.mode == SimulationMode.SECURITY_ONLY:
@@ -470,7 +476,9 @@ class PolicySimulator:
         self._scenarios.append(scenario)
         logger.info(f"å·²æ·»åŠ è‡ªå®šç¾©æƒ…å¢ƒ: {scenario.name}")
 
-    def generate_report(self, results: List[SimulationResult], lang: str = "zh-TW") -> str:
+    def generate_report(
+        self, results: List[SimulationResult], lang: str = "zh-TW"
+    ) -> str:
         """
         ç”Ÿæˆæ¨¡æ“¬å ±å‘Š
 
diff --git a/workspace/src/ai/agents/dependency-manager/tests/test_models.py b/workspace/src/ai/agents/dependency-manager/tests/test_models.py
index 376cf5d..85f5a02 100644
--- a/workspace/src/ai/agents/dependency-manager/tests/test_models.py
+++ b/workspace/src/ai/agents/dependency-manager/tests/test_models.py
@@ -3,8 +3,10 @@
 Tests for Dependency Manager Agent
 """
 
-from models.vulnerability import Vulnerability, VulnerabilitySeverity, VulnerabilitySource
-from models.update import Update, UpdatePolicy, UpdateResult, UpdateStatus, UpdateType
+import sys
+from pathlib import Path
+
+import pytest
 from models.dependency import (
     Dependency,
     DependencyAnalysis,
@@ -12,10 +14,12 @@ from models.dependency import (
     DependencyType,
     Ecosystem,
 )
-import sys
-from pathlib import Path
-
-import pytest
+from models.update import Update, UpdatePolicy, UpdateResult, UpdateStatus, UpdateType
+from models.vulnerability import (
+    Vulnerability,
+    VulnerabilitySeverity,
+    VulnerabilitySource,
+)
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
@@ -51,7 +55,10 @@ class TestDependencyModel:
 
         # æœ€æ–°ç‰ˆæœ¬
         dep_current = Dependency(
-            name="axios", current_version="1.6.0", ecosystem=Ecosystem.NPM, latest_version="1.6.0"
+            name="axios",
+            current_version="1.6.0",
+            ecosystem=Ecosystem.NPM,
+            latest_version="1.6.0",
         )
 
         assert dep_current.is_outdated() is False
@@ -160,11 +167,17 @@ class TestUpdateModel:
         result = UpdateResult(result_id="update-123")
 
         success_update = Update(
-            package="axios", from_version="1.5.0", to_version="1.6.0", status=UpdateStatus.SUCCESS
+            package="axios",
+            from_version="1.5.0",
+            to_version="1.6.0",
+            status=UpdateStatus.SUCCESS,
         )
 
         failed_update = Update(
-            package="moment", from_version="2.29.0", to_version="2.30.0", status=UpdateStatus.FAILED
+            package="moment",
+            from_version="2.29.0",
+            to_version="2.30.0",
+            status=UpdateStatus.FAILED,
         )
 
         result.add_update(success_update)
diff --git a/workspace/src/ai/agents/dependency-manager/tests/test_phase10.py b/workspace/src/ai/agents/dependency-manager/tests/test_phase10.py
index 33406c0..f33dceb 100644
--- a/workspace/src/ai/agents/dependency-manager/tests/test_phase10.py
+++ b/workspace/src/ai/agents/dependency-manager/tests/test_phase10.py
@@ -84,7 +84,11 @@ class TestImplementationPlan(unittest.TestCase):
         from implementation.implementation_plan import Task
 
         task = Task(
-            id="task_1", name="æ¸¬è©¦ä»»å‹™", description="æ¸¬è©¦", estimated_hours=40, actual_hours=20
+            id="task_1",
+            name="æ¸¬è©¦ä»»å‹™",
+            description="æ¸¬è©¦",
+            estimated_hours=40,
+            actual_hours=20,
         )
 
         self.assertEqual(task.progress_percentage(), 50.0)
@@ -182,10 +186,14 @@ class TestSuccessMetrics(unittest.TestCase):
 
         tracker = SuccessMetricsTracker()
 
-        result = tracker.record_value(MetricCategory.TECHNICAL, "code_quality", 85.0, "æ¸¬è©¦è¨˜éŒ„")
+        result = tracker.record_value(
+            MetricCategory.TECHNICAL, "code_quality", 85.0, "æ¸¬è©¦è¨˜éŒ„"
+        )
 
         self.assertTrue(result)
-        self.assertEqual(tracker.technical_metrics["code_quality"].current_value(), 85.0)
+        self.assertEqual(
+            tracker.technical_metrics["code_quality"].current_value(), 85.0
+        )
 
     def test_metric_status(self):
         """æ¸¬è©¦æŒ‡æ¨™ç‹€æ…‹"""
@@ -325,7 +333,11 @@ class TestActionGuide(unittest.TestCase):
 
     def test_recommendation_creation(self):
         """æ¸¬è©¦å»ºè­°å‰µå»º"""
-        from implementation.action_guide import ActionPriority, Recommendation, RecommendationType
+        from implementation.action_guide import (
+            ActionPriority,
+            Recommendation,
+            RecommendationType,
+        )
 
         rec = Recommendation(
             id="rec_1",
diff --git a/workspace/src/ai/agents/dependency-manager/tests/test_phase2.py b/workspace/src/ai/agents/dependency-manager/tests/test_phase2.py
index 36e5242..c125aba 100644
--- a/workspace/src/ai/agents/dependency-manager/tests/test_phase2.py
+++ b/workspace/src/ai/agents/dependency-manager/tests/test_phase2.py
@@ -3,17 +3,17 @@
 Phase 2 Tests - Analyzers and Utils
 """
 
-from utils.dependency_tree import DependencyTree, RiskLevel, TreeNode
-from utils.audit_logger import AuditEventType, AuditLogger, AuditSeverity
-from models.dependency import Dependency, DependencyType, Ecosystem
-from analyzers.pip_analyzer import PipAnalyzer
-from analyzers.go_analyzer import GoAnalyzer
 import os
 import sys
 import tempfile
 from pathlib import Path
 
 import pytest
+from analyzers.go_analyzer import GoAnalyzer
+from analyzers.pip_analyzer import PipAnalyzer
+from models.dependency import Dependency, DependencyType, Ecosystem
+from utils.audit_logger import AuditEventType, AuditLogger, AuditSeverity
+from utils.dependency_tree import DependencyTree, RiskLevel, TreeNode
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
@@ -87,7 +87,9 @@ class TestPipAnalyzer:
 
         assert analyzer._extract_poetry_version("^1.0.0") == "1.0.0"
         assert analyzer._extract_poetry_version({"version": "^2.0.0"}) == "2.0.0"
-        assert analyzer._extract_poetry_version({"git": "https://github.com/..."}) == "git"
+        assert (
+            analyzer._extract_poetry_version({"git": "https://github.com/..."}) == "git"
+        )
         assert analyzer._extract_poetry_version("*") == "*"
 
 
@@ -99,7 +101,9 @@ class TestGoAnalyzer:
         analyzer = GoAnalyzer()
 
         assert analyzer._clean_version("v1.0.0") == "1.0.0"
-        assert analyzer._clean_version("v0.0.0-20210101-abcdef") == "0.0.0-20210101-abcdef"
+        assert (
+            analyzer._clean_version("v0.0.0-20210101-abcdef") == "0.0.0-20210101-abcdef"
+        )
         assert analyzer._clean_version("1.2.3") == "1.2.3"
 
     def test_parse_require_line(self):
@@ -166,8 +170,12 @@ class TestDependencyTree:
         tree = DependencyTree("test-project")
 
         deps = [
-            Dependency(name="express", current_version="4.18.0", ecosystem=Ecosystem.NPM),
-            Dependency(name="lodash", current_version="4.17.21", ecosystem=Ecosystem.NPM),
+            Dependency(
+                name="express", current_version="4.18.0", ecosystem=Ecosystem.NPM
+            ),
+            Dependency(
+                name="lodash", current_version="4.17.21", ecosystem=Ecosystem.NPM
+            ),
         ]
 
         tree.build_tree(deps)
@@ -207,7 +215,9 @@ class TestDependencyTree:
         tree = DependencyTree("test-project")
 
         deps = [
-            Dependency(name="express", current_version="4.18.0", ecosystem=Ecosystem.NPM),
+            Dependency(
+                name="express", current_version="4.18.0", ecosystem=Ecosystem.NPM
+            ),
         ]
 
         tree.build_tree(deps)
@@ -253,7 +263,9 @@ class TestAuditLogger:
         audit = AuditLogger()
 
         event = audit.log(
-            event_type=AuditEventType.ANALYSIS_STARTED, target="test-project", details="é–‹å§‹åˆ†æ"
+            event_type=AuditEventType.ANALYSIS_STARTED,
+            target="test-project",
+            details="é–‹å§‹åˆ†æ",
         )
 
         assert event.event_type == AuditEventType.ANALYSIS_STARTED
diff --git a/workspace/src/ai/agents/dependency-manager/tests/test_phase3.py b/workspace/src/ai/agents/dependency-manager/tests/test_phase3.py
index 24d472c..ae737cb 100644
--- a/workspace/src/ai/agents/dependency-manager/tests/test_phase3.py
+++ b/workspace/src/ai/agents/dependency-manager/tests/test_phase3.py
@@ -3,12 +3,12 @@
 Phase 3 Tests - Policy Simulator and Language Boundary
 """
 
-from utils.policy_simulator import (
-    PolicySimulator,
-    SimulationMode,
-    SimulationResult,
-    SimulationScenario,
-)
+import sys
+from pathlib import Path
+
+import pytest
+from models.dependency import Dependency, DependencyAnalysis, DependencyType, Ecosystem
+from models.update import UpdatePolicy, UpdateType
 from utils.language_boundary import (
     LanguageBoundary,
     LanguageRegistry,
@@ -17,12 +17,12 @@ from utils.language_boundary import (
     msg,
     t,
 )
-from models.update import UpdatePolicy, UpdateType
-from models.dependency import Dependency, DependencyAnalysis, DependencyType, Ecosystem
-import sys
-from pathlib import Path
-
-import pytest
+from utils.policy_simulator import (
+    PolicySimulator,
+    SimulationMode,
+    SimulationResult,
+    SimulationScenario,
+)
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
@@ -247,7 +247,9 @@ class TestLanguageBoundary:
 
     def test_format_message_with_language(self):
         """æ¸¬è©¦æŒ‡å®šèªè¨€æ¶ˆæ¯"""
-        result = self.lb.msg("analysis_started", lang=OutputLanguage.EN, project="test-project")
+        result = self.lb.msg(
+            "analysis_started", lang=OutputLanguage.EN, project="test-project"
+        )
         assert "test-project" in result
         assert "Starting" in result
 
diff --git a/workspace/src/ai/agents/dependency-manager/tests/test_phase4.py b/workspace/src/ai/agents/dependency-manager/tests/test_phase4.py
index 5b43e0e..3715424 100644
--- a/workspace/src/ai/agents/dependency-manager/tests/test_phase4.py
+++ b/workspace/src/ai/agents/dependency-manager/tests/test_phase4.py
@@ -8,18 +8,17 @@ Phase 4 ä¼æ¥­ç´šåŠŸèƒ½å–®å…ƒæ¸¬è©¦
 - ä¸‹ä¸–ä»£å®‰å…¨æ¨¡çµ„
 """
 
-from enterprise.security import (
-    ComplianceFramework,
-    NextGenSecurity,
-    SBOMFormat,
-    SupplyChainRisk,
-    TrustLevel,
-)
-from enterprise.recommendation import (
-    HealthScore,
-    IntelligentRecommendation,
-    RecommendationType,
-    RiskLevel,
+import os
+import sys
+import unittest
+from datetime import datetime, timedelta
+
+from enterprise.analytics import (
+    CommercialAnalytics,
+    CostCategory,
+    CostItem,
+    TechDebtItem,
+    TechDebtType,
 )
 from enterprise.integration import (
     AuthMethod,
@@ -28,17 +27,19 @@ from enterprise.integration import (
     IntegrationType,
     WebhookEvent,
 )
-from enterprise.analytics import (
-    CommercialAnalytics,
-    CostCategory,
-    CostItem,
-    TechDebtItem,
-    TechDebtType,
+from enterprise.recommendation import (
+    HealthScore,
+    IntelligentRecommendation,
+    RecommendationType,
+    RiskLevel,
+)
+from enterprise.security import (
+    ComplianceFramework,
+    NextGenSecurity,
+    SBOMFormat,
+    SupplyChainRisk,
+    TrustLevel,
 )
-import os
-import sys
-import unittest
-from datetime import datetime, timedelta
 
 # æ·»åŠ è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
@@ -97,7 +98,9 @@ class TestEnterpriseIntegration(unittest.TestCase):
         self.assertEqual(len(enabled), 1)
 
         # æŒ‰é¡å‹
-        slack_only = self.integration.list_integrations(integration_type=IntegrationType.SLACK)
+        slack_only = self.integration.list_integrations(
+            integration_type=IntegrationType.SLACK
+        )
         self.assertEqual(len(slack_only), 1)
 
     def test_webhook_handler(self):
@@ -247,8 +250,18 @@ class TestCommercialAnalytics(unittest.TestCase):
     def test_comprehensive_analysis(self):
         """æ¸¬è©¦ç¶œåˆåˆ†æ"""
         dependencies = [
-            {"name": "express", "version": "4.18.0", "outdated": True, "vulnerabilities": 1},
-            {"name": "lodash", "version": "4.17.21", "outdated": False, "vulnerabilities": 0},
+            {
+                "name": "express",
+                "version": "4.18.0",
+                "outdated": True,
+                "vulnerabilities": 1,
+            },
+            {
+                "name": "lodash",
+                "version": "4.17.21",
+                "outdated": False,
+                "vulnerabilities": 0,
+            },
         ]
 
         analysis = self.analytics.comprehensive_analysis(dependencies)
@@ -342,8 +355,18 @@ class TestIntelligentRecommendation(unittest.TestCase):
     def test_generate_recommendations(self):
         """æ¸¬è©¦å»ºè­°ç”Ÿæˆ"""
         dependencies = [
-            {"name": "lodash", "version": "4.0.0", "outdated": True, "vulnerabilities": 0},
-            {"name": "moment", "version": "2.29.0", "outdated": False, "vulnerabilities": 0},
+            {
+                "name": "lodash",
+                "version": "4.0.0",
+                "outdated": True,
+                "vulnerabilities": 0,
+            },
+            {
+                "name": "moment",
+                "version": "2.29.0",
+                "outdated": False,
+                "vulnerabilities": 0,
+            },
         ]
 
         recommendations = self.engine.generate_recommendations(dependencies)
@@ -351,7 +374,9 @@ class TestIntelligentRecommendation(unittest.TestCase):
         self.assertGreater(len(recommendations), 0)
 
         # moment æ‡‰æœ‰æ›¿æ›å»ºè­°
-        replace_recs = [r for r in recommendations if r.rec_type == RecommendationType.REPLACE]
+        replace_recs = [
+            r for r in recommendations if r.rec_type == RecommendationType.REPLACE
+        ]
         self.assertGreater(len(replace_recs), 0)
 
     def test_generate_insight_report(self):
@@ -457,7 +482,9 @@ class TestNextGenSecurity(unittest.TestCase):
 
         self.assertGreater(len(alerts), 0)
 
-        malicious_alerts = [a for a in alerts if a.risk_type == SupplyChainRisk.MALICIOUS_PACKAGE]
+        malicious_alerts = [
+            a for a in alerts if a.risk_type == SupplyChainRisk.MALICIOUS_PACKAGE
+        ]
         self.assertGreater(len(malicious_alerts), 0)
 
     def test_analyze_supply_chain_unpinned(self):
@@ -468,7 +495,9 @@ class TestNextGenSecurity(unittest.TestCase):
 
         alerts = self.security.analyze_supply_chain(dependencies)
 
-        unpinned_alerts = [a for a in alerts if a.risk_type == SupplyChainRisk.UNPINNED_DEPENDENCY]
+        unpinned_alerts = [
+            a for a in alerts if a.risk_type == SupplyChainRisk.UNPINNED_DEPENDENCY
+        ]
         self.assertGreater(len(unpinned_alerts), 0)
 
     def test_assess_trust(self):
@@ -489,7 +518,9 @@ class TestNextGenSecurity(unittest.TestCase):
 
     def test_assess_trust_malicious(self):
         """æ¸¬è©¦ä¿¡ä»»è©•ä¼° - æƒ¡æ„å¥—ä»¶"""
-        assessment = self.security.assess_trust(package_name="event-stream", version="3.3.6")
+        assessment = self.security.assess_trust(
+            package_name="event-stream", version="3.3.6"
+        )
 
         self.assertEqual(assessment.trust_level, TrustLevel.UNTRUSTED)
 
diff --git a/workspace/src/ai/agents/dependency-manager/tests/test_phase5.py b/workspace/src/ai/agents/dependency-manager/tests/test_phase5.py
index ebda9f4..055a44c 100644
--- a/workspace/src/ai/agents/dependency-manager/tests/test_phase5.py
+++ b/workspace/src/ai/agents/dependency-manager/tests/test_phase5.py
@@ -12,15 +12,29 @@ Copyright (c) 2024 MachineNativeOps
 MIT License
 """
 
-from strategy.strategy_advisor import (
-    CapabilityLevel,
-    MarketMaturity,
-    MarketTimingAnalysis,
-    StrategicPriority,
-    StrategyAdvisor,
-    StrategyRecommendation,
-    TechCapability,
-    TechCapabilityAssessment,
+import os
+
+# æ¨¡æ“¬å°å…¥ï¼ˆæ¸¬è©¦æ™‚éœ€è¦ç¢ºä¿è·¯å¾‘æ­£ç¢ºï¼‰
+import sys
+import unittest
+from datetime import datetime
+from typing import Any, Dict
+
+from strategy.case_study_engine import (
+    CaseStudy,
+    CaseStudyEngine,
+    DevelopmentStrategy,
+    EvolutionPhase,
+    LessonLearned,
+    PhaseType,
+)
+from strategy.evolution_tracker import (
+    DevelopmentPhase,
+    EvolutionRoadmap,
+    EvolutionTracker,
+    MaturityLevel,
+    PhaseTransition,
+    ProjectMaturity,
 )
 from strategy.resource_optimizer import (
     AllocationStrategy,
@@ -31,29 +45,16 @@ from strategy.resource_optimizer import (
     TeamAllocation,
     TeamRole,
 )
-from strategy.evolution_tracker import (
-    DevelopmentPhase,
-    EvolutionRoadmap,
-    EvolutionTracker,
-    MaturityLevel,
-    PhaseTransition,
-    ProjectMaturity,
-)
-from strategy.case_study_engine import (
-    CaseStudy,
-    CaseStudyEngine,
-    DevelopmentStrategy,
-    EvolutionPhase,
-    LessonLearned,
-    PhaseType,
+from strategy.strategy_advisor import (
+    CapabilityLevel,
+    MarketMaturity,
+    MarketTimingAnalysis,
+    StrategicPriority,
+    StrategyAdvisor,
+    StrategyRecommendation,
+    TechCapability,
+    TechCapabilityAssessment,
 )
-import os
-
-# æ¨¡æ“¬å°å…¥ï¼ˆæ¸¬è©¦æ™‚éœ€è¦ç¢ºä¿è·¯å¾‘æ­£ç¢ºï¼‰
-import sys
-import unittest
-from datetime import datetime
-from typing import Any, Dict
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
@@ -110,7 +111,9 @@ class TestCaseStudyEngine(unittest.TestCase):
 
     def test_find_cases_by_strategy(self):
         """æ¸¬è©¦æ ¹æ“šç­–ç•¥æŸ¥æ‰¾æ¡ˆä¾‹"""
-        results = self.engine.find_cases_by_strategy(DevelopmentStrategy.COMMERCIAL_ORIENTED)
+        results = self.engine.find_cases_by_strategy(
+            DevelopmentStrategy.COMMERCIAL_ORIENTED
+        )
         self.assertGreater(len(results), 0)
 
         # çµæœæ‡‰è©²åŒ…å«æ¡ˆä¾‹å’Œéšæ®µ
@@ -221,10 +224,22 @@ class TestStrategyAdvisor(unittest.TestCase):
                     "certifications": ["AWS"],
                     "tools": {"Python": "expert"},
                 },
-                "frontend": {"level": "intermediate", "team_members": 3, "experience_years": 2.0},
+                "frontend": {
+                    "level": "intermediate",
+                    "team_members": 3,
+                    "experience_years": 2.0,
+                },
+            },
+            "infrastructure": {
+                "has_cloud": True,
+                "has_ci_cd": True,
+                "has_monitoring": True,
+            },
+            "process": {
+                "has_agile": True,
+                "has_code_review": True,
+                "has_testing": True,
             },
-            "infrastructure": {"has_cloud": True, "has_ci_cd": True, "has_monitoring": True},
-            "process": {"has_agile": True, "has_code_review": True, "has_testing": True},
             "culture": {"innovation_mindset": 0.7, "customer_focus": 0.8},
         }
 
@@ -359,7 +374,9 @@ class TestResourceOptimizer(unittest.TestCase):
 
         # å¢é•·å°å‘æ‡‰è©²æœ‰è¼ƒå¤šè¡ŒéŠ·é ç®—
         if "marketing" in allocation.allocations:
-            marketing_ratio = allocation.allocations["marketing"].amount / allocation.total_budget
+            marketing_ratio = (
+                allocation.allocations["marketing"].amount / allocation.total_budget
+            )
             self.assertGreater(marketing_ratio, 0.2)
 
     def test_optimize_budget_with_constraints(self):
@@ -434,7 +451,9 @@ class TestResourceOptimizer(unittest.TestCase):
     def test_sensitivity_analysis(self):
         """æ¸¬è©¦æ•æ„Ÿåº¦åˆ†æ"""
         result = self.optimizer.generate_optimization(
-            total_budget=1000000, target_headcount=10, strategy=AllocationStrategy.BALANCED
+            total_budget=1000000,
+            target_headcount=10,
+            strategy=AllocationStrategy.BALANCED,
         )
 
         sensitivity = result.sensitivity_analysis
@@ -444,7 +463,9 @@ class TestResourceOptimizer(unittest.TestCase):
 
     def test_resource_report_generation(self):
         """æ¸¬è©¦è³‡æºå„ªåŒ–å ±å‘Šç”Ÿæˆ"""
-        result = self.optimizer.generate_optimization(total_budget=1500000, target_headcount=15)
+        result = self.optimizer.generate_optimization(
+            total_budget=1500000, target_headcount=15
+        )
 
         report = self.optimizer.generate_report(result)
 
@@ -554,7 +575,9 @@ class TestEvolutionTracker(unittest.TestCase):
         """æ¸¬è©¦è½‰æ›åˆ°æŒ‡å®šéšæ®µ"""
         maturity = self.tracker.assess_maturity({"has_mvp": True, "customers": 5})
 
-        transition = self.tracker.evaluate_transition(maturity, target_phase=DevelopmentPhase.SCALE)
+        transition = self.tracker.evaluate_transition(
+            maturity, target_phase=DevelopmentPhase.SCALE
+        )
 
         self.assertEqual(transition.to_phase, DevelopmentPhase.SCALE)
 
@@ -568,7 +591,9 @@ class TestEvolutionTracker(unittest.TestCase):
         }
 
         maturity = self.tracker.assess_maturity(project_data)
-        roadmap = self.tracker.create_roadmap(maturity, target_phase=DevelopmentPhase.SCALE)
+        roadmap = self.tracker.create_roadmap(
+            maturity, target_phase=DevelopmentPhase.SCALE
+        )
 
         self.assertIsInstance(roadmap, EvolutionRoadmap)
         self.assertEqual(roadmap.target_phase, DevelopmentPhase.SCALE)
@@ -581,7 +606,9 @@ class TestEvolutionTracker(unittest.TestCase):
         """æ¸¬è©¦è·¯ç·šåœ–é‡Œç¨‹ç¢‘"""
         maturity = self.tracker.assess_maturity({"has_mvp": False})
 
-        roadmap = self.tracker.create_roadmap(maturity, target_phase=DevelopmentPhase.EFFICIENCY)
+        roadmap = self.tracker.create_roadmap(
+            maturity, target_phase=DevelopmentPhase.EFFICIENCY
+        )
 
         for milestone in roadmap.milestones:
             self.assertIn("phase", milestone)
@@ -600,7 +627,9 @@ class TestEvolutionTracker(unittest.TestCase):
 
         maturity = self.tracker.assess_maturity(project_data)
         transition = self.tracker.evaluate_transition(maturity)
-        roadmap = self.tracker.create_roadmap(maturity, target_phase=DevelopmentPhase.EXPANSION)
+        roadmap = self.tracker.create_roadmap(
+            maturity, target_phase=DevelopmentPhase.EXPANSION
+        )
 
         report = self.tracker.generate_report(maturity, transition, roadmap)
 
@@ -650,7 +679,9 @@ class TestIntegration(unittest.TestCase):
         # 3. è³‡æºå„ªåŒ–
         optimizer = ResourceOptimizer()
         optimization = optimizer.generate_optimization(
-            total_budget=1500000, target_headcount=15, strategy=AllocationStrategy.GROWTH_FOCUSED
+            total_budget=1500000,
+            target_headcount=15,
+            strategy=AllocationStrategy.GROWTH_FOCUSED,
         )
 
         self.assertIsInstance(optimization, OptimizationResult)
@@ -667,14 +698,22 @@ class TestIntegration(unittest.TestCase):
     def test_data_consistency(self):
         """æ¸¬è©¦æ•¸æ“šä¸€è‡´æ€§"""
         optimizer = ResourceOptimizer()
-        result = optimizer.generate_optimization(total_budget=1000000, target_headcount=10)
+        result = optimizer.generate_optimization(
+            total_budget=1000000, target_headcount=10
+        )
 
         # é ç®—åˆ†é…ç¸½å’Œæ‡‰ç­‰æ–¼ç‡Ÿé‹é ç®—éƒ¨åˆ†
-        budget_sum = sum(cat.amount for cat in result.budget_allocation.allocations.values())
-        self.assertAlmostEqual(budget_sum, result.budget_allocation.total_budget, places=0)
+        budget_sum = sum(
+            cat.amount for cat in result.budget_allocation.allocations.values()
+        )
+        self.assertAlmostEqual(
+            budget_sum, result.budget_allocation.total_budget, places=0
+        )
 
         # åœ˜éšŠæˆæœ¬ä¸æ‡‰è¶…éäººåŠ›é ç®—
-        self.assertLessEqual(result.team_allocation.total_cost, 1000000 * 0.7)  # 70% ç”¨æ–¼äººåŠ›
+        self.assertLessEqual(
+            result.team_allocation.total_cost, 1000000 * 0.7
+        )  # 70% ç”¨æ–¼äººåŠ›
 
 
 if __name__ == "__main__":
diff --git a/workspace/src/ai/agents/dependency-manager/tests/test_phase6.py b/workspace/src/ai/agents/dependency-manager/tests/test_phase6.py
index 08da537..78ea88d 100644
--- a/workspace/src/ai/agents/dependency-manager/tests/test_phase6.py
+++ b/workspace/src/ai/agents/dependency-manager/tests/test_phase6.py
@@ -55,7 +55,9 @@ class TestSustainableAnalyzer(unittest.TestCase):
     def test_energy_efficiency_grade(self):
         """æ¸¬è©¦èƒ½æºæ•ˆç‡ç­‰ç´š"""
         efficiency = self.EnergyEfficiency(
-            component_name="api-server", component_type="dependency", efficiency_score=85
+            component_name="api-server",
+            component_type="dependency",
+            efficiency_score=85,
         )
 
         self.assertEqual(efficiency.energy_grade, self.EnergyGrade.A)
@@ -65,7 +67,11 @@ class TestSustainableAnalyzer(unittest.TestCase):
         analyzer = self.SustainableAnalyzer()
 
         footprint = analyzer.analyze_dependency(
-            name="lodash", version="4.17.21", ecosystem="npm", size_mb=1.5, dependencies_count=0
+            name="lodash",
+            version="4.17.21",
+            ecosystem="npm",
+            size_mb=1.5,
+            dependencies_count=0,
         )
 
         self.assertEqual(footprint.dependency_name, "lodash")
@@ -195,7 +201,9 @@ class TestLowCodeIntegration(unittest.TestCase):
         platform = self.LowCodeIntegration()
 
         workflow = platform.create_workflow(
-            workflow_id="wf_001", name="å®‰å…¨æƒæå·¥ä½œæµ", description="å®šæœŸæƒæä¾è³´é …æ¼æ´"
+            workflow_id="wf_001",
+            name="å®‰å…¨æƒæå·¥ä½œæµ",
+            description="å®šæœŸæƒæä¾è³´é …æ¼æ´",
         )
 
         self.assertEqual(workflow.workflow_id, "wf_001")
@@ -324,7 +332,10 @@ class TestPrivacyFramework(unittest.TestCase):
         # æ·»åŠ æ•¸æ“šæ¬„ä½
         design.add_data_field(
             self.DataField(
-                field_name="user_id", field_type="string", is_pii=False, is_encrypted=True
+                field_name="user_id",
+                field_type="string",
+                is_pii=False,
+                is_encrypted=True,
             )
         )
 
@@ -361,7 +372,9 @@ class TestPrivacyFramework(unittest.TestCase):
 
         # æª¢æŸ¥åŒæ„
         has_consent = manager.check_consent(
-            user_id="user_001", purpose="marketing", data_category=self.DataCategory.PERSONAL
+            user_id="user_001",
+            purpose="marketing",
+            data_category=self.DataCategory.PERSONAL,
         )
         self.assertTrue(has_consent)
 
@@ -387,7 +400,9 @@ class TestPrivacyFramework(unittest.TestCase):
 
         # æª¢æŸ¥å‚³è¼¸
         result = sovereignty.check_transfer_allowed(
-            data_type="customer_data", source_jurisdiction="TW", target_jurisdiction="EU"
+            data_type="customer_data",
+            source_jurisdiction="TW",
+            target_jurisdiction="EU",
         )
 
         self.assertTrue(result["allowed"])
@@ -459,7 +474,9 @@ class TestPrivacyFramework(unittest.TestCase):
         framework = self.PrivacyFramework("test-project")
 
         framework.add_data_field(
-            self.DataField(field_name="email", field_type="string", is_pii=True, is_encrypted=True)
+            self.DataField(
+                field_name="email", field_type="string", is_pii=True, is_encrypted=True
+            )
         )
 
         report = framework.generate_full_report()
@@ -565,7 +582,9 @@ class TestDevelopmentTracker(unittest.TestCase):
 
     def test_team_capability_assessment(self):
         """æ¸¬è©¦åœ˜éšŠèƒ½åŠ›è©•ä¼°"""
-        team = self.TeamCapability(team_id="team_001", team_name="é–‹ç™¼åœ˜éšŠ", team_size=10)
+        team = self.TeamCapability(
+            team_id="team_001", team_name="é–‹ç™¼åœ˜éšŠ", team_size=10
+        )
 
         assessment = team.assess_skill(
             category=self.SkillCategory.SECURITY,
@@ -581,7 +600,9 @@ class TestDevelopmentTracker(unittest.TestCase):
 
     def test_capability_gaps(self):
         """æ¸¬è©¦èƒ½åŠ›å·®è·åˆ†æ"""
-        team = self.TeamCapability(team_id="team_001", team_name="é–‹ç™¼åœ˜éšŠ", team_size=10)
+        team = self.TeamCapability(
+            team_id="team_001", team_name="é–‹ç™¼åœ˜éšŠ", team_size=10
+        )
 
         team.assess_skill(self.SkillCategory.SECURITY, 50, 80, 3)
         team.assess_skill(self.SkillCategory.CLOUD, 70, 90, 6)
@@ -648,7 +669,9 @@ class TestDevelopmentTracker(unittest.TestCase):
             metric_name="team_capability_score", threshold=60, comparison="below"
         )
 
-        triggered = optimization.check_alerts({"team_capability_score": 50, "active_strategies": 2})
+        triggered = optimization.check_alerts(
+            {"team_capability_score": 50, "active_strategies": 2}
+        )
 
         self.assertEqual(len(triggered), 1)
         self.assertIn("ä½æ–¼é–¾å€¼", triggered[0]["message"])
diff --git a/workspace/src/ai/agents/dependency-manager/tests/test_phase7.py b/workspace/src/ai/agents/dependency-manager/tests/test_phase7.py
index 365c83a..9e8ecc4 100644
--- a/workspace/src/ai/agents/dependency-manager/tests/test_phase7.py
+++ b/workspace/src/ai/agents/dependency-manager/tests/test_phase7.py
@@ -4,7 +4,11 @@ Phase 7 æ¸¬è©¦ - SMART-V è©•ä¼°æ¡†æ¶
 æ¸¬è©¦ SMART-V é‡åŒ–è©•ä¼°ç³»çµ±çš„å„é …åŠŸèƒ½ã€‚
 """
 
-from evaluation.weight_config import CompanyStage, WeightConfigManager
+import os
+import sys
+import unittest
+
+from evaluation.evaluation_report import EvaluationReportGenerator, ReportConfig
 from evaluation.smartv_framework import (
     AchievabilityEvaluator,
     EvaluationDimension,
@@ -15,10 +19,7 @@ from evaluation.smartv_framework import (
     TechnologyMaturityEvaluator,
     ValueCreationEvaluator,
 )
-from evaluation.evaluation_report import EvaluationReportGenerator, ReportConfig
-import os
-import sys
-import unittest
+from evaluation.weight_config import CompanyStage, WeightConfigManager
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
@@ -199,7 +200,11 @@ class TestSMARTVFramework(unittest.TestCase):
                 "market_maturity": "growing",
                 "competitor_count": 5,
             },
-            "achievability": {"skill_coverage": 75, "experience_years": 4, "budget_adequate": True},
+            "achievability": {
+                "skill_coverage": 75,
+                "experience_years": 4,
+                "budget_adequate": True,
+            },
             "roi": {"roi_percentage": 150, "payback_months": 12},
             "technology_maturity": {"tech_age_years": 5, "library_count": 10000},
             "value_creation": {"moat_strength": "medium", "brand_recognition": 60},
@@ -209,7 +214,8 @@ class TestSMARTVFramework(unittest.TestCase):
 
         self.assertEqual(result.project_name, "æ¸¬è©¦å°ˆæ¡ˆ")
         self.assertIn(
-            result.overall_grade, ["A+", "A", "A-", "B+", "B", "B-", "C+", "C", "C-", "D", "F"]
+            result.overall_grade,
+            ["A+", "A", "A-", "B+", "B", "B-", "C+", "C", "C-", "D", "F"],
         )
         self.assertEqual(len(result.scores), 6)
         self.assertGreater(result.weighted_total, 0)
@@ -259,7 +265,10 @@ class TestWeightConfigManager(unittest.TestCase):
         }
 
         profile = self.manager.create_custom_profile(
-            name="custom_test", stage=CompanyStage.GROWTH, weights=weights, description="æ¸¬è©¦é…ç½®"
+            name="custom_test",
+            stage=CompanyStage.GROWTH,
+            weights=weights,
+            description="æ¸¬è©¦é…ç½®",
         )
 
         self.assertEqual(profile.name, "custom_test")
diff --git a/workspace/src/ai/agents/dependency-manager/tests/test_phase8.py b/workspace/src/ai/agents/dependency-manager/tests/test_phase8.py
index 246a1d8..30daf9f 100644
--- a/workspace/src/ai/agents/dependency-manager/tests/test_phase8.py
+++ b/workspace/src/ai/agents/dependency-manager/tests/test_phase8.py
@@ -4,16 +4,15 @@ Phase 8 å–®å…ƒæ¸¬è©¦
 Tests for Advanced Prompt Combination Strategy Modules
 """
 
-from combination.quarterly_review import (
-    QuarterlyReviewEngine,
-    ReviewCategory,
-    ReviewStatus,
-)
-from combination.dynamic_adjuster import (
-    AdjustmentDirection,
-    AdjustmentTrigger,
-    DynamicAdjuster,
-    KPIMetric,
+import sys
+import unittest
+from datetime import datetime
+from pathlib import Path
+
+from combination.combination_templates import (
+    CombinationTemplateManager,
+    CompanyStage,
+    TemplateCategory,
 )
 from combination.core_satellite import (
     AllocationRole,
@@ -22,15 +21,17 @@ from combination.core_satellite import (
     PromptAllocation,
     PromptCategory,
 )
-from combination.combination_templates import (
-    CombinationTemplateManager,
-    CompanyStage,
-    TemplateCategory,
+from combination.dynamic_adjuster import (
+    AdjustmentDirection,
+    AdjustmentTrigger,
+    DynamicAdjuster,
+    KPIMetric,
+)
+from combination.quarterly_review import (
+    QuarterlyReviewEngine,
+    ReviewCategory,
+    ReviewStatus,
 )
-import sys
-import unittest
-from datetime import datetime
-from pathlib import Path
 
 sys.path.insert(0, str(Path(__file__).resolve().parents[1] / "src"))
 
@@ -188,7 +189,9 @@ class TestQuarterlyReviewEngine(unittest.TestCase):
     def test_complete_review(self):
         """æ¸¬è©¦å®Œæˆå¯©æŸ¥"""
         self.engine.create_review("2024Q3")
-        self.engine.add_review_item("2024Q3", ReviewCategory.MARKET_FEEDBACK, "æ»¿æ„åº¦", 80, 70, "%")
+        self.engine.add_review_item(
+            "2024Q3", ReviewCategory.MARKET_FEEDBACK, "æ»¿æ„åº¦", 80, 70, "%"
+        )
 
         review = self.engine.complete_review("2024Q3")
 
@@ -228,7 +231,9 @@ class TestIntegration(unittest.TestCase):
 
         # 2. ç²å–ç¯„æœ¬
         template_manager = CombinationTemplateManager()
-        template = template_manager.recommend_template(CompanyStage.STARTUP, "monetization")
+        template = template_manager.recommend_template(
+            CompanyStage.STARTUP, "monetization"
+        )
 
         # 3. è¨­ç½®å‹•æ…‹èª¿æ•´
         adjuster = DynamicAdjuster()
diff --git a/workspace/src/ai/agents/dependency-manager/tests/test_phase9.py b/workspace/src/ai/agents/dependency-manager/tests/test_phase9.py
index d78fea2..b0ae415 100644
--- a/workspace/src/ai/agents/dependency-manager/tests/test_phase9.py
+++ b/workspace/src/ai/agents/dependency-manager/tests/test_phase9.py
@@ -3,24 +3,25 @@ Phase 9 å–®å…ƒæ¸¬è©¦
 Cross-platform Integration & Risk Management Tests
 """
 
-from crossplatform.web3_integration import (
-    BlockchainType,
-    ConsensusType,
-    DAppAssessment,
-    NFTAssetType,
-    NFTStrategy,
-    SmartContractDev,
-    Web3Integration,
+import os
+import sys
+import unittest
+
+from crossplatform.arvr_integration import (
+    ARVRIntegration,
+    HardwareRequirement,
+    ImmersiveExperience,
+    InteractionMode,
+    MetaversePlatform,
+    MixedReality,
+    XRType,
 )
-from crossplatform.tech_stack_matrix import (
-    BackendArch,
-    DataProcessing,
-    DeploymentStrategy,
-    FrontendTech,
-    StackRecommendation,
-    TechStackMatrix,
+from crossplatform.emergency_response import (
+    EmergencyResponse,
+    PlanType,
+    TriggerCategory,
+    TriggerCondition,
 )
-from crossplatform.risk_assessment import MitigationStrategy, RiskAssessment, RiskCategory, RiskType
 from crossplatform.iot_integration import (
     DeviceInterconnection,
     EdgeComputing,
@@ -30,24 +31,29 @@ from crossplatform.iot_integration import (
     IoTIntegration,
     IoTProtocol,
 )
-from crossplatform.emergency_response import (
-    EmergencyResponse,
-    PlanType,
-    TriggerCategory,
-    TriggerCondition,
+from crossplatform.risk_assessment import (
+    MitigationStrategy,
+    RiskAssessment,
+    RiskCategory,
+    RiskType,
 )
-from crossplatform.arvr_integration import (
-    ARVRIntegration,
-    HardwareRequirement,
-    ImmersiveExperience,
-    InteractionMode,
-    MetaversePlatform,
-    MixedReality,
-    XRType,
+from crossplatform.tech_stack_matrix import (
+    BackendArch,
+    DataProcessing,
+    DeploymentStrategy,
+    FrontendTech,
+    StackRecommendation,
+    TechStackMatrix,
+)
+from crossplatform.web3_integration import (
+    BlockchainType,
+    ConsensusType,
+    DAppAssessment,
+    NFTAssetType,
+    NFTStrategy,
+    SmartContractDev,
+    Web3Integration,
 )
-import os
-import sys
-import unittest
 
 # æ·»åŠ è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
@@ -214,7 +220,10 @@ class TestARVRIntegration(unittest.TestCase):
             hardware_requirement=HardwareRequirement.STANDALONE,
             target_fov=100,
             target_fps=90,
-            interaction_modes=[InteractionMode.CONTROLLER, InteractionMode.HAND_TRACKING],
+            interaction_modes=[
+                InteractionMode.CONTROLLER,
+                InteractionMode.HAND_TRACKING,
+            ],
             use_case="Training Simulation",
         )
 
@@ -297,7 +306,10 @@ class TestTechStackMatrix(unittest.TestCase):
     def test_optimal_stack_recommendation(self):
         """æ¸¬è©¦æœ€ä½³æŠ€è¡“æ£§æ¨è–¦"""
         result = self.matrix.recommend_optimal_stack(
-            project_type="startup", team_size=8, scalability_need="high", budget_level="medium"
+            project_type="startup",
+            team_size=8,
+            scalability_need="high",
+            budget_level="medium",
         )
 
         self.assertIsNotNone(result.frontend)
@@ -356,11 +368,15 @@ class TestRiskAssessment(unittest.TestCase):
         self.assertEqual(high_risk.category, RiskCategory.HIGH)
 
         # ä¸­é¢¨éšª
-        medium_risk = self.assessment.add_risk(RiskType.MARKET_ACCEPTANCE, "ä¸­é¢¨éšª", "æ¸¬è©¦", 5, 6)
+        medium_risk = self.assessment.add_risk(
+            RiskType.MARKET_ACCEPTANCE, "ä¸­é¢¨éšª", "æ¸¬è©¦", 5, 6
+        )
         self.assertEqual(medium_risk.category, RiskCategory.MEDIUM)
 
         # ä½é¢¨éšª
-        low_risk = self.assessment.add_risk(RiskType.TECHNICAL_DEBT, "ä½é¢¨éšª", "æ¸¬è©¦", 3, 4)
+        low_risk = self.assessment.add_risk(
+            RiskType.TECHNICAL_DEBT, "ä½é¢¨éšª", "æ¸¬è©¦", 3, 4
+        )
         self.assertEqual(low_risk.category, RiskCategory.LOW)
 
     def test_project_risk_assessment(self):
@@ -424,11 +440,19 @@ class TestEmergencyResponse(unittest.TestCase):
     def test_plan_recommendation(self):
         """æ¸¬è©¦é æ¡ˆæ¨è–¦"""
         # æ­£å¸¸æƒ…æ³
-        normal_metrics = {"market_decline": 5, "tech_disruption": 0, "resource_reduction": 10}
+        normal_metrics = {
+            "market_decline": 5,
+            "tech_disruption": 0,
+            "resource_reduction": 10,
+        }
         self.assertEqual(self.response.recommend_plan(normal_metrics), PlanType.PLAN_A)
 
         # éœ€è¦èª¿æ•´
-        adjust_metrics = {"market_decline": 25, "tech_disruption": 0, "resource_reduction": 10}
+        adjust_metrics = {
+            "market_decline": 25,
+            "tech_disruption": 0,
+            "resource_reduction": 10,
+        }
         self.assertEqual(self.response.recommend_plan(adjust_metrics), PlanType.PLAN_B)
 
     def test_add_custom_trigger(self):
diff --git a/workspace/src/ai/embeddings/embedding_engine.py b/workspace/src/ai/embeddings/embedding_engine.py
index bcca272..939479f 100644
--- a/workspace/src/ai/embeddings/embedding_engine.py
+++ b/workspace/src/ai/embeddings/embedding_engine.py
@@ -117,7 +117,9 @@ class EmbeddingEngine:
         self, query_vec: np.ndarray, candidates: List[np.ndarray], top_k: int = 10
     ) -> List[tuple]:
         """Find most similar vectors."""
-        similarities = [(i, self.similarity(query_vec, vec)) for i, vec in enumerate(candidates)]
+        similarities = [
+            (i, self.similarity(query_vec, vec)) for i, vec in enumerate(candidates)
+        ]
         similarities.sort(key=lambda x: x[1], reverse=True)
         return similarities[:top_k]
 
diff --git a/workspace/src/ai/federated/framework/federation_framework.py b/workspace/src/ai/federated/framework/federation_framework.py
index 8e89dde..4bd6374 100644
--- a/workspace/src/ai/federated/framework/federation_framework.py
+++ b/workspace/src/ai/federated/framework/federation_framework.py
@@ -141,7 +141,9 @@ class FederationFramework:
         # Select clients for this round
         selected = self._select_clients()
         if len(selected) < self.config.min_clients:
-            raise ValueError(f"Not enough clients: {len(selected)} < {self.config.min_clients}")
+            raise ValueError(
+                f"Not enough clients: {len(selected)} < {self.config.min_clients}"
+            )
 
         # Distribute model to clients
         for client_id in selected:
@@ -171,7 +173,9 @@ class FederationFramework:
     def _select_clients(self) -> List[str]:
         """Select clients for the current round."""
         available = [
-            cid for cid, c in self._clients.items() if c.status != ClientStatus.DISCONNECTED
+            cid
+            for cid, c in self._clients.items()
+            if c.status != ClientStatus.DISCONNECTED
         ]
 
         num_to_select = max(
@@ -214,7 +218,10 @@ class FederationFramework:
             client_id=client_id,
             round_id=round_id,
             weights=weights,
-            metrics={"loss": random.uniform(0.1, 0.5), "accuracy": random.uniform(0.7, 0.95)},
+            metrics={
+                "loss": random.uniform(0.1, 0.5),
+                "accuracy": random.uniform(0.7, 0.95),
+            },
             data_size=self._clients[client_id].data_size,
             timestamp=datetime.now(timezone.utc),
         )
@@ -237,7 +244,9 @@ class FederationFramework:
         num_updates = len(self._round_updates)
 
         for layer in self._global_weights.keys():
-            layer_weights = [update.weights.get(layer, []) for update in self._round_updates]
+            layer_weights = [
+                update.weights.get(layer, []) for update in self._round_updates
+            ]
             if layer_weights and layer_weights[0]:
                 avg_weights = []
                 for i in range(len(layer_weights[0])):
diff --git a/workspace/src/ai/metacognition/strategist/meta_strategist.py b/workspace/src/ai/metacognition/strategist/meta_strategist.py
index f4698e3..6c91eb6 100644
--- a/workspace/src/ai/metacognition/strategist/meta_strategist.py
+++ b/workspace/src/ai/metacognition/strategist/meta_strategist.py
@@ -176,7 +176,9 @@ class MetaStrategist:
             confidence=self._calculate_confidence(gaps),
         )
 
-    def _map_metric_to_action(self, metric: str, gap: float) -> Tuple[str, Dict[str, Any]]:
+    def _map_metric_to_action(
+        self, metric: str, gap: float
+    ) -> Tuple[str, Dict[str, Any]]:
         """Map a metric gap to an action and layer."""
         # Mapping of metrics to responsible layers
         metric_layer_map = {
diff --git a/workspace/src/apps/web-backend/analyzers/analyzer.py b/workspace/src/apps/web-backend/analyzers/analyzer.py
index 1c69166..f88bbbe 100644
--- a/workspace/src/apps/web-backend/analyzers/analyzer.py
+++ b/workspace/src/apps/web-backend/analyzers/analyzer.py
@@ -121,7 +121,9 @@ class AnalysisResult:
             SeverityLevel.INFO: 0.5,
         }
 
-        total_weight = sum(severity_weights.get(issue.severity, 0) for issue in self.issues)
+        total_weight = sum(
+            severity_weights.get(issue.severity, 0) for issue in self.issues
+        )
 
         return max(0, 100 - total_weight)
 
@@ -166,7 +168,9 @@ class BaseAnalyzer:
         """
         # Default implementation for base analyzer
         # Subclasses should override this method
-        self.logger.warning(f"{self.__class__.__name__}.analyze() called but not implemented")
+        self.logger.warning(
+            f"{self.__class__.__name__}.analyze() called but not implemented"
+        )
         return []
 
 
@@ -243,7 +247,9 @@ class StaticAnalyzer(BaseAnalyzer):
                     type=IssueType.SECURITY,
                     severity=SeverityLevel.HIGH,
                     file=file_path,
-                    line=self._find_line_number(code, r"(query|execute|sql)\s*=\s*['\"].*\+"),
+                    line=self._find_line_number(
+                        code, r"(query|execute|sql)\s*=\s*['\"].*\+"
+                    ),
                     column=1,
                     message="SQL injection risk detected",
                     description="æª¢æ¸¬åˆ°æ½›åœ¨çš„ SQL æ³¨å…¥é¢¨éšª",
@@ -400,7 +406,9 @@ class StaticAnalyzer(BaseAnalyzer):
             r"secret\s*=\s*['\"][\w\W]+['\"]",
             r"token\s*=\s*['\"][\w\W]+['\"]",
         ]
-        return any(re.search(pattern, code, re.IGNORECASE) for pattern in secret_patterns)
+        return any(
+            re.search(pattern, code, re.IGNORECASE) for pattern in secret_patterns
+        )
 
     def _contains_sql_injection_risk(self, code: str) -> bool:
         """æª¢æ¸¬ SQL æ³¨å…¥é¢¨éšª"""
@@ -414,7 +422,11 @@ class StaticAnalyzer(BaseAnalyzer):
 
     def _contains_xss_risk(self, code: str) -> bool:
         """æª¢æ¸¬ XSS é¢¨éšª"""
-        patterns = [r"innerHTML\s*=\s*[^(]", r"document\.write\(", r"\.html\([^)]*\+[^)]*\)"]
+        patterns = [
+            r"innerHTML\s*=\s*[^(]",
+            r"document\.write\(",
+            r"\.html\([^)]*\+[^)]*\)",
+        ]
         return any(re.search(pattern, code, re.IGNORECASE) for pattern in patterns)
 
     def _calculate_cyclomatic_complexity(self, code: str) -> int:
@@ -431,7 +443,9 @@ class StaticAnalyzer(BaseAnalyzer):
         lines = code.split("\n")
         # éæ¿¾ç©ºè¡Œå’Œè¨»é‡‹
         lines = [
-            line.strip() for line in lines if line.strip() and not line.strip().startswith("#")
+            line.strip()
+            for line in lines
+            if line.strip() and not line.strip().startswith("#")
         ]
         if len(lines) < 10:
             return 0.0
@@ -515,7 +529,9 @@ class CodeAnalysisEngine:
             self.logger.error(f"åˆ†ææ–‡ä»¶å¤±æ•— {file_path}: {e}")
             return []
 
-    async def analyze_repository(self, repo_path: str, commit_hash: str) -> AnalysisResult:
+    async def analyze_repository(
+        self, repo_path: str, commit_hash: str
+    ) -> AnalysisResult:
         """
         åˆ†ææ•´å€‹ä»£ç¢¼åº«
 
@@ -541,7 +557,11 @@ class CodeAnalysisEngine:
             analysis_timestamp=start_time,
             duration=duration,
             issues=all_issues,
-            metrics={"files_analyzed": 0, "lines_of_code": 0, "total_issues": len(all_issues)},
+            metrics={
+                "files_analyzed": 0,
+                "lines_of_code": 0,
+                "total_issues": len(all_issues),
+            },
         )
 
 
@@ -553,7 +573,8 @@ class CodeAnalysisEngine:
 async def main() -> None:
     """ä¸»ç¨‹åº"""
     logging.basicConfig(
-        level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+        level=logging.INFO,
+        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
     )
 
     print("ä»£ç¢¼åˆ†æå¼•æ“å·²åˆå§‹åŒ–")
diff --git a/workspace/src/apps/web-backend/services/api.py b/workspace/src/apps/web-backend/services/api.py
index 20cb646..ab470ab 100644
--- a/workspace/src/apps/web-backend/services/api.py
+++ b/workspace/src/apps/web-backend/services/api.py
@@ -123,7 +123,11 @@ async def shutdown_event():
 @app.get("/", response_model=dict[str, str])
 async def root():
     """æ ¹ç«¯é»"""
-    return {"service": "SLASolve Code Analysis API", "version": "2.0.0", "docs": "/api/docs"}
+    return {
+        "service": "SLASolve Code Analysis API",
+        "version": "2.0.0",
+        "docs": "/api/docs",
+    }
 
 
 @app.get("/healthz", response_model=HealthResponse)
@@ -177,7 +181,9 @@ async def analyze_code(request: AnalysisRequest, background_tasks: BackgroundTas
     )
 
     return AnalysisResponse(
-        analysis_id=analysis_id, status="pending", message="Analysis task submitted successfully"
+        analysis_id=analysis_id,
+        status="pending",
+        message="Analysis task submitted successfully",
     )
 
 
@@ -254,10 +260,18 @@ async def get_metrics():
         "engine_metrics": metrics,
         "task_stats": {
             "total": len(analysis_tasks),
-            "pending": sum(1 for t in analysis_tasks.values() if t["status"] == "pending"),
-            "running": sum(1 for t in analysis_tasks.values() if t["status"] == "running"),
-            "completed": sum(1 for t in analysis_tasks.values() if t["status"] == "completed"),
-            "failed": sum(1 for t in analysis_tasks.values() if t["status"] == "failed"),
+            "pending": sum(
+                1 for t in analysis_tasks.values() if t["status"] == "pending"
+            ),
+            "running": sum(
+                1 for t in analysis_tasks.values() if t["status"] == "running"
+            ),
+            "completed": sum(
+                1 for t in analysis_tasks.values() if t["status"] == "completed"
+            ),
+            "failed": sum(
+                1 for t in analysis_tasks.values() if t["status"] == "failed"
+            ),
         },
     }
 
@@ -349,7 +363,9 @@ async def get_language_governance():
                 if history_data and "events" in history_data:
                     history = [
                         {
-                            "timestamp": event.get("timestamp", datetime.utcnow().isoformat()),
+                            "timestamp": event.get(
+                                "timestamp", datetime.utcnow().isoformat()
+                            ),
                             "event": event.get("event", "Event"),
                             "details": event.get("details", ""),
                             "type": event.get("type", "scan"),
@@ -457,7 +473,9 @@ async def get_language_governance():
         "generatedAt": datetime.utcnow().isoformat(),
         "metrics": {
             "totalViolations": len(violations) if violations else 2,
-            "securityFindings": len(semgrep_data["results"]) if semgrep_data["results"] else 1,
+            "securityFindings": (
+                len(semgrep_data["results"]) if semgrep_data["results"] else 1
+            ),
             "architectureCompliance": 92,
             "fixSuccessRate": 87,
         },
diff --git a/workspace/src/apps/web-backend/services/api/language_governance.py b/workspace/src/apps/web-backend/services/api/language_governance.py
index febfa15..49e391f 100644
--- a/workspace/src/apps/web-backend/services/api/language_governance.py
+++ b/workspace/src/apps/web-backend/services/api/language_governance.py
@@ -91,7 +91,9 @@ def extract_violations_from_markdown(md_content: str) -> list[Violation]:
             parts = line.split("â€”")
             if len(parts) >= 2:
                 file_part = parts[0].strip("- *").strip()
-                reason_part = parts[1].strip() if len(parts) > 1 else "Unknown violation"
+                reason_part = (
+                    parts[1].strip() if len(parts) > 1 else "Unknown violation"
+                )
 
                 severity = "warning"
                 if "critical" in line.lower():
@@ -99,7 +101,9 @@ def extract_violations_from_markdown(md_content: str) -> list[Violation]:
                 elif "error" in line.lower():
                     severity = "error"
 
-                violations.append(Violation(file=file_part, reason=reason_part, severity=severity))
+                violations.append(
+                    Violation(file=file_part, reason=reason_part, severity=severity)
+                )
 
     return violations
 
@@ -157,7 +161,9 @@ def load_governance_report() -> GovernanceReport:
                 if isinstance(history_data, list):
                     history = [
                         HistoryEvent(
-                            timestamp=event.get("timestamp", datetime.now().isoformat()),
+                            timestamp=event.get(
+                                "timestamp", datetime.now().isoformat()
+                            ),
                             event=event.get("event", "Event"),
                             details=event.get("details", ""),
                             type=event.get("type", "scan"),
@@ -251,7 +257,11 @@ def load_governance_report() -> GovernanceReport:
 @app.get("/")
 async def root():
     """Root endpoint"""
-    return {"service": "Language Governance API", "version": "1.0.0", "status": "operational"}
+    return {
+        "service": "Language Governance API",
+        "version": "1.0.0",
+        "status": "operational",
+    }
 
 
 @app.get("/api/language-governance", response_model=GovernanceReport)
diff --git a/workspace/src/apps/web-backend/services/code_analyzer.py b/workspace/src/apps/web-backend/services/code_analyzer.py
index 4c63cf1..f942f49 100644
--- a/workspace/src/apps/web-backend/services/code_analyzer.py
+++ b/workspace/src/apps/web-backend/services/code_analyzer.py
@@ -195,7 +195,10 @@ class BaseAnalyzer:
         return f"analysis:{hashlib.md5(content.encode()).hexdigest()}"
 
     async def analyze(
-        self, code: str, file_path: str, strategy: AnalysisStrategy = AnalysisStrategy.STANDARD
+        self,
+        code: str,
+        file_path: str,
+        strategy: AnalysisStrategy = AnalysisStrategy.STANDARD,
     ) -> list[CodeIssue]:
         """åˆ†æä»£ç¢¼ - æ”¯æŒç·©å­˜"""
         cache_key = self._get_cache_key(code, file_path)
@@ -217,7 +220,9 @@ class BaseAnalyzer:
         # å­˜å„²åˆ°ç·©å­˜
         if self.cache_client:
             try:
-                cache_data = json.dumps([asdict(issue) for issue in issues], default=str)
+                cache_data = json.dumps(
+                    [asdict(issue) for issue in issues], default=str
+                )
                 self.cache_client.setex(cache_key, 3600, cache_data)  # 1 å°æ™‚éæœŸ
             except Exception as e:
                 self.logger.warning(f"Cache storage failed: {e}")
@@ -493,7 +498,9 @@ class StaticAnalyzer(BaseAnalyzer):
 
         return "unknown"
 
-    async def _check_security(self, code: str, file_path: str, language: str) -> list[CodeIssue]:
+    async def _check_security(
+        self, code: str, file_path: str, language: str
+    ) -> list[CodeIssue]:
         """æª¢æ¸¬å®‰å…¨æ¼æ´"""
         issues = []
 
@@ -629,7 +636,9 @@ class StaticAnalyzer(BaseAnalyzer):
 
         return issues
 
-    def _detect_csrf_vulnerabilities(self, code: str, file_path: str) -> list[CodeIssue]:
+    def _detect_csrf_vulnerabilities(
+        self, code: str, file_path: str
+    ) -> list[CodeIssue]:
         """æª¢æ¸¬ CSRF æ¼æ´"""
         issues = []
 
@@ -654,7 +663,9 @@ class StaticAnalyzer(BaseAnalyzer):
 
         return issues
 
-    def _detect_unsafe_deserialization(self, code: str, file_path: str) -> list[CodeIssue]:
+    def _detect_unsafe_deserialization(
+        self, code: str, file_path: str
+    ) -> list[CodeIssue]:
         """æª¢æ¸¬ä¸å®‰å…¨çš„ååºåˆ—åŒ–"""
         issues = []
 
@@ -688,7 +699,9 @@ class StaticAnalyzer(BaseAnalyzer):
 
         return issues
 
-    def _detect_cryptographic_weaknesses(self, code: str, file_path: str) -> list[CodeIssue]:
+    def _detect_cryptographic_weaknesses(
+        self, code: str, file_path: str
+    ) -> list[CodeIssue]:
         """æª¢æ¸¬å¯†ç¢¼å­¸å¼±é»"""
         issues = []
 
@@ -767,12 +780,16 @@ class StaticAnalyzer(BaseAnalyzer):
 
         return issues
 
-    async def _check_performance(self, code: str, file_path: str, language: str) -> list[CodeIssue]:
+    async def _check_performance(
+        self, code: str, file_path: str, language: str
+    ) -> list[CodeIssue]:
         """æª¢æ¸¬æ€§èƒ½å•é¡Œ"""
         issues = []
 
         # æª¢æ¸¬ N+1 æŸ¥è©¢
-        if re.search(r"for\s+\w+\s+in\s+.*:\s*.*\.(query|filter|get)\(", code, re.DOTALL):
+        if re.search(
+            r"for\s+\w+\s+in\s+.*:\s*.*\.(query|filter|get)\(", code, re.DOTALL
+        ):
             issues.append(
                 CodeIssue(
                     type=IssueType.PERFORMANCE,
@@ -894,7 +911,9 @@ class StaticAnalyzer(BaseAnalyzer):
 
         return issues
 
-    async def _check_compliance(self, code: str, file_path: str, language: str) -> list[CodeIssue]:
+    async def _check_compliance(
+        self, code: str, file_path: str, language: str
+    ) -> list[CodeIssue]:
         """æª¢æ¸¬åˆè¦æ€§å•é¡Œ"""
         issues = []
 
@@ -930,7 +949,9 @@ class StaticAnalyzer(BaseAnalyzer):
         """è¨ˆç®—ä»£ç¢¼é‡è¤‡ç‡"""
         lines = code.split("\n")
         lines = [
-            line.strip() for line in lines if line.strip() and not line.strip().startswith("#")
+            line.strip()
+            for line in lines
+            if line.strip() and not line.strip().startswith("#")
         ]
         if len(lines) < 10:
             return 0.0
@@ -1054,7 +1075,8 @@ class CodeAnalysisEngine:
 async def main():
     """ä¸»ç¨‹åº"""
     logging.basicConfig(
-        level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+        level=logging.INFO,
+        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
     )
 
     config = {
diff --git a/workspace/src/apps/web-backend/services/models.py b/workspace/src/apps/web-backend/services/models.py
index 6a58c95..7d1d4a7 100644
--- a/workspace/src/apps/web-backend/services/models.py
+++ b/workspace/src/apps/web-backend/services/models.py
@@ -7,18 +7,16 @@
 ============================================================================
 """
 
-from sqlalchemy.orm import Session, sessionmaker
-from sqlalchemy import create_engine
-from contextlib import contextmanager
 import enum
+from contextlib import contextmanager
 from datetime import datetime
 from typing import Any
 
 from sqlalchemy import JSON, Column, DateTime
 from sqlalchemy import Enum as SQLEnum
-from sqlalchemy import Float, ForeignKey, Index, Integer, String, Text
+from sqlalchemy import Float, ForeignKey, Index, Integer, String, Text, create_engine
 from sqlalchemy.ext.declarative import declarative_base
-from sqlalchemy.orm import relationship
+from sqlalchemy.orm import Session, relationship, sessionmaker
 
 Base = declarative_base()
 
@@ -100,7 +98,9 @@ class AnalysisRecord(Base):
     error_message = Column(Text, nullable=True)
 
     # é—œè¯
-    issues = relationship("IssueRecord", back_populates="analysis", cascade="all, delete-orphan")
+    issues = relationship(
+        "IssueRecord", back_populates="analysis", cascade="all, delete-orphan"
+    )
 
     # ç´¢å¼•
     __table_args__ = (
@@ -119,7 +119,9 @@ class AnalysisRecord(Base):
             "strategy": self.strategy,
             "created_at": self.created_at.isoformat() if self.created_at else None,
             "started_at": self.started_at.isoformat() if self.started_at else None,
-            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
+            "completed_at": (
+                self.completed_at.isoformat() if self.completed_at else None
+            ),
             "duration": self.duration,
             "total_issues": self.total_issues,
             "critical_issues": self.critical_issues,
@@ -140,7 +142,9 @@ class IssueRecord(Base):
     id = Column(String(36), primary_key=True)
 
     # å¤–éµ
-    analysis_id = Column(String(36), ForeignKey("analysis_records.id"), nullable=False, index=True)
+    analysis_id = Column(
+        String(36), ForeignKey("analysis_records.id"), nullable=False, index=True
+    )
 
     # å•é¡Œåˆ†é¡
     type = Column(SQLEnum(IssueType), nullable=False, index=True)
@@ -211,7 +215,9 @@ class DatabaseManager:
             echo=False,
             pool_pre_ping=True,
         )
-        self.SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)
+        self.SessionLocal = sessionmaker(
+            autocommit=False, autoflush=False, bind=self.engine
+        )
 
     def create_tables(self):
         """å‰µå»ºæ‰€æœ‰è¡¨"""
diff --git a/workspace/src/apps/web-backend/tests/test_code_analyzer.py b/workspace/src/apps/web-backend/tests/test_code_analyzer.py
index 0303936..2009672 100644
--- a/workspace/src/apps/web-backend/tests/test_code_analyzer.py
+++ b/workspace/src/apps/web-backend/tests/test_code_analyzer.py
@@ -9,6 +9,11 @@ Version: 2.0.0
 ============================================================================
 """
 
+import sys
+from datetime import datetime
+from pathlib import Path
+
+import pytest
 from services.code_analyzer import (
     AnalysisResult,
     AnalysisStrategy,
@@ -21,11 +26,6 @@ from services.code_analyzer import (
     SeverityLevel,
     StaticAnalyzer,
 )
-import sys
-from datetime import datetime
-from pathlib import Path
-
-import pytest
 
 # Add parent directory to path for imports
 sys.path.insert(0, str(Path(__file__).parent.parent))
@@ -107,7 +107,9 @@ class TestDataModels:
 
     def test_analysis_result_creation(self):
         """æ¸¬è©¦åˆ†æçµæœå‰µå»º"""
-        result = AnalysisResult(repository="test-repo", commit_hash="abc123", branch="main")
+        result = AnalysisResult(
+            repository="test-repo", commit_hash="abc123", branch="main"
+        )
 
         assert result.repository == "test-repo"
         assert result.commit_hash == "abc123"
@@ -283,7 +285,9 @@ class TestLanguageAnalyzers:
         )
 
         # Should detect use of 'var'
-        assert any("var" in issue.message.lower() for issue in issues) or len(issues) >= 0
+        assert (
+            any("var" in issue.message.lower() for issue in issues) or len(issues) >= 0
+        )
 
 
 # ============================================================================
@@ -311,7 +315,9 @@ class TestCodeAnalysisEngine:
     async def test_analyze_repository(self, engine):
         """æ¸¬è©¦ä»£ç¢¼åº«åˆ†æ"""
         result = await engine.analyze_repository(
-            repo_path="/tmp/test-repo", commit_hash="abc123", strategy=AnalysisStrategy.STANDARD
+            repo_path="/tmp/test-repo",
+            commit_hash="abc123",
+            strategy=AnalysisStrategy.STANDARD,
         )
 
         assert isinstance(result, AnalysisResult)
diff --git a/workspace/src/automation/architect/core/analysis/performance_analyzer.py b/workspace/src/automation/architect/core/analysis/performance_analyzer.py
index 86cf5bc..5b76492 100644
--- a/workspace/src/automation/architect/core/analysis/performance_analyzer.py
+++ b/workspace/src/automation/architect/core/analysis/performance_analyzer.py
@@ -43,7 +43,9 @@ class PerformanceAnalyzer:
         self.config = config or {}
         logger.info("PerformanceAnalyzer initialized")
 
-    async def analyze(self, code_path: str, profiling: bool = False) -> List[PerformanceIssue]:
+    async def analyze(
+        self, code_path: str, profiling: bool = False
+    ) -> List[PerformanceIssue]:
         """
         åŸ·è¡Œæ€§èƒ½åˆ†æ
 
@@ -78,7 +80,11 @@ class PerformanceAnalyzer:
 
             for line_num, line in enumerate(lines, 1):
                 # æª¢æŸ¥å¸¸è¦‹æ€§èƒ½å•é¡Œ
-                if "for" in line and "for" in lines[line_num] if line_num < len(lines) else False:
+                if (
+                    "for" in line and "for" in lines[line_num]
+                    if line_num < len(lines)
+                    else False
+                ):
                     issues.append(
                         PerformanceIssue(
                             type="nested-loops",
diff --git a/workspace/src/automation/architect/core/analysis/security_scanner.py b/workspace/src/automation/architect/core/analysis/security_scanner.py
index 7de196d..a64cc60 100644
--- a/workspace/src/automation/architect/core/analysis/security_scanner.py
+++ b/workspace/src/automation/architect/core/analysis/security_scanner.py
@@ -67,8 +67,16 @@ class SecurityScanner:
                 "hardcoded-api-key",
                 "Hardcoded API key detected",
             ),
-            (r'secret\s*=\s*["\'][^"\']+["\']', "hardcoded-secret", "Hardcoded secret detected"),
-            (r'token\s*=\s*["\'][^"\']+["\']', "hardcoded-token", "Hardcoded token detected"),
+            (
+                r'secret\s*=\s*["\'][^"\']+["\']',
+                "hardcoded-secret",
+                "Hardcoded secret detected",
+            ),
+            (
+                r'token\s*=\s*["\'][^"\']+["\']',
+                "hardcoded-token",
+                "Hardcoded token detected",
+            ),
             (
                 r'private[_-]?key\s*=\s*["\'][^"\']+["\']',
                 "hardcoded-private-key",
@@ -98,7 +106,11 @@ class SecurityScanner:
         # XSS æ¨¡å¼
         self.xss_patterns = [
             (r"innerHTML\s*=\s*", "xss", "Potential XSS vulnerability via innerHTML"),
-            (r"document\.write\s*\(", "xss", "Potential XSS vulnerability via document.write"),
+            (
+                r"document\.write\s*\(",
+                "xss",
+                "Potential XSS vulnerability via document.write",
+            ),
             (r"eval\s*\(", "eval-usage", "Use of eval() can lead to code injection"),
         ]
 
@@ -192,7 +204,9 @@ class SecurityScanner:
 
         return issues
 
-    def _check_secrets(self, line: str, file_path: Path, line_num: int) -> List[SecurityIssue]:
+    def _check_secrets(
+        self, line: str, file_path: Path, line_num: int
+    ) -> List[SecurityIssue]:
         """æª¢æŸ¥ç¡¬ç·¨ç¢¼å¯†é‘°"""
         issues = []
 
@@ -234,7 +248,9 @@ class SecurityScanner:
 
         return issues
 
-    def _check_xss(self, line: str, file_path: Path, line_num: int) -> List[SecurityIssue]:
+    def _check_xss(
+        self, line: str, file_path: Path, line_num: int
+    ) -> List[SecurityIssue]:
         """æª¢æŸ¥ XSS é¢¨éšª"""
         issues = []
 
@@ -257,7 +273,9 @@ class SecurityScanner:
 
         return issues
 
-    def _check_crypto(self, line: str, file_path: Path, line_num: int) -> List[SecurityIssue]:
+    def _check_crypto(
+        self, line: str, file_path: Path, line_num: int
+    ) -> List[SecurityIssue]:
         """æª¢æŸ¥ä¸å®‰å…¨çš„åŠ å¯†ç®—æ³•"""
         issues = []
 
diff --git a/workspace/src/automation/architect/core/analysis/static_analyzer.py b/workspace/src/automation/architect/core/analysis/static_analyzer.py
index d294382..3faf91c 100644
--- a/workspace/src/automation/architect/core/analysis/static_analyzer.py
+++ b/workspace/src/automation/architect/core/analysis/static_analyzer.py
@@ -63,7 +63,10 @@ class StaticAnalyzer:
         logger.info("StaticAnalyzer initialized")
 
     async def analyze(
-        self, code_path: str, language: Optional[str] = None, rules: Optional[List[str]] = None
+        self,
+        code_path: str,
+        language: Optional[str] = None,
+        rules: Optional[List[str]] = None,
     ) -> AnalysisResult:
         """
         åŸ·è¡Œéœæ…‹ä»£ç¢¼åˆ†æ
@@ -92,7 +95,9 @@ class StaticAnalyzer:
             all_metrics[str(path)] = file_metrics
         elif path.is_dir():
             for file_path in self._get_code_files(path):
-                file_issues, file_metrics = await self._analyze_file(file_path, language)
+                file_issues, file_metrics = await self._analyze_file(
+                    file_path, language
+                )
                 issues.extend(file_issues)
                 all_metrics[str(file_path)] = file_metrics
         else:
@@ -182,7 +187,13 @@ class StaticAnalyzer:
             CodeMetrics: ä»£ç¢¼æŒ‡æ¨™
         """
         lines = code.split("\n")
-        loc = len([line for line in lines if line.strip() and not line.strip().startswith("#")])
+        loc = len(
+            [
+                line
+                for line in lines
+                if line.strip() and not line.strip().startswith("#")
+            ]
+        )
 
         # ç°¡åŒ–çš„å¾ªç’°è¤‡é›œåº¦è¨ˆç®—
         complexity = self._calculate_cyclomatic_complexity(code, language)
@@ -204,7 +215,11 @@ class StaticAnalyzer:
             try:
                 tree = ast.parse(code)
                 function_count = len(
-                    [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
+                    [
+                        node
+                        for node in ast.walk(tree)
+                        if isinstance(node, ast.FunctionDef)
+                    ]
                 )
                 class_count = len(
                     [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
@@ -213,7 +228,9 @@ class StaticAnalyzer:
                 pass
 
         # å¯ç¶­è­·æ€§æŒ‡æ•¸ (ç°¡åŒ–ç‰ˆ)
-        maintainability = max(0, 100 - complexity * 2 - (100 - comment_ratio * 100) * 0.5)
+        maintainability = max(
+            0, 100 - complexity * 2 - (100 - comment_ratio * 100) * 0.5
+        )
 
         return CodeMetrics(
             lines_of_code=loc,
@@ -236,7 +253,18 @@ class StaticAnalyzer:
             int: å¾ªç’°è¤‡é›œåº¦
         """
         # ç°¡åŒ–çš„è¤‡é›œåº¦è¨ˆç®—ï¼šè¨ˆç®—æ±ºç­–é»
-        decision_keywords = ["if", "elif", "else", "for", "while", "case", "catch", "&&", "||", "?"]
+        decision_keywords = [
+            "if",
+            "elif",
+            "else",
+            "for",
+            "while",
+            "case",
+            "catch",
+            "&&",
+            "||",
+            "?",
+        ]
         complexity = 1  # åŸºç¤è¤‡é›œåº¦
 
         for keyword in decision_keywords:
@@ -263,7 +291,11 @@ class StaticAnalyzer:
             # æª¢æŸ¥é•·å‡½æ•¸
             for node in ast.walk(tree):
                 if isinstance(node, ast.FunctionDef):
-                    func_lines = node.end_lineno - node.lineno if hasattr(node, "end_lineno") else 0
+                    func_lines = (
+                        node.end_lineno - node.lineno
+                        if hasattr(node, "end_lineno")
+                        else 0
+                    )
                     if func_lines > 50:
                         issues.append(
                             {
@@ -344,7 +376,9 @@ class StaticAnalyzer:
 
         return issues
 
-    def _check_complexity(self, code: str, metrics: CodeMetrics, file_path: Path) -> List[Dict]:
+    def _check_complexity(
+        self, code: str, metrics: CodeMetrics, file_path: Path
+    ) -> List[Dict]:
         """
         æª¢æŸ¥ä»£ç¢¼è¤‡é›œåº¦
 
diff --git a/workspace/src/automation/architect/core/orchestration/pipeline.py b/workspace/src/automation/architect/core/orchestration/pipeline.py
index 003609a..b4a4998 100644
--- a/workspace/src/automation/architect/core/orchestration/pipeline.py
+++ b/workspace/src/automation/architect/core/orchestration/pipeline.py
@@ -14,7 +14,12 @@ except ImportError:
 
     logger = logging.getLogger(__name__)
 
-from ..analysis import ArchitectureAnalyzer, PerformanceAnalyzer, SecurityScanner, StaticAnalyzer
+from ..analysis import (
+    ArchitectureAnalyzer,
+    PerformanceAnalyzer,
+    SecurityScanner,
+    StaticAnalyzer,
+)
 from ..repair import ASTTransformer, RepairVerifier, RuleEngine
 
 
@@ -88,7 +93,9 @@ class AnalysisPipeline:
 
         start_time = time.time()
 
-        logger.info(f"Starting analysis pipeline for: {code_path} (scenario: {scenario})")
+        logger.info(
+            f"Starting analysis pipeline for: {code_path} (scenario: {scenario})"
+        )
 
         try:
             # éšæ®µ 1: ä¸¦è¡ŒåŸ·è¡Œå„ç¨®åˆ†æ
@@ -99,20 +106,30 @@ class AnalysisPipeline:
                 self._run_architecture_analysis(code_path),
             ]
 
-            analysis_results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
+            analysis_results = await asyncio.gather(
+                *analysis_tasks, return_exceptions=True
+            )
 
             results_dict = {
                 "static_analysis": (
-                    analysis_results[0] if not isinstance(analysis_results[0], Exception) else None
+                    analysis_results[0]
+                    if not isinstance(analysis_results[0], Exception)
+                    else None
                 ),
                 "security_scan": (
-                    analysis_results[1] if not isinstance(analysis_results[1], Exception) else None
+                    analysis_results[1]
+                    if not isinstance(analysis_results[1], Exception)
+                    else None
                 ),
                 "performance_analysis": (
-                    analysis_results[2] if not isinstance(analysis_results[2], Exception) else None
+                    analysis_results[2]
+                    if not isinstance(analysis_results[2], Exception)
+                    else None
                 ),
                 "architecture_analysis": (
-                    analysis_results[3] if not isinstance(analysis_results[3], Exception) else None
+                    analysis_results[3]
+                    if not isinstance(analysis_results[3], Exception)
+                    else None
                 ),
             }
 
diff --git a/workspace/src/automation/architect/core/repair/repair_verifier.py b/workspace/src/automation/architect/core/repair/repair_verifier.py
index 052458d..7e86f6d 100644
--- a/workspace/src/automation/architect/core/repair/repair_verifier.py
+++ b/workspace/src/automation/architect/core/repair/repair_verifier.py
@@ -40,7 +40,9 @@ class RepairVerifier:
         self.config = config or {}
         logger.info("RepairVerifier initialized")
 
-    async def verify(self, file_path: str, run_tests: bool = True) -> VerificationResult:
+    async def verify(
+        self, file_path: str, run_tests: bool = True
+    ) -> VerificationResult:
         """
         åŸ·è¡Œé©—è­‰
 
diff --git a/workspace/src/automation/architect/core/repair/rule_engine.py b/workspace/src/automation/architect/core/repair/rule_engine.py
index 66a6847..c592e3e 100644
--- a/workspace/src/automation/architect/core/repair/rule_engine.py
+++ b/workspace/src/automation/architect/core/repair/rule_engine.py
@@ -149,5 +149,9 @@ class RuleEngine:
         except Exception as e:
             logger.error(f"Error applying fixes: {e}")
             return RepairResult(
-                file_path=file_path, rules_applied=[], changes_made=0, success=False, message=str(e)
+                file_path=file_path,
+                rules_applied=[],
+                changes_made=0,
+                success=False,
+                message=str(e),
             )
diff --git a/workspace/src/automation/architect/examples/basic_usage.py b/workspace/src/automation/architect/examples/basic_usage.py
index f80dfb6..de87303 100644
--- a/workspace/src/automation/architect/examples/basic_usage.py
+++ b/workspace/src/automation/architect/examples/basic_usage.py
@@ -5,11 +5,12 @@ Basic Usage Example
 æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Automation Architect ç³»çµ±é€²è¡Œä»£ç¢¼åˆ†æ
 """
 
-from core.orchestration.pipeline import AnalysisPipeline
 import asyncio
 import sys
 from pathlib import Path
 
+from core.orchestration.pipeline import AnalysisPipeline
+
 # æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘ä»¥ä¾¿å°å…¥
 sys.path.insert(0, str(Path(__file__).parent.parent))
 
@@ -23,14 +24,19 @@ async def main():
     pipeline = AnalysisPipeline()
 
     # ç¤ºä¾‹ä»£ç¢¼è·¯å¾‘ (å¯ä»¥æ›¿æ›ç‚ºå¯¦éš›ä»£ç¢¼è·¯å¾‘)
-    code_path = str(Path(__file__).parent.parent / "core" / "analysis" / "static_analyzer.py")
+    code_path = str(
+        Path(__file__).parent.parent / "core" / "analysis" / "static_analyzer.py"
+    )
 
     print(f"åˆ†æç›®æ¨™: {code_path}\n")
 
     # åŸ·è¡Œåˆ†æ
     print("é–‹å§‹åŸ·è¡Œä»£ç¢¼åˆ†æ...")
     result = await pipeline.analyze(
-        code_path=code_path, scenario="general", enable_repair=False, enable_verification=False
+        code_path=code_path,
+        scenario="general",
+        enable_repair=False,
+        enable_verification=False,
     )
 
     # é¡¯ç¤ºçµæœ
diff --git a/workspace/src/automation/architect/tests/unit/test_security_scanner.py b/workspace/src/automation/architect/tests/unit/test_security_scanner.py
index 854c163..f1fc6be 100644
--- a/workspace/src/automation/architect/tests/unit/test_security_scanner.py
+++ b/workspace/src/automation/architect/tests/unit/test_security_scanner.py
@@ -3,12 +3,12 @@ Unit tests for SecurityScanner
 å®‰å…¨æƒæå™¨å–®å…ƒæ¸¬è©¦
 """
 
-from core.analysis.security_scanner import SecurityIssue, SecurityScanner
 import sys
 import tempfile
 from pathlib import Path
 
 import pytest
+from core.analysis.security_scanner import SecurityIssue, SecurityScanner
 
 sys.path.insert(0, str(Path(__file__).parent.parent.parent))
 
@@ -113,7 +113,9 @@ async def test_detect_weak_crypto(scanner, vulnerable_python_file):
 async def test_severity_filter(scanner, vulnerable_python_file):
     """æ¸¬è©¦åš´é‡ç¨‹åº¦éæ¿¾"""
     # åªç²å– critical å•é¡Œ
-    critical_issues = await scanner.scan(str(vulnerable_python_file), severity_filter=["critical"])
+    critical_issues = await scanner.scan(
+        str(vulnerable_python_file), severity_filter=["critical"]
+    )
 
     assert all(issue.severity == "critical" for issue in critical_issues)
 
diff --git a/workspace/src/automation/architect/tests/unit/test_static_analyzer.py b/workspace/src/automation/architect/tests/unit/test_static_analyzer.py
index 6a69e4d..7f23318 100644
--- a/workspace/src/automation/architect/tests/unit/test_static_analyzer.py
+++ b/workspace/src/automation/architect/tests/unit/test_static_analyzer.py
@@ -3,12 +3,12 @@ Unit tests for StaticAnalyzer
 éœæ…‹åˆ†æå™¨å–®å…ƒæ¸¬è©¦
 """
 
-from core.analysis.static_analyzer import AnalysisResult, StaticAnalyzer
 import sys
 import tempfile
 from pathlib import Path
 
 import pytest
+from core.analysis.static_analyzer import AnalysisResult, StaticAnalyzer
 
 # æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent.parent))
diff --git a/workspace/src/automation/genetic/genetic_optimizer.py b/workspace/src/automation/genetic/genetic_optimizer.py
index 4febfaa..63b1a18 100644
--- a/workspace/src/automation/genetic/genetic_optimizer.py
+++ b/workspace/src/automation/genetic/genetic_optimizer.py
@@ -214,7 +214,9 @@ class GeneticOptimizer:
                 return individual
         return sorted_pop[-1]
 
-    def _crossover(self, parent1: Individual, parent2: Individual) -> Tuple[Individual, Individual]:
+    def _crossover(
+        self, parent1: Individual, parent2: Individual
+    ) -> Tuple[Individual, Individual]:
         """Perform crossover between two parents."""
         child1_genes = {}
         child2_genes = {}
diff --git a/workspace/src/automation/self_awareness_report.py b/workspace/src/automation/self_awareness_report.py
index 58e65d7..a07f768 100644
--- a/workspace/src/automation/self_awareness_report.py
+++ b/workspace/src/automation/self_awareness_report.py
@@ -44,7 +44,11 @@ def _parse_sections(manifest_text: str) -> dict[str, str]:
     for index, match in enumerate(matches):
         title = match.group("title").strip()
         start = match.end()
-        end = matches[index + 1].start() if index + 1 < len(matches) else len(manifest_text)
+        end = (
+            matches[index + 1].start()
+            if index + 1 < len(matches)
+            else len(manifest_text)
+        )
         sections[title.lower()] = manifest_text[start:end].strip()
 
     return sections
@@ -80,7 +84,9 @@ def _summarize_sections(sections: dict[str, str]) -> SectionSummary:
     guardrails = _split_bullets(sections.get("guardrails (what we avoid)", ""))
     signals = _split_bullets(sections.get("proof & self-check signals", ""))
 
-    return SectionSummary(identity=identity, needs=needs, guardrails=guardrails, signals=signals)
+    return SectionSummary(
+        identity=identity, needs=needs, guardrails=guardrails, signals=signals
+    )
 
 
 def _validate_command(command: str) -> bool:
@@ -180,7 +186,9 @@ def _run_command_summary(
             command=command,
             exit_code=-1,
             success=False,
-            output_tail=["Invalid command syntax. Check for unclosed quotes or escape characters."],
+            output_tail=[
+                "Invalid command syntax. Check for unclosed quotes or escape characters."
+            ],
         )
     except subprocess.TimeoutExpired as e:
         # Handle timeout: return a special AutomationResult
@@ -214,7 +222,8 @@ def _run_command_summary(
 
     joined_lines = [
         line
-        for line in (result.stdout or "").splitlines() + (result.stderr or "").splitlines()
+        for line in (result.stdout or "").splitlines()
+        + (result.stderr or "").splitlines()
         if line
     ]
     tail = joined_lines[-max_lines:] if joined_lines else []
@@ -252,9 +261,13 @@ def _render_report(
 
     needs_md = "\n".join(f"- {item}" for item in needs) if needs else "- (none listed)"
     guardrails_md = (
-        "\n".join(f"- {item}" for item in guardrails) if guardrails else "- (none listed)"
+        "\n".join(f"- {item}" for item in guardrails)
+        if guardrails
+        else "- (none listed)"
+    )
+    signals_md = (
+        "\n".join(f"- {item}" for item in signals) if signals else "- (none listed)"
     )
-    signals_md = "\n".join(f"- {item}" for item in signals) if signals else "- (none listed)"
 
     sections_md = [
         "## ğŸ“£ Repository Self-Awareness Report",
@@ -371,7 +384,9 @@ def main() -> None:
     if args.automation_cmd:
         for entry in args.automation_cmd:
             if not entry or "=" not in entry:
-                raise ValueError("automation-cmd entries must be in the form Label=command")
+                raise ValueError(
+                    "automation-cmd entries must be in the form Label=command"
+                )
             label, command = entry.split("=", 1)
             command_pairs.append((label.strip() or "Custom", command.strip()))
 
@@ -389,7 +404,9 @@ def main() -> None:
 
     json_output = args.json_output
     if json_output:
-        generated_at = datetime.now(UTC).replace(microsecond=0).isoformat().replace("+00:00", "Z")
+        generated_at = (
+            datetime.now(UTC).replace(microsecond=0).isoformat().replace("+00:00", "Z")
+        )
         payload = {
             "generated_at": generated_at,
             "manifest_path": str(manifest_path),
diff --git a/workspace/src/automation/zero_touch_deployment.py b/workspace/src/automation/zero_touch_deployment.py
index d3ba884..37f32ad 100644
--- a/workspace/src/automation/zero_touch_deployment.py
+++ b/workspace/src/automation/zero_touch_deployment.py
@@ -164,7 +164,9 @@ class ZeroTouchDeploymentEngine:
     def _register_default_handlers(self) -> None:
         """Register default deployment handlers"""
         self.deployment_handlers[DeploymentStrategy.ROLLING] = self._deploy_rolling
-        self.deployment_handlers[DeploymentStrategy.BLUE_GREEN] = self._deploy_blue_green
+        self.deployment_handlers[DeploymentStrategy.BLUE_GREEN] = (
+            self._deploy_blue_green
+        )
         self.deployment_handlers[DeploymentStrategy.CANARY] = self._deploy_canary
         self.deployment_handlers[DeploymentStrategy.RECREATE] = self._deploy_recreate
 
@@ -250,7 +252,9 @@ class ZeroTouchDeploymentEngine:
         try:
             # Prepare deployment
             result.status = DeploymentStatus.PREPARING
-            result.logs.append(f"[{datetime.now().isoformat()}] Preparing deployment...")
+            result.logs.append(
+                f"[{datetime.now().isoformat()}] Preparing deployment..."
+            )
             await self._prepare_deployment(config, result)
 
             # Execute deployment based on strategy
@@ -259,12 +263,16 @@ class ZeroTouchDeploymentEngine:
                 f"[{datetime.now().isoformat()}] Executing {config.strategy.value} deployment..."
             )
 
-            handler = self.deployment_handlers.get(config.strategy, self._deploy_rolling)
+            handler = self.deployment_handlers.get(
+                config.strategy, self._deploy_rolling
+            )
             await handler(config, result)
 
             # Verify deployment
             result.status = DeploymentStatus.VERIFYING
-            result.logs.append(f"[{datetime.now().isoformat()}] Verifying deployment health...")
+            result.logs.append(
+                f"[{datetime.now().isoformat()}] Verifying deployment health..."
+            )
 
             is_healthy = await self._verify_deployment(config, result)
 
@@ -295,17 +303,23 @@ class ZeroTouchDeploymentEngine:
 
         return result
 
-    async def _prepare_deployment(self, config: DeploymentConfig, result: DeploymentResult) -> None:
+    async def _prepare_deployment(
+        self, config: DeploymentConfig, result: DeploymentResult
+    ) -> None:
         """Prepare for deployment"""
         # Simulate preparation steps
         await asyncio.sleep(0.1)
 
         result.logs.append(f"  - Environment: {config.target.environment.value}")
-        result.logs.append(f"  - Artifact: {config.artifact.name}:{config.artifact.version}")
+        result.logs.append(
+            f"  - Artifact: {config.artifact.name}:{config.artifact.version}"
+        )
         result.logs.append(f"  - Strategy: {config.strategy.value}")
         result.logs.append(f"  - Replicas: {config.target.replicas}")
 
-    async def _deploy_rolling(self, config: DeploymentConfig, result: DeploymentResult) -> None:
+    async def _deploy_rolling(
+        self, config: DeploymentConfig, result: DeploymentResult
+    ) -> None:
         """Execute rolling deployment"""
         replicas = config.target.replicas
 
@@ -315,7 +329,9 @@ class ZeroTouchDeploymentEngine:
 
         result.logs.append("  - Rolling deployment complete")
 
-    async def _deploy_blue_green(self, config: DeploymentConfig, result: DeploymentResult) -> None:
+    async def _deploy_blue_green(
+        self, config: DeploymentConfig, result: DeploymentResult
+    ) -> None:
         """Execute blue-green deployment"""
         result.logs.append("  - Spinning up green environment...")
         await asyncio.sleep(0.1)
@@ -328,7 +344,9 @@ class ZeroTouchDeploymentEngine:
 
         result.logs.append("  - Blue-green deployment complete")
 
-    async def _deploy_canary(self, config: DeploymentConfig, result: DeploymentResult) -> None:
+    async def _deploy_canary(
+        self, config: DeploymentConfig, result: DeploymentResult
+    ) -> None:
         """Execute canary deployment"""
         result.logs.append("  - Deploying canary instance (10% traffic)...")
         await asyncio.sleep(0.05)
@@ -341,7 +359,9 @@ class ZeroTouchDeploymentEngine:
 
         result.logs.append("  - Canary deployment complete")
 
-    async def _deploy_recreate(self, config: DeploymentConfig, result: DeploymentResult) -> None:
+    async def _deploy_recreate(
+        self, config: DeploymentConfig, result: DeploymentResult
+    ) -> None:
         """Execute recreate deployment"""
         result.logs.append("  - Terminating existing instances...")
         await asyncio.sleep(0.05)
@@ -351,7 +371,9 @@ class ZeroTouchDeploymentEngine:
 
         result.logs.append("  - Recreate deployment complete")
 
-    async def _verify_deployment(self, config: DeploymentConfig, result: DeploymentResult) -> bool:
+    async def _verify_deployment(
+        self, config: DeploymentConfig, result: DeploymentResult
+    ) -> bool:
         """Verify deployment health"""
         # Simulate health check
         await asyncio.sleep(0.1)
@@ -392,7 +414,9 @@ class ZeroTouchDeploymentEngine:
             "target": result.target.name,
             "artifact": f"{result.artifact.name}:{result.artifact.version}",
             "started_at": result.started_at.isoformat(),
-            "completed_at": result.completed_at.isoformat() if result.completed_at else None,
+            "completed_at": (
+                result.completed_at.isoformat() if result.completed_at else None
+            ),
             "duration_seconds": result.duration_seconds,
             "health_status": result.health_status,
             "error": result.error,
diff --git a/workspace/src/autonomous/agents/__init__.py b/workspace/src/autonomous/agents/__init__.py
index d3473c8..d014241 100644
--- a/workspace/src/autonomous/agents/__init__.py
+++ b/workspace/src/autonomous/agents/__init__.py
@@ -27,7 +27,9 @@ import sys
 from pathlib import Path
 
 
-def _import_kebab_module(module_alias: str, file_name: str, legacy_alias: str | None = None):
+def _import_kebab_module(
+    module_alias: str, file_name: str, legacy_alias: str | None = None
+):
     """
     Load kebab-case source files and expose them under underscore-based aliases.
 
@@ -81,7 +83,9 @@ def _import_kebab_module(module_alias: str, file_name: str, legacy_alias: str |
 
 
 # Import base agent components
-_base_agent = _import_kebab_module("base_agent", "base-agent.py", legacy_alias="agents.base_agent")
+_base_agent = _import_kebab_module(
+    "base_agent", "base-agent.py", legacy_alias="agents.base_agent"
+)
 if _base_agent:
     BaseAgent = _base_agent.BaseAgent
     AgentStatus = _base_agent.AgentStatus
diff --git a/workspace/src/autonomous/agents/agents/recognition_server.py b/workspace/src/autonomous/agents/agents/recognition_server.py
index 59f5182..cd331a9 100644
--- a/workspace/src/autonomous/agents/agents/recognition_server.py
+++ b/workspace/src/autonomous/agents/agents/recognition_server.py
@@ -86,7 +86,10 @@ class RecognitionServer:
             "action": action,
             "need_code": need_code,
             "query": query,
-            "context": {"has_problem": bool(problem_content), "has_code": bool(editor_code)},
+            "context": {
+                "has_problem": bool(problem_content),
+                "has_code": bool(editor_code),
+            },
         }
 
         logger.info(f"Intent analysis result: action={action}, need_code={need_code}")
@@ -167,7 +170,9 @@ class RecognitionServer:
         # Check for diagram generation
         if any(keyword in query_lower for keyword in diagram_keywords):
             # Exclude if asking about code itself
-            if "code" in query_lower and ("show" in query_lower or "mermaid" in query_lower):
+            if "code" in query_lower and (
+                "show" in query_lower or "mermaid" in query_lower
+            ):
                 return self.ACTION_PROCEED
             return self.ACTION_GENERATE_DIAGRAM
 
@@ -272,13 +277,19 @@ class RecognitionServer:
 
         # Check safety
         if not intent_result["safe"]:
-            yield {"type": "blocked", "data": {"message": "Request blocked for security"}}
+            yield {
+                "type": "blocked",
+                "data": {"message": "Request blocked for security"},
+            }
             return
 
         # Yield routing information
         yield {
             "type": "routing",
-            "data": {"action": intent_result["action"], "need_code": intent_result["need_code"]},
+            "data": {
+                "action": intent_result["action"],
+                "need_code": intent_result["need_code"],
+            },
         }
 
         # Complete
diff --git a/workspace/src/autonomous/agents/agents/task_executor.py b/workspace/src/autonomous/agents/agents/task_executor.py
index 524b101..59ebe0d 100644
--- a/workspace/src/autonomous/agents/agents/task_executor.py
+++ b/workspace/src/autonomous/agents/agents/task_executor.py
@@ -18,7 +18,9 @@ import logging
 from typing import Any, AsyncGenerator, Dict, Optional
 
 # Configure logging - must be before any logger usage
-logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
+logging.basicConfig(
+    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
+)
 logger = logging.getLogger(__name__)
 
 try:
@@ -76,7 +78,9 @@ class TaskExecutor:
         self.context_history = []
         logger.info("Context reset")
 
-    async def analyze_code(self, code: str, analysis_type: str = "comprehensive") -> Dict[str, Any]:
+    async def analyze_code(
+        self, code: str, analysis_type: str = "comprehensive"
+    ) -> Dict[str, Any]:
         """
         Analyze code for quality, security, and performance issues
 
@@ -108,7 +112,9 @@ class TaskExecutor:
 
         # Generate automated fix recommendations
         if results["issues"]:
-            results["recommendations"] = await self._generate_recommendations(results["issues"])
+            results["recommendations"] = await self._generate_recommendations(
+                results["issues"]
+            )
 
         logger.info(f"Analysis complete: {len(results['issues'])} issues found")
         return results
diff --git a/workspace/src/autonomous/agents/agents/visualization_agent.py b/workspace/src/autonomous/agents/agents/visualization_agent.py
index b867ff1..4e7754a 100644
--- a/workspace/src/autonomous/agents/agents/visualization_agent.py
+++ b/workspace/src/autonomous/agents/agents/visualization_agent.py
@@ -66,7 +66,10 @@ class VisualizationAgent:
             "topic": topic,
             "explanation": explanation,
             "follow_up_questions": follow_ups,
-            "has_context": {"problem": bool(problem_content), "code": bool(editor_code)},
+            "has_context": {
+                "problem": bool(problem_content),
+                "code": bool(editor_code),
+            },
         }
 
         # Store in history
@@ -90,7 +93,14 @@ class VisualizationAgent:
         # Algorithm topics
         if any(
             keyword in query_lower
-            for keyword in ["sort", "search", "algorithm", "complexity", "éæ­¸", "recursion"]
+            for keyword in [
+                "sort",
+                "search",
+                "algorithm",
+                "complexity",
+                "éæ­¸",
+                "recursion",
+            ]
         ):
             return "algorithm"
 
@@ -136,7 +146,12 @@ class VisualizationAgent:
             Structured explanation
         """
         # Base explanation structure
-        explanation = {"summary": "", "analogy": "", "key_points": [], "practical_example": ""}
+        explanation = {
+            "summary": "",
+            "analogy": "",
+            "key_points": [],
+            "practical_example": "",
+        }
 
         if topic == "algorithm":
             explanation["summary"] = "ç®—æ³•æ˜¯è§£æ±ºå•é¡Œçš„æ­¥é©Ÿæ–¹æ³•"
@@ -147,11 +162,15 @@ class VisualizationAgent:
                 "æ¯æ­¥é©Ÿéƒ½æ˜¯å¯åŸ·è¡Œçš„",
                 "æœ€çµ‚èƒ½è§£æ±ºç‰¹å®šå•é¡Œ",
             ]
-            explanation["practical_example"] = "åœ¨è‡ªå‹•é§•é§›ä¸­ï¼Œè·¯å¾‘è¦åŠƒç®—æ³•æ±ºå®šè»Šè¼›è¡Œé§›è·¯ç·š"
+            explanation["practical_example"] = (
+                "åœ¨è‡ªå‹•é§•é§›ä¸­ï¼Œè·¯å¾‘è¦åŠƒç®—æ³•æ±ºå®šè»Šè¼›è¡Œé§›è·¯ç·š"
+            )
 
         elif topic == "data_structure":
             explanation["summary"] = "æ•¸æ“šçµæ§‹æ˜¯çµ„ç¹”å’Œå­˜å„²æ•¸æ“šçš„æ–¹å¼"
-            explanation["analogy"] = "å°±åƒåœ–æ›¸é¤¨çš„åˆ†é¡ç³»çµ±ï¼Œä¸åŒçš„çµ„ç¹”æ–¹å¼é©åˆä¸åŒçš„æŸ¥æ‰¾éœ€æ±‚"
+            explanation["analogy"] = (
+                "å°±åƒåœ–æ›¸é¤¨çš„åˆ†é¡ç³»çµ±ï¼Œä¸åŒçš„çµ„ç¹”æ–¹å¼é©åˆä¸åŒçš„æŸ¥æ‰¾éœ€æ±‚"
+            )
             explanation["key_points"] = [
                 "é¸æ“‡åˆé©çš„æ•¸æ“šçµæ§‹å½±éŸ¿æ•ˆç‡",
                 "ä¸åŒæ“ä½œæœ‰ä¸åŒçš„æ™‚é–“è¤‡é›œåº¦",
@@ -233,8 +252,16 @@ class VisualizationAgent:
                 "ä»€éº¼æ™‚å€™æ‡‰è©²ä½¿ç”¨ç•°æ­¥è™•ç†ï¼Ÿ",
                 "å¦‚ä½•è™•ç†ç«¶æ…‹æ¢ä»¶ï¼Ÿ",
             ],
-            "safety": ["å¦‚ä½•è¨­è¨ˆå®¹éŒ¯æ©Ÿåˆ¶ï¼Ÿ", "æ€æ¨£è™•ç†ç•°å¸¸æƒ…æ³ï¼Ÿ", "å¦‚ä½•é©—è­‰ç³»çµ±çš„å®‰å…¨æ€§ï¼Ÿ"],
-            "general": ["é€™å€‹æ¦‚å¿µçš„å¯¦éš›æ‡‰ç”¨å ´æ™¯ï¼Ÿ", "æœ‰å“ªäº›æœ€ä½³å¯¦è¸ï¼Ÿ", "å¸¸è¦‹çš„éŒ¯èª¤æ˜¯ä»€éº¼ï¼Ÿ"],
+            "safety": [
+                "å¦‚ä½•è¨­è¨ˆå®¹éŒ¯æ©Ÿåˆ¶ï¼Ÿ",
+                "æ€æ¨£è™•ç†ç•°å¸¸æƒ…æ³ï¼Ÿ",
+                "å¦‚ä½•é©—è­‰ç³»çµ±çš„å®‰å…¨æ€§ï¼Ÿ",
+            ],
+            "general": [
+                "é€™å€‹æ¦‚å¿µçš„å¯¦éš›æ‡‰ç”¨å ´æ™¯ï¼Ÿ",
+                "æœ‰å“ªäº›æœ€ä½³å¯¦è¸ï¼Ÿ",
+                "å¸¸è¦‹çš„éŒ¯èª¤æ˜¯ä»€éº¼ï¼Ÿ",
+            ],
         }
 
         return base_questions.get(topic, base_questions["general"])
diff --git a/workspace/src/autonomous/agents/auto_upgrade_env.py b/workspace/src/autonomous/agents/auto_upgrade_env.py
index bea7d18..60f0e62 100644
--- a/workspace/src/autonomous/agents/auto_upgrade_env.py
+++ b/workspace/src/autonomous/agents/auto_upgrade_env.py
@@ -30,7 +30,9 @@ from packaging import version
 from packaging.requirements import Requirement
 
 # Configure logging
-logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
+logging.basicConfig(
+    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
+)
 logger = logging.getLogger(__name__)
 
 
@@ -217,7 +219,9 @@ class AutoUpgradeEnvironment:
 
         return recommendations.get(dep_name, [])
 
-    def install_package(self, pip_package: str, use_cache: bool = True) -> Tuple[bool, str]:
+    def install_package(
+        self, pip_package: str, use_cache: bool = True
+    ) -> Tuple[bool, str]:
         """
         Install a package using pip with caching support
 
@@ -257,7 +261,9 @@ class AutoUpgradeEnvironment:
                     "package": pip_package,
                     "success": True,
                     "timestamp": (
-                        subprocess.check_output(["date", "+%Y-%m-%d %H:%M:%S"], text=True).strip()
+                        subprocess.check_output(
+                            ["date", "+%Y-%m-%d %H:%M:%S"], text=True
+                        ).strip()
                         if sys.platform != "win32"
                         else "now"
                     ),
@@ -295,7 +301,9 @@ class AutoUpgradeEnvironment:
         results = {}
 
         with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
-            future_to_pkg = {executor.submit(self.install_package, pkg): pkg for pkg in packages}
+            future_to_pkg = {
+                executor.submit(self.install_package, pkg): pkg for pkg in packages
+            }
 
             for future in concurrent.futures.as_completed(future_to_pkg):
                 pkg = future_to_pkg[future]
@@ -352,9 +360,13 @@ class AutoUpgradeEnvironment:
                     results[dep_name] = False
 
                     if not dep_info.get("optional", False):
-                        logger.error(f"âœ— å¿…éœ€ä¾è³´å®‰è£å¤±æ•— Required dependency failed: {dep_name}")
+                        logger.error(
+                            f"âœ— å¿…éœ€ä¾è³´å®‰è£å¤±æ•— Required dependency failed: {dep_name}"
+                        )
                     else:
-                        logger.warning(f"âš  å¯é¸ä¾è³´å®‰è£å¤±æ•— Optional dependency failed: {dep_name}")
+                        logger.warning(
+                            f"âš  å¯é¸ä¾è³´å®‰è£å¤±æ•— Optional dependency failed: {dep_name}"
+                        )
             else:
                 self.missing_deps.append(dep_name)
                 results[dep_name] = False
@@ -422,7 +434,9 @@ class AutoUpgradeEnvironment:
                 with open(config_path, "r") as f:
                     content = f.read()
                     # Extract dependencies from [project.dependencies]
-                    deps_match = re.search(r"\[project\.dependencies\](.*?)\[", content, re.DOTALL)
+                    deps_match = re.search(
+                        r"\[project\.dependencies\](.*?)\[", content, re.DOTALL
+                    )
                     if deps_match:
                         deps_section = deps_match.group(1)
                         for line in deps_section.split("\n"):
@@ -444,7 +458,9 @@ class AutoUpgradeEnvironment:
                 with open(config_path, "r") as f:
                     content = f.read()
                     # Extract pip dependencies
-                    pip_match = re.search(r"- pip:(.*?)(?:\n[^ ]|\Z)", content, re.DOTALL)
+                    pip_match = re.search(
+                        r"- pip:(.*?)(?:\n[^ ]|\Z)", content, re.DOTALL
+                    )
                     if pip_match:
                         pip_section = pip_match.group(1)
                         for line in pip_section.split("\n"):
@@ -452,14 +468,18 @@ class AutoUpgradeEnvironment:
                             if line:
                                 packages.append(line)
 
-            logger.info(f"âœ“ å¾é…ç½®æ–‡ä»¶åŠ è¼‰ Loaded {len(packages)} dependencies from {config_path}")
+            logger.info(
+                f"âœ“ å¾é…ç½®æ–‡ä»¶åŠ è¼‰ Loaded {len(packages)} dependencies from {config_path}"
+            )
 
         except Exception as e:
             logger.error(f"âœ— åŠ è¼‰é…ç½®æ–‡ä»¶å¤±æ•— Failed to load config: {e}")
 
         return packages
 
-    def upgrade_from_config(self, config_path: Path, parallel: bool = True) -> Dict[str, bool]:
+    def upgrade_from_config(
+        self, config_path: Path, parallel: bool = True
+    ) -> Dict[str, bool]:
         """
         Upgrade dependencies from configuration file
 
@@ -479,7 +499,9 @@ class AutoUpgradeEnvironment:
         # Detect conflicts
         conflicts = self.detect_version_conflicts(packages)
         if conflicts:
-            logger.warning(f"âš  æª¢æ¸¬åˆ° {len(conflicts)} å€‹ç‰ˆæœ¬è¡çª Detected version conflicts:")
+            logger.warning(
+                f"âš  æª¢æ¸¬åˆ° {len(conflicts)} å€‹ç‰ˆæœ¬è¡çª Detected version conflicts:"
+            )
             for conflict in conflicts:
                 logger.warning(
                     f"  - {conflict['package']}: {conflict['existing']} vs {conflict['new']}"
@@ -488,7 +510,9 @@ class AutoUpgradeEnvironment:
 
         # Install packages
         if parallel and len(packages) > 1:
-            logger.info(f"ä½¿ç”¨ä¸¦è¡Œå®‰è£ Using parallel installation for {len(packages)} packages")
+            logger.info(
+                f"ä½¿ç”¨ä¸¦è¡Œå®‰è£ Using parallel installation for {len(packages)} packages"
+            )
             install_results = self.install_packages_parallel(packages)
 
             results = {}
@@ -532,9 +556,7 @@ class AutoUpgradeEnvironment:
                     # Show recommendations
                     recommendations = self.recommend_dependencies(dep)
                     if recommendations:
-                        summary += (
-                            f"    ğŸ’¡ æ¨è–¦ç›¸é—œä¾è³´ Recommended: {', '.join(recommendations)}\n"
-                        )
+                        summary += f"    ğŸ’¡ æ¨è–¦ç›¸é—œä¾è³´ Recommended: {', '.join(recommendations)}\n"
                 else:
                     summary += f"  - {dep}\n"
 
@@ -544,18 +566,14 @@ class AutoUpgradeEnvironment:
                 if dep in self.DEPENDENCY_MAP:
                     summary += f"  - {dep}: {self.DEPENDENCY_MAP[dep]['description']}\n"
                     if self.DEPENDENCY_MAP[dep].get("optional", False):
-                        summary += (
-                            f"    (å¯é¸ä¾è³´ï¼ŒåŠŸèƒ½å¯èƒ½å—é™ Optional, features may be limited)\n"
-                        )
+                        summary += f"    (å¯é¸ä¾è³´ï¼ŒåŠŸèƒ½å¯èƒ½å—é™ Optional, features may be limited)\n"
                 else:
                     summary += f"  - {dep}\n"
 
         if self.conflict_log:
             summary += f"\nâš  ç‰ˆæœ¬è¡çª Version Conflicts ({len(self.conflict_log)}):\n"
             for conflict in self.conflict_log:
-                summary += (
-                    f"  - {conflict['package']}: {conflict['existing']} â‡„ {conflict['new']}\n"
-                )
+                summary += f"  - {conflict['package']}: {conflict['existing']} â‡„ {conflict['new']}\n"
 
         # Cache statistics
         if hasattr(self, "cache") and self.cache:
@@ -592,14 +610,20 @@ def auto_upgrade_on_import():
 if __name__ == "__main__":
     import argparse
 
-    parser = argparse.ArgumentParser(description="Auto Upgrade Environment Configuration")
+    parser = argparse.ArgumentParser(
+        description="Auto Upgrade Environment Configuration"
+    )
     parser.add_argument(
         "--upgrade-all", action="store_true", help="Upgrade all optional dependencies"
     )
     parser.add_argument(
-        "--check-only", action="store_true", help="Check dependencies without installing"
+        "--check-only",
+        action="store_true",
+        help="Check dependencies without installing",
+    )
+    parser.add_argument(
+        "--deps", nargs="+", help="Specific dependencies to check/upgrade"
     )
-    parser.add_argument("--deps", nargs="+", help="Specific dependencies to check/upgrade")
     parser.add_argument(
         "--from-config",
         type=str,
@@ -615,15 +639,21 @@ if __name__ == "__main__":
         action="store_true",
         help="Detect version conflicts without installing",
     )
-    parser.add_argument("--clear-cache", action="store_true", help="Clear installation cache")
-    parser.add_argument("--recommend", type=str, help="Show recommended dependencies for a package")
+    parser.add_argument(
+        "--clear-cache", action="store_true", help="Clear installation cache"
+    )
+    parser.add_argument(
+        "--recommend", type=str, help="Show recommended dependencies for a package"
+    )
 
     args = parser.parse_args()
 
     # Create upgrader
     upgrader = AutoUpgradeEnvironment(auto_install=not args.check_only)
 
-    print("=== æ™ºèƒ½ç’°å¢ƒå‡ç´šç³»çµ± - ä¼æ¥­ç‰ˆ Intelligent Environment Upgrade System - Enterprise ===\n")
+    print(
+        "=== æ™ºèƒ½ç’°å¢ƒå‡ç´šç³»çµ± - ä¼æ¥­ç‰ˆ Intelligent Environment Upgrade System - Enterprise ===\n"
+    )
 
     # Handle clear cache
     if args.clear_cache:
diff --git a/workspace/src/autonomous/agents/autopilot-agent.py b/workspace/src/autonomous/agents/autopilot-agent.py
index 739d0d4..dbed3b7 100644
--- a/workspace/src/autonomous/agents/autopilot-agent.py
+++ b/workspace/src/autonomous/agents/autopilot-agent.py
@@ -120,8 +120,12 @@ class AutopilotAgent(BaseAgent):
     def _check_tool(self, tool: str) -> dict[str, Any]:
         """æª¢æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨"""
         try:
-            result = subprocess.run([tool, "--version"], capture_output=True, text=True, timeout=5)
-            version = result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+            result = subprocess.run(
+                [tool, "--version"], capture_output=True, text=True, timeout=5
+            )
+            version = (
+                result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+            )
             return {
                 "tool": tool,
                 "status": "ok" if result.returncode == 0 else "error",
@@ -145,7 +149,9 @@ class AutopilotAgent(BaseAgent):
             print(f"  {icon} {check['tool']}: {version}")
 
         print()
-        self.log_info(f"è¨ºæ–·çµæœ: {diagnosis['passed']} é€šé, {diagnosis['failed']} å¤±æ•—")
+        self.log_info(
+            f"è¨ºæ–·çµæœ: {diagnosis['passed']} é€šé, {diagnosis['failed']} å¤±æ•—"
+        )
 
     def queue_task(self, task_name: str, options: dict | None = None) -> None:
         """
@@ -267,7 +273,9 @@ class AutopilotAgent(BaseAgent):
         self.log_info(f"åŸ·è¡Œæ ¸å¿ƒè‡ªå‹•é§•é§›: {core_script}")
 
         try:
-            result = subprocess.run(["node", str(core_script), "diagnose"], cwd=self.project_root)
+            result = subprocess.run(
+                ["node", str(core_script), "diagnose"], cwd=self.project_root
+            )
             return result.returncode
         except Exception as e:
             self.log_error(f"åŸ·è¡Œå¤±æ•—: {e}")
diff --git a/workspace/src/autonomous/agents/base-agent.py b/workspace/src/autonomous/agents/base-agent.py
index 9a3a34b..4574d74 100644
--- a/workspace/src/autonomous/agents/base-agent.py
+++ b/workspace/src/autonomous/agents/base-agent.py
@@ -172,4 +172,6 @@ class BaseAgent(ABC):
         }
 
     def __repr__(self) -> str:
-        return f"<{self.__class__.__name__}(name='{self.name}', status='{self.status}')>"
+        return (
+            f"<{self.__class__.__name__}(name='{self.name}', status='{self.status}')>"
+        )
diff --git a/workspace/src/autonomous/agents/coordinator-agent.py b/workspace/src/autonomous/agents/coordinator-agent.py
index 81ab27d..2d142d7 100644
--- a/workspace/src/autonomous/agents/coordinator-agent.py
+++ b/workspace/src/autonomous/agents/coordinator-agent.py
@@ -99,14 +99,22 @@ class CoordinatorAgent(BaseAgent):
                 analysis["tools"][tool] = {
                     "installed": result.returncode == 0,
                     "version": (
-                        result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+                        result.stdout.strip().split("\n")[0]
+                        if result.returncode == 0
+                        else None
                     ),
                 }
             except (FileNotFoundError, subprocess.TimeoutExpired):
                 analysis["tools"][tool] = {"installed": False, "version": None}
 
         # æª¢æŸ¥å°ˆæ¡ˆçµæ§‹
-        required_dirs = ["config/dev", ".vscode", "v1-python-drones", "shared", "migration"]
+        required_dirs = [
+            "config/dev",
+            ".vscode",
+            "v1-python-drones",
+            "shared",
+            "migration",
+        ]
         for dir_name in required_dirs:
             dir_path = self.project_root / dir_name
             analysis["structure"][dir_name] = dir_path.exists()
@@ -201,7 +209,9 @@ class CoordinatorAgent(BaseAgent):
         Returns:
             åŸ·è¡Œçµæœä»£ç¢¼
         """
-        core_script = self.project_root / "config/dev" / "automation" / "drone-coordinator.py"
+        core_script = (
+            self.project_root / "config/dev" / "automation" / "drone-coordinator.py"
+        )
 
         if not core_script.exists():
             self.log_error(f"æ ¸å¿ƒå”èª¿å™¨è…³æœ¬ä¸å­˜åœ¨: {core_script}")
diff --git a/workspace/src/autonomous/agents/deployment-agent.py b/workspace/src/autonomous/agents/deployment-agent.py
index c5fde4d..05f3cca 100644
--- a/workspace/src/autonomous/agents/deployment-agent.py
+++ b/workspace/src/autonomous/agents/deployment-agent.py
@@ -132,10 +132,14 @@ class DeploymentAgent(BaseAgent):
         # æª¢æŸ¥ Docker Compose
         try:
             # å˜—è©¦æ–°ç‰ˆ docker compose
-            result = subprocess.run(["docker", "compose", "version"], capture_output=True)
+            result = subprocess.run(
+                ["docker", "compose", "version"], capture_output=True
+            )
             if result.returncode != 0:
                 # å˜—è©¦èˆŠç‰ˆ docker-compose
-                subprocess.run(["docker-compose", "--version"], capture_output=True, check=True)
+                subprocess.run(
+                    ["docker-compose", "--version"], capture_output=True, check=True
+                )
             self.log_success("  Docker Compose âœ“")
         except (FileNotFoundError, subprocess.CalledProcessError):
             self.log_error("  Docker Compose æœªå®‰è£")
@@ -154,7 +158,9 @@ class DeploymentAgent(BaseAgent):
         self.log_info(f"ğŸ”§ æº–å‚™éƒ¨ç½²ç’°å¢ƒ: {self.deploy_env}")
 
         # è¼‰å…¥ç’°å¢ƒé…ç½®
-        env_file = self.project_root / "config/dev" / "environments" / f"{self.deploy_env}.env"
+        env_file = (
+            self.project_root / "config/dev" / "environments" / f"{self.deploy_env}.env"
+        )
 
         if env_file.exists():
             self.log_info(f"  è¼‰å…¥ç’°å¢ƒé…ç½®: {env_file}")
@@ -211,7 +217,9 @@ class DeploymentAgent(BaseAgent):
             )
         except subprocess.TimeoutExpired:
             self.log_warn("  å®‰è£è¶…æ™‚ï¼Œå˜—è©¦ npm install")
-            subprocess.run(["npm", "install"], cwd=self.project_root, capture_output=True)
+            subprocess.run(
+                ["npm", "install"], cwd=self.project_root, capture_output=True
+            )
         except Exception:
             pass
 
@@ -263,12 +271,16 @@ class DeploymentAgent(BaseAgent):
         """åŸ·è¡Œ docker compose å‘½ä»¤"""
         try:
             # å˜—è©¦æ–°ç‰ˆ docker compose
-            result = subprocess.run(["docker", "compose"] + args, cwd=cwd, capture_output=True)
+            result = subprocess.run(
+                ["docker", "compose"] + args, cwd=cwd, capture_output=True
+            )
             if result.returncode == 0:
                 return True
 
             # å˜—è©¦èˆŠç‰ˆ docker-compose
-            result = subprocess.run(["docker-compose"] + args, cwd=cwd, capture_output=True)
+            result = subprocess.run(
+                ["docker-compose"] + args, cwd=cwd, capture_output=True
+            )
             return result.returncode == 0
         except Exception:
             return False
@@ -305,7 +317,9 @@ class DeploymentAgent(BaseAgent):
                 pass
 
             if i < self.health_check_retries:
-                self.log_warn(f"  éƒ¨åˆ†æœå‹™å°šæœªå°±ç·’ï¼Œç­‰å¾… {self.health_check_interval}s...")
+                self.log_warn(
+                    f"  éƒ¨åˆ†æœå‹™å°šæœªå°±ç·’ï¼Œç­‰å¾… {self.health_check_interval}s..."
+                )
                 import time
 
                 time.sleep(self.health_check_interval)
@@ -340,7 +354,9 @@ class DeploymentAgent(BaseAgent):
         Returns:
             åŸ·è¡Œçµæœä»£ç¢¼
         """
-        core_script = self.project_root / "config/dev" / "automation" / "deployment-drone.sh"
+        core_script = (
+            self.project_root / "config/dev" / "automation" / "deployment-drone.sh"
+        )
 
         if not core_script.exists():
             self.log_error(f"æ ¸å¿ƒéƒ¨ç½²è…³æœ¬ä¸å­˜åœ¨: {core_script}")
@@ -349,7 +365,9 @@ class DeploymentAgent(BaseAgent):
         self.log_info(f"åŸ·è¡Œæ ¸å¿ƒéƒ¨ç½²è…³æœ¬: {core_script}")
 
         try:
-            result = subprocess.run(["bash", str(core_script), "status"], cwd=self.project_root)
+            result = subprocess.run(
+                ["bash", str(core_script), "status"], cwd=self.project_root
+            )
             return result.returncode
         except Exception as e:
             self.log_error(f"åŸ·è¡Œå¤±æ•—: {e}")
diff --git a/workspace/src/autonomous/agents/migration/migrator.py b/workspace/src/autonomous/agents/migration/migrator.py
index f795eea..b1ddc7c 100644
--- a/workspace/src/autonomous/agents/migration/migrator.py
+++ b/workspace/src/autonomous/agents/migration/migrator.py
@@ -92,20 +92,28 @@ class Migrator:
             "v1_exists": self.v1_path.exists(),
             "v2_exists": self.v2_path.exists(),
             "drone_config_exists": (self._project_root / "drone-config.yml").exists(),
-            "island_config_exists": (self._project_root / "island-control.yml").exists(),
+            "island_config_exists": (
+                self._project_root / "island-control.yml"
+            ).exists(),
             "can_migrate_v1_to_v2": False,
             "can_migrate_v2_to_v1": False,
         }
 
-        result["can_migrate_v1_to_v2"] = result["v1_exists"] and result["drone_config_exists"]
-        result["can_migrate_v2_to_v1"] = result["v2_exists"] and result["island_config_exists"]
+        result["can_migrate_v1_to_v2"] = (
+            result["v1_exists"] and result["drone_config_exists"]
+        )
+        result["can_migrate_v2_to_v1"] = (
+            result["v2_exists"] and result["island_config_exists"]
+        )
 
         # é¡¯ç¤ºæª¢æŸ¥çµæœ
         print("\nğŸ“‹ é·ç§»å‰æª¢æŸ¥çµæœ:")
         print(f"  v1-python-drones: {'âœ…' if result['v1_exists'] else 'âŒ'}")
         print(f"  v2-multi-islands: {'âœ…' if result['v2_exists'] else 'âŒ'}")
         print(f"  drone-config.yml: {'âœ…' if result['drone_config_exists'] else 'âŒ'}")
-        print(f"  island-control.yml: {'âœ…' if result['island_config_exists'] else 'âŒ'}")
+        print(
+            f"  island-control.yml: {'âœ…' if result['island_config_exists'] else 'âŒ'}"
+        )
         print(f"  å¯åŸ·è¡Œ v1 â†’ v2: {'âœ…' if result['can_migrate_v1_to_v2'] else 'âŒ'}")
         print(f"  å¯åŸ·è¡Œ v2 â†’ v1: {'âœ…' if result['can_migrate_v2_to_v1'] else 'âŒ'}")
         print()
@@ -323,7 +331,11 @@ def main() -> int:
     parser = argparse.ArgumentParser(description="SynergyMesh ç‰ˆæœ¬é·ç§»å·¥å…·")
 
     parser.add_argument(
-        "--direction", "-d", choices=["v1-to-v2", "v2-to-v1"], required=True, help="é·ç§»æ–¹å‘"
+        "--direction",
+        "-d",
+        choices=["v1-to-v2", "v2-to-v1"],
+        required=True,
+        help="é·ç§»æ–¹å‘",
     )
 
     parser.add_argument("--dry-run", action="store_true", help="ä¹¾è·‘æ¨¡å¼ï¼ˆä¸å¯¦éš›åŸ·è¡Œï¼‰")
diff --git a/workspace/src/autonomous/agents/migration/scripts/v1_to_v2.py b/workspace/src/autonomous/agents/migration/scripts/v1_to_v2.py
index d5ccd7c..2fa3770 100644
--- a/workspace/src/autonomous/agents/migration/scripts/v1_to_v2.py
+++ b/workspace/src/autonomous/agents/migration/scripts/v1_to_v2.py
@@ -5,10 +5,11 @@ v1 â†’ v2 é·ç§»è…³æœ¬
 å°‡ v1-python-drones é·ç§»è‡³ v2-multi-islands æ¶æ§‹ã€‚
 """
 
-from migration.migrator import Migrator
 import sys
 from pathlib import Path
 
+from migration.migrator import Migrator
+
 # æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))
 
diff --git a/workspace/src/autonomous/agents/migration/scripts/v2_to_v1.py b/workspace/src/autonomous/agents/migration/scripts/v2_to_v1.py
index 738b9dd..5093e76 100644
--- a/workspace/src/autonomous/agents/migration/scripts/v2_to_v1.py
+++ b/workspace/src/autonomous/agents/migration/scripts/v2_to_v1.py
@@ -5,10 +5,11 @@ v2 â†’ v1 é™ç´šé·ç§»è…³æœ¬
 å°‡ v2-multi-islands é™ç´šè‡³ v1-python-drones æ¶æ§‹ã€‚
 """
 
-from migration.migrator import Migrator
 import sys
 from pathlib import Path
 
+from migration.migrator import Migrator
+
 # æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))
 
diff --git a/workspace/src/autonomous/agents/pipeline_service.py b/workspace/src/autonomous/agents/pipeline_service.py
index 1527e31..b216b7a 100644
--- a/workspace/src/autonomous/agents/pipeline_service.py
+++ b/workspace/src/autonomous/agents/pipeline_service.py
@@ -33,7 +33,9 @@ try:
     _upgrader = AutoUpgradeEnvironment(auto_install=True)
     _upgrade_results = _upgrader.check_and_upgrade(["dotenv", "loguru"])
     if _upgrader.installed_deps:
-        logger.info(f"å·²è‡ªå‹•å‡ç´šç’°å¢ƒ Auto-upgraded: {', '.join(_upgrader.installed_deps)}")
+        logger.info(
+            f"å·²è‡ªå‹•å‡ç´šç’°å¢ƒ Auto-upgraded: {', '.join(_upgrader.installed_deps)}"
+        )
 except Exception as e:
     logger.warning(f"ç’°å¢ƒå‡ç´šæª¢æŸ¥è·³é Auto-upgrade skipped: {e}")
 
@@ -102,7 +104,9 @@ class PipelineService:
             # Step 2: Intent recognition and routing
             if self.recognition_server:
                 intent_result = self.recognition_server.process_request(
-                    query=query, problem_content=problem_content, editor_code=editor_code
+                    query=query,
+                    problem_content=problem_content,
+                    editor_code=editor_code,
                 )
 
                 if intent_result["status"] == "blocked":
@@ -121,11 +125,17 @@ class PipelineService:
 
             # Step 3: Route to appropriate handler
             if action == "visualize":
-                result = await self._handle_visualization(query, problem_content, editor_code)
+                result = await self._handle_visualization(
+                    query, problem_content, editor_code
+                )
             elif action == "generate_diagram":
-                result = await self._handle_diagram_generation(query, problem_content, editor_code)
+                result = await self._handle_diagram_generation(
+                    query, problem_content, editor_code
+                )
             else:  # proceed
-                result = await self._handle_code_analysis(query, editor_code, analysis_type)
+                result = await self._handle_code_analysis(
+                    query, editor_code, analysis_type
+                )
 
             return {
                 "request_id": request_id,
@@ -164,12 +174,18 @@ class PipelineService:
         fixed_code = None
         if analysis_result["issues"]:
             critical_issues = [
-                issue for issue in analysis_result["issues"] if issue.get("severity") == "critical"
+                issue
+                for issue in analysis_result["issues"]
+                if issue.get("severity") == "critical"
             ]
 
             if critical_issues:
-                logger.info(f"Found {len(critical_issues)} critical issues, attempting auto-fix")
-                fixed_code = await self.task_executor.execute_auto_fix(code, critical_issues[0])
+                logger.info(
+                    f"Found {len(critical_issues)} critical issues, attempting auto-fix"
+                )
+                fixed_code = await self.task_executor.execute_auto_fix(
+                    code, critical_issues[0]
+                )
 
         return {
             "type": "code_analysis",
@@ -252,7 +268,10 @@ class PipelineService:
         logger.info(f"[{request_id}] Starting streaming process")
 
         # Yield initial status
-        yield {"type": "status", "data": {"status": "started", "request_id": request_id}}
+        yield {
+            "type": "status",
+            "data": {"status": "started", "request_id": request_id},
+        }
 
         # Intent recognition
         if self.recognition_server:
@@ -262,13 +281,18 @@ class PipelineService:
                 yield chunk
 
         # Main processing
-        result = await self.process_request(query, problem_content, editor_code, analysis_type)
+        result = await self.process_request(
+            query, problem_content, editor_code, analysis_type
+        )
 
         # Yield result
         yield {"type": "result", "data": result}
 
         # Complete
-        yield {"type": "complete", "data": {"status": "completed", "request_id": request_id}}
+        yield {
+            "type": "complete",
+            "data": {"status": "completed", "request_id": request_id},
+        }
 
         logger.info(f"[{request_id}] Streaming process completed")
 
@@ -304,9 +328,13 @@ class PipelineService:
         return {
             "status": "healthy",
             "agents": {
-                "recognition_server": "available" if self.recognition_server else "unavailable",
+                "recognition_server": (
+                    "available" if self.recognition_server else "unavailable"
+                ),
                 "task_executor": "available" if self.task_executor else "unavailable",
-                "visualization_agent": "available" if self.visualization_agent else "unavailable",
+                "visualization_agent": (
+                    "available" if self.visualization_agent else "unavailable"
+                ),
             },
             "total_requests_processed": self.request_count,
         }
diff --git a/workspace/src/autonomous/agents/synergymesh_core/autonomous_coordinator.py b/workspace/src/autonomous/agents/synergymesh_core/autonomous_coordinator.py
index 6b167ae..cf5e568 100644
--- a/workspace/src/autonomous/agents/synergymesh_core/autonomous_coordinator.py
+++ b/workspace/src/autonomous/agents/synergymesh_core/autonomous_coordinator.py
@@ -168,7 +168,9 @@ class AutonomousCoordinator:
 
         logger.info(f"AutonomousCoordinator initialized with {worker_count} workers")
 
-    def register_task_handler(self, task_type: str, handler: Callable[..., Awaitable[Any]]) -> None:
+    def register_task_handler(
+        self, task_type: str, handler: Callable[..., Awaitable[Any]]
+    ) -> None:
         """
         Register a task handler for autonomous execution
 
@@ -459,7 +461,9 @@ class AutonomousCoordinator:
         """Check internal coordinator health"""
         queue_size = len(self.task_queue)
         running_count = len(self.running_tasks)
-        failed_ratio = self.stats["tasks_failed"] / max(self.stats["tasks_processed"], 1)
+        failed_ratio = self.stats["tasks_failed"] / max(
+            self.stats["tasks_processed"], 1
+        )
 
         status = SystemHealth.HEALTHY
         message = "All systems nominal"
@@ -518,7 +522,8 @@ class AutonomousCoordinator:
             task
             for task in self.running_tasks.values()
             if task.started_at
-            and (datetime.now() - task.started_at).seconds > self.STUCK_TASK_TIMEOUT_SECONDS
+            and (datetime.now() - task.started_at).seconds
+            > self.STUCK_TASK_TIMEOUT_SECONDS
         ]
 
         for task in stuck_tasks:
@@ -546,7 +551,9 @@ class AutonomousCoordinator:
 
             self.recovery_actions.append(action)
             self.stats["auto_recoveries"] += 1
-            logger.info(f"Auto-recovery action: {action.description} - {action.result_message}")
+            logger.info(
+                f"Auto-recovery action: {action.description} - {action.result_message}"
+            )
 
         # Check if we need to adjust worker count
         if (
@@ -613,7 +620,9 @@ class AutonomousCoordinator:
             "priority": task.priority.name,
             "created_at": task.created_at.isoformat() if task.created_at else None,
             "started_at": task.started_at.isoformat() if task.started_at else None,
-            "completed_at": task.completed_at.isoformat() if task.completed_at else None,
+            "completed_at": (
+                task.completed_at.isoformat() if task.completed_at else None
+            ),
             "retry_count": task.retry_count,
             "error": task.error,
             "result": task.result,
@@ -641,7 +650,10 @@ class AutonomousCoordinator:
             "tasks_failed": self.stats["tasks_failed"],
             "auto_recoveries": self.stats["auto_recoveries"],
             "success_rate": round(
-                self.stats["tasks_succeeded"] / max(self.stats["tasks_processed"], 1) * 100, 2
+                self.stats["tasks_succeeded"]
+                / max(self.stats["tasks_processed"], 1)
+                * 100,
+                2,
             ),
         }
 
@@ -682,7 +694,9 @@ class AutonomousCoordinator:
 if __name__ == "__main__":
     import json
 
-    async def example_task_handler(task_name: str, duration: float = 0.5) -> Dict[str, Any]:
+    async def example_task_handler(
+        task_name: str, duration: float = 0.5
+    ) -> Dict[str, Any]:
         """Example task handler"""
         await asyncio.sleep(duration)
         return {
diff --git a/workspace/src/autonomous/agents/synergymesh_core/ecosystem_orchestrator.py b/workspace/src/autonomous/agents/synergymesh_core/ecosystem_orchestrator.py
index 6b3c815..eaed364 100644
--- a/workspace/src/autonomous/agents/synergymesh_core/ecosystem_orchestrator.py
+++ b/workspace/src/autonomous/agents/synergymesh_core/ecosystem_orchestrator.py
@@ -377,7 +377,10 @@ class EcosystemOrchestrator:
                 logger.error(f"Error in message handler: {e}")
 
     def register_message_handler(
-        self, subsystem_id: str, message_type: MessageType, handler: Callable[..., Awaitable[Any]]
+        self,
+        subsystem_id: str,
+        message_type: MessageType,
+        handler: Callable[..., Awaitable[Any]],
     ) -> None:
         """
         Register a message handler for a subsystem
@@ -467,7 +470,8 @@ class EcosystemOrchestrator:
             sid
             for sid in subsystem_ids
             if sid in self.subsystems
-            and self.subsystems[sid].status in [SubsystemStatus.READY, SubsystemStatus.ACTIVE]
+            and self.subsystems[sid].status
+            in [SubsystemStatus.READY, SubsystemStatus.ACTIVE]
         ]
 
         if not available:
@@ -511,7 +515,9 @@ class EcosystemOrchestrator:
             logger.error(f"Coordination task failed: {e}")
             task.status = "failed"
 
-    def allocate_resource(self, subsystem_id: str, resource_type: str, amount: float) -> str:
+    def allocate_resource(
+        self, subsystem_id: str, resource_type: str, amount: float
+    ) -> str:
         """
         Allocate resources to a subsystem
 
@@ -541,7 +547,9 @@ class EcosystemOrchestrator:
 
         return allocation_id
 
-    def update_subsystem_status(self, subsystem_id: str, status: SubsystemStatus) -> bool:
+    def update_subsystem_status(
+        self, subsystem_id: str, status: SubsystemStatus
+    ) -> bool:
         """
         Update the status of a subsystem
 
@@ -574,7 +582,9 @@ class EcosystemOrchestrator:
                 )
             )
 
-        logger.info(f"Subsystem {subsystem_id} status: {old_status.value} -> {status.value}")
+        logger.info(
+            f"Subsystem {subsystem_id} status: {old_status.value} -> {status.value}"
+        )
         return True
 
     async def start(self) -> None:
@@ -663,15 +673,22 @@ class EcosystemOrchestrator:
                         and subsystem.status == SubsystemStatus.ACTIVE
                     ):
                         logger.warning(
-                            f"Subsystem {subsystem.name} heartbeat stale, " f"marking as degraded"
+                            f"Subsystem {subsystem.name} heartbeat stale, "
+                            f"marking as degraded"
+                        )
+                        self.update_subsystem_status(
+                            subsystem_id, SubsystemStatus.DEGRADED
                         )
-                        self.update_subsystem_status(subsystem_id, SubsystemStatus.DEGRADED)
 
                     # Check dependencies
                     if not self._check_dependencies(subsystem):
                         if subsystem.status == SubsystemStatus.ACTIVE:
-                            logger.warning(f"Subsystem {subsystem.name} dependencies not met")
-                            self.update_subsystem_status(subsystem_id, SubsystemStatus.DEGRADED)
+                            logger.warning(
+                                f"Subsystem {subsystem.name} dependencies not met"
+                            )
+                            self.update_subsystem_status(
+                                subsystem_id, SubsystemStatus.DEGRADED
+                            )
 
                 await asyncio.sleep(self.HEALTH_CHECK_INTERVAL_SECONDS)
 
@@ -693,7 +710,11 @@ class EcosystemOrchestrator:
             subsystem_counts[subsystem.status.value] += 1
 
         pending_tasks = len(
-            [t for t in self.coordination_tasks.values() if t.status in ["pending", "running"]]
+            [
+                t
+                for t in self.coordination_tasks.values()
+                if t.status in ["pending", "running"]
+            ]
         )
 
         return {
@@ -768,7 +789,9 @@ if __name__ == "__main__":
 
     async def example_handler(message: EcosystemMessage) -> None:
         """Example message handler"""
-        logger.info(f"Received message: {message.message_type.value} from {message.source_id}")
+        logger.info(
+            f"Received message: {message.message_type.value} from {message.source_id}"
+        )
 
     async def main():
         orchestrator = EcosystemOrchestrator()
diff --git a/workspace/src/autonomous/agents/synergymesh_core/evolution_orchestrator.py b/workspace/src/autonomous/agents/synergymesh_core/evolution_orchestrator.py
index b94a1fe..392ffbb 100644
--- a/workspace/src/autonomous/agents/synergymesh_core/evolution_orchestrator.py
+++ b/workspace/src/autonomous/agents/synergymesh_core/evolution_orchestrator.py
@@ -112,7 +112,9 @@ class EvolutionOrchestrator:
         self.config: dict[str, Any] = {}
         self.constraints: list[str] = []
 
-        logger.info(f"Evolution Orchestrator initialized with repo root: {self.repo_root}")
+        logger.info(
+            f"Evolution Orchestrator initialized with repo root: {self.repo_root}"
+        )
 
     def load_evolution_state(self) -> EvolutionState:
         """Load the current evolution state from YAML
@@ -121,7 +123,9 @@ class EvolutionOrchestrator:
             EvolutionState object with current metrics and scores
         """
         if not self.evolution_state_path.exists():
-            raise FileNotFoundError(f"Evolution state not found: {self.evolution_state_path}")
+            raise FileNotFoundError(
+                f"Evolution state not found: {self.evolution_state_path}"
+            )
 
         with self.evolution_state_path.open("r", encoding="utf-8") as f:
             data = yaml.safe_load(f)
@@ -155,7 +159,8 @@ class EvolutionOrchestrator:
         self.constraints = self.config.get("constraints", [])
 
         logger.info(
-            f"Loaded config v{self.config.get('version')}: " f"{len(self.constraints)} constraints"
+            f"Loaded config v{self.config.get('version')}: "
+            f"{len(self.constraints)} constraints"
         )
         return self.config
 
@@ -166,10 +171,14 @@ class EvolutionOrchestrator:
             List of objectives sorted by priority (lowest score first)
         """
         if not self.evolution_state:
-            raise RuntimeError("Evolution state not loaded. Call load_evolution_state() first.")
+            raise RuntimeError(
+                "Evolution state not loaded. Call load_evolution_state() first."
+            )
 
         # Sort objectives by score (lowest first = highest priority)
-        sorted_objectives = sorted(self.evolution_state.objectives, key=lambda obj: obj["score"])
+        sorted_objectives = sorted(
+            self.evolution_state.objectives, key=lambda obj: obj["score"]
+        )
 
         logger.info(
             f"Analyzed {len(sorted_objectives)} objectives. "
@@ -179,7 +188,9 @@ class EvolutionOrchestrator:
 
         return sorted_objectives
 
-    def generate_actions_for_objective(self, objective: dict[str, Any]) -> list[RefactorAction]:
+    def generate_actions_for_objective(
+        self, objective: dict[str, Any]
+    ) -> list[RefactorAction]:
         """Generate refactor actions for a specific objective
 
         Args:
@@ -336,7 +347,8 @@ class EvolutionOrchestrator:
                     is_valid, violations = self.check_constraints(action)
                     if not is_valid:
                         logger.warning(
-                            f"Action {action.action_id} has constraint violations: " f"{violations}"
+                            f"Action {action.action_id} has constraint violations: "
+                            f"{violations}"
                         )
                         action.status = ActionStatus.BLOCKED
 
@@ -391,7 +403,9 @@ class EvolutionOrchestrator:
             days = total_hours / 8
             return f"{days:.1f} days"
 
-    def export_plan_to_markdown(self, plan: ActionPlan, output_path: Path | None = None) -> str:
+    def export_plan_to_markdown(
+        self, plan: ActionPlan, output_path: Path | None = None
+    ) -> str:
         """Export action plan to markdown format
 
         Args:
@@ -424,11 +438,15 @@ class EvolutionOrchestrator:
             if not priority_actions:
                 continue
 
-            lines.append(f"## {priority.value}: {priority.name.replace('_', ' ').title()}")
+            lines.append(
+                f"## {priority.value}: {priority.name.replace('_', ' ').title()}"
+            )
             lines.append(f"**{len(priority_actions)} å€‹å‹•ä½œ**\n")
 
             for action in priority_actions:
-                lines.append(f"### [{action.status.value.upper()}] {action.description}")
+                lines.append(
+                    f"### [{action.status.value.upper()}] {action.description}"
+                )
                 lines.append(f"- **Action ID**: `{action.action_id}`")
                 lines.append(f"- **Objective**: {action.objective_id}")
                 lines.append(f"- **Cluster**: {action.cluster}")
@@ -440,7 +458,9 @@ class EvolutionOrchestrator:
                     lines.append(f"- **Playbook**: `{action.playbook_path}`")
 
                 if action.constraints_checked:
-                    status_icon = "âœ…" if action.status != ActionStatus.BLOCKED else "âŒ"
+                    status_icon = (
+                        "âœ…" if action.status != ActionStatus.BLOCKED else "âŒ"
+                    )
                     lines.append(f"- **Constraints**: {status_icon} Checked")
 
                 if action.commands:
diff --git a/workspace/src/autonomous/agents/synergymesh_core/natural_language_processor.py b/workspace/src/autonomous/agents/synergymesh_core/natural_language_processor.py
index a0de809..0d7e81c 100644
--- a/workspace/src/autonomous/agents/synergymesh_core/natural_language_processor.py
+++ b/workspace/src/autonomous/agents/synergymesh_core/natural_language_processor.py
@@ -92,7 +92,15 @@ class NaturalLanguageProcessor:
     # Intent keywords mapping
     INTENT_KEYWORDS = {
         IntentType.DATA_MIGRATION: {
-            "en": ["migrate", "sync", "transfer", "move data", "copy data", "import", "export"],
+            "en": [
+                "migrate",
+                "sync",
+                "transfer",
+                "move data",
+                "copy data",
+                "import",
+                "export",
+            ],
             "zh": ["é·ç§»", "åŒæ­¥", "è½‰ç§»", "ç§»å‹•è³‡æ–™", "åŒ¯å…¥", "åŒ¯å‡º", "è³‡æ–™åŒæ­¥"],
         },
         IntentType.SYSTEM_INTEGRATION: {
@@ -162,7 +170,9 @@ class NaturalLanguageProcessor:
             return "zh"
         return "en"
 
-    def parse_intent(self, query: str, session_id: Optional[str] = None) -> ParsedIntent:
+    def parse_intent(
+        self, query: str, session_id: Optional[str] = None
+    ) -> ParsedIntent:
         """
         Parse user intent from natural language query
 
@@ -227,7 +237,9 @@ class NaturalLanguageProcessor:
                 self.conversation_context[session_id] = []
             self.conversation_context[session_id].append(parsed)
 
-        logger.info(f"Intent parsed: {best_intent.value} (confidence: {best_confidence:.2f})")
+        logger.info(
+            f"Intent parsed: {best_intent.value} (confidence: {best_confidence:.2f})"
+        )
         return parsed
 
     def _extract_entities(self, query: str, language: str) -> Dict[str, Any]:
@@ -267,7 +279,9 @@ class NaturalLanguageProcessor:
 
         return entities
 
-    async def translate_to_technical_spec(self, intent: ParsedIntent) -> TechnicalSpecification:
+    async def translate_to_technical_spec(
+        self, intent: ParsedIntent
+    ) -> TechnicalSpecification:
         """
         Translate parsed intent into technical specification
 
@@ -444,7 +458,9 @@ class NaturalLanguageProcessor:
 
         return tasks
 
-    def _estimate_complexity(self, intent: ParsedIntent, tasks: List[Dict[str, Any]]) -> str:
+    def _estimate_complexity(
+        self, intent: ParsedIntent, tasks: List[Dict[str, Any]]
+    ) -> str:
         """Estimate complexity based on intent and tasks"""
         # Complexity heuristics
         if len(tasks) >= 4:
@@ -453,7 +469,9 @@ class NaturalLanguageProcessor:
             return "medium"
         return "low"
 
-    def _determine_automation_level(self, intent: ParsedIntent, tasks: List[Dict[str, Any]]) -> str:
+    def _determine_automation_level(
+        self, intent: ParsedIntent, tasks: List[Dict[str, Any]]
+    ) -> str:
         """Determine automation level for the specification"""
         automated_count = sum(1 for t in tasks if t.get("automated", False))
         ratio = automated_count / len(tasks) if tasks else 0
@@ -548,7 +566,9 @@ class NaturalLanguageProcessor:
         logger.info(f"Natural request processed: {spec.spec_id}")
         return result
 
-    def _generate_user_message(self, intent: ParsedIntent, spec: TechnicalSpecification) -> str:
+    def _generate_user_message(
+        self, intent: ParsedIntent, spec: TechnicalSpecification
+    ) -> str:
         """Generate user-friendly response message"""
         if intent.language == "zh":
             return (
@@ -567,7 +587,9 @@ class NaturalLanguageProcessor:
     def get_statistics(self) -> Dict[str, Any]:
         """Get processor statistics"""
         total_sessions = len(self.conversation_context)
-        total_intents = sum(len(intents) for intents in self.conversation_context.values())
+        total_intents = sum(
+            len(intents) for intents in self.conversation_context.values()
+        )
 
         intent_counts = {}
         for intents in self.conversation_context.values():
@@ -611,7 +633,9 @@ if __name__ == "__main__":
 
         for query in test_queries:
             print(f"Query: {query}")
-            result = await processor.process_natural_request(query, session_id="test-session")
+            result = await processor.process_natural_request(
+                query, session_id="test-session"
+            )
             print(f"Result:\n{json.dumps(result, indent=2, ensure_ascii=False)}\n")
             print("-" * 50 + "\n")
 
diff --git a/workspace/src/autonomous/agents/synergymesh_core/nli_layer.py b/workspace/src/autonomous/agents/synergymesh_core/nli_layer.py
index b13f091..b200a5f 100644
--- a/workspace/src/autonomous/agents/synergymesh_core/nli_layer.py
+++ b/workspace/src/autonomous/agents/synergymesh_core/nli_layer.py
@@ -145,7 +145,9 @@ class NaturalLanguageInteractionLayer:
         # Register default handlers
         self._register_default_handlers()
 
-        logger.info("NaturalLanguageInteractionLayer initialized - è‡ªç„¶èªè¨€äº¤äº’å±¤å·²åˆå§‹åŒ–")
+        logger.info(
+            "NaturalLanguageInteractionLayer initialized - è‡ªç„¶èªè¨€äº¤äº’å±¤å·²åˆå§‹åŒ–"
+        )
 
     def _register_default_handlers(self) -> None:
         """Register default interaction handlers"""
@@ -220,7 +222,11 @@ class NaturalLanguageInteractionLayer:
         self.stats["mode_usage"][InteractionMode.TEXT.value] += 1
 
         # Detect language
-        language = self._detect_language(text) if context.language == "auto" else context.language
+        language = (
+            self._detect_language(text)
+            if context.language == "auto"
+            else context.language
+        )
 
         # Analyze intent
         intent, confidence = self._analyze_intent(text, language)
@@ -289,7 +295,16 @@ class NaturalLanguageInteractionLayer:
             return UserIntent.QUERY, 0.8
 
         # Command intent (default for action requests)
-        command_keywords = ["create", "migrate", "deploy", "sync", "å»ºç«‹", "é·ç§»", "éƒ¨ç½²", "åŒæ­¥"]
+        command_keywords = [
+            "create",
+            "migrate",
+            "deploy",
+            "sync",
+            "å»ºç«‹",
+            "é·ç§»",
+            "éƒ¨ç½²",
+            "åŒæ­¥",
+        ]
         if any(kw in text_lower for kw in command_keywords):
             return UserIntent.COMMAND, 0.85
 
@@ -323,7 +338,9 @@ class NaturalLanguageInteractionLayer:
             response_text = templates["help"].format(suggestions=", ".join(suggestions))
 
         elif intent == UserIntent.CANCEL:
-            response_text = "å·²å–æ¶ˆæ“ä½œã€‚" if language == "zh" else "Operation cancelled."
+            response_text = (
+                "å·²å–æ¶ˆæ“ä½œã€‚" if language == "zh" else "Operation cancelled."
+            )
 
         elif intent == UserIntent.COMMAND:
             # Extract action from text
@@ -337,7 +354,9 @@ class NaturalLanguageInteractionLayer:
             ]
 
         elif intent == UserIntent.QUERY:
-            response_text = "æ­£åœ¨æŸ¥è©¢ç›¸é—œä¿¡æ¯..." if language == "zh" else "Querying information..."
+            response_text = (
+                "æ­£åœ¨æŸ¥è©¢ç›¸é—œä¿¡æ¯..." if language == "zh" else "Querying information..."
+            )
 
         else:
             response_text = templates["greeting"]
@@ -462,7 +481,9 @@ class NaturalLanguageInteractionLayer:
             for comp in self.visual_components.values()
         ]
 
-    def create_visual_workflow(self, name: str, components: List[Dict[str, Any]]) -> Dict[str, Any]:
+    def create_visual_workflow(
+        self, name: str, components: List[Dict[str, Any]]
+    ) -> Dict[str, Any]:
         """
         Create a workflow from visual components
 
diff --git a/workspace/src/autonomous/agents/synergymesh_core/orchestration_layer.py b/workspace/src/autonomous/agents/synergymesh_core/orchestration_layer.py
index ecef760..b6d7576 100644
--- a/workspace/src/autonomous/agents/synergymesh_core/orchestration_layer.py
+++ b/workspace/src/autonomous/agents/synergymesh_core/orchestration_layer.py
@@ -280,7 +280,10 @@ class IntentUnderstandingEngine:
             entities["target"] = target_match.group(1)
 
         # Extract system names
-        system_patterns = [r"(\w+)\s*(?:system|ç³»çµ±)", r"(\w+)\s*(?:database|è³‡æ–™åº«|db)"]
+        system_patterns = [
+            r"(\w+)\s*(?:system|ç³»çµ±)",
+            r"(\w+)\s*(?:database|è³‡æ–™åº«|db)",
+        ]
 
         for pattern in system_patterns:
             match = re.search(pattern, text_lower)
@@ -387,7 +390,10 @@ class IntentUnderstandingEngine:
             "intents_parsed": self.stats["intents_parsed"],
             "successful_parses": self.stats["successful_parses"],
             "success_rate": round(
-                self.stats["successful_parses"] / max(self.stats["intents_parsed"], 1) * 100, 2
+                self.stats["successful_parses"]
+                / max(self.stats["intents_parsed"], 1)
+                * 100,
+                2,
             ),
             "intent_distribution": self.stats["intent_distribution"],
             "active_contexts": len(self.context_memories),
@@ -412,13 +418,19 @@ class TaskOrchestrationEngine:
     WORKFLOW_TEMPLATES = {
         TaskType.DATA_MIGRATION: [
             {"name": "Analyze Source", "description": "Analyze source data structure"},
-            {"name": "Validate Target", "description": "Validate target system compatibility"},
+            {
+                "name": "Validate Target",
+                "description": "Validate target system compatibility",
+            },
             {"name": "Generate Scripts", "description": "Generate migration scripts"},
             {"name": "Execute Migration", "description": "Execute data migration"},
             {"name": "Verify Data", "description": "Verify data integrity"},
         ],
         TaskType.DATA_SYNC: [
-            {"name": "Configure Sync", "description": "Configure synchronization settings"},
+            {
+                "name": "Configure Sync",
+                "description": "Configure synchronization settings",
+            },
             {"name": "Initial Sync", "description": "Perform initial data sync"},
             {"name": "Setup Monitoring", "description": "Setup continuous monitoring"},
         ],
@@ -474,7 +486,8 @@ class TaskOrchestrationEngine:
 
         # Get template for task type
         template = self.WORKFLOW_TEMPLATES.get(
-            intent.task_type, [{"name": "Execute", "description": "Execute custom task"}]
+            intent.task_type,
+            [{"name": "Execute", "description": "Execute custom task"}],
         )
 
         # Generate steps from template
@@ -486,7 +499,10 @@ class TaskOrchestrationEngine:
                 description=step_template["description"],
                 task_type=intent.task_type,
                 dependencies=[f"step-{i}"] if i > 0 else [],
-                parameters={"entities": intent.entities, "constraints": intent.constraints},
+                parameters={
+                    "entities": intent.entities,
+                    "constraints": intent.constraints,
+                },
             )
             steps.append(step)
 
@@ -550,7 +566,11 @@ class TaskOrchestrationEngine:
             workflow.completed_at = datetime.now()
             self.stats["workflows_completed"] += 1
 
-            return {"workflow_id": workflow_id, "status": "completed", "results": results}
+            return {
+                "workflow_id": workflow_id,
+                "status": "completed",
+                "results": results,
+            }
 
         except Exception as e:
             workflow.status = WorkflowStatus.FAILED
@@ -586,11 +606,16 @@ class TaskOrchestrationEngine:
             "name": workflow.name,
             "status": workflow.status.value,
             "steps": [
-                {"step_id": s.step_id, "name": s.name, "status": s.status} for s in workflow.steps
+                {"step_id": s.step_id, "name": s.name, "status": s.status}
+                for s in workflow.steps
             ],
             "created_at": workflow.created_at.isoformat(),
-            "started_at": workflow.started_at.isoformat() if workflow.started_at else None,
-            "completed_at": workflow.completed_at.isoformat() if workflow.completed_at else None,
+            "started_at": (
+                workflow.started_at.isoformat() if workflow.started_at else None
+            ),
+            "completed_at": (
+                workflow.completed_at.isoformat() if workflow.completed_at else None
+            ),
         }
 
     def get_statistics(self) -> Dict[str, Any]:
@@ -601,7 +626,10 @@ class TaskOrchestrationEngine:
             "workflows_failed": self.stats["workflows_failed"],
             "steps_executed": self.stats["steps_executed"],
             "success_rate": round(
-                self.stats["workflows_completed"] / max(self.stats["workflows_created"], 1) * 100, 2
+                self.stats["workflows_completed"]
+                / max(self.stats["workflows_created"], 1)
+                * 100,
+                2,
             ),
             "active_workflows": len(
                 [
diff --git a/workspace/src/autonomous/agents/synergymesh_core/self_evolution_engine.py b/workspace/src/autonomous/agents/synergymesh_core/self_evolution_engine.py
index 5680b6c..6f2197c 100644
--- a/workspace/src/autonomous/agents/synergymesh_core/self_evolution_engine.py
+++ b/workspace/src/autonomous/agents/synergymesh_core/self_evolution_engine.py
@@ -161,7 +161,9 @@ class SelfEvolutionEngine:
 
         # Evolution handlers
         self._evolution_handlers: Dict[str, Callable[..., Awaitable[bool]]] = {}
-        self._validation_handlers: Dict[str, Callable[..., Awaitable[Dict[str, Any]]]] = {}
+        self._validation_handlers: Dict[
+            str, Callable[..., Awaitable[Dict[str, Any]]]
+        ] = {}
 
         # Configuration
         self.config = {
@@ -275,7 +277,9 @@ class SelfEvolutionEngine:
         cycle_id = f"cycle-{uuid.uuid4().hex[:8]}"
         self.is_evolving = True
 
-        self.current_cycle = EvolutionCycle(cycle_id=cycle_id, phase=EvolutionPhase.LEARNING)
+        self.current_cycle = EvolutionCycle(
+            cycle_id=cycle_id, phase=EvolutionPhase.LEARNING
+        )
 
         logger.info(f"Starting evolution cycle: {cycle_id}")
 
@@ -343,7 +347,9 @@ class SelfEvolutionEngine:
                         confidence=0.8,
                     )
 
-        logger.info(f"Learning phase complete: {len(self.current_cycle.learning_records)} records")
+        logger.info(
+            f"Learning phase complete: {len(self.current_cycle.learning_records)} records"
+        )
 
     async def _analyze_patterns(
         self, pattern_type: str, patterns: List[Dict[str, Any]]
@@ -360,7 +366,9 @@ class SelfEvolutionEngine:
         if pattern_type == LearningType.ERROR_PATTERN.value:
             error_count = len(patterns)
             if error_count > 5:
-                insights.append(f"Recurring error pattern detected: {error_count} occurrences")
+                insights.append(
+                    f"Recurring error pattern detected: {error_count} occurrences"
+                )
 
         return insights
 
@@ -418,7 +426,9 @@ class SelfEvolutionEngine:
 
         # Filter by impact threshold
         self.current_cycle.opportunities = [
-            opp for opp in opportunities if opp.impact_score >= self.config["impact_threshold"]
+            opp
+            for opp in opportunities
+            if opp.impact_score >= self.config["impact_threshold"]
         ]
 
         self.opportunities.extend(self.current_cycle.opportunities)
@@ -499,11 +509,17 @@ class SelfEvolutionEngine:
                     try:
                         result = await handler()
                         action.validated = result.get("passed", True)
-                        validation_results["component_results"][action.target_component] = result
+                        validation_results["component_results"][
+                            action.target_component
+                        ] = result
                     except Exception as e:
-                        logger.error(f"Validation failed for {action.target_component}: {e}")
+                        logger.error(
+                            f"Validation failed for {action.target_component}: {e}"
+                        )
                         action.validated = False
-                        validation_results["component_results"][action.target_component] = {
+                        validation_results["component_results"][
+                            action.target_component
+                        ] = {
                             "passed": False,
                             "error": str(e),
                         }
@@ -517,7 +533,9 @@ class SelfEvolutionEngine:
 
         # Check if any validation failed
         failed_validations = [
-            a for a in self.current_cycle.actions if a.status == "applied" and not a.validated
+            a
+            for a in self.current_cycle.actions
+            if a.status == "applied" and not a.validated
         ]
 
         if failed_validations:
@@ -525,10 +543,15 @@ class SelfEvolutionEngine:
             logger.warning(f"Validation failed for {len(failed_validations)} actions")
 
         self.current_cycle.validation_results = validation_results
-        logger.info(f"Validation phase complete: {validation_results['overall_status']}")
+        logger.info(
+            f"Validation phase complete: {validation_results['overall_status']}"
+        )
 
         # If validation failed and auto-rollback is enabled, trigger rollback
-        if validation_results["overall_status"] == "failed" and self.config["auto_rollback"]:
+        if (
+            validation_results["overall_status"] == "failed"
+            and self.config["auto_rollback"]
+        ):
             await self._rollback_cycle()
 
     async def _execute_deployment_phase(self) -> None:
@@ -587,7 +610,9 @@ class SelfEvolutionEngine:
                 "cycle_id": self.current_cycle.cycle_id if self.current_cycle else None,
                 "phase": self.current_cycle.phase.value if self.current_cycle else None,
                 "started_at": (
-                    self.current_cycle.started_at.isoformat() if self.current_cycle else None
+                    self.current_cycle.started_at.isoformat()
+                    if self.current_cycle
+                    else None
                 ),
             },
             "learning_records_count": len(self.learning_records),
@@ -608,7 +633,9 @@ class SelfEvolutionEngine:
             "rollbacks": self.stats["rollbacks"],
             "optimizations_applied": self.stats["optimizations_applied"],
             "success_rate": round(
-                self.stats["successful_evolutions"] / max(self.stats["total_evolutions"], 1) * 100,
+                self.stats["successful_evolutions"]
+                / max(self.stats["total_evolutions"], 1)
+                * 100,
                 2,
             ),
             "pattern_types": list(self.pattern_memory.keys()),
diff --git a/workspace/src/autonomous/agents/test-vectors/generator.py b/workspace/src/autonomous/agents/test-vectors/generator.py
index 56e41db..266e1f4 100644
--- a/workspace/src/autonomous/agents/test-vectors/generator.py
+++ b/workspace/src/autonomous/agents/test-vectors/generator.py
@@ -73,7 +73,10 @@ class TestVectorGenerator:
         },
         "sql_injection": {
             "pattern": 'query = "{prefix}" + {user_input} + "{suffix}"',
-            "prefixes": ["SELECT * FROM users WHERE id = ", "DELETE FROM logs WHERE user = "],
+            "prefixes": [
+                "SELECT * FROM users WHERE id = ",
+                "DELETE FROM logs WHERE user = ",
+            ],
             "suffixes": ["", " AND 1=1"],
             "cwe": "CWE-89",
         },
@@ -241,7 +244,9 @@ class TestVectorGenerator:
             metadata={"combined": True, "issue_count": 3},
         )
 
-    def generate_all_variations(self, count_per_type: int = 3) -> list[GeneratedTestCase]:
+    def generate_all_variations(
+        self, count_per_type: int = 3
+    ) -> list[GeneratedTestCase]:
         """Generate all test case variations.
 
         Args:
diff --git a/workspace/src/autonomous/agents/tests/test_phase10_components.py b/workspace/src/autonomous/agents/tests/test_phase10_components.py
index 65fe08d..460b68a 100644
--- a/workspace/src/autonomous/agents/tests/test_phase10_components.py
+++ b/workspace/src/autonomous/agents/tests/test_phase10_components.py
@@ -28,7 +28,10 @@ class TestCircuitBreaker:
 
     def test_circuit_breaker_initial_state(self):
         """Test circuit breaker starts in closed state"""
-        from core.safety_mechanisms.circuit_breaker import CircuitBreaker, CircuitBreakerState
+        from core.safety_mechanisms.circuit_breaker import (
+            CircuitBreaker,
+            CircuitBreakerState,
+        )
 
         breaker = CircuitBreaker()
         assert breaker.state == CircuitBreakerState.CLOSED
@@ -108,7 +111,10 @@ class TestEscalationLadder:
 
     def test_escalation_ladder_initial_state(self):
         """Test escalation ladder starts at normal"""
-        from core.safety_mechanisms.escalation_ladder import EscalationLadder, EscalationLevel
+        from core.safety_mechanisms.escalation_ladder import (
+            EscalationLadder,
+            EscalationLevel,
+        )
 
         ladder = EscalationLadder()
         assert ladder.current_level == EscalationLevel.LEVEL_0_NORMAL
@@ -116,7 +122,10 @@ class TestEscalationLadder:
     @pytest.mark.asyncio
     async def test_escalation_ladder_escalate(self):
         """Test escalating levels"""
-        from core.safety_mechanisms.escalation_ladder import EscalationLadder, EscalationLevel
+        from core.safety_mechanisms.escalation_ladder import (
+            EscalationLadder,
+            EscalationLevel,
+        )
 
         ladder = EscalationLadder()
 
@@ -129,7 +138,10 @@ class TestEscalationLadder:
     @pytest.mark.asyncio
     async def test_escalation_ladder_de_escalate(self):
         """Test de-escalating levels"""
-        from core.safety_mechanisms.escalation_ladder import EscalationLadder, EscalationLevel
+        from core.safety_mechanisms.escalation_ladder import (
+            EscalationLadder,
+            EscalationLevel,
+        )
 
         ladder = EscalationLadder()
 
@@ -141,11 +153,16 @@ class TestEscalationLadder:
     @pytest.mark.asyncio
     async def test_escalation_ladder_set_level(self):
         """Test setting specific level"""
-        from core.safety_mechanisms.escalation_ladder import EscalationLadder, EscalationLevel
+        from core.safety_mechanisms.escalation_ladder import (
+            EscalationLadder,
+            EscalationLevel,
+        )
 
         ladder = EscalationLadder()
 
-        await ladder.set_level(EscalationLevel.LEVEL_3_CRITICAL, "Critical issue", "test_system")
+        await ladder.set_level(
+            EscalationLevel.LEVEL_3_CRITICAL, "Critical issue", "test_system"
+        )
 
         assert ladder.current_level == EscalationLevel.LEVEL_3_CRITICAL
 
@@ -191,7 +208,10 @@ class TestRollbackSystem:
     @pytest.mark.asyncio
     async def test_rollback_with_handlers(self):
         """Test rollback with component handlers"""
-        from core.safety_mechanisms.rollback_system import RollbackStrategy, RollbackSystem
+        from core.safety_mechanisms.rollback_system import (
+            RollbackStrategy,
+            RollbackSystem,
+        )
 
         state = {"value": 10}
 
@@ -234,7 +254,10 @@ class TestAnomalyDetector:
 
     def test_anomaly_detector_add_metric(self):
         """Test adding metrics"""
-        from core.safety_mechanisms.anomaly_detector import AnomalyDetector, DetectionStrategy
+        from core.safety_mechanisms.anomaly_detector import (
+            AnomalyDetector,
+            DetectionStrategy,
+        )
 
         detector = AnomalyDetector()
         detector.add_metric(
@@ -246,7 +269,10 @@ class TestAnomalyDetector:
     @pytest.mark.asyncio
     async def test_anomaly_detector_threshold(self):
         """Test threshold-based anomaly detection"""
-        from core.safety_mechanisms.anomaly_detector import AnomalyDetector, DetectionStrategy
+        from core.safety_mechanisms.anomaly_detector import (
+            AnomalyDetector,
+            DetectionStrategy,
+        )
 
         detector = AnomalyDetector()
         detector.add_metric(
@@ -271,7 +297,10 @@ class TestAnomalyDetector:
 
         summary = detector.get_metrics_summary()
         # Initially empty (no values recorded)
-        assert "test_metric" not in summary or summary.get("test_metric", {}).get("count", 0) == 0
+        assert (
+            "test_metric" not in summary
+            or summary.get("test_metric", {}).get("count", 0) == 0
+        )
 
 
 # ============ Emergency Stop Tests ============
@@ -306,12 +335,18 @@ class TestEmergencyStop:
     @pytest.mark.asyncio
     async def test_emergency_stop_trigger(self):
         """Test triggering emergency stop"""
-        from core.safety_mechanisms.emergency_stop import EmergencyStop, StopReason, StopScope
+        from core.safety_mechanisms.emergency_stop import (
+            EmergencyStop,
+            StopReason,
+            StopScope,
+        )
 
         stop = EmergencyStop()
 
         stopped_components = []
-        stop.register_component("test", stop_handler=lambda: stopped_components.append("test"))
+        stop.register_component(
+            "test", stop_handler=lambda: stopped_components.append("test")
+        )
 
         result = await stop.trigger(StopReason.SECURITY_BREACH, StopScope.SYSTEM)
 
@@ -322,11 +357,17 @@ class TestEmergencyStop:
     @pytest.mark.asyncio
     async def test_emergency_stop_recover(self):
         """Test recovery from emergency stop"""
-        from core.safety_mechanisms.emergency_stop import EmergencyStop, StopReason, StopScope
+        from core.safety_mechanisms.emergency_stop import (
+            EmergencyStop,
+            StopReason,
+            StopScope,
+        )
 
         stop = EmergencyStop()
 
-        stop.register_component("test", stop_handler=lambda: None, recovery_handler=lambda: None)
+        stop.register_component(
+            "test", stop_handler=lambda: None, recovery_handler=lambda: None
+        )
 
         await stop.trigger(StopReason.MANUAL, StopScope.SYSTEM)
         results = await stop.recover()
@@ -350,7 +391,11 @@ class TestSafetyNet:
 
     def test_safety_net_add_check(self):
         """Test adding safety checks"""
-        from core.safety_mechanisms.safety_net import SafetyCheck, SafetyLayer, SafetyNet
+        from core.safety_mechanisms.safety_net import (
+            SafetyCheck,
+            SafetyLayer,
+            SafetyNet,
+        )
 
         safety = SafetyNet()
 
@@ -382,7 +427,11 @@ class TestSafetyNet:
     @pytest.mark.asyncio
     async def test_safety_net_validate_fail(self):
         """Test safety net validation (failing)"""
-        from core.safety_mechanisms.safety_net import SafetyCheck, SafetyLayer, SafetyNet
+        from core.safety_mechanisms.safety_net import (
+            SafetyCheck,
+            SafetyLayer,
+            SafetyNet,
+        )
 
         safety = SafetyNet()
         safety.add_check(
@@ -455,8 +504,14 @@ class TestSafetyMechanismsIntegration:
     @pytest.mark.asyncio
     async def test_circuit_breaker_with_anomaly_detection(self):
         """Test circuit breaker triggered by anomaly detection"""
-        from core.safety_mechanisms.anomaly_detector import AnomalyDetector, DetectionStrategy
-        from core.safety_mechanisms.circuit_breaker import CircuitBreaker, CircuitBreakerConfig
+        from core.safety_mechanisms.anomaly_detector import (
+            AnomalyDetector,
+            DetectionStrategy,
+        )
+        from core.safety_mechanisms.circuit_breaker import (
+            CircuitBreaker,
+            CircuitBreakerConfig,
+        )
 
         breaker = CircuitBreaker(CircuitBreakerConfig(failure_threshold=1))
         detector = AnomalyDetector()
@@ -472,8 +527,15 @@ class TestSafetyMechanismsIntegration:
     @pytest.mark.asyncio
     async def test_escalation_with_emergency_stop(self):
         """Test escalation ladder triggering emergency stop"""
-        from core.safety_mechanisms.emergency_stop import EmergencyStop, StopReason, StopScope
-        from core.safety_mechanisms.escalation_ladder import EscalationLadder, EscalationLevel
+        from core.safety_mechanisms.emergency_stop import (
+            EmergencyStop,
+            StopReason,
+            StopScope,
+        )
+        from core.safety_mechanisms.escalation_ladder import (
+            EscalationLadder,
+            EscalationLevel,
+        )
 
         ladder = EscalationLadder()
         stop = EmergencyStop()
@@ -489,11 +551,15 @@ class TestSafetyMechanismsIntegration:
 
         # Escalate to emergency level
         await ladder.set_level(
-            EscalationLevel.LEVEL_4_EMERGENCY, "Cascading failure detected", "monitoring"
+            EscalationLevel.LEVEL_4_EMERGENCY,
+            "Cascading failure detected",
+            "monitoring",
         )
 
         # Give async task time to complete
         await asyncio.sleep(0.1)
 
         # System should be stopped
-        assert stop.is_stopped or ladder.current_level == EscalationLevel.LEVEL_4_EMERGENCY
+        assert (
+            stop.is_stopped or ladder.current_level == EscalationLevel.LEVEL_4_EMERGENCY
+        )
diff --git a/workspace/src/autonomous/agents/tests/test_phase11_components.py b/workspace/src/autonomous/agents/tests/test_phase11_components.py
index ddf8596..004a293 100644
--- a/workspace/src/autonomous/agents/tests/test_phase11_components.py
+++ b/workspace/src/autonomous/agents/tests/test_phase11_components.py
@@ -10,11 +10,12 @@ Tests for:
 - ObservabilityPlatform
 """
 
-from core.monitoring_system.smart_anomaly_detector import AnomalySeverity
-from core.monitoring_system.self_learning import PatternType
-from core.monitoring_system.observability_platform import EventType, LogLevel, TraceStatus
-from core.monitoring_system.intelligent_monitoring import MetricType as MT
-from core.monitoring_system.auto_remediation import RemediationStatus, RemediationType
+import asyncio
+import os
+import sys
+from datetime import datetime, timedelta
+
+import pytest
 from core.monitoring_system import (  # Intelligent Monitoring; Smart Anomaly Detection; Auto Diagnosis; Auto Remediation; Self Learning; Observability Platform
     Alert,
     AlertSeverity,
@@ -48,12 +49,15 @@ from core.monitoring_system import (  # Intelligent Monitoring; Smart Anomaly De
     SmartAnomalyDetector,
     TraceSpan,
 )
-import asyncio
-import os
-import sys
-from datetime import datetime, timedelta
-
-import pytest
+from core.monitoring_system.auto_remediation import RemediationStatus, RemediationType
+from core.monitoring_system.intelligent_monitoring import MetricType as MT
+from core.monitoring_system.observability_platform import (
+    EventType,
+    LogLevel,
+    TraceStatus,
+)
+from core.monitoring_system.self_learning import PatternType
+from core.monitoring_system.smart_anomaly_detector import AnomalySeverity
 
 # Add parent directory to path for imports
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))
@@ -178,7 +182,9 @@ class TestSmartAnomalyDetector:
 
     def test_hybrid_detection(self):
         """Test hybrid detection strategy"""
-        detector = SmartAnomalyDetector(default_strategy=AnomalyDetectionStrategy.HYBRID)
+        detector = SmartAnomalyDetector(
+            default_strategy=AnomalyDetectionStrategy.HYBRID
+        )
         detector.learn_baseline("latency", [100, 105, 98, 102, 101])
 
         result = detector.detect("latency", 500)
@@ -274,7 +280,9 @@ class TestRemediationExecutor:
         executor = RemediationExecutor()
 
         action = RemediationAction(
-            name="restart_service", action_type=RemediationType.RESTART, target="test-service"
+            name="restart_service",
+            action_type=RemediationType.RESTART,
+            target="test-service",
         )
 
         result = await executor.execute(action)
@@ -303,7 +311,9 @@ class TestAutoRemediationEngine:
         """Test registering a playbook"""
         engine = AutoRemediationEngine()
 
-        playbook = RemediationPlaybook(name="test_playbook", trigger_conditions=["high cpu"])
+        playbook = RemediationPlaybook(
+            name="test_playbook", trigger_conditions=["high cpu"]
+        )
 
         engine.register_playbook(playbook)
         retrieved = engine.get_playbook(playbook.playbook_id)
@@ -330,7 +340,9 @@ class TestAutoRemediationEngine:
 
         playbook = RemediationPlaybook(
             name="test",
-            actions=[RemediationAction(name="step1", action_type=RemediationType.RESTART)],
+            actions=[
+                RemediationAction(name="step1", action_type=RemediationType.RESTART)
+            ],
         )
         engine.register_playbook(playbook)
 
@@ -359,7 +371,9 @@ class TestPatternLearner:
         """Test learning a new pattern"""
         learner = PatternLearner()
 
-        pattern = learner.learn(conditions=[{"metric": "cpu", "value": 95}], description="High CPU")
+        pattern = learner.learn(
+            conditions=[{"metric": "cpu", "value": 95}], description="High CPU"
+        )
 
         assert pattern is not None
         assert pattern.frequency == 1
@@ -368,7 +382,9 @@ class TestPatternLearner:
         """Test finding similar patterns"""
         learner = PatternLearner()
 
-        learner.learn(conditions=[{"metric": "cpu", "value": 95}], description="High CPU")
+        learner.learn(
+            conditions=[{"metric": "cpu", "value": 95}], description="High CPU"
+        )
 
         # Learn similar pattern - should increment existing
         pattern = learner.learn(conditions=[{"metric": "cpu", "value": 90}])
diff --git a/workspace/src/autonomous/agents/tests/test_phase12_components.py b/workspace/src/autonomous/agents/tests/test_phase12_components.py
index 7d2a74a..04c689f 100644
--- a/workspace/src/autonomous/agents/tests/test_phase12_components.py
+++ b/workspace/src/autonomous/agents/tests/test_phase12_components.py
@@ -2,13 +2,16 @@
 Tests for Phase 12: GitHub Issues CI Error Auto-Handler System
 """
 
-# Import Phase 12 components
-from core.ci_error_handler.issue_manager import CIIssue, IssueManager, IssueStatus, IssueTemplate
-from core.ci_error_handler.fix_status_tracker import (
-    FixHistory,
-    FixMetrics,
-    FixStatus,
-    FixStatusTracker,
+import sys
+from datetime import datetime, timedelta
+
+import pytest
+from core.ci_error_handler.auto_fix_engine import (
+    AutoFixEngine,
+    FixAttempt,
+    FixResult,
+    FixRule,
+    FixStrategy,
 )
 from core.ci_error_handler.ci_error_analyzer import (
     CIError,
@@ -17,17 +20,20 @@ from core.ci_error_handler.ci_error_analyzer import (
     ErrorPattern,
     ErrorSeverity,
 )
-from core.ci_error_handler.auto_fix_engine import (
-    AutoFixEngine,
-    FixAttempt,
-    FixResult,
-    FixRule,
-    FixStrategy,
+from core.ci_error_handler.fix_status_tracker import (
+    FixHistory,
+    FixMetrics,
+    FixStatus,
+    FixStatusTracker,
 )
-import sys
-from datetime import datetime, timedelta
 
-import pytest
+# Import Phase 12 components
+from core.ci_error_handler.issue_manager import (
+    CIIssue,
+    IssueManager,
+    IssueStatus,
+    IssueTemplate,
+)
 
 sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh")
 
@@ -294,7 +300,10 @@ class TestAutoFixEngine:
         )
 
         attempt = engine.create_fix_attempt(
-            error, FixStrategy.AUTO_FIX, "Auto-fix ESLint errors", files_modified=["src/index.ts"]
+            error,
+            FixStrategy.AUTO_FIX,
+            "Auto-fix ESLint errors",
+            files_modified=["src/index.ts"],
         )
 
         assert attempt.error_id == "ERR-003"
@@ -311,7 +320,9 @@ class TestAutoFixEngine:
             message="ESLint error",
         )
 
-        attempt = engine.create_fix_attempt(error, FixStrategy.CREATE_PR, "Create fix PR")
+        attempt = engine.create_fix_attempt(
+            error, FixStrategy.CREATE_PR, "Create fix PR"
+        )
 
         updated = engine.record_attempt_result(
             attempt.attempt_id,
@@ -409,7 +420,9 @@ class TestFixStatusTracker:
         tracker = FixStatusTracker()
         tracker.start_tracking("ERR-002", "build_error")
 
-        updated = tracker.update_status("ERR-002", FixStatus.IN_PROGRESS, "Fix attempt started")
+        updated = tracker.update_status(
+            "ERR-002", FixStatus.IN_PROGRESS, "Fix attempt started"
+        )
 
         assert updated.status == FixStatus.IN_PROGRESS
         assert len(updated.history) == 2
@@ -432,7 +445,9 @@ class TestFixStatusTracker:
         tracker.start_tracking("ERR-004", "test_failure")
         tracker.link_pr("ERR-004", 789, "https://github.com/test/repo/pull/789")
 
-        updated = tracker.mark_pr_merged("ERR-004", commit_sha="abc123", merged_by="test_user")
+        updated = tracker.mark_pr_merged(
+            "ERR-004", commit_sha="abc123", merged_by="test_user"
+        )
 
         assert updated.status == FixStatus.PR_MERGED
         assert updated.resolved_by == "test_user"
@@ -527,10 +542,14 @@ class TestPhase12Integration:
 
         # 4. Track fix
         tracker = FixStatusTracker()
-        tracked = tracker.start_tracking(error.error_id, error.category.value, issue.issue_id)
+        tracked = tracker.start_tracking(
+            error.error_id, error.category.value, issue.issue_id
+        )
 
         # 5. Create and record fix attempt
-        attempt = engine.create_fix_attempt(error, FixStrategy.CREATE_PR, "Fix type error")
+        attempt = engine.create_fix_attempt(
+            error, FixStrategy.CREATE_PR, "Fix type error"
+        )
         tracker.add_attempt(error.error_id, attempt)
 
         # 6. Link PR
diff --git a/workspace/src/autonomous/agents/tests/test_phase13_components.py b/workspace/src/autonomous/agents/tests/test_phase13_components.py
index ad51fae..6628c1c 100644
--- a/workspace/src/autonomous/agents/tests/test_phase13_components.py
+++ b/workspace/src/autonomous/agents/tests/test_phase13_components.py
@@ -2,33 +2,28 @@
 Phase 13 Tests: Deep Verifiable YAML Module System
 """
 
-# Import Phase 13 components
-from core.yaml_module_system.yaml_schema_validator import (
-    SchemaRegistry,
-    ValidationError,
-    ValidationErrorType,
-    ValidationResult,
-    YAMLSchemaValidator,
-)
-from core.yaml_module_system.yaml_module_definition import (
-    ChangelogEntry,
-    LifecycleState,
-    ModuleLifecycle,
-    ModuleMetadata,
-    ModuleOwner,
-    TestVector,
-    TestVectorType,
-    YAMLModuleDefinition,
+import sys
+from datetime import datetime
+from typing import Any, Dict
+
+import pytest
+from core.yaml_module_system.audit_trail import (
+    AuditAction,
+    AuditEntry,
+    AuditLevel,
+    AuditLogger,
+    ChangeRecord,
+    ChangeTracker,
 )
-from core.yaml_module_system.slsa_compliance import (
-    SBOM,
-    ArtifactSigner,
-    SBOMGenerator,
-    SignatureAlgorithm,
-    SignedArtifact,
-    SLSALevel,
-    SLSAProvenance,
-    SLSAProvenanceGenerator,
+from core.yaml_module_system.ci_verification_pipeline import (
+    CIVerificationPipeline,
+    Evidence,
+    EvidenceCollector,
+    PipelineStage,
+    PipelineStageType,
+    StageResult,
+    StageStatus,
+    VerificationReport,
 )
 from core.yaml_module_system.policy_gate import (
     PolicyAction,
@@ -39,29 +34,35 @@ from core.yaml_module_system.policy_gate import (
     PolicySeverity,
     PolicyViolation,
 )
-from core.yaml_module_system.ci_verification_pipeline import (
-    CIVerificationPipeline,
-    Evidence,
-    EvidenceCollector,
-    PipelineStage,
-    PipelineStageType,
-    StageResult,
-    StageStatus,
-    VerificationReport,
+from core.yaml_module_system.slsa_compliance import (
+    SBOM,
+    ArtifactSigner,
+    SBOMGenerator,
+    SignatureAlgorithm,
+    SignedArtifact,
+    SLSALevel,
+    SLSAProvenance,
+    SLSAProvenanceGenerator,
 )
-from core.yaml_module_system.audit_trail import (
-    AuditAction,
-    AuditEntry,
-    AuditLevel,
-    AuditLogger,
-    ChangeRecord,
-    ChangeTracker,
+from core.yaml_module_system.yaml_module_definition import (
+    ChangelogEntry,
+    LifecycleState,
+    ModuleLifecycle,
+    ModuleMetadata,
+    ModuleOwner,
+    TestVector,
+    TestVectorType,
+    YAMLModuleDefinition,
 )
-import sys
-from datetime import datetime
-from typing import Any, Dict
 
-import pytest
+# Import Phase 13 components
+from core.yaml_module_system.yaml_schema_validator import (
+    SchemaRegistry,
+    ValidationError,
+    ValidationErrorType,
+    ValidationResult,
+    YAMLSchemaValidator,
+)
 
 sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh")
 
@@ -206,14 +207,20 @@ class TestYAMLSchemaValidator:
         result = validator.validate({"name": "test"}, schema)
         assert not result.valid
         assert any(
-            e.error_type == ValidationErrorType.REQUIRED_FIELD_MISSING for e in result.errors
+            e.error_type == ValidationErrorType.REQUIRED_FIELD_MISSING
+            for e in result.errors
         )
 
     def test_string_validation(self):
         """Test string validation"""
         validator = YAMLSchemaValidator()
 
-        schema = {"type": "string", "minLength": 3, "maxLength": 10, "pattern": "^[a-z]+$"}
+        schema = {
+            "type": "string",
+            "minLength": 3,
+            "maxLength": 10,
+            "pattern": "^[a-z]+$",
+        }
 
         # Valid
         result = validator.validate("hello", schema)
@@ -231,7 +238,12 @@ class TestYAMLSchemaValidator:
         """Test array validation"""
         validator = YAMLSchemaValidator()
 
-        schema = {"type": "array", "minItems": 1, "maxItems": 5, "items": {"type": "string"}}
+        schema = {
+            "type": "array",
+            "minItems": 1,
+            "maxItems": 5,
+            "items": {"type": "string"},
+        }
 
         # Valid
         result = validator.validate(["a", "b", "c"], schema)
@@ -326,7 +338,9 @@ class TestCIVerificationPipeline:
 
         assert report.passed
         assert len(report.stages) >= 4
-        assert all(s.status in [StageStatus.PASSED, StageStatus.SKIPPED] for s in report.stages)
+        assert all(
+            s.status in [StageStatus.PASSED, StageStatus.SKIPPED] for s in report.stages
+        )
 
     def test_stage_dependencies(self):
         """Test stage dependencies"""
diff --git a/workspace/src/autonomous/agents/tests/test_phase14_components.py b/workspace/src/autonomous/agents/tests/test_phase14_components.py
index 693be7c..7fc1d72 100644
--- a/workspace/src/autonomous/agents/tests/test_phase14_components.py
+++ b/workspace/src/autonomous/agents/tests/test_phase14_components.py
@@ -7,7 +7,6 @@ from datetime import datetime
 from typing import Any, Dict
 
 import pytest
-
 from core.main_system.automation_pipeline import (
     AutomationPipeline,
     PipelineConfig,
@@ -197,7 +196,9 @@ class TestSystemBootstrap:
         class SimpleService:
             pass
 
-        bootstrap.register_service(ServiceDefinition(name="simple", service_class=SimpleService))
+        bootstrap.register_service(
+            ServiceDefinition(name="simple", service_class=SimpleService)
+        )
 
         result = bootstrap.initialize()
         assert result is True
@@ -390,4 +391,6 @@ class TestPhaseIntegration:
         for task_type, expected_phases in task_types:
             result = core.process_task({"type": task_type, "id": f"test_{task_type}"})
             for phase in expected_phases:
-                assert phase in result["processed_by"], f"Task {task_type} missing {phase}"
+                assert (
+                    phase in result["processed_by"]
+                ), f"Task {task_type} missing {phase}"
diff --git a/workspace/src/autonomous/agents/tests/test_phase3_components.py b/workspace/src/autonomous/agents/tests/test_phase3_components.py
index b86bd92..1d84bbc 100644
--- a/workspace/src/autonomous/agents/tests/test_phase3_components.py
+++ b/workspace/src/autonomous/agents/tests/test_phase3_components.py
@@ -8,13 +8,16 @@ Tests for:
 - ZeroTouchDeploymentEngine
 """
 
-from core.ai_decision_engine import (
-    AIDecisionEngine,
-    ConfidenceLevel,
-    DecisionContext,
-    DecisionOption,
-    DecisionPriority,
-    DecisionType,
+import asyncio
+import os
+import sys
+
+import pytest
+from automation.zero_touch_deployment import (
+    DeploymentEnvironment,
+    DeploymentStatus,
+    DeploymentStrategy,
+    ZeroTouchDeploymentEngine,
 )
 from bridges.language_bridges import (
     BridgeStatus,
@@ -23,17 +26,14 @@ from bridges.language_bridges import (
     Language,
     LanguageBridgeManager,
 )
-from automation.zero_touch_deployment import (
-    DeploymentEnvironment,
-    DeploymentStatus,
-    DeploymentStrategy,
-    ZeroTouchDeploymentEngine,
+from core.ai_decision_engine import (
+    AIDecisionEngine,
+    ConfidenceLevel,
+    DecisionContext,
+    DecisionOption,
+    DecisionPriority,
+    DecisionType,
 )
-import asyncio
-import os
-import sys
-
-import pytest
 
 # Add paths for imports
 sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh")
@@ -121,7 +121,9 @@ class TestAIDecisionEngine:
         """Test outcome prediction"""
         current_state = {"success_rate": 0.95, "error_rate": 0.02, "performance": 0.8}
 
-        prediction = await engine.predict_outcome(current_state, prediction_type="system_health")
+        prediction = await engine.predict_outcome(
+            current_state, prediction_type="system_health"
+        )
 
         assert prediction.prediction_id.startswith("pred-")
         assert 0 <= prediction.probability <= 1
@@ -133,7 +135,11 @@ class TestAIDecisionEngine:
         # Make a decision first
         async def make_and_record():
             context = DecisionContext(context_id="ctx-3", domain="test")
-            options = [DecisionOption(option_id="opt-1", name="Test", description="Test option")]
+            options = [
+                DecisionOption(
+                    option_id="opt-1", name="Test", description="Test option"
+                )
+            ]
             decision = await engine.make_decision(context, options)
 
             engine.record_outcome(decision.decision_id, success=True)
diff --git a/workspace/src/autonomous/agents/tests/test_phase4_components.py b/workspace/src/autonomous/agents/tests/test_phase4_components.py
index 94ab696..a63f1b2 100644
--- a/workspace/src/autonomous/agents/tests/test_phase4_components.py
+++ b/workspace/src/autonomous/agents/tests/test_phase4_components.py
@@ -7,15 +7,11 @@ Tests for:
 - AutoGovernanceHub
 """
 
-from core.autonomous_trust_engine import (
-    AutonomousTrustEngine,
-    AutonomyLevel,
-    DecisionOutcome,
-    ProposedAction,
-    RiskLevel,
-    SafetyNet,
-    TrustDomain,
-)
+import asyncio
+import os
+import sys
+
+import pytest
 from core.auto_governance_hub import (
     AutoGovernanceHub,
     ChangeRequest,
@@ -25,11 +21,15 @@ from core.auto_governance_hub import (
     PolicyEnforcement,
     PolicyType,
 )
-import asyncio
-import os
-import sys
-
-import pytest
+from core.autonomous_trust_engine import (
+    AutonomousTrustEngine,
+    AutonomyLevel,
+    DecisionOutcome,
+    ProposedAction,
+    RiskLevel,
+    SafetyNet,
+    TrustDomain,
+)
 
 # Add paths for imports
 sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh")
@@ -269,7 +269,10 @@ class TestAutoGovernanceHub:
             change_type=ChangeType.ACCESS,
             description="Grant temporary access",
             requestor="auth-service",
-            parameters={"least_privilege_compliant": True, "no_permanent_elevation": True},
+            parameters={
+                "least_privilege_compliant": True,
+                "no_permanent_elevation": True,
+            },
             risk_score=0.4,
         )
 
@@ -376,8 +379,18 @@ class TestPhase4Integration:
 
         # Simulate multiple operations
         operations = [
-            ("config_update", TrustDomain.CONFIGURATION, RiskLevel.LOW, ChangeType.CONFIGURATION),
-            ("deploy_canary", TrustDomain.DEPLOYMENT, RiskLevel.MODERATE, ChangeType.DEPLOYMENT),
+            (
+                "config_update",
+                TrustDomain.CONFIGURATION,
+                RiskLevel.LOW,
+                ChangeType.CONFIGURATION,
+            ),
+            (
+                "deploy_canary",
+                TrustDomain.DEPLOYMENT,
+                RiskLevel.MODERATE,
+                ChangeType.DEPLOYMENT,
+            ),
             ("grant_access", TrustDomain.SECURITY, RiskLevel.LOW, ChangeType.ACCESS),
         ]
 
@@ -440,7 +453,10 @@ class TestPhase4Integration:
 
             # No decision should require human approval
             assert decision.outcome != "requires_human_approval"
-            assert "human" not in decision.reasoning.lower() or "not" in decision.reasoning.lower()
+            assert (
+                "human" not in decision.reasoning.lower()
+                or "not" in decision.reasoning.lower()
+            )
 
         # Check governance decisions don't escalate to humans
         for i in range(5):
diff --git a/workspace/src/autonomous/agents/tests/test_phase5_components.py b/workspace/src/autonomous/agents/tests/test_phase5_components.py
index 1eb311e..0c27fe9 100644
--- a/workspace/src/autonomous/agents/tests/test_phase5_components.py
+++ b/workspace/src/autonomous/agents/tests/test_phase5_components.py
@@ -7,12 +7,17 @@ Phase 5 focuses on:
 3. Automatic Bug Detection and Fixing
 """
 
-from hallucination_detector import (
-    HallucinationDetection,
-    HallucinationDetector,
-    HallucinationType,
-    SeverityLevel,
-    ValidationResult,
+import os
+import sys
+
+import pytest
+from auto_bug_detector import (
+    AutoBugDetector,
+    BugCategory,
+    BugFix,
+    DetectedBug,
+    FixConfidence,
+    FixStatus,
 )
 from context_understanding_engine import (
     ContextAnalysis,
@@ -21,18 +26,13 @@ from context_understanding_engine import (
     IntentCategory,
     ParsedIntent,
 )
-from auto_bug_detector import (
-    AutoBugDetector,
-    BugCategory,
-    BugFix,
-    DetectedBug,
-    FixConfidence,
-    FixStatus,
+from hallucination_detector import (
+    HallucinationDetection,
+    HallucinationDetector,
+    HallucinationType,
+    SeverityLevel,
+    ValidationResult,
 )
-import os
-import sys
-
-import pytest
 
 # Add core directory to path
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "..", "core"))
@@ -94,7 +94,9 @@ class TestHallucinationDetector:
         """
         result = detector.validate_code(code, "python")
         incomplete_issues = [
-            h for h in result.hallucinations if h.hallucination_type == HallucinationType.INCOMPLETE
+            h
+            for h in result.hallucinations
+            if h.hallucination_type == HallucinationType.INCOMPLETE
         ]
         assert len(incomplete_issues) > 0
 
@@ -123,7 +125,9 @@ class TestHallucinationDetector:
         """
         result = detector.validate_code(code, "python")
         assert result.overall_confidence > 0.5
-        critical_issues = [h for h in result.hallucinations if h.severity == SeverityLevel.CRITICAL]
+        critical_issues = [
+            h for h in result.hallucinations if h.severity == SeverityLevel.CRITICAL
+        ]
         assert len(critical_issues) == 0
 
     def test_custom_validator_registration(self):
@@ -200,7 +204,9 @@ class TestContextUnderstandingEngine:
     def test_parse_migration_intent(self):
         """Test parsing migration intent from Chinese request"""
         engine = ContextUnderstandingEngine()
-        result = engine.analyze_request("user-1", "æˆ‘éœ€è¦å°‡ç”¨æˆ¶è³‡æ–™å¾èˆŠç³»çµ±é·ç§»åˆ°æ–°ç³»çµ±")
+        result = engine.analyze_request(
+            "user-1", "æˆ‘éœ€è¦å°‡ç”¨æˆ¶è³‡æ–™å¾èˆŠç³»çµ±é·ç§»åˆ°æ–°ç³»çµ±"
+        )
         assert result.parsed_intent.primary_intent == IntentCategory.MIGRATION
         assert result.understanding_confidence > 0
 
@@ -219,7 +225,9 @@ class TestContextUnderstandingEngine:
     def test_extract_entities(self):
         """Test entity extraction from request"""
         engine = ContextUnderstandingEngine()
-        result = engine.analyze_request("user-1", "Migrate user data from old system to new system")
+        result = engine.analyze_request(
+            "user-1", "Migrate user data from old system to new system"
+        )
         entities = result.parsed_intent.entities
         assert "systems" in entities or "data_types" in entities
 
diff --git a/workspace/src/autonomous/agents/tests/test_phase6_components.py b/workspace/src/autonomous/agents/tests/test_phase6_components.py
index e43fa9b..c2db865 100644
--- a/workspace/src/autonomous/agents/tests/test_phase6_components.py
+++ b/workspace/src/autonomous/agents/tests/test_phase6_components.py
@@ -11,27 +11,21 @@ Tests for all Phase 6 components:
 - GuardrailSystem (è­·æ¬„ç³»çµ±)
 """
 
-from core.ai_constitution.policy_as_prompt import (
-    EnforcementAction,
-    PolicyAsPrompt,
-    PolicyType,
-)
-from core.ai_constitution.operational_rules import (
-    CommunicationRule,
-    DataHandlingRule,
-    OperationalRuleEngine,
-    ResourceUsageRule,
-    RuleCategory,
-    RuleSeverity,
-    SystemAccessRule,
+import asyncio
+import os
+import sys
+
+import pytest
+from core.ai_constitution.adaptive_guidelines import (
+    AdaptiveGuidelineEngine,
+    ContextualGuideline,
+    DomainGuideline,
+    LearningGuideline,
 )
-from core.ai_constitution.guardrails import (
-    ComplianceGuardrail,
-    EthicsGuardrail,
-    GuardrailSeverity,
-    GuardrailSystem,
-    GuardrailType,
-    SafetyGuardrail,
+from core.ai_constitution.constitution_engine import (
+    ActionProposal,
+    ConstitutionEngine,
+    VerdictType,
 )
 from core.ai_constitution.fundamental_laws import (
     EnforcementLevel,
@@ -42,22 +36,28 @@ from core.ai_constitution.fundamental_laws import (
     LawZero,
     ProposedAction,
 )
-from core.ai_constitution.constitution_engine import (
-    ActionProposal,
-    ConstitutionEngine,
-    VerdictType,
+from core.ai_constitution.guardrails import (
+    ComplianceGuardrail,
+    EthicsGuardrail,
+    GuardrailSeverity,
+    GuardrailSystem,
+    GuardrailType,
+    SafetyGuardrail,
 )
-from core.ai_constitution.adaptive_guidelines import (
-    AdaptiveGuidelineEngine,
-    ContextualGuideline,
-    DomainGuideline,
-    LearningGuideline,
+from core.ai_constitution.operational_rules import (
+    CommunicationRule,
+    DataHandlingRule,
+    OperationalRuleEngine,
+    ResourceUsageRule,
+    RuleCategory,
+    RuleSeverity,
+    SystemAccessRule,
+)
+from core.ai_constitution.policy_as_prompt import (
+    EnforcementAction,
+    PolicyAsPrompt,
+    PolicyType,
 )
-import asyncio
-import os
-import sys
-
-import pytest
 
 # Add the project root to the path
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))
@@ -240,7 +240,9 @@ class TestDataHandlingRule:
         }
         result = rule.check(operation)
         # May still have warnings but should pass critical checks
-        critical_violations = [v for v in result.violations if v.severity == RuleSeverity.CRITICAL]
+        critical_violations = [
+            v for v in result.violations if v.severity == RuleSeverity.CRITICAL
+        ]
         assert len(critical_violations) == 0
 
 
@@ -376,7 +378,9 @@ class TestLearningGuideline:
 
         # Record outcomes
         for i in range(12):
-            learning.record_outcome({"type": "backup", "method": "incremental"}, {"success": True})
+            learning.record_outcome(
+                {"type": "backup", "method": "incremental"}, {"success": True}
+            )
 
         recommendation = learning.get_recommendation("backup")
         # May or may not have recommendation depending on confidence
@@ -430,7 +434,10 @@ class TestConstitutionEngine:
         )
         verdict = await engine.evaluate(proposal)
         assert verdict is not None
-        assert verdict.verdict_type in [VerdictType.APPROVED, VerdictType.APPROVED_WITH_CONDITIONS]
+        assert verdict.verdict_type in [
+            VerdictType.APPROVED,
+            VerdictType.APPROVED_WITH_CONDITIONS,
+        ]
 
     @pytest.mark.asyncio
     async def test_engine_evaluate_harmful_action(self):
diff --git a/workspace/src/autonomous/agents/tests/test_phase7_components.py b/workspace/src/autonomous/agents/tests/test_phase7_components.py
index d84bd88..82ad615 100644
--- a/workspace/src/autonomous/agents/tests/test_phase7_components.py
+++ b/workspace/src/autonomous/agents/tests/test_phase7_components.py
@@ -23,7 +23,9 @@ class TestKnowledgeBase:
         """Test knowledge base initializes with built-in knowledge."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from knowledge_base import KnowledgeBase, KnowledgeCategory
 
         kb = KnowledgeBase()
@@ -39,7 +41,9 @@ class TestKnowledgeBase:
         """Test retrieving a concept."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from knowledge_base import KnowledgeBase
 
         kb = KnowledgeBase()
@@ -53,20 +57,26 @@ class TestKnowledgeBase:
         """Test retrieving a best practice."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from knowledge_base import KnowledgeBase
 
         kb = KnowledgeBase()
         practice = kb.get_best_practice("use_transactions")
 
         assert practice is not None
-        assert "äº‹å‹™" in practice.principle or "transaction" in practice.principle.lower()
+        assert (
+            "äº‹å‹™" in practice.principle or "transaction" in practice.principle.lower()
+        )
 
     def test_get_anti_pattern(self):
         """Test retrieving an anti-pattern."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from knowledge_base import KnowledgeBase
 
         kb = KnowledgeBase()
@@ -80,7 +90,9 @@ class TestKnowledgeBase:
         """Test searching concepts."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from knowledge_base import KnowledgeBase
 
         kb = KnowledgeBase()
@@ -92,7 +104,9 @@ class TestKnowledgeBase:
         """Test getting relevant knowledge for a context."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from knowledge_base import KnowledgeBase
 
         kb = KnowledgeBase()
@@ -106,7 +120,9 @@ class TestKnowledgeBase:
         """Test adding a new concept."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from knowledge_base import ConceptDefinition, KnowledgeBase, KnowledgeCategory
 
         kb = KnowledgeBase()
@@ -130,7 +146,9 @@ class TestKnowledgeBase:
         """Test getting domain knowledge."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from knowledge_base import KnowledgeBase, KnowledgeCategory
 
         kb = KnowledgeBase()
@@ -152,7 +170,9 @@ class TestSkillsTraining:
         """Test training system initializes with built-in content."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from skills_training import SkillsTrainingSystem
 
         system = SkillsTrainingSystem()
@@ -166,7 +186,9 @@ class TestSkillsTraining:
         """Test retrieving a skill."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from skills_training import SkillLevel, SkillsTrainingSystem
 
         system = SkillsTrainingSystem()
@@ -180,7 +202,9 @@ class TestSkillsTraining:
         """Test retrieving a training module."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from skills_training import SkillsTrainingSystem
 
         system = SkillsTrainingSystem()
@@ -194,7 +218,9 @@ class TestSkillsTraining:
         """Test starting a training session."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from skills_training import SkillsTrainingSystem
 
         system = SkillsTrainingSystem()
@@ -210,7 +236,9 @@ class TestSkillsTraining:
         """Test submitting an exercise answer."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from skills_training import SkillsTrainingSystem
 
         system = SkillsTrainingSystem()
@@ -228,7 +256,9 @@ class TestSkillsTraining:
         """Test getting agent skill level."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from skills_training import SkillLevel, SkillsTrainingSystem
 
         system = SkillsTrainingSystem()
@@ -240,7 +270,9 @@ class TestSkillsTraining:
         """Test retrieving a learning path."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from skills_training import SkillsTrainingSystem
 
         system = SkillsTrainingSystem()
@@ -254,7 +286,9 @@ class TestSkillsTraining:
         """Test getting learning path progress."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from skills_training import SkillsTrainingSystem
 
         system = SkillsTrainingSystem()
@@ -268,7 +302,9 @@ class TestSkillsTraining:
         """Test getting recommended modules."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from skills_training import SkillsTrainingSystem
 
         system = SkillsTrainingSystem()
@@ -287,7 +323,9 @@ class TestExampleLibrary:
         """Test example library initializes with built-in examples."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from example_library import ExampleLibrary
 
         library = ExampleLibrary()
@@ -301,7 +339,9 @@ class TestExampleLibrary:
         """Test retrieving a code example."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from example_library import ExampleLibrary
 
         library = ExampleLibrary()
@@ -316,7 +356,9 @@ class TestExampleLibrary:
         """Test retrieving a scenario example."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from example_library import ExampleLibrary
 
         library = ExampleLibrary()
@@ -330,7 +372,9 @@ class TestExampleLibrary:
         """Test retrieving a decision example."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from example_library import ExampleLibrary
 
         library = ExampleLibrary()
@@ -344,7 +388,9 @@ class TestExampleLibrary:
         """Test searching examples."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from example_library import ExampleLibrary
 
         library = ExampleLibrary()
@@ -357,7 +403,9 @@ class TestExampleLibrary:
         """Test getting examples for a category."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from example_library import ExampleCategory, ExampleLibrary
 
         library = ExampleLibrary()
@@ -370,7 +418,9 @@ class TestExampleLibrary:
         """Test adding a code example."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from example_library import CodeExample, ExampleCategory, ExampleLibrary
 
         library = ExampleLibrary()
@@ -399,7 +449,9 @@ class TestVirtualExperts:
         """Test VirtualExpert base class."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from expert_base import ExpertKnowledge, ExpertPersonality, VirtualExpert
 
         expert = VirtualExpert(
@@ -418,7 +470,9 @@ class TestVirtualExperts:
         """Test expert self-introduction."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from domain_experts import DrAlexChen
 
         expert = DrAlexChen()
@@ -431,7 +485,9 @@ class TestVirtualExperts:
         """Test expert domain handling check."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from domain_experts import DrAlexChen, MarcusJohnson
 
         ai_expert = DrAlexChen()
@@ -445,7 +501,9 @@ class TestVirtualExperts:
         """Test expert providing guidance."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from domain_experts import MarcusJohnson
 
         expert = MarcusJohnson()
@@ -458,7 +516,9 @@ class TestVirtualExperts:
         """Test expert code review."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from domain_experts import MarcusJohnson
 
         expert = MarcusJohnson()
@@ -478,7 +538,9 @@ def save_password(password):
         """Test VirtualExpertTeam initialization."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from expert_team import VirtualExpertTeam
 
         team = VirtualExpertTeam()
@@ -491,7 +553,9 @@ def save_password(password):
         """Test listing all experts."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from expert_team import VirtualExpertTeam
 
         team = VirtualExpertTeam()
@@ -505,7 +569,9 @@ def save_password(password):
         """Test finding experts for specific domains."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from expert_team import VirtualExpertTeam
 
         team = VirtualExpertTeam()
@@ -520,7 +586,9 @@ def save_password(password):
         """Test creating a consultation."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from expert_team import ConsultationType, VirtualExpertTeam
 
         team = VirtualExpertTeam()
@@ -542,7 +610,9 @@ def save_password(password):
         """Test processing a consultation."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from expert_team import ConsultationType, VirtualExpertTeam
 
         team = VirtualExpertTeam()
@@ -566,7 +636,9 @@ def save_password(password):
         """Test Dr. Alex Chen expert."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from domain_experts import DrAlexChen
 
         expert = DrAlexChen()
@@ -579,19 +651,26 @@ def save_password(password):
         """Test Li Wei database expert."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from domain_experts import LiWei
 
         expert = LiWei()
 
         assert expert.name == "Li Wei"
-        assert "database" in expert.knowledge.primary_domains[0].lower() or "æ•¸æ“šåº«" in expert.title
+        assert (
+            "database" in expert.knowledge.primary_domains[0].lower()
+            or "æ•¸æ“šåº«" in expert.title
+        )
 
     def test_domain_expert_emma_thompson(self):
         """Test Emma Thompson DevOps expert."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from domain_experts import EmmaThompson
 
         expert = EmmaThompson()
@@ -603,7 +682,9 @@ def save_password(password):
         """Test expert guidance for deployment topic."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from domain_experts import EmmaThompson
 
         expert = EmmaThompson()
@@ -615,7 +696,9 @@ def save_password(password):
         """Test expert guidance for database topic."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
         from domain_experts import LiWei
 
         expert = LiWei()
@@ -634,7 +717,9 @@ class TestPhase7Integration:
         """Test knowledge base integrates with training system."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from knowledge_base import KnowledgeBase
         from skills_training import SkillsTrainingSystem
 
@@ -655,7 +740,9 @@ class TestPhase7Integration:
         """Test example library provides examples for training."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
         from example_library import ExampleCategory, ExampleLibrary
         from skills_training import SkillsTrainingSystem
 
@@ -675,8 +762,12 @@ class TestPhase7Integration:
         """Test experts can leverage knowledge base."""
         import sys
 
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts")
-        sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system")
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/virtual_experts"
+        )
+        sys.path.insert(
+            0, "/home/runner/work/SynergyMesh/SynergyMesh/core/training_system"
+        )
 
         from expert_team import ConsultationType, VirtualExpertTeam
         from knowledge_base import KnowledgeBase
diff --git a/workspace/src/autonomous/agents/tests/test_phase8_components.py b/workspace/src/autonomous/agents/tests/test_phase8_components.py
index 115fee0..7c84802 100644
--- a/workspace/src/autonomous/agents/tests/test_phase8_components.py
+++ b/workspace/src/autonomous/agents/tests/test_phase8_components.py
@@ -5,6 +5,11 @@
 â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 """
 
+import asyncio
+import os
+import sys
+
+import pytest
 from core.execution_engine import (
     ActionExecutor,
     ActionPlan,
@@ -31,11 +36,6 @@ from core.execution_engine import (
     VerificationResult,
     VerificationStrategy,
 )
-import asyncio
-import os
-import sys
-
-import pytest
 
 # Add parent directory to path for imports
 sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
@@ -514,7 +514,9 @@ class TestRollbackManager:
     @pytest.mark.asyncio
     async def test_rollback_execution(self, manager):
         """æ¸¬è©¦å›æ»¾åŸ·è¡Œ"""
-        manager.create_checkpoint("step1", {"database_table1": {}}, execution_id="exec_rb")
+        manager.create_checkpoint(
+            "step1", {"database_table1": {}}, execution_id="exec_rb"
+        )
         manager.create_checkpoint("step2", {"file_config": {}}, execution_id="exec_rb")
 
         plan = await manager.rollback_execution("exec_rb")
@@ -633,7 +635,10 @@ class TestPhase8Integration:
         # å¦‚æœéœ€è¦å›æ»¾
         if not result.verification_passed and not context.dry_run:
             rollback_plan = await rollback_manager.rollback_to_checkpoint(checkpoint.id)
-            assert rollback_plan.status in [RollbackStatus.COMPLETED, RollbackStatus.PARTIAL]
+            assert rollback_plan.status in [
+                RollbackStatus.COMPLETED,
+                RollbackStatus.PARTIAL,
+            ]
 
     def test_capability_requirement_check(self):
         """æ¸¬è©¦èƒ½åŠ›éœ€æ±‚æª¢æŸ¥"""
diff --git a/workspace/src/autonomous/agents/tests/test_phase8_enhancement.py b/workspace/src/autonomous/agents/tests/test_phase8_enhancement.py
index 49bf953..e2bf8af 100644
--- a/workspace/src/autonomous/agents/tests/test_phase8_enhancement.py
+++ b/workspace/src/autonomous/agents/tests/test_phase8_enhancement.py
@@ -8,16 +8,32 @@ Tests for:
 - Python Bridge
 """
 
-from core.tech_stack.python_bridge import (
-    EnvironmentType,
-    ExecutionMode,
-    PackageManager,
-    PythonBridge,
-    PythonEnvironment,
-    PythonEnvironmentConfig,
-    PythonExecutor,
-    PythonPackage,
-    PythonVersion,
+import asyncio
+import os
+import sys
+
+import pytest
+from core.tech_stack.architecture_config import (
+    ArchitectureLayer,
+    FrameworkCategory,
+    FrameworkConfig,
+    LanguageConfig,
+    LanguageType,
+    TechStackConfig,
+    get_recommended_stack,
+    get_stack_summary,
+)
+from core.tech_stack.framework_integrations import (
+    AgentConfig,
+    AgentType,
+    AutoGenIntegration,
+    CrewAIIntegration,
+    FrameworkCredentials,
+    FrameworkIntegration,
+    FrameworkOrchestrator,
+    FrameworkStatus,
+    LangChainIntegration,
+    LangGraphIntegration,
 )
 from core.tech_stack.multi_agent_coordinator import (
     AgentCapability,
@@ -34,33 +50,17 @@ from core.tech_stack.multi_agent_coordinator import (
     create_devops_agent,
     create_security_agent,
 )
-from core.tech_stack.framework_integrations import (
-    AgentConfig,
-    AgentType,
-    AutoGenIntegration,
-    CrewAIIntegration,
-    FrameworkCredentials,
-    FrameworkIntegration,
-    FrameworkOrchestrator,
-    FrameworkStatus,
-    LangChainIntegration,
-    LangGraphIntegration,
-)
-from core.tech_stack.architecture_config import (
-    ArchitectureLayer,
-    FrameworkCategory,
-    FrameworkConfig,
-    LanguageConfig,
-    LanguageType,
-    TechStackConfig,
-    get_recommended_stack,
-    get_stack_summary,
+from core.tech_stack.python_bridge import (
+    EnvironmentType,
+    ExecutionMode,
+    PackageManager,
+    PythonBridge,
+    PythonEnvironment,
+    PythonEnvironmentConfig,
+    PythonExecutor,
+    PythonPackage,
+    PythonVersion,
 )
-import asyncio
-import os
-import sys
-
-import pytest
 
 # Add the project root to path
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))
@@ -231,7 +231,9 @@ class TestFrameworkIntegrations:
         id2 = await integration.create_agent(agent2)
 
         # Create crew
-        crew_id = await integration.create_crew("test_crew", "Research Team", [id1, id2])
+        crew_id = await integration.create_crew(
+            "test_crew", "Research Team", [id1, id2]
+        )
 
         assert crew_id == "test_crew"
         assert crew_id in integration.crews
@@ -246,7 +248,9 @@ class TestFrameworkIntegrations:
         agent_id = await integration.create_agent(agent)
 
         crew_id = await integration.create_crew("crew1", "Test", [agent_id])
-        task_id = await integration.create_task("task1", "Do something", agent_id, "Result")
+        task_id = await integration.create_task(
+            "task1", "Do something", agent_id, "Result"
+        )
 
         result = await integration.execute_crew(crew_id, [task_id])
 
@@ -368,7 +372,9 @@ class TestFrameworkIntegrations:
 
         langchain = LangChainIntegration()
         orchestrator.register_framework(langchain, set_as_default=True)
-        await orchestrator.initialize_all({"langchain": FrameworkCredentials(api_key="test")})
+        await orchestrator.initialize_all(
+            {"langchain": FrameworkCredentials(api_key="test")}
+        )
 
         # Create agent
         config = AgentConfig(name="TestAgent")
@@ -402,7 +408,10 @@ class TestMultiAgentCoordinator:
         """Test agent task capability check"""
         agent = AgentDefinition(
             name="Coder",
-            capabilities=[AgentCapability.CODE_GENERATION, AgentCapability.CODE_DEBUGGING],
+            capabilities=[
+                AgentCapability.CODE_GENERATION,
+                AgentCapability.CODE_DEBUGGING,
+            ],
         )
 
         assert agent.can_handle_task([AgentCapability.CODE_GENERATION])
@@ -414,17 +423,23 @@ class TestMultiAgentCoordinator:
 
         # Register agents
         coder = AgentDefinition(
-            name="Coder", role=AgentRole.CODER, capabilities=[AgentCapability.CODE_GENERATION]
+            name="Coder",
+            role=AgentRole.CODER,
+            capabilities=[AgentCapability.CODE_GENERATION],
         )
         reviewer = AgentDefinition(
-            name="Reviewer", role=AgentRole.REVIEWER, capabilities=[AgentCapability.CODE_REVIEW]
+            name="Reviewer",
+            role=AgentRole.REVIEWER,
+            capabilities=[AgentCapability.CODE_REVIEW],
         )
 
         router.register_agent(coder)
         router.register_agent(reviewer)
 
         # Create task
-        task = TeamTask(title="Write Code", required_capabilities=[AgentCapability.CODE_GENERATION])
+        task = TeamTask(
+            title="Write Code", required_capabilities=[AgentCapability.CODE_GENERATION]
+        )
 
         # Route task
         assigned = router.route_task(task)
@@ -530,10 +545,14 @@ class TestMultiAgentCoordinator:
         coordinator = MultiAgentCoordinator()
         await coordinator.start()
 
-        agent = AgentDefinition(name="Worker", capabilities=[AgentCapability.TASK_EXECUTION])
+        agent = AgentDefinition(
+            name="Worker", capabilities=[AgentCapability.TASK_EXECUTION]
+        )
         coordinator.register_agent(agent)
 
-        task = TeamTask(title="Test Task", required_capabilities=[AgentCapability.TASK_EXECUTION])
+        task = TeamTask(
+            title="Test Task", required_capabilities=[AgentCapability.TASK_EXECUTION]
+        )
         task_id = await coordinator.submit_task(task)
 
         assert task_id in coordinator.tasks
@@ -569,7 +588,11 @@ class TestMultiAgentCoordinator:
         agent = AgentDefinition(name="Worker", max_concurrent_tasks=5)
         coordinator.register_agent(agent)
 
-        tasks = [TeamTask(title="Task1"), TeamTask(title="Task2"), TeamTask(title="Task3")]
+        tasks = [
+            TeamTask(title="Task1"),
+            TeamTask(title="Task2"),
+            TeamTask(title="Task3"),
+        ]
 
         results = await coordinator.execute_workflow(tasks, parallel=True)
 
@@ -635,7 +658,9 @@ class TestPythonBridge:
     @pytest.mark.asyncio
     async def test_python_environment_create(self):
         """Test Python environment creation"""
-        config = PythonEnvironmentConfig(name="test_env", environment_type=EnvironmentType.SYSTEM)
+        config = PythonEnvironmentConfig(
+            name="test_env", environment_type=EnvironmentType.SYSTEM
+        )
 
         env = PythonEnvironment(config)
         result = await env.create()
@@ -646,7 +671,9 @@ class TestPythonBridge:
     @pytest.mark.asyncio
     async def test_python_environment_install_package(self):
         """Test package installation in environment"""
-        config = PythonEnvironmentConfig(name="test_env", environment_type=EnvironmentType.SYSTEM)
+        config = PythonEnvironmentConfig(
+            name="test_env", environment_type=EnvironmentType.SYSTEM
+        )
 
         env = PythonEnvironment(config)
         await env.create()
@@ -660,7 +687,9 @@ class TestPythonBridge:
     @pytest.mark.asyncio
     async def test_python_executor(self):
         """Test Python executor"""
-        config = PythonEnvironmentConfig(name="test_env", environment_type=EnvironmentType.SYSTEM)
+        config = PythonEnvironmentConfig(
+            name="test_env", environment_type=EnvironmentType.SYSTEM
+        )
         env = PythonEnvironment(config)
         await env.create()
 
diff --git a/workspace/src/autonomous/agents/tests/test_phase9_components.py b/workspace/src/autonomous/agents/tests/test_phase9_components.py
index 0308927..5f2277d 100644
--- a/workspace/src/autonomous/agents/tests/test_phase9_components.py
+++ b/workspace/src/autonomous/agents/tests/test_phase9_components.py
@@ -4,33 +4,19 @@ Tests for Tool System, LangChain Integration, Agent Orchestration,
 Function Calling, and MCP Integration
 """
 
-from core.execution_architecture.tool_system import (
-    Tool,
-    ToolCategory,
-    ToolExecutor,
-    ToolRegistry,
-    ToolResult,
-    ToolStatus,
-    create_api_tool,
-    create_code_tool,
-    create_database_tool,
-)
-from core.execution_architecture.mcp_integration import (
-    MCPBridge,
-    MCPMessageType,
-    MCPServerConfig,
-    MCPTool,
-    MCPToolCall,
-    MCPToolConsumer,
-    MCPToolProvider,
-    MCPToolResult,
-)
-from core.execution_architecture.langchain_integration import (
-    AgentConfig,
-    ChainBuilder,
-    LangChainToolAdapter,
-    LangChainToolFormat,
-    ReActAgentBuilder,
+import asyncio
+import sys
+from datetime import datetime
+
+import pytest
+from core.execution_architecture.agent_orchestration import (
+    AgentOrchestrator,
+    ExecutionContext,
+    ExecutionPlan,
+    ExecutionStep,
+    OrchestratorConfig,
+    StepStatus,
+    TaskPlanner,
 )
 from core.execution_architecture.function_calling import (
     FunctionCallHandler,
@@ -43,20 +29,34 @@ from core.execution_architecture.function_calling import (
     create_code_function,
     create_query_function,
 )
-from core.execution_architecture.agent_orchestration import (
-    AgentOrchestrator,
-    ExecutionContext,
-    ExecutionPlan,
-    ExecutionStep,
-    OrchestratorConfig,
-    StepStatus,
-    TaskPlanner,
+from core.execution_architecture.langchain_integration import (
+    AgentConfig,
+    ChainBuilder,
+    LangChainToolAdapter,
+    LangChainToolFormat,
+    ReActAgentBuilder,
+)
+from core.execution_architecture.mcp_integration import (
+    MCPBridge,
+    MCPMessageType,
+    MCPServerConfig,
+    MCPTool,
+    MCPToolCall,
+    MCPToolConsumer,
+    MCPToolProvider,
+    MCPToolResult,
+)
+from core.execution_architecture.tool_system import (
+    Tool,
+    ToolCategory,
+    ToolExecutor,
+    ToolRegistry,
+    ToolResult,
+    ToolStatus,
+    create_api_tool,
+    create_code_tool,
+    create_database_tool,
 )
-import asyncio
-import sys
-from datetime import datetime
-
-import pytest
 
 sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh")
 
@@ -154,10 +154,14 @@ class TestToolRegistry:
         """Test searching tools"""
         registry = ToolRegistry()
         tool1 = Tool(
-            name="query_users", description="Query user data", category=ToolCategory.DATABASE
+            name="query_users",
+            description="Query user data",
+            category=ToolCategory.DATABASE,
         )
         tool2 = Tool(
-            name="send_email", description="Send email", category=ToolCategory.COMMUNICATION
+            name="send_email",
+            description="Send email",
+            category=ToolCategory.COMMUNICATION,
         )
 
         registry.register(tool1)
@@ -207,7 +211,10 @@ class TestLangChainToolAdapter:
         """Test adapting a tool to LangChain format"""
         adapter = LangChainToolAdapter()
         tool = Tool(
-            name="test", description="Test tool", category=ToolCategory.CODE, execute_fn=lambda x: x
+            name="test",
+            description="Test tool",
+            category=ToolCategory.CODE,
+            execute_fn=lambda x: x,
         )
         adapted = adapter.adapt(tool)
         assert isinstance(adapted, LangChainToolFormat)
@@ -472,7 +479,9 @@ class TestMCPTool:
 
     def test_to_mcp_format(self):
         """Test conversion to MCP format"""
-        tool = MCPTool(name="test_tool", description="A test tool", input_schema={"type": "object"})
+        tool = MCPTool(
+            name="test_tool", description="A test tool", input_schema={"type": "object"}
+        )
         mcp_format = tool.to_mcp_format()
         assert mcp_format["name"] == "test_tool"
         assert "inputSchema" in mcp_format
@@ -611,7 +620,9 @@ class TestToolFactories:
     def test_create_code_tool(self):
         """Test code tool factory"""
         tool = create_code_tool(
-            name="execute", description="Execute code", execute_fn=lambda x: "code result"
+            name="execute",
+            description="Execute code",
+            execute_fn=lambda x: "code result",
         )
         assert tool.category == ToolCategory.CODE
         assert "code" in tool.tags
diff --git a/workspace/src/autonomous/agents/tests/test_synergymesh_core.py b/workspace/src/autonomous/agents/tests/test_synergymesh_core.py
index d428283..67d854d 100644
--- a/workspace/src/autonomous/agents/tests/test_synergymesh_core.py
+++ b/workspace/src/autonomous/agents/tests/test_synergymesh_core.py
@@ -9,47 +9,47 @@ Tests for:
 - EcosystemOrchestrator
 """
 
-from machinenativeops_core.orchestration_layer import (
-    IntentUnderstandingEngine,
-    TaskOrchestrationEngine,
-    TaskType,
-    WorkflowStatus,
+import asyncio
+import os
+import sys
+from datetime import datetime
+
+import pytest
+from machinenativeops_core.autonomous_coordinator import (
+    AutonomousCoordinator,
+    SystemHealth,
+    TaskPriority,
+    TaskStatus,
+)
+from machinenativeops_core.ecosystem_orchestrator import (
+    EcosystemOrchestrator,
+    MessagePriority,
+    MessageType,
+    SubsystemStatus,
+    SubsystemType,
+)
+from machinenativeops_core.natural_language_processor import (
+    IntentType,
+    NaturalLanguageProcessor,
+    ParsedIntent,
 )
 from machinenativeops_core.nli_layer import (
     InteractionMode,
     NaturalLanguageInteractionLayer,
     UserIntent,
 )
+from machinenativeops_core.orchestration_layer import (
+    IntentUnderstandingEngine,
+    TaskOrchestrationEngine,
+    TaskType,
+    WorkflowStatus,
+)
 from machinenativeops_core.self_evolution_engine import (
     EvolutionPhase,
     LearningType,
     OptimizationType,
     SelfEvolutionEngine,
 )
-from machinenativeops_core.natural_language_processor import (
-    IntentType,
-    NaturalLanguageProcessor,
-    ParsedIntent,
-)
-from machinenativeops_core.ecosystem_orchestrator import (
-    EcosystemOrchestrator,
-    MessagePriority,
-    MessageType,
-    SubsystemStatus,
-    SubsystemType,
-)
-from machinenativeops_core.autonomous_coordinator import (
-    AutonomousCoordinator,
-    SystemHealth,
-    TaskPriority,
-    TaskStatus,
-)
-import asyncio
-import os
-import sys
-from datetime import datetime
-
-import pytest
 
 # Add the intelligent-automation directory to path for imports
 _current_dir = os.path.dirname(os.path.abspath(__file__))
@@ -276,7 +276,10 @@ class TestAutonomousCoordinator:
         await coordinator.start()
 
         task_id = coordinator.schedule_task(
-            name="Execute Test", description="Test execution", task_type="execute_test", params={}
+            name="Execute Test",
+            description="Test execution",
+            task_type="execute_test",
+            params={},
         )
 
         # Wait for task to complete
@@ -488,7 +491,8 @@ class TestEcosystemOrchestrator:
         assert subsystem_id not in orchestrator.subsystems
         assert (
             "temp_capability" not in orchestrator._capability_index
-            or subsystem_id not in orchestrator._capability_index.get("temp_capability", set())
+            or subsystem_id
+            not in orchestrator._capability_index.get("temp_capability", set())
         )
 
     def test_find_subsystems_by_capability(self, orchestrator):
@@ -536,7 +540,9 @@ class TestEcosystemOrchestrator:
             name="Status Test", subsystem_type=SubsystemType.CUSTOM, capabilities=[]
         )
 
-        result = orchestrator.update_subsystem_status(subsystem_id, SubsystemStatus.ACTIVE)
+        result = orchestrator.update_subsystem_status(
+            subsystem_id, SubsystemStatus.ACTIVE
+        )
 
         assert result is True
         assert orchestrator.subsystems[subsystem_id].status == SubsystemStatus.ACTIVE
@@ -585,7 +591,9 @@ class TestEcosystemOrchestrator:
     def test_get_subsystem_info(self, orchestrator):
         """Test getting subsystem info"""
         subsystem_id = orchestrator.register_subsystem(
-            name="Info Test", subsystem_type=SubsystemType.CODE_ANALYZER, capabilities=["analysis"]
+            name="Info Test",
+            subsystem_type=SubsystemType.CODE_ANALYZER,
+            capabilities=["analysis"],
         )
 
         info = orchestrator.get_subsystem_info(subsystem_id)
@@ -644,7 +652,9 @@ class TestSynergyMeshIntegration:
         await orchestrator.start()
 
         # Process a natural language request
-        result = await nlp.process_natural_request("I need to analyze and optimize this code")
+        result = await nlp.process_natural_request(
+            "I need to analyze and optimize this code"
+        )
 
         assert result["status"] == "success"
 
@@ -744,7 +754,9 @@ class TestNaturalLanguageInteractionLayer:
     def test_register_visual_component(self, nli):
         """Test registering visual components"""
         comp_id = nli.register_visual_component(
-            component_type="source", label="Data Source", description="Source connection"
+            component_type="source",
+            label="Data Source",
+            description="Source connection",
         )
 
         assert comp_id.startswith("comp-")
@@ -833,7 +845,9 @@ class TestIntentUnderstandingEngine:
 
     def test_priority_detection(self, intent_engine):
         """Test priority detection"""
-        intent = intent_engine.parse_intent("Urgent: deploy the application immediately")
+        intent = intent_engine.parse_intent(
+            "Urgent: deploy the application immediately"
+        )
 
         assert intent.priority == "high"
 
diff --git a/workspace/src/autonomous/core/mape-k/mape_k_loop.py b/workspace/src/autonomous/core/mape-k/mape_k_loop.py
index adf30ef..28b9a34 100644
--- a/workspace/src/autonomous/core/mape-k/mape_k_loop.py
+++ b/workspace/src/autonomous/core/mape-k/mape_k_loop.py
@@ -216,7 +216,9 @@ class MAPEKLoop:
                 except Exception as e:
                     # Log executor failure and record in results
                     plan_id = getattr(plan, "id", "unknown")
-                    self.logger.warning(f"Executor failed for plan {plan_id}: {e}", exc_info=True)
+                    self.logger.warning(
+                        f"Executor failed for plan {plan_id}: {e}", exc_info=True
+                    )
                     results.append(
                         ExecutionResult(
                             plan_id=plan.id,
@@ -230,7 +232,10 @@ class MAPEKLoop:
         return results
 
     async def _learn(
-        self, anomalies: List[Anomaly], plans: List[RemediationPlan], results: List[ExecutionResult]
+        self,
+        anomalies: List[Anomaly],
+        plans: List[RemediationPlan],
+        results: List[ExecutionResult],
     ) -> None:
         """Knowledge phase: Learn from execution."""
         for anomaly, plan, result in zip(anomalies, plans, results):
diff --git a/workspace/src/autonomous/core/remediation/auto_remediation.py b/workspace/src/autonomous/core/remediation/auto_remediation.py
index 3d1d17c..4012ee4 100644
--- a/workspace/src/autonomous/core/remediation/auto_remediation.py
+++ b/workspace/src/autonomous/core/remediation/auto_remediation.py
@@ -97,9 +97,13 @@ class AutoRemediation:
         for action in job.actions:
             try:
                 result = await self._execute_action(action)
-                results.append({"action_id": action.id, "success": True, "result": result})
+                results.append(
+                    {"action_id": action.id, "success": True, "result": result}
+                )
             except Exception as e:
-                results.append({"action_id": action.id, "success": False, "error": str(e)})
+                results.append(
+                    {"action_id": action.id, "success": False, "error": str(e)}
+                )
 
                 # Attempt rollback if available
                 if action.rollback_action:
@@ -129,38 +133,52 @@ class AutoRemediation:
         except asyncio.TimeoutError:
             raise TimeoutError(f"Action {action.id} timed out after {action.timeout}s")
 
-    async def _handle_restart(self, target: str, params: Dict[str, Any]) -> Dict[str, Any]:
+    async def _handle_restart(
+        self, target: str, params: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Handle restart strategy."""
         # Placeholder implementation
         graceful = params.get("graceful", True)
         return {"target": target, "action": "restart", "graceful": graceful}
 
-    async def _handle_rollback(self, target: str, params: Dict[str, Any]) -> Dict[str, Any]:
+    async def _handle_rollback(
+        self, target: str, params: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Handle rollback strategy."""
         version = params.get("version", "previous")
         return {"target": target, "action": "rollback", "version": version}
 
-    async def _handle_scale(self, target: str, params: Dict[str, Any]) -> Dict[str, Any]:
+    async def _handle_scale(
+        self, target: str, params: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Handle scale strategy."""
         replicas = params.get("replicas", 1)
         return {"target": target, "action": "scale", "replicas": replicas}
 
-    async def _handle_failover(self, target: str, params: Dict[str, Any]) -> Dict[str, Any]:
+    async def _handle_failover(
+        self, target: str, params: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Handle failover strategy."""
         backup = params.get("backup_target")
         return {"target": target, "action": "failover", "backup": backup}
 
-    async def _handle_patch(self, target: str, params: Dict[str, Any]) -> Dict[str, Any]:
+    async def _handle_patch(
+        self, target: str, params: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Handle patch strategy."""
         patch = params.get("patch")
         return {"target": target, "action": "patch", "applied": patch is not None}
 
-    async def _handle_isolate(self, target: str, params: Dict[str, Any]) -> Dict[str, Any]:
+    async def _handle_isolate(
+        self, target: str, params: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Handle isolate strategy."""
         duration = params.get("duration", 300)
         return {"target": target, "action": "isolate", "duration": duration}
 
-    def register_handler(self, strategy: RemediationStrategy, handler: Callable) -> None:
+    def register_handler(
+        self, strategy: RemediationStrategy, handler: Callable
+    ) -> None:
         """Register a custom remediation handler."""
         self._handlers[strategy] = handler
 
@@ -168,7 +186,9 @@ class AutoRemediation:
         """Get job by ID."""
         return self._jobs.get(job_id)
 
-    def list_jobs(self, status: Optional[RemediationStatus] = None) -> List[RemediationJob]:
+    def list_jobs(
+        self, status: Optional[RemediationStatus] = None
+    ) -> List[RemediationJob]:
         """List all jobs, optionally filtered by status."""
         jobs = list(self._jobs.values())
         if status:
diff --git a/workspace/src/autonomous/deployment/instant_execution_engine_v2.py b/workspace/src/autonomous/deployment/instant_execution_engine_v2.py
index 2c41cfc..f26678e 100644
--- a/workspace/src/autonomous/deployment/instant_execution_engine_v2.py
+++ b/workspace/src/autonomous/deployment/instant_execution_engine_v2.py
@@ -116,7 +116,9 @@ class InstantAgent(ABC):
     def __init__(self, config: AgentConfig):
         self.config = config
         self.agent_id = str(uuid.uuid4())[:8]
-        self.logger = logging.getLogger(f"agent-{config.agent_type.value}-{self.agent_id}")
+        self.logger = logging.getLogger(
+            f"agent-{config.agent_type.value}-{self.agent_id}"
+        )
 
     @abstractmethod
     async def execute(self, input_data: Any) -> Any:
@@ -128,7 +130,9 @@ class InstantAgent(ABC):
         last_error = None
         for attempt in range(self.config.retry_count):
             try:
-                return await asyncio.wait_for(self.execute(input_data), timeout=self.config.timeout)
+                return await asyncio.wait_for(
+                    self.execute(input_data), timeout=self.config.timeout
+                )
             except asyncio.TimeoutError:
                 last_error = f"Timeout after {self.config.timeout}s"
                 self.logger.warning(f"Attempt {attempt + 1} timeout")
@@ -136,7 +140,9 @@ class InstantAgent(ABC):
                 last_error = str(e)
                 self.logger.warning(f"Attempt {attempt + 1} failed: {e}")
 
-        raise RuntimeError(f"All {self.config.retry_count} attempts failed: {last_error}")
+        raise RuntimeError(
+            f"All {self.config.retry_count} attempts failed: {last_error}"
+        )
 
 
 class AnalyzerAgent(InstantAgent):
@@ -252,7 +258,9 @@ class ParallelAgentPool:
         parallelism = parallelism or config.parallelism
         parallelism = min(parallelism, len(inputs), self.max_workers)
 
-        self.logger.info(f"Executing {len(inputs)} tasks with parallelism={parallelism}")
+        self.logger.info(
+            f"Executing {len(inputs)} tasks with parallelism={parallelism}"
+        )
 
         # Create agent instances
         agents = [agent_class(config) for _ in range(parallelism)]
@@ -266,7 +274,9 @@ class ParallelAgentPool:
                 return await agent.execute_with_retry(input_data)
 
         # Execute all tasks
-        tasks = [process_one(agents[i % parallelism], inp) for i, inp in enumerate(inputs)]
+        tasks = [
+            process_one(agents[i % parallelism], inp) for i, inp in enumerate(inputs)
+        ]
 
         results = await asyncio.gather(*tasks, return_exceptions=True)
 
@@ -292,7 +302,10 @@ class InstantPipeline:
     """
 
     def __init__(
-        self, name: str, stages: List[Dict[str, Any]], thresholds: Optional[LatencyThreshold] = None
+        self,
+        name: str,
+        stages: List[Dict[str, Any]],
+        thresholds: Optional[LatencyThreshold] = None,
     ):
         self.name = name
         self.stages = stages
@@ -359,7 +372,9 @@ class InstantPipeline:
                 error=str(e),
             )
 
-    async def _execute_stage(self, stage_config: Dict[str, Any], input_data: Any) -> StageResult:
+    async def _execute_stage(
+        self, stage_config: Dict[str, Any], input_data: Any
+    ) -> StageResult:
         """Execute a single pipeline stage"""
         stage_id = stage_config.get("name", str(uuid.uuid4())[:8])
         agent_type = stage_config.get("agent", AgentType.ANALYZER)
@@ -373,14 +388,20 @@ class InstantPipeline:
             # Get agent class
             agent_class = self._get_agent_class(agent_type)
             config = AgentConfig(
-                agent_type=agent_type if isinstance(agent_type, AgentType) else AgentType.ANALYZER,
+                agent_type=(
+                    agent_type
+                    if isinstance(agent_type, AgentType)
+                    else AgentType.ANALYZER
+                ),
                 parallelism=parallelism,
                 max_latency=max_latency,
             )
 
             # Execute
             if parallelism > 1 and isinstance(input_data, list):
-                results = await self.agent_pool.execute_parallel(agent_class, config, input_data)
+                results = await self.agent_pool.execute_parallel(
+                    agent_class, config, input_data
+                )
                 output = {"batch_results": results, "count": len(results)}
             else:
                 agent = agent_class(config)
@@ -481,9 +502,24 @@ def create_instant_feature_pipeline() -> InstantPipeline:
         name="instant-feature-delivery",
         stages=[
             {"name": "analysis", "agent": "analyzer", "latency": 5.0, "parallelism": 1},
-            {"name": "generation", "agent": "generator", "latency": 30.0, "parallelism": 64},
-            {"name": "validation", "agent": "validator", "latency": 10.0, "parallelism": 32},
-            {"name": "deployment", "agent": "deployer", "latency": 30.0, "parallelism": 32},
+            {
+                "name": "generation",
+                "agent": "generator",
+                "latency": 30.0,
+                "parallelism": 64,
+            },
+            {
+                "name": "validation",
+                "agent": "validator",
+                "latency": 10.0,
+                "parallelism": 32,
+            },
+            {
+                "name": "deployment",
+                "agent": "deployer",
+                "latency": 30.0,
+                "parallelism": 32,
+            },
         ],
     )
 
@@ -493,10 +529,25 @@ def create_instant_fix_pipeline() -> InstantPipeline:
     return InstantPipeline(
         name="instant-fix-delivery",
         stages=[
-            {"name": "detection", "agent": "analyzer", "latency": 1.0, "parallelism": 1},
-            {"name": "diagnosis", "agent": "analyzer", "latency": 2.0, "parallelism": 8},
+            {
+                "name": "detection",
+                "agent": "analyzer",
+                "latency": 1.0,
+                "parallelism": 1,
+            },
+            {
+                "name": "diagnosis",
+                "agent": "analyzer",
+                "latency": 2.0,
+                "parallelism": 8,
+            },
             {"name": "fix", "agent": "generator", "latency": 10.0, "parallelism": 16},
-            {"name": "deployment", "agent": "deployer", "latency": 30.0, "parallelism": 32},
+            {
+                "name": "deployment",
+                "agent": "deployer",
+                "latency": 30.0,
+                "parallelism": 32,
+            },
         ],
     )
 
@@ -507,8 +558,18 @@ def create_instant_optimization_pipeline() -> InstantPipeline:
         name="instant-optimization",
         stages=[
             {"name": "analysis", "agent": "analyzer", "latency": 5.0, "parallelism": 4},
-            {"name": "optimization", "agent": "generator", "latency": 15.0, "parallelism": 16},
-            {"name": "deployment", "agent": "deployer", "latency": 30.0, "parallelism": 16},
+            {
+                "name": "optimization",
+                "agent": "generator",
+                "latency": 15.0,
+                "parallelism": 16,
+            },
+            {
+                "name": "deployment",
+                "agent": "deployer",
+                "latency": 30.0,
+                "parallelism": 16,
+            },
         ],
     )
 
@@ -533,27 +594,35 @@ class InstantExecutionEngine:
         """Setup default pipelines"""
         self.executor.register_pipeline("feature", create_instant_feature_pipeline())
         self.executor.register_pipeline("fix", create_instant_fix_pipeline())
-        self.executor.register_pipeline("optimization", create_instant_optimization_pipeline())
+        self.executor.register_pipeline(
+            "optimization", create_instant_optimization_pipeline()
+        )
 
     def _setup_default_handlers(self):
         """Setup default event handlers"""
         # Git push handler
         self.executor.register_handler(
             "git_push",
-            lambda data: "feature" if data.get("branch") in ["main", "develop"] else None,
+            lambda data: (
+                "feature" if data.get("branch") in ["main", "develop"] else None
+            ),
         )
 
         # Issue created handler
         self.executor.register_handler(
             "issue_created",
-            lambda data: "feature" if "feature-request" in data.get("labels", []) else None,
+            lambda data: (
+                "feature" if "feature-request" in data.get("labels", []) else None
+            ),
         )
 
         # Error detected handler
         self.executor.register_handler("error_detected", lambda data: "fix")
 
         # Performance degradation handler
-        self.executor.register_handler("performance_degradation", lambda data: "optimization")
+        self.executor.register_handler(
+            "performance_degradation", lambda data: "optimization"
+        )
 
     async def execute_feature(self, requirements: Dict[str, Any]) -> PipelineResult:
         """Execute instant feature delivery"""
diff --git a/workspace/src/autonomous/deployment/instant_execution_pipeline.py b/workspace/src/autonomous/deployment/instant_execution_pipeline.py
index 388b67d..25a6bd6 100644
--- a/workspace/src/autonomous/deployment/instant_execution_pipeline.py
+++ b/workspace/src/autonomous/deployment/instant_execution_pipeline.py
@@ -49,10 +49,9 @@ sys.path.insert(0, str(REPO_ROOT / "tests" / "automation"))
 
 # Import dependencies
 try:
+    from ai.governance_engine import AIGovernanceEngine, DecisionType, RiskLevel
     from baseline_validation_engine import BaselineValidationEngine
     from test_framework_patterns import TestSuiteRunner
-
-    from ai.governance_engine import AIGovernanceEngine, DecisionType, RiskLevel
 except ImportError as e:
     print(f"âš ï¸  Import warning: {e}")
     print("Some features may be limited")
@@ -141,7 +140,9 @@ class InstantExecutionPipeline:
             )
 
             # Validation Engine
-            self.validation_engine = BaselineValidationEngine(namespace=self.context.namespace)
+            self.validation_engine = BaselineValidationEngine(
+                namespace=self.context.namespace
+            )
 
             # Test Runner
             self.test_runner = TestSuiteRunner()
@@ -152,9 +153,13 @@ class InstantExecutionPipeline:
     def log(self, message: str, level: str = "INFO"):
         """Log message with timestamp"""
         timestamp = datetime.now().strftime("%H:%M:%S")
-        emoji = {"INFO": "â„¹ï¸", "SUCCESS": "âœ…", "ERROR": "âŒ", "WARNING": "âš ï¸", "PROGRESS": "ğŸ”„"}.get(
-            level, "ğŸ“"
-        )
+        emoji = {
+            "INFO": "â„¹ï¸",
+            "SUCCESS": "âœ…",
+            "ERROR": "âŒ",
+            "WARNING": "âš ï¸",
+            "PROGRESS": "ğŸ”„",
+        }.get(level, "ğŸ“")
 
         print(f"[{timestamp}] {emoji}  {message}")
 
@@ -191,7 +196,9 @@ class InstantExecutionPipeline:
             # 1. Codebase Scan
             self.log("Step 1/4: Codebase Deep Scan", level="PROGRESS")
             metrics = self.ai_engine.analyze_codebase(REPO_ROOT)
-            self.log(f"  âœ“ Analyzed {metrics.total_files} files ({metrics.total_lines} lines)")
+            self.log(
+                f"  âœ“ Analyzed {metrics.total_files} files ({metrics.total_lines} lines)"
+            )
             self.log(f"  âœ“ YAML: {metrics.yaml_files}, Python: {metrics.python_files}")
 
             # 2. Pattern Recognition
@@ -226,7 +233,9 @@ class InstantExecutionPipeline:
             self.log("")
             self.log(f"Decision: {decision.decision.value.upper()}", level="SUCCESS")
             self.log(f"Confidence: {decision.confidence:.1%}")
-            self.log(f"Risk Score: {decision.risk_score:.1f}/100 ({decision.risk_level.value})")
+            self.log(
+                f"Risk Score: {decision.risk_score:.1f}/100 ({decision.risk_level.value})"
+            )
             self.log(f"Duration: {duration:.2f}s")
 
             # Check if within time budget
@@ -235,7 +244,8 @@ class InstantExecutionPipeline:
 
             status = (
                 StageStatus.SUCCESS
-                if decision.decision in [DecisionType.APPROVE, DecisionType.CONDITIONAL_APPROVE]
+                if decision.decision
+                in [DecisionType.APPROVE, DecisionType.CONDITIONAL_APPROVE]
                 else StageStatus.FAILED
             )
 
@@ -290,19 +300,25 @@ class InstantExecutionPipeline:
             # 1. Run automated tests
             self.log("Step 1/3: Automated Testing", level="PROGRESS")
             test_results = self.test_runner.run_all_tests()
-            self.log(f"  âœ“ Tests: {test_results['passed']}/{test_results['total_tests']} passed")
+            self.log(
+                f"  âœ“ Tests: {test_results['passed']}/{test_results['total_tests']} passed"
+            )
 
             # 2. Configuration validation
             self.log("Step 2/3: Configuration Validation", level="PROGRESS")
             config_valid = self._validate_configurations()
-            self.log(f"  âœ“ Configuration validation: {'PASS' if config_valid else 'FAIL'}")
+            self.log(
+                f"  âœ“ Configuration validation: {'PASS' if config_valid else 'FAIL'}"
+            )
 
             # 3. Baseline validation (if cluster available)
             self.log("Step 3/3: Baseline Validation", level="PROGRESS")
             baseline_success = True
             try:
                 baseline_success = self.validation_engine.run_all_validations()
-                self.log(f"  âœ“ Baseline validation: {'PASS' if baseline_success else 'FAIL'}")
+                self.log(
+                    f"  âœ“ Baseline validation: {'PASS' if baseline_success else 'FAIL'}"
+                )
             except Exception as e:
                 self.log(f"  âš ï¸  Baseline validation skipped: {e}", level="WARNING")
 
@@ -360,7 +376,9 @@ class InstantExecutionPipeline:
         self.log("=" * 60)
         self.log("STAGE 3: Automated Deployment", level="INFO")
         self.log("=" * 60)
-        self.log(f"Target Duration: < {self.context.max_stage_duration[stage]/60:.0f}min")
+        self.log(
+            f"Target Duration: < {self.context.max_stage_duration[stage]/60:.0f}min"
+        )
         print()
 
         try:
@@ -389,7 +407,10 @@ class InstantExecutionPipeline:
                 deploy_success = result.returncode == 0
                 self.log(f"  âœ“ Deployment: {'SUCCESS' if deploy_success else 'FAILED'}")
             else:
-                self.log(f"  âš ï¸  Deployment script not found: {deploy_script}", level="WARNING")
+                self.log(
+                    f"  âš ï¸  Deployment script not found: {deploy_script}",
+                    level="WARNING",
+                )
                 deploy_success = False
 
             # 2. Health monitoring
@@ -405,7 +426,11 @@ class InstantExecutionPipeline:
 
             duration = time.time() - start_time
 
-            status = StageStatus.SUCCESS if deploy_success and verification else StageStatus.FAILED
+            status = (
+                StageStatus.SUCCESS
+                if deploy_success and verification
+                else StageStatus.FAILED
+            )
 
             self.log("")
             self.log(f"Deployment complete: {status.value.upper()}", level="SUCCESS")
@@ -451,7 +476,10 @@ class InstantExecutionPipeline:
         for pattern in yaml_patterns:
             for yaml_file in REPO_ROOT.rglob(pattern):
                 # Skip certain directories
-                if any(skip in yaml_file.parts for skip in [".git", "node_modules", ".venv"]):
+                if any(
+                    skip in yaml_file.parts
+                    for skip in [".git", "node_modules", ".venv"]
+                ):
                     continue
 
                 resources.append(
@@ -516,7 +544,10 @@ class InstantExecutionPipeline:
             result_2 = await self.run_stage_2_synthetic_validation()
             self.stage_results.append(result_2)
 
-            if result_2.status == StageStatus.FAILED and not self.context.skip_validation:
+            if (
+                result_2.status == StageStatus.FAILED
+                and not self.context.skip_validation
+            ):
                 self.log("âŒ Pipeline stopped: Stage 2 failed", level="ERROR")
                 return self._generate_summary()
 
@@ -560,7 +591,8 @@ class InstantExecutionPipeline:
                 for result in self.stage_results
             ],
             "success": all(
-                r.status in [StageStatus.SUCCESS, StageStatus.SKIPPED] for r in self.stage_results
+                r.status in [StageStatus.SUCCESS, StageStatus.SKIPPED]
+                for r in self.stage_results
             ),
         }
 
@@ -575,13 +607,18 @@ class InstantExecutionPipeline:
             f"  Total Duration: {summary['total_duration']:.2f}s ({summary['total_duration']/60:.1f}min)"
         )
         print(f"  Stages Executed: {summary['stages']}/3")
-        print(f"  Overall Status: {'âœ… SUCCESS' if summary['success'] else 'âŒ FAILED'}")
+        print(
+            f"  Overall Status: {'âœ… SUCCESS' if summary['success'] else 'âŒ FAILED'}"
+        )
         print()
 
         for result in summary["results"]:
-            emoji = {"success": "âœ…", "failed": "âŒ", "skipped": "â­ï¸", "pending": "â¸ï¸"}.get(
-                result["status"], "â“"
-            )
+            emoji = {
+                "success": "âœ…",
+                "failed": "âŒ",
+                "skipped": "â­ï¸",
+                "pending": "â¸ï¸",
+            }.get(result["status"], "â“")
             print(
                 f"  {emoji} Stage {result['stage']}: {result['status'].upper()} ({result['duration']:.2f}s)"
             )
@@ -598,17 +635,26 @@ async def main():
         formatter_class=argparse.RawDescriptionHelpFormatter,
     )
 
-    parser.add_argument("action", choices=["run", "validate", "stage"], help="Action to perform")
     parser.add_argument(
-        "--stage", type=int, choices=[1, 2, 3], help="Specific stage to run (for 'stage' action)"
+        "action", choices=["run", "validate", "stage"], help="Action to perform"
+    )
+    parser.add_argument(
+        "--stage",
+        type=int,
+        choices=[1, 2, 3],
+        help="Specific stage to run (for 'stage' action)",
     )
     parser.add_argument(
         "--namespace", default="machinenativenops-system", help="Kubernetes namespace"
     )
     parser.add_argument(
-        "--dry-run", action="store_true", help="Perform dry run without actual deployment"
+        "--dry-run",
+        action="store_true",
+        help="Perform dry run without actual deployment",
+    )
+    parser.add_argument(
+        "--skip-validation", action="store_true", help="Skip validation failures"
     )
-    parser.add_argument("--skip-validation", action="store_true", help="Skip validation failures")
     parser.add_argument("--output", help="Output file for results (JSON)")
 
     args = parser.parse_args()
diff --git a/workspace/src/autonomous/infrastructure/config/integrations/jira-integration.py b/workspace/src/autonomous/infrastructure/config/integrations/jira-integration.py
index b6f91f4..14dbb84 100755
--- a/workspace/src/autonomous/infrastructure/config/integrations/jira-integration.py
+++ b/workspace/src/autonomous/infrastructure/config/integrations/jira-integration.py
@@ -22,7 +22,10 @@ class JiraIntegration:
         # request debugging is disabled.
         self.auth = (username, api_token)
         self.project_key = project_key
-        self.headers = {"Content-Type": "application/json", "Accept": "application/json"}
+        self.headers = {
+            "Content-Type": "application/json",
+            "Accept": "application/json",
+        }
 
     def create_security_issue(
         self,
@@ -190,10 +193,15 @@ def main():
         sys.exit(1)
 
     # Get alert details from command line or environment
-    severity = os.getenv("ALERT_SEVERITY", sys.argv[1] if len(sys.argv) > 1 else "medium")
-    summary = os.getenv("ALERT_SUMMARY", sys.argv[2] if len(sys.argv) > 2 else "Security Alert")
+    severity = os.getenv(
+        "ALERT_SEVERITY", sys.argv[1] if len(sys.argv) > 1 else "medium"
+    )
+    summary = os.getenv(
+        "ALERT_SUMMARY", sys.argv[2] if len(sys.argv) > 2 else "Security Alert"
+    )
     description = os.getenv(
-        "ALERT_DESCRIPTION", sys.argv[3] if len(sys.argv) > 3 else "Security issue detected"
+        "ALERT_DESCRIPTION",
+        sys.argv[3] if len(sys.argv) > 3 else "Security issue detected",
     )
     alert_type = os.getenv("ALERT_TYPE", "Security Alert")
     repository = os.getenv("GITHUB_REPOSITORY", "unknown")
diff --git a/workspace/src/autonomous/infrastructure/testing-compatibility/test_compatibility.py b/workspace/src/autonomous/infrastructure/testing-compatibility/test_compatibility.py
index 3f67d48..4f5365b 100644
--- a/workspace/src/autonomous/infrastructure/testing-compatibility/test_compatibility.py
+++ b/workspace/src/autonomous/infrastructure/testing-compatibility/test_compatibility.py
@@ -65,7 +65,10 @@ compatibility_matrix:
     def test_imu_data_fusion(self):
         """æ¸¬è©¦ IMU è³‡æ–™èåˆ"""
         # æ¨¡æ“¬ IMU è³‡æ–™
-        imu_data = {"acceleration": [0.1, 0.2, 9.8], "angular_velocity": [0.01, 0.02, 0.03]}
+        imu_data = {
+            "acceleration": [0.1, 0.2, 9.8],
+            "angular_velocity": [0.01, 0.02, 0.03],
+        }
 
         # é©—è­‰èåˆçµæœ
         fused_state = self.fuse_imu_data(imu_data)
@@ -79,7 +82,9 @@ compatibility_matrix:
         current_altitude = 0.0
 
         # è¨ˆç®—æ§åˆ¶å‘½ä»¤
-        motor_commands = self.compute_altitude_control(target_altitude, current_altitude)
+        motor_commands = self.compute_altitude_control(
+            target_altitude, current_altitude
+        )
 
         self.assertEqual(len(motor_commands), 4)  # å››è»¸ç„¡äººæ©Ÿ
         self.assertTrue(all(0 <= cmd <= 1.0 for cmd in motor_commands))
diff --git a/workspace/src/bridges/language-islands/__init__.py b/workspace/src/bridges/language-islands/__init__.py
index b1f9b7c..4f7ed21 100644
--- a/workspace/src/bridges/language-islands/__init__.py
+++ b/workspace/src/bridges/language-islands/__init__.py
@@ -9,7 +9,9 @@ import sys
 from pathlib import Path
 
 
-def _import_kebab_module(module_alias: str, file_name: str, legacy_alias: str | None = None):
+def _import_kebab_module(
+    module_alias: str, file_name: str, legacy_alias: str | None = None
+):
     """
     Import a module from a kebab-case filename and register module aliases.
 
@@ -68,11 +70,15 @@ _rust_island = _import_kebab_module(
 )
 RustIsland = _rust_island.RustIsland
 
-_go_island = _import_kebab_module("go_island", "go-island.py", legacy_alias="islands.go_island")
+_go_island = _import_kebab_module(
+    "go_island", "go-island.py", legacy_alias="islands.go_island"
+)
 GoIsland = _go_island.GoIsland
 
 _typescript_island = _import_kebab_module(
-    "typescript_island", "typescript-island.py", legacy_alias="islands.typescript_island"
+    "typescript_island",
+    "typescript-island.py",
+    legacy_alias="islands.typescript_island",
 )
 TypeScriptIsland = _typescript_island.TypeScriptIsland
 
diff --git a/workspace/src/bridges/language-islands/base-island.py b/workspace/src/bridges/language-islands/base-island.py
index 60fadcd..0a916e1 100644
--- a/workspace/src/bridges/language-islands/base-island.py
+++ b/workspace/src/bridges/language-islands/base-island.py
@@ -102,7 +102,9 @@ class BaseIsland(ABC):
         try:
             import importlib
 
-            config_module = importlib.import_module("bridges.language-islands.config.island-config")
+            config_module = importlib.import_module(
+                "bridges.language-islands.config.island-config"
+            )
             IslandConfig = config_module.IslandConfig
             island_config = IslandConfig.load()
             self.config = island_config.get_island(self.island_id) or {}
@@ -122,7 +124,9 @@ class BaseIsland(ABC):
         """
         cmd, arg = self._get_language_check_command()
         try:
-            result = subprocess.run([cmd, arg], capture_output=True, text=True, timeout=5)
+            result = subprocess.run(
+                [cmd, arg], capture_output=True, text=True, timeout=5
+            )
             if result.returncode == 0:
                 version = result.stdout.strip().split("\n")[0]
                 return True, version
@@ -183,7 +187,9 @@ class BaseIsland(ABC):
             "island_id": self.island_id,
             "language": self.language,
             "status": self.status,
-            "activated_at": self.activated_at.isoformat() if self.activated_at else None,
+            "activated_at": (
+                self.activated_at.isoformat() if self.activated_at else None
+            ),
             "capabilities": self.capabilities,
             "tool_available": available,
             "tool_version": version,
@@ -191,4 +197,6 @@ class BaseIsland(ABC):
         }
 
     def __repr__(self) -> str:
-        return f"<{self.__class__.__name__}(name='{self.name}', status='{self.status}')>"
+        return (
+            f"<{self.__class__.__name__}(name='{self.name}', status='{self.status}')>"
+        )
diff --git a/workspace/src/bridges/language-islands/config/island-config.py b/workspace/src/bridges/language-islands/config/island-config.py
index 28a5f82..a2851a2 100644
--- a/workspace/src/bridges/language-islands/config/island-config.py
+++ b/workspace/src/bridges/language-islands/config/island-config.py
@@ -82,25 +82,41 @@ class IslandConfig:
                     "name": "Rust æ€§èƒ½æ ¸å¿ƒå³¶",
                     "enabled": True,
                     "priority": 1,
-                    "capabilities": ["performance_monitor", "security_guardian", "data_pipeline"],
+                    "capabilities": [
+                        "performance_monitor",
+                        "security_guardian",
+                        "data_pipeline",
+                    ],
                 },
                 "go": {
                     "name": "Go é›²åŸç”Ÿæœå‹™å³¶",
                     "enabled": True,
                     "priority": 2,
-                    "capabilities": ["api_gateway", "microservice_mesh", "container_manager"],
+                    "capabilities": [
+                        "api_gateway",
+                        "microservice_mesh",
+                        "container_manager",
+                    ],
                 },
                 "typescript": {
                     "name": "TypeScript å…¨æ£§é–‹ç™¼å³¶",
                     "enabled": True,
                     "priority": 3,
-                    "capabilities": ["web_dashboard", "api_client_generator", "real_time_monitor"],
+                    "capabilities": [
+                        "web_dashboard",
+                        "api_client_generator",
+                        "real_time_monitor",
+                    ],
                 },
                 "python": {
                     "name": "Python AI æ•¸æ“šå³¶",
                     "enabled": True,
                     "priority": 4,
-                    "capabilities": ["ai_code_assistant", "data_analysis", "ml_pipeline"],
+                    "capabilities": [
+                        "ai_code_assistant",
+                        "data_analysis",
+                        "ml_pipeline",
+                    ],
                 },
                 "java": {
                     "name": "Java ä¼æ¥­æœå‹™å³¶",
@@ -160,5 +176,7 @@ class IslandConfig:
     def get_enabled_islands(self) -> list[str]:
         """å–å¾—æ‰€æœ‰å•Ÿç”¨çš„å³¶å¶¼"""
         return [
-            island_id for island_id, config in self.islands.items() if config.get("enabled", True)
+            island_id
+            for island_id, config in self.islands.items()
+            if config.get("enabled", True)
         ]
diff --git a/workspace/src/bridges/language-islands/java-island.py b/workspace/src/bridges/language-islands/java-island.py
index 3a07ff2..aec53a5 100644
--- a/workspace/src/bridges/language-islands/java-island.py
+++ b/workspace/src/bridges/language-islands/java-island.py
@@ -103,7 +103,11 @@ class JavaIsland(BaseIsland):
         for tool_name, cmd in tool_commands:
             try:
                 result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
-                version = result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+                version = (
+                    result.stdout.strip().split("\n")[0]
+                    if result.returncode == 0
+                    else None
+                )
                 tools[tool_name] = {
                     "available": result.returncode == 0,
                     "version": version,
diff --git a/workspace/src/bridges/language-islands/python-island.py b/workspace/src/bridges/language-islands/python-island.py
index 3b552d1..e4f73ad 100644
--- a/workspace/src/bridges/language-islands/python-island.py
+++ b/workspace/src/bridges/language-islands/python-island.py
@@ -33,7 +33,9 @@ class PythonIsland(BaseIsland):
     """
 
     def __init__(self) -> None:
-        super().__init__(name="ğŸ Python AI æ•¸æ“šå³¶", island_id="python", language="python")
+        super().__init__(
+            name="ğŸ Python AI æ•¸æ“šå³¶", island_id="python", language="python"
+        )
         self.capabilities = [
             "ai_code_assistant",
             "data_analysis",
@@ -151,7 +153,9 @@ class PythonIsland(BaseIsland):
         self.log_info("åŸ·è¡Œ v1-python-drones ç³»çµ±...")
 
         try:
-            result = subprocess.run(["python3", str(v1_main), "--mode=auto"], cwd=self.project_root)
+            result = subprocess.run(
+                ["python3", str(v1_main), "--mode=auto"], cwd=self.project_root
+            )
             return result.returncode
         except Exception as e:
             self.log_error(f"åŸ·è¡Œå¤±æ•—: {e}")
diff --git a/workspace/src/bridges/language-islands/typescript-island.py b/workspace/src/bridges/language-islands/typescript-island.py
index 9bca793..3bb01c2 100644
--- a/workspace/src/bridges/language-islands/typescript-island.py
+++ b/workspace/src/bridges/language-islands/typescript-island.py
@@ -33,7 +33,9 @@ class TypeScriptIsland(BaseIsland):
 
     def __init__(self) -> None:
         super().__init__(
-            name="âš¡ TypeScript å…¨æ£§é–‹ç™¼å³¶", island_id="typescript", language="typescript"
+            name="âš¡ TypeScript å…¨æ£§é–‹ç™¼å³¶",
+            island_id="typescript",
+            language="typescript",
         )
         self.capabilities = [
             "web_dashboard",
@@ -92,7 +94,9 @@ class TypeScriptIsland(BaseIsland):
     def _check_node(self) -> bool:
         """æª¢æŸ¥ Node.js"""
         try:
-            result = subprocess.run(["node", "--version"], capture_output=True, timeout=5)
+            result = subprocess.run(
+                ["node", "--version"], capture_output=True, timeout=5
+            )
             return result.returncode == 0
         except (FileNotFoundError, subprocess.TimeoutExpired):
             return False
@@ -114,7 +118,9 @@ class TypeScriptIsland(BaseIsland):
                 tools[tool_name] = {
                     "available": result.returncode == 0,
                     "version": (
-                        result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+                        result.stdout.strip().split("\n")[0]
+                        if result.returncode == 0
+                        else None
                     ),
                 }
             except (FileNotFoundError, subprocess.TimeoutExpired):
@@ -144,5 +150,9 @@ class TypeScriptIsland(BaseIsland):
             print(f"    {status} {tool}: {version}")
 
         print("\n  å°ˆæ¡ˆ:")
-        print(f"    package.json: {'âœ…' if result['project_info']['has_package_json'] else 'âŒ'}")
-        print(f"    tsconfig.json: {'âœ…' if result['project_info']['has_tsconfig'] else 'âŒ'}")
+        print(
+            f"    package.json: {'âœ…' if result['project_info']['has_package_json'] else 'âŒ'}"
+        )
+        print(
+            f"    tsconfig.json: {'âœ…' if result['project_info']['has_tsconfig'] else 'âŒ'}"
+        )
diff --git a/workspace/src/bridges/language_bridges.py b/workspace/src/bridges/language_bridges.py
index a20c360..6ed6a19 100644
--- a/workspace/src/bridges/language_bridges.py
+++ b/workspace/src/bridges/language_bridges.py
@@ -270,7 +270,10 @@ class LanguageBridgeManager:
         return connection_id
 
     async def execute_cross_language(
-        self, connection_id: str, code_fragment: CodeFragment, timeout_seconds: float = 30.0
+        self,
+        connection_id: str,
+        code_fragment: CodeFragment,
+        timeout_seconds: float = 30.0,
     ) -> ExecutionResult:
         """
         Execute code across language boundary
@@ -306,12 +309,16 @@ class LanguageBridgeManager:
         try:
             # Convert types if needed
             converted_params = self._convert_types(
-                code_fragment.parameters, code_fragment.language, connection.target.language
+                code_fragment.parameters,
+                code_fragment.language,
+                connection.target.language,
             )
 
             # Simulate execution (in real implementation, would call actual
             # bridge)
-            output = await self._simulate_execution(code_fragment, connection.target.language)
+            output = await self._simulate_execution(
+                code_fragment, connection.target.language
+            )
 
             execution_time = (datetime.now() - start_time).total_seconds() * 1000
 
@@ -385,7 +392,9 @@ class LanguageBridgeManager:
             "bridge_type": connection.bridge_type.value,
             "status": connection.status.value,
             "established_at": (
-                connection.established_at.isoformat() if connection.established_at else None
+                connection.established_at.isoformat()
+                if connection.established_at
+                else None
             ),
             "metrics": connection.metrics,
         }
@@ -417,7 +426,9 @@ class LanguageBridgeManager:
             "executions_total": self.stats["executions_total"],
             "executions_successful": self.stats["executions_successful"],
             "success_rate": round(
-                self.stats["executions_successful"] / max(self.stats["executions_total"], 1) * 100,
+                self.stats["executions_successful"]
+                / max(self.stats["executions_total"], 1)
+                * 100,
                 2,
             ),
             "supported_languages": [lang.value for lang in Language],
diff --git a/workspace/src/business/__init__.py b/workspace/src/business/__init__.py
index a637215..dbf40a1 100644
--- a/workspace/src/business/__init__.py
+++ b/workspace/src/business/__init__.py
@@ -9,4 +9,9 @@ from .services import BusinessServiceManager
 from .workflows import BusinessWorkflowEngine
 
 __version__ = "1.0.0"
-__all__ = ["BusinessServiceManager", "BusinessWorkflowEngine", "BusinessModels", "BusinessAPI"]
+__all__ = [
+    "BusinessServiceManager",
+    "BusinessWorkflowEngine",
+    "BusinessModels",
+    "BusinessAPI",
+]
diff --git a/workspace/src/business/api.py b/workspace/src/business/api.py
index 6568b7c..4c97204 100644
--- a/workspace/src/business/api.py
+++ b/workspace/src/business/api.py
@@ -141,11 +141,15 @@ class BusinessAPI:
 
         @self.app.put("/api/v1/projects/{project_id}", response_model=Project)
         async def update_project(
-            project_id: str, updates: Dict[str, Any], user_id: str = Depends(get_current_user)
+            project_id: str,
+            updates: Dict[str, Any],
+            user_id: str = Depends(get_current_user),
         ):
             """æ›´æ–°é …ç›®"""
             try:
-                project = await self.business_service.update_project(project_id, updates)
+                project = await self.business_service.update_project(
+                    project_id, updates
+                )
                 if not project:
                     raise HTTPException(status_code=404, detail="Project not found")
                 return project
@@ -153,7 +157,9 @@ class BusinessAPI:
                 raise HTTPException(status_code=500, detail=str(e))
 
         @self.app.delete("/api/v1/projects/{project_id}")
-        async def delete_project(project_id: str, user_id: str = Depends(get_current_user)):
+        async def delete_project(
+            project_id: str, user_id: str = Depends(get_current_user)
+        ):
             """åˆªé™¤é …ç›®"""
             try:
                 success = await self.business_service.delete_project(project_id)
@@ -199,7 +205,9 @@ class BusinessAPI:
 
         # ä»»å‹™ç®¡ç† API
         @self.app.post("/api/v1/tasks", response_model=Task)
-        async def create_task(request: CreateTaskRequest, user_id: str = Depends(get_current_user)):
+        async def create_task(
+            request: CreateTaskRequest, user_id: str = Depends(get_current_user)
+        ):
             """å‰µå»ºä»»å‹™"""
             try:
                 return await self.business_service.create_task(request)
@@ -218,7 +226,9 @@ class BusinessAPI:
 
         @self.app.put("/api/v1/tasks/{task_id}", response_model=Task)
         async def update_task(
-            task_id: str, request: UpdateTaskRequest, user_id: str = Depends(get_current_user)
+            task_id: str,
+            request: UpdateTaskRequest,
+            user_id: str = Depends(get_current_user),
         ):
             """æ›´æ–°ä»»å‹™"""
             try:
@@ -268,7 +278,9 @@ class BusinessAPI:
                 all_tasks = await self.business_service.list_tasks(total_query)
                 total = len(all_tasks)
 
-                return TaskListResponse(tasks=tasks, total=total, page=page, page_size=page_size)
+                return TaskListResponse(
+                    tasks=tasks, total=total, page=page, page_size=page_size
+                )
             except Exception as e:
                 raise HTTPException(status_code=500, detail=str(e))
 
@@ -301,7 +313,9 @@ class BusinessAPI:
         ):
             """åŸ·è¡Œä»»å‹™å¯©æ‰¹å·¥ä½œæµ"""
             try:
-                result = await self.workflow_engine.execute_task_approval_workflow(task_id)
+                result = await self.workflow_engine.execute_task_approval_workflow(
+                    task_id
+                )
                 return result
             except ValueError as e:
                 raise HTTPException(status_code=404, detail=str(e))
@@ -316,8 +330,10 @@ class BusinessAPI:
         ):
             """åŸ·è¡Œè³‡æºåˆ†é…å·¥ä½œæµ"""
             try:
-                result = await self.workflow_engine.execute_resource_allocation_workflow(
-                    project_id, resource_requirements
+                result = (
+                    await self.workflow_engine.execute_resource_allocation_workflow(
+                        project_id, resource_requirements
+                    )
                 )
                 return result
             except ValueError as e:
@@ -331,7 +347,9 @@ class BusinessAPI:
         ):
             """åŸ·è¡Œè³ªé‡æª¢æŸ¥å·¥ä½œæµ"""
             try:
-                result = await self.workflow_engine.execute_quality_check_workflow(task_id)
+                result = await self.workflow_engine.execute_quality_check_workflow(
+                    task_id
+                )
                 return result
             except ValueError as e:
                 raise HTTPException(status_code=404, detail=str(e))
@@ -353,7 +371,9 @@ class BusinessAPI:
         async def list_workflow_executions(workflow_id: Optional[str] = Query(None)):
             """åˆ—å‡ºå·¥ä½œæµåŸ·è¡Œ"""
             try:
-                executions = await self.workflow_engine.list_workflow_executions(workflow_id)
+                executions = await self.workflow_engine.list_workflow_executions(
+                    workflow_id
+                )
                 return executions
             except Exception as e:
                 raise HTTPException(status_code=500, detail=str(e))
@@ -364,7 +384,9 @@ class BusinessAPI:
         ):
             """å–æ¶ˆå·¥ä½œæµåŸ·è¡Œ"""
             try:
-                success = await self.workflow_engine.cancel_workflow_execution(execution_id)
+                success = await self.workflow_engine.cancel_workflow_execution(
+                    execution_id
+                )
                 if not success:
                     raise HTTPException(status_code=404, detail="Execution not found")
                 return {"message": "Execution cancelled successfully"}
@@ -377,7 +399,9 @@ class BusinessAPI:
         ):
             """é‡è©¦å·¥ä½œæµåŸ·è¡Œ"""
             try:
-                result = await self.workflow_engine.retry_workflow_execution(execution_id)
+                result = await self.workflow_engine.retry_workflow_execution(
+                    execution_id
+                )
                 if not result:
                     raise HTTPException(status_code=404, detail="Execution not found")
                 return result
diff --git a/workspace/src/business/models.py b/workspace/src/business/models.py
index d087d60..fbe20cb 100644
--- a/workspace/src/business/models.py
+++ b/workspace/src/business/models.py
@@ -118,7 +118,9 @@ class BusinessMetrics(BaseModel):
     completed_projects: int = Field(0, description="å·²å®Œæˆé …ç›®æ•¸")
     total_tasks: int = Field(0, description="ä»»å‹™ç¸½æ•¸")
     completed_tasks: int = Field(0, description="å·²å®Œæˆä»»å‹™æ•¸")
-    average_completion_time: Optional[float] = Field(None, description="å¹³å‡å®Œæˆæ™‚é–“ï¼ˆå°æ™‚ï¼‰")
+    average_completion_time: Optional[float] = Field(
+        None, description="å¹³å‡å®Œæˆæ™‚é–“ï¼ˆå°æ™‚ï¼‰"
+    )
     resource_utilization: float = Field(0.0, ge=0, le=1, description="è³‡æºåˆ©ç”¨ç‡")
     cost_efficiency: Optional[float] = Field(None, description="æˆæœ¬æ•ˆç‡")
     quality_score: float = Field(0.0, ge=0, le=100, description="è³ªé‡åˆ†æ•¸")
@@ -185,7 +187,9 @@ class CreateTaskRequest(BaseModel):
 class UpdateTaskRequest(BaseModel):
     """æ›´æ–°ä»»å‹™è«‹æ±‚"""
 
-    name: Optional[str] = Field(None, min_length=1, max_length=100, description="ä»»å‹™åç¨±")
+    name: Optional[str] = Field(
+        None, min_length=1, max_length=100, description="ä»»å‹™åç¨±"
+    )
     description: Optional[str] = Field(None, max_length=500, description="ä»»å‹™æè¿°")
     assignee: Optional[str] = Field(None, description="åŸ·è¡Œäºº")
     status: Optional[BusinessStatus] = Field(None, description="ä»»å‹™ç‹€æ…‹")
diff --git a/workspace/src/business/services.py b/workspace/src/business/services.py
index ce4ad1a..213599a 100644
--- a/workspace/src/business/services.py
+++ b/workspace/src/business/services.py
@@ -142,7 +142,9 @@ class BusinessServiceManager:
         """ç²å–é …ç›®"""
         return self.projects.get(project_id)
 
-    async def update_project(self, project_id: str, updates: Dict[str, Any]) -> Optional[Project]:
+    async def update_project(
+        self, project_id: str, updates: Dict[str, Any]
+    ) -> Optional[Project]:
         """æ›´æ–°é …ç›®"""
         if project_id not in self.projects:
             return None
@@ -248,7 +250,9 @@ class BusinessServiceManager:
         """ç²å–ä»»å‹™"""
         return self.tasks.get(task_id)
 
-    async def update_task(self, task_id: str, request: UpdateTaskRequest) -> Optional[Task]:
+    async def update_task(
+        self, task_id: str, request: UpdateTaskRequest
+    ) -> Optional[Task]:
         """æ›´æ–°ä»»å‹™"""
         if task_id not in self.tasks:
             return None
@@ -332,7 +336,9 @@ class BusinessServiceManager:
             Priority.MEDIUM: 2,
             Priority.LOW: 3,
         }
-        tasks.sort(key=lambda x: (priority_order[x.priority], x.created_at), reverse=True)
+        tasks.sort(
+            key=lambda x: (priority_order[x.priority], x.created_at), reverse=True
+        )
 
         # åˆ†é 
         start = (query.page - 1) * query.page_size
@@ -350,7 +356,11 @@ class BusinessServiceManager:
 
     # å·¥ä½œæµç®¡ç†
     async def execute_workflow(
-        self, workflow_id: str, name: str, triggered_by: str, parameters: Dict[str, Any] = None
+        self,
+        workflow_id: str,
+        name: str,
+        triggered_by: str,
+        parameters: Dict[str, Any] = None,
     ) -> WorkflowExecution:
         """åŸ·è¡Œå·¥ä½œæµ"""
         execution = WorkflowExecution(
@@ -375,7 +385,9 @@ class BusinessServiceManager:
 
         return execution
 
-    async def get_workflow_execution(self, execution_id: str) -> Optional[WorkflowExecution]:
+    async def get_workflow_execution(
+        self, execution_id: str
+    ) -> Optional[WorkflowExecution]:
         """ç²å–å·¥ä½œæµåŸ·è¡Œ"""
         return self.workflows.get(execution_id)
 
@@ -387,12 +399,18 @@ class BusinessServiceManager:
 
         # è¨ˆç®—é …ç›®æŒ‡æ¨™
         total_projects = len(projects)
-        active_projects = len([p for p in projects if p.status == BusinessStatus.ACTIVE])
-        completed_projects = len([p for p in projects if p.status == BusinessStatus.COMPLETED])
+        active_projects = len(
+            [p for p in projects if p.status == BusinessStatus.ACTIVE]
+        )
+        completed_projects = len(
+            [p for p in projects if p.status == BusinessStatus.COMPLETED]
+        )
 
         # è¨ˆç®—ä»»å‹™æŒ‡æ¨™
         total_tasks = len(tasks)
-        completed_tasks = len([t for t in tasks if t.status == BusinessStatus.COMPLETED])
+        completed_tasks = len(
+            [t for t in tasks if t.status == BusinessStatus.COMPLETED]
+        )
 
         # è¨ˆç®—å¹³å‡å®Œæˆæ™‚é–“
         completed_tasks_with_time = [
@@ -413,7 +431,9 @@ class BusinessServiceManager:
 
         # è¨ˆç®—è³‡æºåˆ©ç”¨ç‡ï¼ˆç°¡åŒ–è¨ˆç®—ï¼‰
         active_tasks = [t for t in tasks if t.status == BusinessStatus.ACTIVE]
-        resource_utilization = min(len(active_tasks) / 10.0, 1.0)  # å‡è¨­æœ€å¤§å®¹é‡10å€‹ä»»å‹™
+        resource_utilization = min(
+            len(active_tasks) / 10.0, 1.0
+        )  # å‡è¨­æœ€å¤§å®¹é‡10å€‹ä»»å‹™
 
         # è¨ˆç®—è³ªé‡åˆ†æ•¸ï¼ˆåŸºæ–¼å®Œæˆç‡ï¼‰
         quality_score = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
diff --git a/workspace/src/business/workflows.py b/workspace/src/business/workflows.py
index c6b46b4..94741bd 100644
--- a/workspace/src/business/workflows.py
+++ b/workspace/src/business/workflows.py
@@ -79,10 +79,14 @@ class BusinessWorkflowEngine:
                 config={"type": "validation", "target": "project"},
             ),
             WorkflowTask(
-                id="allocate_resources", name="åˆ†é…è³‡æº", config={"type": "resource_allocation"}
+                id="allocate_resources",
+                name="åˆ†é…è³‡æº",
+                config={"type": "resource_allocation"},
             ),
             WorkflowTask(
-                id="setup_monitoring", name="è¨­ç½®ç›£æ§", config={"type": "monitoring_setup"}
+                id="setup_monitoring",
+                name="è¨­ç½®ç›£æ§",
+                config={"type": "monitoring_setup"},
             ),
             WorkflowTask(
                 id="notify_stakeholders",
@@ -94,10 +98,16 @@ class BusinessWorkflowEngine:
         # ä»»å‹™å¯©æ‰¹å·¥ä½œæµ
         task_approval_workflow = [
             WorkflowTask(
-                id="validate_dependencies", name="é©—è­‰ä¾è³´", config={"type": "dependency_check"}
+                id="validate_dependencies",
+                name="é©—è­‰ä¾è³´",
+                config={"type": "dependency_check"},
+            ),
+            WorkflowTask(
+                id="check_resources", name="æª¢æŸ¥è³‡æº", config={"type": "resource_check"}
+            ),
+            WorkflowTask(
+                id="security_review", name="å®‰å…¨å¯©æ ¸", config={"type": "security_check"}
             ),
-            WorkflowTask(id="check_resources", name="æª¢æŸ¥è³‡æº", config={"type": "resource_check"}),
-            WorkflowTask(id="security_review", name="å®‰å…¨å¯©æ ¸", config={"type": "security_check"}),
             WorkflowTask(
                 id="approve_task",
                 name="å¯©æ‰¹ä»»å‹™",
@@ -113,23 +123,35 @@ class BusinessWorkflowEngine:
                 config={"type": "requirements_assessment"},
             ),
             WorkflowTask(
-                id="check_availability", name="æª¢æŸ¥å¯ç”¨æ€§", config={"type": "availability_check"}
+                id="check_availability",
+                name="æª¢æŸ¥å¯ç”¨æ€§",
+                config={"type": "availability_check"},
             ),
             WorkflowTask(id="allocate", name="åˆ†é…è³‡æº", config={"type": "allocation"}),
             WorkflowTask(
-                id="update_inventory", name="æ›´æ–°åº«å­˜", config={"type": "inventory_update"}
+                id="update_inventory",
+                name="æ›´æ–°åº«å­˜",
+                config={"type": "inventory_update"},
             ),
         ]
 
         # è³ªé‡æª¢æŸ¥å·¥ä½œæµ
         quality_workflow = [
-            WorkflowTask(id="code_analysis", name="ä»£ç¢¼åˆ†æ", config={"type": "static_analysis"}),
-            WorkflowTask(id="security_scan", name="å®‰å…¨æƒæ", config={"type": "security_scan"}),
             WorkflowTask(
-                id="performance_test", name="æ€§èƒ½æ¸¬è©¦", config={"type": "performance_test"}
+                id="code_analysis", name="ä»£ç¢¼åˆ†æ", config={"type": "static_analysis"}
+            ),
+            WorkflowTask(
+                id="security_scan", name="å®‰å…¨æƒæ", config={"type": "security_scan"}
+            ),
+            WorkflowTask(
+                id="performance_test",
+                name="æ€§èƒ½æ¸¬è©¦",
+                config={"type": "performance_test"},
             ),
             WorkflowTask(
-                id="generate_report", name="ç”Ÿæˆå ±å‘Š", config={"type": "report_generation"}
+                id="generate_report",
+                name="ç”Ÿæˆå ±å‘Š",
+                config={"type": "report_generation"},
             ),
         ]
 
@@ -213,9 +235,13 @@ class BusinessWorkflowEngine:
 
         # æ›´æ–°ä»»å‹™ç‹€æ…‹
         if execution.status == BusinessStatus.COMPLETED:
-            await self.business_service.update_task(task_id, {"status": BusinessStatus.ACTIVE})
+            await self.business_service.update_task(
+                task_id, {"status": BusinessStatus.ACTIVE}
+            )
         elif execution.status == BusinessStatus.FAILED:
-            await self.business_service.update_task(task_id, {"status": BusinessStatus.CANCELLED})
+            await self.business_service.update_task(
+                task_id, {"status": BusinessStatus.CANCELLED}
+            )
 
         return {
             "execution_id": execution.id,
@@ -310,13 +336,17 @@ class BusinessWorkflowEngine:
 
         for task_config in tasks:
             workflow_task = WorkflowTask(
-                id=task_config["id"], name=task_config["name"], config=task_config.get("config", {})
+                id=task_config["id"],
+                name=task_config["name"],
+                config=task_config.get("config", {}),
             )
             workflow_tasks.append(workflow_task)
 
         workflow_id = f"custom_{name.lower().replace(' ', '_')}"
 
-        await self.workflow_engine.create_workflow(workflow_id, description, workflow_tasks)
+        await self.workflow_engine.create_workflow(
+            workflow_id, description, workflow_tasks
+        )
 
         self.custom_workflows[workflow_id] = workflow_tasks
 
@@ -355,7 +385,9 @@ class BusinessWorkflowEngine:
             "status": execution.status,
             "progress": execution.progress,
             "started_at": execution.started_at.isoformat(),
-            "completed_at": execution.completed_at.isoformat() if execution.completed_at else None,
+            "completed_at": (
+                execution.completed_at.isoformat() if execution.completed_at else None
+            ),
             "results": execution.results,
             "error_message": execution.error_message,
         }
@@ -377,7 +409,9 @@ class BusinessWorkflowEngine:
                         "progress": execution.progress,
                         "started_at": execution.started_at.isoformat(),
                         "completed_at": (
-                            execution.completed_at.isoformat() if execution.completed_at else None
+                            execution.completed_at.isoformat()
+                            if execution.completed_at
+                            else None
                         ),
                     }
                 )
@@ -406,7 +440,9 @@ class BusinessWorkflowEngine:
 
         return True
 
-    async def retry_workflow_execution(self, execution_id: str) -> Optional[Dict[str, Any]]:
+    async def retry_workflow_execution(
+        self, execution_id: str
+    ) -> Optional[Dict[str, Any]]:
         """é‡è©¦å·¥ä½œæµåŸ·è¡Œ"""
         execution = await self.business_service.get_workflow_execution(execution_id)
         if not execution:
diff --git a/workspace/src/ci-tools/config-manager/config_manager.py b/workspace/src/ci-tools/config-manager/config_manager.py
index b03f735..6cd74f6 100644
--- a/workspace/src/ci-tools/config-manager/config_manager.py
+++ b/workspace/src/ci-tools/config-manager/config_manager.py
@@ -87,7 +87,9 @@ class CIConfigManager:
 
         if not logger.handlers:
             handler = logging.StreamHandler()
-            formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
+            formatter = logging.Formatter(
+                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+            )
             handler.setFormatter(formatter)
             logger.addHandler(handler)
 
@@ -289,7 +291,9 @@ TRACE_ENABLED={{ trace_enabled }}
             "required": ["name", "on", "jobs"],
             "properties": {
                 "name": {"type": "string"},
-                "on": {"anyOf": [{"type": "string"}, {"type": "object"}, {"type": "array"}]},
+                "on": {
+                    "anyOf": [{"type": "string"}, {"type": "object"}, {"type": "array"}]
+                },
                 "env": {"type": "object"},
                 "jobs": {
                     "type": "object",
@@ -298,8 +302,12 @@ TRACE_ENABLED={{ trace_enabled }}
                             "type": "object",
                             "required": ["runs-on"],
                             "properties": {
-                                "runs-on": {"anyOf": [{"type": "string"}, {"type": "array"}]},
-                                "needs": {"anyOf": [{"type": "string"}, {"type": "array"}]},
+                                "runs-on": {
+                                    "anyOf": [{"type": "string"}, {"type": "array"}]
+                                },
+                                "needs": {
+                                    "anyOf": [{"type": "string"}, {"type": "array"}]
+                                },
                                 "steps": {
                                     "type": "array",
                                     "items": {
@@ -338,7 +346,10 @@ TRACE_ENABLED={{ trace_enabled }}
                 "metadata": {
                     "type": "object",
                     "required": ["name"],
-                    "properties": {"name": {"type": "string"}, "namespace": {"type": "string"}},
+                    "properties": {
+                        "name": {"type": "string"},
+                        "namespace": {"type": "string"},
+                    },
                 },
                 "spec": {
                     "type": "object",
@@ -367,9 +378,13 @@ TRACE_ENABLED={{ trace_enabled }}
                                                         "type": "array",
                                                         "items": {
                                                             "type": "object",
-                                                            "required": ["containerPort"],
+                                                            "required": [
+                                                                "containerPort"
+                                                            ],
                                                             "properties": {
-                                                                "containerPort": {"type": "integer"}
+                                                                "containerPort": {
+                                                                    "type": "integer"
+                                                                }
                                                             },
                                                         },
                                                     },
@@ -393,7 +408,11 @@ TRACE_ENABLED={{ trace_enabled }}
         )
 
     def create_config_from_template(
-        self, template_name: str, variables: Dict[str, Any], config_name: str, description: str = ""
+        self,
+        template_name: str,
+        variables: Dict[str, Any],
+        config_name: str,
+        description: str = "",
     ) -> CIConfig:
         """å¾æ¨¡æ¿å‰µå»ºé…ç½®"""
 
@@ -501,14 +520,19 @@ TRACE_ENABLED={{ trace_enabled }}
 
         try:
             # æ ¹æ“šé…ç½®é¡å‹ä¿å­˜æ ¼å¼
-            if config.config_type == ConfigType.ENVIRONMENT and "raw_content" in config.content:
+            if (
+                config.config_type == ConfigType.ENVIRONMENT
+                and "raw_content" in config.content
+            ):
                 # ç’°å¢ƒè®Šæ•¸é…ç½®ç›´æ¥ä¿å­˜åŸå§‹å…§å®¹
                 with open(file_path, "w", encoding="utf-8") as f:
                     f.write(config.content["raw_content"])
             else:
                 # å…¶ä»–é…ç½®ä½¿ç”¨ YAML æ ¼å¼
                 with open(file_path, "w", encoding="utf-8") as f:
-                    yaml.dump(config.content, f, default_flow_style=False, allow_unicode=True)
+                    yaml.dump(
+                        config.content, f, default_flow_style=False, allow_unicode=True
+                    )
 
             # æ›´æ–°é…ç½®æ–‡ä»¶è·¯å¾‘
             config.file_path = str(file_path)
@@ -556,7 +580,10 @@ TRACE_ENABLED={{ trace_enabled }}
                 version="1.0.0",
                 description=f"å¾æ–‡ä»¶è¼‰å…¥: {file_path}",
                 content=parsed_content,
-                metadata={"source_file": str(file_path), "loaded_at": datetime.now().isoformat()},
+                metadata={
+                    "source_file": str(file_path),
+                    "loaded_at": datetime.now().isoformat(),
+                },
                 created_at=datetime.now(),
                 updated_at=datetime.now(),
                 file_path=str(file_path),
@@ -666,7 +693,9 @@ TRACE_ENABLED={{ trace_enabled }}
 
         return True
 
-    def export_configs(self, output_dir: str, config_type: ConfigType = None) -> List[str]:
+    def export_configs(
+        self, output_dir: str, config_type: ConfigType = None
+    ) -> List[str]:
         """å°å‡ºé…ç½®åˆ°æŒ‡å®šç›®éŒ„"""
 
         output_dir = Path(output_dir)
@@ -681,7 +710,9 @@ TRACE_ENABLED={{ trace_enabled }}
 
             try:
                 with open(file_path, "w", encoding="utf-8") as f:
-                    yaml.dump(config.content, f, default_flow_style=False, allow_unicode=True)
+                    yaml.dump(
+                        config.content, f, default_flow_style=False, allow_unicode=True
+                    )
 
                 exported_files.append(str(file_path))
 
diff --git a/workspace/src/ci-tools/deployment-rollback/rollback_manager.py b/workspace/src/ci-tools/deployment-rollback/rollback_manager.py
index 938d07a..b21c827 100644
--- a/workspace/src/ci-tools/deployment-rollback/rollback_manager.py
+++ b/workspace/src/ci-tools/deployment-rollback/rollback_manager.py
@@ -130,7 +130,10 @@ class RollbackManager:
                 "namespace": "default",
                 "timeout": 300,
             },
-            "docker": {"registry": os.getenv("DOCKER_REGISTRY", "docker.io"), "timeout": 180},
+            "docker": {
+                "registry": os.getenv("DOCKER_REGISTRY", "docker.io"),
+                "timeout": 180,
+            },
             "rollback": {
                 "default_timeout": 300,
                 "health_check_interval": 10,
@@ -158,7 +161,9 @@ class RollbackManager:
 
         if not logger.handlers:
             handler = logging.StreamHandler()
-            formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
+            formatter = logging.Formatter(
+                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+            )
             handler.setFormatter(formatter)
             logger.addHandler(handler)
 
@@ -196,7 +201,9 @@ class RollbackManager:
         self.logger.info(f"å‰µå»ºéƒ¨ç½²å¿«ç…§: {deployment_id}")
 
         # æ”¶é›†é…ç½®æ•¸æ“š
-        config_data = self._collect_deployment_config(platform, environment, service_name)
+        config_data = self._collect_deployment_config(
+            platform, environment, service_name
+        )
 
         # æ”¶é›†å¥åº·æª¢æŸ¥é…ç½®
         health_checks = self._collect_health_checks(platform, service_name)
@@ -267,7 +274,9 @@ class RollbackManager:
                     break
 
             # ç²å– Service é…ç½®
-            services = v1.list_namespaced_service(namespace=self.config["kubernetes"]["namespace"])
+            services = v1.list_namespaced_service(
+                namespace=self.config["kubernetes"]["namespace"]
+            )
 
             for service in services.items:
                 if service_name in service.metadata.name:
@@ -321,13 +330,20 @@ class RollbackManager:
 
         return config_data
 
-    def _collect_health_checks(self, platform: DeploymentPlatform, service_name: str) -> List[str]:
+    def _collect_health_checks(
+        self, platform: DeploymentPlatform, service_name: str
+    ) -> List[str]:
         """æ”¶é›†å¥åº·æª¢æŸ¥é…ç½®"""
         health_checks = []
 
         if platform == DeploymentPlatform.KUBERNETES:
             # Kubernetes å¥åº·æª¢æŸ¥ç«¯é»
-            health_checks = [f"/healthz", f"/health", f"/actuator/health", f"/api/health"]
+            health_checks = [
+                f"/healthz",
+                f"/health",
+                f"/actuator/health",
+                f"/api/health",
+            ]
         elif platform == DeploymentPlatform.DOCKER:
             # Docker å¥åº·æª¢æŸ¥
             health_checks = ["docker health check", "container status"]
@@ -499,16 +515,28 @@ class RollbackManager:
 
     def _generate_pre_rollback_checks(self, snapshot: DeploymentSnapshot) -> List[str]:
         """ç”Ÿæˆå›æ»¾å‰æª¢æŸ¥"""
-        checks = ["é©—è­‰ç›®æ¨™é¡åƒå­˜åœ¨", "æª¢æŸ¥è³‡æºå¯ç”¨æ€§", "é©—è­‰é…ç½®æ–‡ä»¶å®Œæ•´æ€§", "æª¢æŸ¥ç¶²çµ¡é€£æ¥"]
+        checks = [
+            "é©—è­‰ç›®æ¨™é¡åƒå­˜åœ¨",
+            "æª¢æŸ¥è³‡æºå¯ç”¨æ€§",
+            "é©—è­‰é…ç½®æ–‡ä»¶å®Œæ•´æ€§",
+            "æª¢æŸ¥ç¶²çµ¡é€£æ¥",
+        ]
 
         if snapshot.platform == DeploymentPlatform.KUBERNETES:
-            checks.extend(["é©—è­‰ Kubernetes é›†ç¾¤ç‹€æ…‹", "æª¢æŸ¥å‘½åç©ºé–“è³‡æºé…é¡", "é©—è­‰ RBAC æ¬Šé™"])
+            checks.extend(
+                ["é©—è­‰ Kubernetes é›†ç¾¤ç‹€æ…‹", "æª¢æŸ¥å‘½åç©ºé–“è³‡æºé…é¡", "é©—è­‰ RBAC æ¬Šé™"]
+            )
 
         return checks
 
     def _generate_post_rollback_checks(self, snapshot: DeploymentSnapshot) -> List[str]:
         """ç”Ÿæˆå›æ»¾å¾Œæª¢æŸ¥"""
-        checks = ["é©—è­‰æœå‹™å•Ÿå‹•ç‹€æ…‹", "åŸ·è¡Œå¥åº·æª¢æŸ¥", "æª¢æŸ¥æ—¥èªŒéŒ¯èª¤", "é©—è­‰ API ç«¯é»å¯è¨ªå•æ€§"]
+        checks = [
+            "é©—è­‰æœå‹™å•Ÿå‹•ç‹€æ…‹",
+            "åŸ·è¡Œå¥åº·æª¢æŸ¥",
+            "æª¢æŸ¥æ—¥èªŒéŒ¯èª¤",
+            "é©—è­‰ API ç«¯é»å¯è¨ªå•æ€§",
+        ]
 
         if snapshot.platform == DeploymentPlatform.KUBERNETES:
             checks.extend(["æª¢æŸ¥ Pod ç‹€æ…‹", "é©—è­‰ Service ç«¯é»", "æª¢æŸ¥è³‡æºä½¿ç”¨æƒ…æ³"])
@@ -547,7 +575,9 @@ class RollbackManager:
 
             # åŸ·è¡Œå›æ»¾æ­¥é©Ÿ
             for step in plan.steps:
-                step_result = await self._execute_rollback_step(execution, step, snapshot)
+                step_result = await self._execute_rollback_step(
+                    execution, step, snapshot
+                )
                 execution.steps_executed.append(step_result)
 
                 if not step_result["success"]:
@@ -568,7 +598,9 @@ class RollbackManager:
 
         finally:
             execution.end_time = datetime.now()
-            execution.duration = (execution.end_time - execution.start_time).total_seconds()
+            execution.duration = (
+                execution.end_time - execution.start_time
+            ).total_seconds()
 
             # ä¿å­˜åŸ·è¡Œè¨˜éŒ„
             self.rollback_history[rollback_id] = execution
@@ -576,10 +608,14 @@ class RollbackManager:
             # ç™¼é€é€šçŸ¥
             await self._send_rollback_notification(execution, plan)
 
-        self.logger.info(f"å›æ»¾åŸ·è¡Œå®Œæˆ: {rollback_id} - ç‹€æ…‹: {execution.status.value}")
+        self.logger.info(
+            f"å›æ»¾åŸ·è¡Œå®Œæˆ: {rollback_id} - ç‹€æ…‹: {execution.status.value}"
+        )
         return execution
 
-    async def _execute_pre_rollback_checks(self, execution: RollbackExecution, plan: RollbackPlan):
+    async def _execute_pre_rollback_checks(
+        self, execution: RollbackExecution, plan: RollbackPlan
+    ):
         """åŸ·è¡Œå›æ»¾å‰æª¢æŸ¥"""
         execution.rollback_logs.append("é–‹å§‹åŸ·è¡Œå›æ»¾å‰æª¢æŸ¥...")
 
@@ -588,14 +624,18 @@ class RollbackManager:
                 if "é¡åƒå­˜åœ¨" in check:
                     success = await self._check_image_exists(plan.deployment_snapshot)
                 elif "è³‡æºå¯ç”¨æ€§" in check:
-                    success = await self._check_resource_availability(plan.deployment_snapshot)
+                    success = await self._check_resource_availability(
+                        plan.deployment_snapshot
+                    )
                 elif "é›†ç¾¤ç‹€æ…‹" in check:
                     success = await self._check_cluster_status()
                 else:
                     success = True  # é»˜èªé€šé
 
                 execution.health_check_results[check] = success
-                execution.rollback_logs.append(f"æª¢æŸ¥ '{check}': {'é€šé' if success else 'å¤±æ•—'}")
+                execution.rollback_logs.append(
+                    f"æª¢æŸ¥ '{check}': {'é€šé' if success else 'å¤±æ•—'}"
+                )
 
                 if not success:
                     raise Exception(f"å›æ»¾å‰æª¢æŸ¥å¤±æ•—: {check}")
@@ -607,7 +647,10 @@ class RollbackManager:
         execution.rollback_logs.append("å›æ»¾å‰æª¢æŸ¥å®Œæˆ")
 
     async def _execute_rollback_step(
-        self, execution: RollbackExecution, step: Dict[str, Any], snapshot: DeploymentSnapshot
+        self,
+        execution: RollbackExecution,
+        step: Dict[str, Any],
+        snapshot: DeploymentSnapshot,
     ) -> Dict[str, Any]:
         """åŸ·è¡Œå›æ»¾æ­¥é©Ÿ"""
         step_name = step["name"]
@@ -664,7 +707,9 @@ class RollbackManager:
                 "error": str(e),
             }
 
-            execution.rollback_logs.append(f"æ­¥é©Ÿ '{step_name}' å¤±æ•—: {e} (è€—æ™‚: {duration:.2f}s)")
+            execution.rollback_logs.append(
+                f"æ­¥é©Ÿ '{step_name}' å¤±æ•—: {e} (è€—æ™‚: {duration:.2f}s)"
+            )
 
             return result
 
@@ -685,7 +730,10 @@ class RollbackManager:
         """å‚™ä»½ç•¶å‰éƒ¨ç½²"""
         try:
             # é€™è£¡å¯¦ç¾ç•¶å‰éƒ¨ç½²çš„å‚™ä»½é‚è¼¯
-            backup_data = {"snapshot": asdict(snapshot), "backup_time": datetime.now().isoformat()}
+            backup_data = {
+                "snapshot": asdict(snapshot),
+                "backup_time": datetime.now().isoformat(),
+            }
 
             backup_file = (
                 Path(self.config["backup"]["backup_directory"])
@@ -766,7 +814,9 @@ class RollbackManager:
             self.logger.error(f"å›æ»¾ç‹€æ…‹é©—è­‰å¤±æ•—: {e}")
             return False
 
-    async def _perform_health_check(self, health_check: str, snapshot: DeploymentSnapshot) -> bool:
+    async def _perform_health_check(
+        self, health_check: str, snapshot: DeploymentSnapshot
+    ) -> bool:
         """åŸ·è¡Œå¥åº·æª¢æŸ¥"""
         try:
             if health_check.startswith("/"):
@@ -784,7 +834,9 @@ class RollbackManager:
         except Exception:
             return False
 
-    async def _execute_post_rollback_checks(self, execution: RollbackExecution, plan: RollbackPlan):
+    async def _execute_post_rollback_checks(
+        self, execution: RollbackExecution, plan: RollbackPlan
+    ):
         """åŸ·è¡Œå›æ»¾å¾Œæª¢æŸ¥"""
         execution.rollback_logs.append("é–‹å§‹åŸ·è¡Œå›æ»¾å¾Œæª¢æŸ¥...")
 
@@ -793,21 +845,27 @@ class RollbackManager:
                 if "æœå‹™å•Ÿå‹•" in check:
                     success = await self._check_service_status(plan.deployment_snapshot)
                 elif "å¥åº·æª¢æŸ¥" in check:
-                    success = await self._verify_rollback_status(plan.deployment_snapshot)
+                    success = await self._verify_rollback_status(
+                        plan.deployment_snapshot
+                    )
                 elif "API ç«¯é»" in check:
                     success = await self._check_api_endpoints(plan.deployment_snapshot)
                 else:
                     success = True
 
                 execution.health_check_results[check] = success
-                execution.rollback_logs.append(f"æª¢æŸ¥ '{check}': {'é€šé' if success else 'å¤±æ•—'}")
+                execution.rollback_logs.append(
+                    f"æª¢æŸ¥ '{check}': {'é€šé' if success else 'å¤±æ•—'}"
+                )
 
             except Exception as e:
                 execution.rollback_logs.append(f"æª¢æŸ¥ '{check}' ç•°å¸¸: {e}")
 
         execution.rollback_logs.append("å›æ»¾å¾Œæª¢æŸ¥å®Œæˆ")
 
-    async def _send_rollback_notification(self, execution: RollbackExecution, plan: RollbackPlan):
+    async def _send_rollback_notification(
+        self, execution: RollbackExecution, plan: RollbackPlan
+    ):
         """ç™¼é€å›æ»¾é€šçŸ¥"""
         status_emoji = "âœ…" if execution.status == RollbackStatus.SUCCESS else "âŒ"
         message = f"""
@@ -843,7 +901,9 @@ class RollbackManager:
         history.sort(key=lambda x: x.start_time, reverse=True)
         return history[:limit]
 
-    def get_available_snapshots(self, service_name: str = None) -> List[DeploymentSnapshot]:
+    def get_available_snapshots(
+        self, service_name: str = None
+    ) -> List[DeploymentSnapshot]:
         """ç²å–å¯ç”¨å¿«ç…§"""
         snapshots = list(self.snapshots.values())
 
diff --git a/workspace/src/ci-tools/documentation-generator/doc_generator.py b/workspace/src/ci-tools/documentation-generator/doc_generator.py
index 560de4d..c31a042 100644
--- a/workspace/src/ci-tools/documentation-generator/doc_generator.py
+++ b/workspace/src/ci-tools/documentation-generator/doc_generator.py
@@ -120,7 +120,12 @@ class DocumentationGenerator:
 
         # é»˜èªé…ç½®
         return {
-            "source_paths": {"python": "src", "api": "src/api", "docs": "docs", "config": "config"},
+            "source_paths": {
+                "python": "src",
+                "api": "src/api",
+                "docs": "docs",
+                "config": "config",
+            },
             "output_directory": "generated-docs",
             "templates_directory": "templates/docs",
             "formats": ["html", "markdown"],
@@ -137,7 +142,11 @@ class DocumentationGenerator:
                 "include_git_info": True,
                 "auto_commit_docs": False,
             },
-            "publishing": {"auto_deploy": False, "deploy_target": "gh-pages", "base_url": ""},
+            "publishing": {
+                "auto_deploy": False,
+                "deploy_target": "gh-pages",
+                "base_url": "",
+            },
         }
 
     def _setup_logger(self) -> logging.Logger:
@@ -147,7 +156,9 @@ class DocumentationGenerator:
 
         if not logger.handlers:
             handler = logging.StreamHandler()
-            formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
+            formatter = logging.Formatter(
+                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+            )
             handler.setFormatter(formatter)
             logger.addHandler(handler)
 
@@ -202,7 +213,10 @@ class DocumentationGenerator:
         }
 
     def generate_documentation(
-        self, doc_type: DocType, source_path: str = None, output_formats: List[OutputFormat] = None
+        self,
+        doc_type: DocType,
+        source_path: str = None,
+        output_formats: List[OutputFormat] = None,
     ) -> Dict[str, Documentation]:
         """ç”Ÿæˆæ–‡æª”"""
 
@@ -233,7 +247,9 @@ class DocumentationGenerator:
             self.logger.error(f"æ–‡æª”ç”Ÿæˆå¤±æ•—: {e}")
             raise
 
-    def _extract_source_data(self, doc_type: DocType, source_path: str) -> Dict[str, Any]:
+    def _extract_source_data(
+        self, doc_type: DocType, source_path: str
+    ) -> Dict[str, Any]:
         """æå–æºæ•¸æ“š"""
 
         source_path = Path(source_path)
@@ -263,7 +279,9 @@ class DocumentationGenerator:
 
         return generator.generate(source_data, self.config)
 
-    def _export_docs(self, docs: Dict[str, Documentation], output_formats: List[OutputFormat]):
+    def _export_docs(
+        self, docs: Dict[str, Documentation], output_formats: List[OutputFormat]
+    ):
         """å°å‡ºæ–‡æª”"""
 
         output_dir = Path(self.config["output_directory"])
@@ -278,7 +296,9 @@ class DocumentationGenerator:
                         file_path = exporter.export(doc, output_dir)
                         self.logger.info(f"å·²å°å‡ºæ–‡æª”: {file_path}")
                     except Exception as e:
-                        self.logger.error(f"å°å‡ºæ–‡æª”å¤±æ•— {doc_id} ({format_type.value}): {e}")
+                        self.logger.error(
+                            f"å°å‡ºæ–‡æª”å¤±æ•— {doc_id} ({format_type.value}): {e}"
+                        )
 
     def _get_default_source_path(self, doc_type: DocType) -> str:
         """ç²å–é»˜èªæºè·¯å¾‘"""
@@ -311,11 +331,15 @@ class DocumentationGenerator:
         except ImportError:
             return f"<pre><code>{code}</code></pre>"
 
-    def generate_api_documentation(self, api_path: str = None) -> Dict[str, Documentation]:
+    def generate_api_documentation(
+        self, api_path: str = None
+    ) -> Dict[str, Documentation]:
         """ç”Ÿæˆ API æ–‡æª”"""
         return self.generate_documentation(DocType.API, api_path)
 
-    def generate_code_documentation(self, code_path: str = None) -> Dict[str, Documentation]:
+    def generate_code_documentation(
+        self, code_path: str = None
+    ) -> Dict[str, Documentation]:
         """ç”Ÿæˆä»£ç¢¼æ–‡æª”"""
         return self.generate_documentation(DocType.CODE, code_path)
 
@@ -327,10 +351,14 @@ class DocumentationGenerator:
 
     def generate_readme(self, project_root: str = None) -> Documentation:
         """ç”Ÿæˆ README æ–‡æª”"""
-        docs = self.generate_documentation(DocType.README, project_root, [OutputFormat.MARKDOWN])
+        docs = self.generate_documentation(
+            DocType.README, project_root, [OutputFormat.MARKDOWN]
+        )
         return docs.get("readme")
 
-    def update_documentation(self, doc_id: str, source_changes: Dict[str, Any]) -> Documentation:
+    def update_documentation(
+        self, doc_id: str, source_changes: Dict[str, Any]
+    ) -> Documentation:
         """æ›´æ–°æ–‡æª”"""
 
         if doc_id not in self.documentation_cache:
@@ -466,10 +494,14 @@ class PythonCodeExtractor(BaseExtractor):
             "docstring": ast.get_docstring(node),
             "args": [arg.arg for arg in node.args.args],
             "returns": (
-                ast.unparse(node.returns) if hasattr(ast, "unparse") and node.returns else None
+                ast.unparse(node.returns)
+                if hasattr(ast, "unparse") and node.returns
+                else None
             ),
             "decorators": (
-                [ast.unparse(dec) for dec in node.decorators] if hasattr(ast, "unparse") else []
+                [ast.unparse(dec) for dec in node.decorators]
+                if hasattr(ast, "unparse")
+                else []
             ),
             "is_async": isinstance(node, ast.AsyncFunctionDef),
             "complexity": self._calculate_complexity(node),
@@ -489,10 +521,16 @@ class PythonCodeExtractor(BaseExtractor):
             "name": node.name,
             "line_number": node.lineno,
             "docstring": ast.get_docstring(node),
-            "bases": [ast.unparse(base) for base in node.bases] if hasattr(ast, "unparse") else [],
+            "bases": (
+                [ast.unparse(base) for base in node.bases]
+                if hasattr(ast, "unparse")
+                else []
+            ),
             "methods": methods,
             "decorators": (
-                [ast.unparse(dec) for dec in node.decorators] if hasattr(ast, "unparse") else []
+                [ast.unparse(dec) for dec in node.decorators]
+                if hasattr(ast, "unparse")
+                else []
             ),
         }
 
@@ -507,7 +545,9 @@ class PythonCodeExtractor(BaseExtractor):
                     "name": target.id,
                     "line_number": node.lineno,
                     "value": (
-                        ast.unparse(node.value) if hasattr(ast, "unparse") else str(node.value)
+                        ast.unparse(node.value)
+                        if hasattr(ast, "unparse")
+                        else str(node.value)
                     ),
                     "is_uppercase": target.id.isupper(),
                 }
@@ -576,7 +616,9 @@ class APISpecExtractor(BaseExtractor):
         )
 
         for file_path in openapi_files:
-            if any(name in str(file_path).lower() for name in ["openapi", "swagger", "api"]):
+            if any(
+                name in str(file_path).lower() for name in ["openapi", "swagger", "api"]
+            ):
                 try:
                     spec_endpoints = self._extract_openapi_endpoints(file_path)
                     endpoints.extend(spec_endpoints)
@@ -713,7 +755,9 @@ class GitInfoExtractor(BaseExtractor):
                 "commit_message": repo.head.commit.message,
                 "author": str(repo.head.commit.author),
                 "last_modified": repo.head.commit.committed_date.isoformat(),
-                "remote_url": next(iter(repo.remotes.urls()), "") if repo.remotes else "",
+                "remote_url": (
+                    next(iter(repo.remotes.urls()), "") if repo.remotes else ""
+                ),
                 "is_dirty": repo.is_dirty(),
                 "untracked_files": len(repo.untracked_files),
             }
@@ -760,7 +804,9 @@ class APIDocGenerator(BaseDocGenerator):
         grouped_endpoints = {}
         for endpoint in endpoints:
             path_prefix = (
-                "/" + endpoint.path.split("/")[1] if len(endpoint.path.split("/")) > 1 else "root"
+                "/" + endpoint.path.split("/")[1]
+                if len(endpoint.path.split("/")) > 1
+                else "root"
             )
             if path_prefix not in grouped_endpoints:
                 grouped_endpoints[path_prefix] = []
@@ -856,7 +902,10 @@ class CodeDocGenerator(BaseDocGenerator):
             description="å®Œæ•´çš„ä»£ç¢¼åƒè€ƒæ–‡æª”",
             doc_type=DocType.CODE,
             sections=sections,
-            metadata={"total_modules": len(modules), "generated_at": datetime.now().isoformat()},
+            metadata={
+                "total_modules": len(modules),
+                "generated_at": datetime.now().isoformat(),
+            },
             created_at=datetime.now(),
             updated_at=datetime.now(),
         )
diff --git a/workspace/src/ci-tools/monitoring-alerting/monitoring_system.py b/workspace/src/ci-tools/monitoring-alerting/monitoring_system.py
index f894c93..952f561 100644
--- a/workspace/src/ci-tools/monitoring-alerting/monitoring_system.py
+++ b/workspace/src/ci-tools/monitoring-alerting/monitoring_system.py
@@ -21,7 +21,13 @@ import prometheus_client
 import psutil
 import requests
 import yaml
-from prometheus_client import CollectorRegistry, Counter, Gauge, Histogram, generate_latest
+from prometheus_client import (
+    CollectorRegistry,
+    Counter,
+    Gauge,
+    Histogram,
+    generate_latest,
+)
 from redis import Redis
 
 
@@ -141,7 +147,11 @@ class MonitoringSystem:
         # é»˜èªé…ç½®
         return {
             "prometheus": {"enabled": True, "port": 8090, "endpoint": "/metrics"},
-            "metrics": {"retention_hours": 24, "collection_interval": 30, "batch_size": 100},
+            "metrics": {
+                "retention_hours": 24,
+                "collection_interval": 30,
+                "batch_size": 100,
+            },
             "alerts": {
                 "evaluation_interval": 60,
                 "max_alerts_per_rule": 10,
@@ -168,7 +178,9 @@ class MonitoringSystem:
 
         if not logger.handlers:
             handler = logging.StreamHandler()
-            formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
+            formatter = logging.Formatter(
+                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+            )
             handler.setFormatter(formatter)
             logger.addHandler(handler)
 
@@ -372,14 +384,18 @@ class MonitoringSystem:
             }
 
             self.redis_client.lpush(key, json.dumps(data))
-            self.redis_client.expire(key, self.config["metrics"]["retention_hours"] * 3600)
+            self.redis_client.expire(
+                key, self.config["metrics"]["retention_hours"] * 3600
+            )
 
         except Exception as e:
             self.logger.error(f"ä¿å­˜æŒ‡æ¨™åˆ° Redis å¤±æ•—: {e}")
 
     def _cleanup_old_metrics(self):
         """æ¸…ç†èˆŠçš„æŒ‡æ¨™æ•¸æ“š"""
-        retention_time = datetime.now() - timedelta(hours=self.config["metrics"]["retention_hours"])
+        retention_time = datetime.now() - timedelta(
+            hours=self.config["metrics"]["retention_hours"]
+        )
 
         # ä¿ç•™æœ€è¿‘çš„æ•¸æ“š
         max_items = self.config["metrics"]["batch_size"] * 10
@@ -480,7 +496,9 @@ class MonitoringSystem:
                 return
 
             # è©•ä¼°æ¢ä»¶
-            is_triggered = self._evaluate_condition(current_value, rule.condition, rule.threshold)
+            is_triggered = self._evaluate_condition(
+                current_value, rule.condition, rule.threshold
+            )
 
             # æª¢æŸ¥æ˜¯å¦å·²ç¶“å­˜åœ¨å‘Šè­¦
             existing_alert = self.active_alerts.get(rule_id)
@@ -509,7 +527,9 @@ class MonitoringSystem:
         for metric_data in reversed(self.metric_data):
             if metric_data.name == metric_name:
                 # æª¢æŸ¥æ¨™ç±¤æ˜¯å¦åŒ¹é…
-                if not labels or all(metric_data.labels.get(k) == v for k, v in labels.items()):
+                if not labels or all(
+                    metric_data.labels.get(k) == v for k, v in labels.items()
+                ):
                     return metric_data.value
 
         # å¾ Redis ä¸­æŸ¥æ‰¾
@@ -530,7 +550,9 @@ class MonitoringSystem:
 
         return None
 
-    def _evaluate_condition(self, value: float, condition: str, threshold: float) -> bool:
+    def _evaluate_condition(
+        self, value: float, condition: str, threshold: float
+    ) -> bool:
         """è©•ä¼°æ¢ä»¶"""
         try:
             if condition == ">":
@@ -663,13 +685,21 @@ class MonitoringSystem:
                     "color": color,
                     "fields": [
                         {"title": "å‘Šè­¦åç¨±", "value": rule.name, "short": True},
-                        {"title": "åš´é‡ç¨‹åº¦", "value": alert.severity.value.upper(), "short": True},
+                        {
+                            "title": "åš´é‡ç¨‹åº¦",
+                            "value": alert.severity.value.upper(),
+                            "short": True,
+                        },
                         {
                             "title": "é–‹å§‹æ™‚é–“",
                             "value": alert.start_time.strftime("%Y-%m-%d %H:%M:%S"),
                             "short": True,
                         },
-                        {"title": "è©•ä¼°æ¬¡æ•¸", "value": str(alert.evaluation_count), "short": True},
+                        {
+                            "title": "è©•ä¼°æ¬¡æ•¸",
+                            "value": str(alert.evaluation_count),
+                            "short": True,
+                        },
                     ],
                     "footer": "ç›£æ§ç³»çµ±",
                     "ts": int(alert.start_time.timestamp()),
@@ -706,7 +736,9 @@ class MonitoringSystem:
         headers = channel.config.get("headers", {})
 
         async with aiohttp.ClientSession() as session:
-            async with session.post(webhook_url, json=payload, headers=headers) as response:
+            async with session.post(
+                webhook_url, json=payload, headers=headers
+            ) as response:
                 if response.status not in [200, 201, 204]:
                     self.logger.error(f"Webhook é€šçŸ¥ç™¼é€å¤±æ•—: {response.status}")
 
@@ -809,7 +841,10 @@ class MonitoringSystem:
         )
 
     def get_metrics_data(
-        self, metric_name: str = None, start_time: datetime = None, end_time: datetime = None
+        self,
+        metric_name: str = None,
+        start_time: datetime = None,
+        end_time: datetime = None,
     ) -> List[MetricData]:
         """ç²å–æŒ‡æ¨™æ•¸æ“š"""
 
@@ -831,7 +866,9 @@ class MonitoringSystem:
     def get_active_alerts(self) -> List[Alert]:
         """ç²å–æ´»èºå‘Šè­¦"""
         return [
-            alert for alert in self.active_alerts.values() if alert.status == AlertStatus.ACTIVE
+            alert
+            for alert in self.active_alerts.values()
+            if alert.status == AlertStatus.ACTIVE
         ]
 
     def get_alert_history(self, limit: int = 100) -> List[Alert]:
@@ -848,7 +885,9 @@ class MonitoringSystem:
         self.start_prometheus_server()
 
         # å•Ÿå‹•ç³»çµ±æŒ‡æ¨™æ”¶é›†
-        system_metrics_thread = threading.Thread(target=self.collect_system_metrics, daemon=True)
+        system_metrics_thread = threading.Thread(
+            target=self.collect_system_metrics, daemon=True
+        )
         system_metrics_thread.start()
 
         # å•Ÿå‹•å‘Šè­¦è©•ä¼°ä»»å‹™
diff --git a/workspace/src/ci-tools/test-automation/test_framework.py b/workspace/src/ci-tools/test-automation/test_framework.py
index 766f054..bdf2aa6 100644
--- a/workspace/src/ci-tools/test-automation/test_framework.py
+++ b/workspace/src/ci-tools/test-automation/test_framework.py
@@ -174,7 +174,9 @@ class TestAutomationFramework:
 
         if not logger.handlers:
             handler = logging.StreamHandler()
-            formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
+            formatter = logging.Formatter(
+                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+            )
             handler.setFormatter(formatter)
             logger.addHandler(handler)
 
@@ -460,9 +462,13 @@ class TestAutomationFramework:
         await self._execute_hooks("after_suite", suite_name)
 
         # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
-        report = self._generate_test_report(suite_name, start_time, end_time, test_results)
+        report = self._generate_test_report(
+            suite_name, start_time, end_time, test_results
+        )
 
-        self.logger.info(f"æ¸¬è©¦å¥—ä»¶åŸ·è¡Œå®Œæˆ: {suite_name} - æˆåŠŸç‡: {report.success_rate:.1f}%")
+        self.logger.info(
+            f"æ¸¬è©¦å¥—ä»¶åŸ·è¡Œå®Œæˆ: {suite_name} - æˆåŠŸç‡: {report.success_rate:.1f}%"
+        )
 
         return report
 
@@ -503,11 +509,17 @@ class TestAutomationFramework:
         success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
 
         # è¦†è“‹ç‡åŒ¯ç¸½ï¼ˆç°¡åŒ–å¯¦ç¾ï¼‰
-        coverage_summary = {"total_lines": 1000, "covered_lines": 850, "coverage_percentage": 85.0}
+        coverage_summary = {
+            "total_lines": 1000,
+            "covered_lines": 850,
+            "coverage_percentage": 85.0,
+        }
 
         # æ€§èƒ½æŒ‡æ¨™
         performance_metrics = {
-            "average_test_duration": total_duration / total_tests if total_tests > 0 else 0,
+            "average_test_duration": (
+                total_duration / total_tests if total_tests > 0 else 0
+            ),
             "slowest_test": max((r.duration for r in test_results), default=0),
             "fastest_test": min((r.duration for r in test_results), default=0),
         }
@@ -536,7 +548,8 @@ class TestAutomationFramework:
 
         if format_type == "html":
             output_path = (
-                output_dir / f"{report.suite_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
+                output_dir
+                / f"{report.suite_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
             )
 
             if format_type in self.report_generators:
@@ -550,7 +563,8 @@ class TestAutomationFramework:
 
         elif format_type == "json":
             output_path = (
-                output_dir / f"{report.suite_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
+                output_dir
+                / f"{report.suite_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
             )
 
             report_data = asdict(report)
@@ -623,7 +637,9 @@ class TestAutomationFramework:
         self.logger.info(f"åœ¨ {test_directory} ä¸­ç™¼ç¾ {len(discovered_tests)} å€‹æ¸¬è©¦")
         return discovered_tests
 
-    def filter_tests_by_priority(self, test_ids: List[str], min_priority: Priority) -> List[str]:
+    def filter_tests_by_priority(
+        self, test_ids: List[str], min_priority: Priority
+    ) -> List[str]:
         """æ ¹æ“šå„ªå…ˆç´šéæ¿¾æ¸¬è©¦"""
         priority_order = {
             Priority.LOW: 0,
@@ -667,10 +683,26 @@ class TestAutomationFramework:
                 {
                     "color": color,
                     "fields": [
-                        {"title": "ç¸½æ¸¬è©¦æ•¸", "value": str(report.total_tests), "short": True},
-                        {"title": "é€šé", "value": str(report.passed_tests), "short": True},
-                        {"title": "å¤±æ•—", "value": str(report.failed_tests), "short": True},
-                        {"title": "æˆåŠŸç‡", "value": f"{report.success_rate:.1f}%", "short": True},
+                        {
+                            "title": "ç¸½æ¸¬è©¦æ•¸",
+                            "value": str(report.total_tests),
+                            "short": True,
+                        },
+                        {
+                            "title": "é€šé",
+                            "value": str(report.passed_tests),
+                            "short": True,
+                        },
+                        {
+                            "title": "å¤±æ•—",
+                            "value": str(report.failed_tests),
+                            "short": True,
+                        },
+                        {
+                            "title": "æˆåŠŸç‡",
+                            "value": f"{report.success_rate:.1f}%",
+                            "short": True,
+                        },
                     ],
                 }
             ],
@@ -714,7 +746,9 @@ class TestAutomationFramework:
 
 # æ¸¬è©¦è£é£¾å™¨
 def test_case(
-    test_name: str, test_type: TestType = TestType.UNIT, priority: Priority = Priority.MEDIUM
+    test_name: str,
+    test_type: TestType = TestType.UNIT,
+    priority: Priority = Priority.MEDIUM,
 ):
     """æ¸¬è©¦ç”¨ä¾‹è£é£¾å™¨"""
 
diff --git a/workspace/src/core/ai_constitution/adaptive_guidelines.py b/workspace/src/core/ai_constitution/adaptive_guidelines.py
index 19956f3..b4a736b 100644
--- a/workspace/src/core/ai_constitution/adaptive_guidelines.py
+++ b/workspace/src/core/ai_constitution/adaptive_guidelines.py
@@ -212,7 +212,9 @@ class DomainGuideline:
 
         if "resource_constrained" in context and context["resource_constrained"]:
             if key == "batch_size":
-                recommendation = max(guideline.get("min", 100), guideline.get("value", 1000) // 2)
+                recommendation = max(
+                    guideline.get("min", 100), guideline.get("value", 1000) // 2
+                )
                 confidence = 0.75
 
         return GuidelineEvaluation(
@@ -240,7 +242,9 @@ class DomainGuideline:
             if feedback_type == "too_strict":
                 if "options" in guideline:
                     options = guideline["options"]
-                    current_idx = options.index(old_value) if old_value in options else 0
+                    current_idx = (
+                        options.index(old_value) if old_value in options else 0
+                    )
                     if current_idx > 0:
                         new_value = options[current_idx - 1]
                 elif isinstance(old_value, (int, float)):
@@ -249,7 +253,9 @@ class DomainGuideline:
             elif feedback_type == "too_lenient":
                 if "options" in guideline:
                     options = guideline["options"]
-                    current_idx = options.index(old_value) if old_value in options else 0
+                    current_idx = (
+                        options.index(old_value) if old_value in options else 0
+                    )
                     if current_idx < len(options) - 1:
                         new_value = options[current_idx + 1]
                 elif isinstance(old_value, (int, float)):
@@ -381,7 +387,11 @@ class LearningGuideline:
             self._learning_data[operation_type] = []
 
         self._learning_data[operation_type].append(
-            {"operation": operation, "outcome": outcome, "timestamp": datetime.utcnow().isoformat()}
+            {
+                "operation": operation,
+                "outcome": outcome,
+                "timestamp": datetime.utcnow().isoformat(),
+            }
         )
 
         # ç•¶æ•¸æ“šè¶³å¤ æ™‚è§¸ç™¼å­¸ç¿’
@@ -423,7 +433,9 @@ class LearningGuideline:
             for key, value in first_op.items():
                 if key not in ["type", "timestamp", "id"]:
                     # æª¢æŸ¥æ­¤åƒæ•¸åœ¨æ‰€æœ‰æˆåŠŸæ¡ˆä¾‹ä¸­æ˜¯å¦ä¸€è‡´
-                    consistent = all(r.get("operation", {}).get(key) == value for r in records)
+                    consistent = all(
+                        r.get("operation", {}).get(key) == value for r in records
+                    )
                     if consistent:
                         common_params[key] = value
 
@@ -552,7 +564,10 @@ class AdaptiveGuidelineEngine:
         return result
 
     def _merge_recommendations(
-        self, domain: Dict[str, Any], contextual: Dict[str, Any], learned: Dict[str, Any]
+        self,
+        domain: Dict[str, Any],
+        contextual: Dict[str, Any],
+        learned: Dict[str, Any],
     ) -> Dict[str, Any]:
         """åˆä½µæ‰€æœ‰ä¾†æºçš„å»ºè­°"""
         merged = {}
@@ -575,7 +590,9 @@ class AdaptiveGuidelineEngine:
 
         return merged
 
-    def record_operation_outcome(self, operation: Dict[str, Any], outcome: Dict[str, Any]):
+    def record_operation_outcome(
+        self, operation: Dict[str, Any], outcome: Dict[str, Any]
+    ):
         """è¨˜éŒ„æ“ä½œçµæœä¾›å­¸ç¿’"""
         self.learning.record_outcome(operation, outcome)
 
@@ -591,7 +608,9 @@ class AdaptiveGuidelineEngine:
         return {
             "domains": list(self._domain_guidelines.keys()),
             "learned_patterns": len(self.learning.get_learned_patterns()),
-            "active_contextual_guidelines": len(self.contextual.get_all_active_guidelines()),
+            "active_contextual_guidelines": len(
+                self.contextual.get_all_active_guidelines()
+            ),
         }
 
 
diff --git a/workspace/src/core/ai_constitution/constitution_engine.py b/workspace/src/core/ai_constitution/constitution_engine.py
index 27e44fa..9a6f2e0 100644
--- a/workspace/src/core/ai_constitution/constitution_engine.py
+++ b/workspace/src/core/ai_constitution/constitution_engine.py
@@ -73,7 +73,9 @@ class ConstitutionVerdict:
     priority: VerdictPriority
 
     # ä¸‰å±¤é©—è­‰çµæœ
-    fundamental_law_results: Dict[str, LawVerificationResult] = field(default_factory=dict)
+    fundamental_law_results: Dict[str, LawVerificationResult] = field(
+        default_factory=dict
+    )
     operational_rule_results: Dict[str, RuleCheckResult] = field(default_factory=dict)
     guideline_recommendations: Dict[str, Any] = field(default_factory=dict)
 
@@ -241,7 +243,9 @@ class ConstitutionEngine:
         data = f"{proposal.proposal_id}{datetime.utcnow().isoformat()}"
         return f"VERDICT_{hashlib.sha256(data.encode()).hexdigest()[:12]}"
 
-    def _check_absolute_violations(self, results: Dict[str, LawVerificationResult]) -> List[str]:
+    def _check_absolute_violations(
+        self, results: Dict[str, LawVerificationResult]
+    ) -> List[str]:
         """æª¢æŸ¥æ˜¯å¦æœ‰çµ•å°é•è¦"""
         violations = []
 
@@ -251,7 +255,9 @@ class ConstitutionEngine:
 
         return violations
 
-    def _check_operational_rules(self, proposal: ActionProposal) -> Dict[str, RuleCheckResult]:
+    def _check_operational_rules(
+        self, proposal: ActionProposal
+    ) -> Dict[str, RuleCheckResult]:
         """æª¢æŸ¥æ“ä½œè¦å‰‡"""
         results = {}
 
@@ -265,7 +271,9 @@ class ConstitutionEngine:
             "requestor": proposal.requestor,
             "encrypted": proposal.parameters.get("encrypted", False),
             "access_logged": proposal.parameters.get("access_logged", False),
-            "authorization_verified": proposal.parameters.get("authorization_verified", False),
+            "authorization_verified": proposal.parameters.get(
+                "authorization_verified", False
+            ),
         }
 
         # æª¢æŸ¥æ‰€æœ‰é©ç”¨è¦å‰‡
@@ -520,9 +528,12 @@ class ConstitutionEngine:
 
         if stats["total_verdicts"] > 0:
             stats["approval_rate"] = round(
-                (stats["approved"] + stats["modified"]) / stats["total_verdicts"] * 100, 2
+                (stats["approved"] + stats["modified"]) / stats["total_verdicts"] * 100,
+                2,
+            )
+            stats["denial_rate"] = round(
+                stats["denied"] / stats["total_verdicts"] * 100, 2
             )
-            stats["denial_rate"] = round(stats["denied"] / stats["total_verdicts"] * 100, 2)
         else:
             stats["approval_rate"] = 0
             stats["denial_rate"] = 0
diff --git a/workspace/src/core/ai_constitution/fundamental_laws.py b/workspace/src/core/ai_constitution/fundamental_laws.py
index 0922bb5..87b131c 100644
--- a/workspace/src/core/ai_constitution/fundamental_laws.py
+++ b/workspace/src/core/ai_constitution/fundamental_laws.py
@@ -220,9 +220,13 @@ class LawOne:
         self._verification_history.append(result)
         return result
 
-    def _detect_harm(self, action: ProposedAction, keywords: List[str]) -> Optional[str]:
+    def _detect_harm(
+        self, action: ProposedAction, keywords: List[str]
+    ) -> Optional[str]:
         """åµæ¸¬è¡Œå‹•ä¸­çš„å‚·å®³é—œéµå­—"""
-        action_text = f"{action.action_type} {action.description} {action.target}".lower()
+        action_text = (
+            f"{action.action_type} {action.description} {action.target}".lower()
+        )
         for keyword in keywords:
             if keyword in action_text:
                 return keyword
@@ -330,7 +334,9 @@ class LawTwo:
         self._verification_history.append(result)
         return result
 
-    def _log_command(self, action: ProposedAction, is_human_command: bool, will_execute: bool):
+    def _log_command(
+        self, action: ProposedAction, is_human_command: bool, will_execute: bool
+    ):
         """è¨˜éŒ„å‘½ä»¤"""
         self._command_log.append(
             {
@@ -405,7 +411,9 @@ class LawThree:
         # æª¢æŸ¥è³‡æºæ¶ˆè€—
         resource_impact = self._assess_resource_impact(action)
         if resource_impact > 0.8:
-            recommendations.append(f"è­¦å‘Šï¼šæ­¤è¡Œå‹•å¯èƒ½æ¶ˆè€— {resource_impact*100:.1f}% ç³»çµ±è³‡æº")
+            recommendations.append(
+                f"è­¦å‘Šï¼šæ­¤è¡Œå‹•å¯èƒ½æ¶ˆè€— {resource_impact*100:.1f}% ç³»çµ±è³‡æº"
+            )
 
         result = LawVerificationResult(
             law_id=self.LAW_ID,
@@ -495,7 +503,9 @@ class FundamentalLaws:
 
         self._verification_cache: Dict[str, LawVerificationResult] = {}
 
-    async def verify_all(self, action: ProposedAction) -> Dict[str, LawVerificationResult]:
+    async def verify_all(
+        self, action: ProposedAction
+    ) -> Dict[str, LawVerificationResult]:
         """
         é©—è­‰è¡Œå‹•æ˜¯å¦ç¬¦åˆæ‰€æœ‰æ ¹æœ¬æ³•å‰‡
         æŒ‰å„ªå…ˆç´šé †åºé©—è­‰ï¼Œä¸€æ—¦é•åå³åœæ­¢
diff --git a/workspace/src/core/ai_constitution/guardrails.py b/workspace/src/core/ai_constitution/guardrails.py
index 6ef497b..4e04033 100644
--- a/workspace/src/core/ai_constitution/guardrails.py
+++ b/workspace/src/core/ai_constitution/guardrails.py
@@ -665,7 +665,9 @@ class GuardrailSystem:
             stats["total_failures"] += guardrail.fail_count
 
         if stats["total_checks"] > 0:
-            stats["pass_rate"] = round(stats["total_passes"] / stats["total_checks"] * 100, 2)
+            stats["pass_rate"] = round(
+                stats["total_passes"] / stats["total_checks"] * 100, 2
+            )
         else:
             stats["pass_rate"] = 0
 
diff --git a/workspace/src/core/ai_constitution/operational_rules.py b/workspace/src/core/ai_constitution/operational_rules.py
index b946fdd..7afa529 100644
--- a/workspace/src/core/ai_constitution/operational_rules.py
+++ b/workspace/src/core/ai_constitution/operational_rules.py
@@ -136,7 +136,10 @@ class DataHandlingRule:
                         rule_name="åŠ å¯†è¦æ±‚",
                         severity=RuleSeverity.CRITICAL,
                         description=f"æ•æ„Ÿæ•¸æ“š {data_type} å¿…é ˆåŠ å¯†",
-                        context={"data_type": data_type, "category": sensitive_category},
+                        context={
+                            "data_type": data_type,
+                            "category": sensitive_category,
+                        },
                     )
                 )
                 auto_corrections.append("auto_encrypt_data")
@@ -169,7 +172,8 @@ class DataHandlingRule:
 
         result = RuleCheckResult(
             rule_id=self.RULE_ID,
-            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL]) == 0,
+            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL])
+            == 0,
             violations=violations,
             warnings=warnings,
             auto_corrections=auto_corrections,
@@ -188,7 +192,9 @@ class DataHandlingRule:
                 return category
         return None
 
-    def apply_auto_correction(self, correction: str, data: Dict[str, Any]) -> Dict[str, Any]:
+    def apply_auto_correction(
+        self, correction: str, data: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """æ‡‰ç”¨è‡ªå‹•ä¿®æ­£"""
         if correction == "auto_encrypt_data":
             # æ¨¡æ“¬åŠ å¯†
@@ -196,7 +202,9 @@ class DataHandlingRule:
             data["encryption_algorithm"] = "AES-256-GCM"
         elif correction == "enable_access_logging":
             data["access_logged"] = True
-            data["log_id"] = hashlib.sha256(str(datetime.utcnow()).encode()).hexdigest()[:16]
+            data["log_id"] = hashlib.sha256(
+                str(datetime.utcnow()).encode()
+            ).hexdigest()[:16]
 
         return data
 
@@ -295,7 +303,8 @@ class SystemAccessRule:
 
         result = RuleCheckResult(
             rule_id=self.RULE_ID,
-            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL]) == 0,
+            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL])
+            == 0,
             violations=violations,
             warnings=warnings,
             auto_corrections=auto_corrections,
@@ -308,7 +317,10 @@ class SystemAccessRule:
     def _is_prohibited_resource(self, resource: str) -> bool:
         """æª¢æŸ¥æ˜¯å¦ç‚ºç¦æ­¢è³‡æº"""
         resource_lower = resource.lower()
-        return any(prohibited.lower() in resource_lower for prohibited in self.PROHIBITED_RESOURCES)
+        return any(
+            prohibited.lower() in resource_lower
+            for prohibited in self.PROHIBITED_RESOURCES
+        )
 
     def _categorize_resource(self, resource: str) -> str:
         """åˆ†é¡è³‡æº"""
@@ -441,7 +453,8 @@ class ResourceUsageRule:
 
         result = RuleCheckResult(
             rule_id=self.RULE_ID,
-            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL]) == 0,
+            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL])
+            == 0,
             violations=violations,
             warnings=warnings,
             auto_corrections=auto_corrections,
@@ -573,7 +586,8 @@ class CommunicationRule:
 
         result = RuleCheckResult(
             rule_id=self.RULE_ID,
-            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL]) == 0,
+            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL])
+            == 0,
             violations=violations,
             warnings=warnings,
             auto_corrections=auto_corrections,
@@ -591,9 +605,9 @@ class CommunicationRule:
             "recipient_count": len(communication.get("recipients", [])),
             "content_size": len(communication.get("content", "")),
             "timestamp": datetime.utcnow().isoformat(),
-            "log_id": hashlib.sha256(f"{communication}{datetime.utcnow()}".encode()).hexdigest()[
-                :16
-            ],
+            "log_id": hashlib.sha256(
+                f"{communication}{datetime.utcnow()}".encode()
+            ).hexdigest()[:16],
         }
         self._communication_log.append(safe_comm)
 
@@ -632,7 +646,9 @@ class OperationalRuleEngine:
             RuleCategory.COMMUNICATION: self.communication,
         }
 
-    def check_operation(self, category: RuleCategory, operation: Dict[str, Any]) -> RuleCheckResult:
+    def check_operation(
+        self, category: RuleCategory, operation: Dict[str, Any]
+    ) -> RuleCheckResult:
         """æª¢æŸ¥ç‰¹å®šé¡åˆ¥çš„æ“ä½œ"""
         rule = self._all_rules.get(category)
         if rule:
diff --git a/workspace/src/core/ai_constitution/policy_as_prompt.py b/workspace/src/core/ai_constitution/policy_as_prompt.py
index ed2e41a..7a47ff2 100644
--- a/workspace/src/core/ai_constitution/policy_as_prompt.py
+++ b/workspace/src/core/ai_constitution/policy_as_prompt.py
@@ -200,7 +200,9 @@ class PolicyEnforcer:
 
         # æŒ‰å„ªå…ˆç´šæ’åºè­·æ¬„
         sorted_guardrails = sorted(
-            self._guardrails.values(), key=lambda g: g.policy_prompt.priority, reverse=True
+            self._guardrails.values(),
+            key=lambda g: g.policy_prompt.priority,
+            reverse=True,
         )
 
         for guardrail in sorted_guardrails:
@@ -217,7 +219,9 @@ class PolicyEnforcer:
                 # æ ¹æ“šåŸ·è¡Œå‹•ä½œæ±ºå®šè™•ç†
                 action = guardrail.policy_prompt.enforcement_action
                 if action == EnforcementAction.DENY:
-                    results["actions_taken"].append(f"æ‹’çµ•: {guardrail.policy_prompt.policy_name}")
+                    results["actions_taken"].append(
+                        f"æ‹’çµ•: {guardrail.policy_prompt.policy_name}"
+                    )
                     break  # ç«‹å³åœæ­¢
                 elif action == EnforcementAction.WARN:
                     results["warnings"].extend(check_result["violations"])
@@ -264,7 +268,9 @@ class PolicyEnforcer:
                 1 for g in self._guardrails.values() if g.policy_prompt.enabled
             ),
             "total_checks": sum(g.check_count for g in self._guardrails.values()),
-            "total_violations": sum(g.violation_count for g in self._guardrails.values()),
+            "total_violations": sum(
+                g.violation_count for g in self._guardrails.values()
+            ),
         }
 
         if stats["total_checks"] > 0:
@@ -513,7 +519,9 @@ class PolicyAsPrompt:
         patterns.extend(prohibit_matches)
 
         # æŸ¥æ‰¾è‹±æ–‡é—œéµè©
-        english_matches = re.findall(r"prohibit[ed]?\s+([a-zA-Z_]+)", document, re.IGNORECASE)
+        english_matches = re.findall(
+            r"prohibit[ed]?\s+([a-zA-Z_]+)", document, re.IGNORECASE
+        )
         patterns.extend(english_matches)
 
         return patterns
@@ -531,7 +539,9 @@ class PolicyAsPrompt:
         else:
             return EnforcementAction.WARN
 
-    def enforce_policies(self, content: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
+    def enforce_policies(
+        self, content: str, context: Dict[str, Any] = None
+    ) -> Dict[str, Any]:
         """åŸ·è¡Œæ‰€æœ‰æ”¿ç­–"""
         return self.enforcer.enforce(content, context)
 
diff --git a/workspace/src/core/ai_decision_engine.py b/workspace/src/core/ai_decision_engine.py
index 18e20ce..72ebb76 100644
--- a/workspace/src/core/ai_decision_engine.py
+++ b/workspace/src/core/ai_decision_engine.py
@@ -131,7 +131,12 @@ class AIDecisionEngine:
     """
 
     # Decision weights for different criteria
-    DEFAULT_WEIGHTS = {"benefit": 0.4, "risk": 0.3, "confidence": 0.2, "prerequisites_met": 0.1}
+    DEFAULT_WEIGHTS = {
+        "benefit": 0.4,
+        "risk": 0.3,
+        "confidence": 0.2,
+        "prerequisites_met": 0.1,
+    }
 
     def __init__(self):
         """Initialize the AI Decision Engine"""
@@ -259,7 +264,9 @@ class AIDecisionEngine:
 
         return scored_options
 
-    def _check_prerequisites(self, option: DecisionOption, context: DecisionContext) -> bool:
+    def _check_prerequisites(
+        self, option: DecisionOption, context: DecisionContext
+    ) -> bool:
         """Check if all prerequisites are met"""
         if not option.prerequisites:
             return True
@@ -281,7 +288,9 @@ class AIDecisionEngine:
 
         patterns = self.learned_patterns[domain]
         similar_decisions = [
-            p for p in patterns if p.get("option_name") == option.name and p.get("success", False)
+            p
+            for p in patterns
+            if p.get("option_name") == option.name and p.get("success", False)
         ]
 
         if not similar_decisions:
@@ -303,7 +312,10 @@ class AIDecisionEngine:
         return ConfidenceLevel.UNCERTAIN
 
     def _generate_reasoning(
-        self, context: DecisionContext, selected: DecisionOption, alternatives: List[DecisionOption]
+        self,
+        context: DecisionContext,
+        selected: DecisionOption,
+        alternatives: List[DecisionOption],
     ) -> str:
         """Generate human-readable reasoning for decision"""
         parts = [
@@ -320,7 +332,9 @@ class AIDecisionEngine:
             )
 
         if context.objectives:
-            parts.append(f"- Aligns with objectives: {', '.join(context.objectives[:3])}")
+            parts.append(
+                f"- Aligns with objectives: {', '.join(context.objectives[:3])}"
+            )
 
         return "\n".join(parts)
 
@@ -344,7 +358,9 @@ class AIDecisionEngine:
             confidence_level=ConfidenceLevel.UNCERTAIN,
         )
 
-    def _learn_from_decision(self, context: DecisionContext, decision: Decision) -> None:
+    def _learn_from_decision(
+        self, context: DecisionContext, decision: Decision
+    ) -> None:
         """Learn from decision for future improvements"""
         if context.domain not in self.learned_patterns:
             self.learned_patterns[context.domain] = []
@@ -362,7 +378,10 @@ class AIDecisionEngine:
         self.stats["learning_cycles"] += 1
 
     async def predict_outcome(
-        self, current_state: Dict[str, Any], prediction_type: str, horizon: str = "short_term"
+        self,
+        current_state: Dict[str, Any],
+        prediction_type: str,
+        horizon: str = "short_term",
     ) -> PredictionResult:
         """
         Predict future outcome based on current state
@@ -386,7 +405,9 @@ class AIDecisionEngine:
         probability = self._calculate_prediction_probability(factors)
 
         # Generate recommendations
-        recommendations = self._generate_recommendations(prediction_type, probability, factors)
+        recommendations = self._generate_recommendations(
+            prediction_type, probability, factors
+        )
 
         # Determine predicted outcome
         predicted_outcome = {
@@ -429,7 +450,9 @@ class AIDecisionEngine:
                 "value": value,
                 "impact": self._calculate_factor_impact(key, value, prediction_type),
                 "direction": (
-                    "positive" if isinstance(value, (int, float)) and value > 0 else "neutral"
+                    "positive"
+                    if isinstance(value, (int, float)) and value > 0
+                    else "neutral"
                 ),
             }
             factors.append(factor)
@@ -492,13 +515,20 @@ class AIDecisionEngine:
     def _assess_impact(self, prediction_type: str, probability: float) -> str:
         """Assess the impact level of prediction"""
         if probability > 0.8:
-            return "high_positive" if "success" in prediction_type.lower() else "high_negative"
+            return (
+                "high_positive"
+                if "success" in prediction_type.lower()
+                else "high_negative"
+            )
         elif probability > 0.5:
             return "moderate"
         return "low"
 
     def record_outcome(
-        self, decision_id: str, success: bool, outcome_data: Optional[Dict[str, Any]] = None
+        self,
+        decision_id: str,
+        success: bool,
+        outcome_data: Optional[Dict[str, Any]] = None,
     ) -> None:
         """
         Record the outcome of a decision for learning
@@ -533,7 +563,10 @@ class AIDecisionEngine:
             "predictions_made": self.stats["predictions_made"],
             "successful_decisions": self.stats["successful_decisions"],
             "success_rate": round(
-                self.stats["successful_decisions"] / max(self.stats["decisions_made"], 1) * 100, 2
+                self.stats["successful_decisions"]
+                / max(self.stats["decisions_made"], 1)
+                * 100,
+                2,
             ),
             "learning_cycles": self.stats["learning_cycles"],
             "domains_learned": list(self.learned_patterns.keys()),
diff --git a/workspace/src/core/auto_bug_detector.py b/workspace/src/core/auto_bug_detector.py
index bd22585..d068ccf 100644
--- a/workspace/src/core/auto_bug_detector.py
+++ b/workspace/src/core/auto_bug_detector.py
@@ -489,7 +489,9 @@ class AutoBugDetector:
         self._fix_templates["MISSING_ERROR_HANDLING"] = fix_missing_error_handling
         self._fix_templates["HARDCODED_VALUES"] = fix_hardcoded_values
 
-    def _assess_fix_confidence(self, bug: DetectedBug, fixed_code: str) -> FixConfidence:
+    def _assess_fix_confidence(
+        self, bug: DetectedBug, fixed_code: str
+    ) -> FixConfidence:
         """Assess confidence level of a fix (è©•ä¼°ä¿®å¾©çš„ç½®ä¿¡åº¦)"""
         # ç°¡å–®çš„å•Ÿç™¼å¼è©•ä¼°
         if bug.category == BugCategory.SECURITY:
@@ -566,11 +568,15 @@ class AutoBugDetector:
                 self._stats["total_verified"] / self._stats["total_fixed"] * 100, 2
             )
 
-    def register_custom_detector(self, detector: Callable[[str], list[DetectedBug]]) -> None:
+    def register_custom_detector(
+        self, detector: Callable[[str], list[DetectedBug]]
+    ) -> None:
         """Register a custom bug detector (è¨»å†Šè‡ªå®šç¾©éŒ¯èª¤æª¢æ¸¬å™¨)"""
         self._custom_detectors.append(detector)
 
-    def register_fix_template(self, pattern: str, template: Callable[[str], str]) -> None:
+    def register_fix_template(
+        self, pattern: str, template: Callable[[str], str]
+    ) -> None:
         """Register a custom fix template (è¨»å†Šè‡ªå®šç¾©ä¿®å¾©æ¨¡æ¿)"""
         self._fix_templates[pattern] = template
 
diff --git a/workspace/src/core/auto_governance_hub.py b/workspace/src/core/auto_governance_hub.py
index e67a656..60c5619 100644
--- a/workspace/src/core/auto_governance_hub.py
+++ b/workspace/src/core/auto_governance_hub.py
@@ -145,12 +145,20 @@ class AutoGovernanceHub:
         "deployment_auto_approve": {
             "type": PolicyType.DEPLOYMENT,
             "enforcement": PolicyEnforcement.AUTO_CORRECT,
-            "auto_approve": ["risk_score_below_threshold", "tests_passing", "no_breaking_changes"],
+            "auto_approve": [
+                "risk_score_below_threshold",
+                "tests_passing",
+                "no_breaking_changes",
+            ],
         },
         "security_auto_enforce": {
             "type": PolicyType.SECURITY,
             "enforcement": PolicyEnforcement.STRICT,
-            "auto_approve": ["no_privilege_escalation", "encryption_enabled", "audit_trail_active"],
+            "auto_approve": [
+                "no_privilege_escalation",
+                "encryption_enabled",
+                "audit_trail_active",
+            ],
         },
     }
 
@@ -190,7 +198,10 @@ class AutoGovernanceHub:
                     "no_breaking_changes == true",
                     "rollback_available == true",
                 ],
-                auto_deny_conditions=["risk_score > 0.9", "security_vulnerabilities > 0"],
+                auto_deny_conditions=[
+                    "risk_score > 0.9",
+                    "security_vulnerabilities > 0",
+                ],
             )
         )
 
@@ -243,7 +254,9 @@ class AutoGovernanceHub:
         self.policies[policy.policy_id] = policy
         logger.info(f"Policy added: {policy.name}")
 
-    async def process_change_request(self, request: ChangeRequest) -> GovernanceDecision:
+    async def process_change_request(
+        self, request: ChangeRequest
+    ) -> GovernanceDecision:
         """
         Process change request with fully autonomous governance
 
@@ -293,7 +306,9 @@ class AutoGovernanceHub:
             policy_applied=policy_applied,
             reasoning=reasoning,
             conditions_met=[
-                r["conditions_met"] for r in evaluation_results if r.get("conditions_met")
+                r["conditions_met"]
+                for r in evaluation_results
+                if r.get("conditions_met")
             ],
             auto_corrections=auto_corrections,
         )
@@ -307,12 +322,15 @@ class AutoGovernanceHub:
         self.decisions.append(decision)
 
         logger.info(
-            f"Governance decision: {decision_id} - {action.value} " f"(policy: {policy_applied})"
+            f"Governance decision: {decision_id} - {action.value} "
+            f"(policy: {policy_applied})"
         )
 
         return decision
 
-    def _get_applicable_policies(self, change_type: ChangeType) -> List[GovernancePolicy]:
+    def _get_applicable_policies(
+        self, change_type: ChangeType
+    ) -> List[GovernancePolicy]:
         """Get policies applicable to change type"""
         type_mapping = {
             ChangeType.DEPLOYMENT: [PolicyType.DEPLOYMENT, PolicyType.SECURITY],
@@ -435,9 +453,15 @@ class AutoGovernanceHub:
         """Determine final action from all policy evaluations"""
         # Priority: DENY > AUTO_FIX > ESCALATE_TO_SYSTEM > APPROVE
 
-        deny_results = [r for r in evaluation_results if r["action"] == GovernanceAction.DENY]
+        deny_results = [
+            r for r in evaluation_results if r["action"] == GovernanceAction.DENY
+        ]
         if deny_results:
-            return (GovernanceAction.DENY, deny_results[0]["reason"], deny_results[0]["policy_id"])
+            return (
+                GovernanceAction.DENY,
+                deny_results[0]["reason"],
+                deny_results[0]["policy_id"],
+            )
 
         auto_fix_results = [
             r for r in evaluation_results if r["action"] == GovernanceAction.AUTO_FIX
@@ -450,7 +474,9 @@ class AutoGovernanceHub:
             )
 
         escalate_results = [
-            r for r in evaluation_results if r["action"] == GovernanceAction.ESCALATE_TO_SYSTEM
+            r
+            for r in evaluation_results
+            if r["action"] == GovernanceAction.ESCALATE_TO_SYSTEM
         ]
         if escalate_results:
             # System escalation means more analysis, not human approval
@@ -460,7 +486,9 @@ class AutoGovernanceHub:
                 escalate_results[0]["policy_id"],
             )
 
-        approve_results = [r for r in evaluation_results if r["action"] == GovernanceAction.APPROVE]
+        approve_results = [
+            r for r in evaluation_results if r["action"] == GovernanceAction.APPROVE
+        ]
         if approve_results:
             return (
                 GovernanceAction.APPROVE,
@@ -556,7 +584,9 @@ class AutoGovernanceHub:
                             "policy": policy.name,
                             "issue": check_result["issue"],
                             "severity": (
-                                "high" if policy.enforcement == PolicyEnforcement.STRICT else "low"
+                                "high"
+                                if policy.enforcement == PolicyEnforcement.STRICT
+                                else "low"
                             ),
                         }
                     )
@@ -571,7 +601,9 @@ class AutoGovernanceHub:
         self.compliance_cache[scope] = status
         return status
 
-    async def _check_policy_compliance(self, policy: GovernancePolicy) -> Dict[str, Any]:
+    async def _check_policy_compliance(
+        self, policy: GovernancePolicy
+    ) -> Dict[str, Any]:
         """Check compliance with a specific policy"""
         # Simulated compliance check
         await asyncio.sleep(0.01)
@@ -598,7 +630,9 @@ class AutoGovernanceHub:
 
     def get_statistics(self) -> Dict[str, Any]:
         """Get governance hub statistics"""
-        approval_rate = self.stats["auto_approved"] / max(self.stats["total_requests"], 1) * 100
+        approval_rate = (
+            self.stats["auto_approved"] / max(self.stats["total_requests"], 1) * 100
+        )
 
         return {
             "total_requests": self.stats["total_requests"],
diff --git a/workspace/src/core/ci_error_handler/auto_fix_engine.py b/workspace/src/core/ci_error_handler/auto_fix_engine.py
index 0986965..b09beb8 100644
--- a/workspace/src/core/ci_error_handler/auto_fix_engine.py
+++ b/workspace/src/core/ci_error_handler/auto_fix_engine.py
@@ -250,7 +250,9 @@ Provide:
     def _generate_attempt_id(self) -> str:
         """Generate unique attempt ID"""
         self._attempt_counter += 1
-        return f"FIX-{datetime.now().strftime('%Y%m%d%H%M%S')}-{self._attempt_counter:04d}"
+        return (
+            f"FIX-{datetime.now().strftime('%Y%m%d%H%M%S')}-{self._attempt_counter:04d}"
+        )
 
     def analyze_fix_options(self, error: CIError) -> Dict[str, Any]:
         """
@@ -285,7 +287,9 @@ Provide:
 
         # Determine recommended strategy
         if options["matching_rules"]:
-            safe_rules = [r for r in options["matching_rules"] if r["safe_to_auto_apply"]]
+            safe_rules = [
+                r for r in options["matching_rules"] if r["safe_to_auto_apply"]
+            ]
             if safe_rules:
                 options["recommended_strategy"] = FixStrategy.AUTO_FIX
             else:
diff --git a/workspace/src/core/ci_error_handler/ci_error_analyzer.py b/workspace/src/core/ci_error_handler/ci_error_analyzer.py
index 11b7e0d..efb71e6 100644
--- a/workspace/src/core/ci_error_handler/ci_error_analyzer.py
+++ b/workspace/src/core/ci_error_handler/ci_error_analyzer.py
@@ -286,7 +286,9 @@ class CIErrorAnalyzer:
     def _generate_error_id(self) -> str:
         """Generate a unique error ID"""
         self._error_counter += 1
-        return f"ERR-{datetime.now().strftime('%Y%m%d%H%M%S')}-{self._error_counter:04d}"
+        return (
+            f"ERR-{datetime.now().strftime('%Y%m%d%H%M%S')}-{self._error_counter:04d}"
+        )
 
     def analyze_log(self, log_content: str, source: str = "unknown") -> List[CIError]:
         """
@@ -345,7 +347,9 @@ class CIErrorAnalyzer:
 
         return errors
 
-    def _extract_file_info(self, log_content: str, category: ErrorCategory) -> Dict[str, Any]:
+    def _extract_file_info(
+        self, log_content: str, category: ErrorCategory
+    ) -> Dict[str, Any]:
         """Extract file path and line number from log content"""
         # Common patterns for file:line:column format
         patterns = [
@@ -367,7 +371,9 @@ class CIErrorAnalyzer:
 
         return {}
 
-    def _extract_code_snippet(self, log_content: str, file_info: Dict[str, Any]) -> Optional[str]:
+    def _extract_code_snippet(
+        self, log_content: str, file_info: Dict[str, Any]
+    ) -> Optional[str]:
         """Extract code snippet from log content if available"""
         # Look for code snippet markers
         snippet_patterns = [
diff --git a/workspace/src/core/ci_error_handler/fix_status_tracker.py b/workspace/src/core/ci_error_handler/fix_status_tracker.py
index 67b1395..8b4514a 100644
--- a/workspace/src/core/ci_error_handler/fix_status_tracker.py
+++ b/workspace/src/core/ci_error_handler/fix_status_tracker.py
@@ -259,7 +259,9 @@ class FixStatusTracker:
 
         return tracked
 
-    def link_pr(self, error_id: str, pr_number: int, pr_url: str) -> Optional[TrackedFix]:
+    def link_pr(
+        self, error_id: str, pr_number: int, pr_url: str
+    ) -> Optional[TrackedFix]:
         """
         Link a PR to a tracked fix
 
@@ -407,13 +409,19 @@ class FixStatusTracker:
 
     def get_pending_fixes(self) -> List[TrackedFix]:
         """Get all pending fixes"""
-        pending_statuses = {FixStatus.PENDING, FixStatus.IN_PROGRESS, FixStatus.PR_CREATED}
+        pending_statuses = {
+            FixStatus.PENDING,
+            FixStatus.IN_PROGRESS,
+            FixStatus.PR_CREATED,
+        }
         return [f for f in self._tracked_fixes.values() if f.status in pending_statuses]
 
     def get_resolved_fixes(self) -> List[TrackedFix]:
         """Get all resolved fixes"""
         resolved_statuses = {FixStatus.VERIFIED, FixStatus.PR_MERGED}
-        return [f for f in self._tracked_fixes.values() if f.status in resolved_statuses]
+        return [
+            f for f in self._tracked_fixes.values() if f.status in resolved_statuses
+        ]
 
     def calculate_metrics(self, since: Optional[datetime] = None) -> FixMetrics:
         """
@@ -478,7 +486,9 @@ class FixStatusTracker:
         tracked = self._tracked_fixes.get(error_id)
         return tracked.history if tracked else []
 
-    def generate_summary_report(self, since: Optional[datetime] = None) -> Dict[str, Any]:
+    def generate_summary_report(
+        self, since: Optional[datetime] = None
+    ) -> Dict[str, Any]:
         """
         Generate a summary report of fix tracking
 
diff --git a/workspace/src/core/ci_error_handler/issue_manager.py b/workspace/src/core/ci_error_handler/issue_manager.py
index 1f9d8c9..a050968 100644
--- a/workspace/src/core/ci_error_handler/issue_manager.py
+++ b/workspace/src/core/ci_error_handler/issue_manager.py
@@ -220,7 +220,10 @@ class IssueManager:
         self._issues: Dict[str, CIIssue] = {}
 
     def create_issue_content(
-        self, error: CIError, workflow_info: Dict[str, Any], template_id: str = "default"
+        self,
+        error: CIError,
+        workflow_info: Dict[str, Any],
+        template_id: str = "default",
     ) -> Dict[str, Any]:
         """
         Create issue content from error
@@ -286,7 +289,9 @@ class IssueManager:
             return issue
         return None
 
-    def add_fix_attempt(self, error_id: str, fix_info: Dict[str, Any]) -> Optional[CIIssue]:
+    def add_fix_attempt(
+        self, error_id: str, fix_info: Dict[str, Any]
+    ) -> Optional[CIIssue]:
         """Add a fix attempt to an issue"""
         if error_id in self._issues:
             issue = self._issues[error_id]
@@ -297,7 +302,9 @@ class IssueManager:
             return issue
         return None
 
-    def add_comment(self, error_id: str, comment: str, author: str = "bot") -> Optional[CIIssue]:
+    def add_comment(
+        self, error_id: str, comment: str, author: str = "bot"
+    ) -> Optional[CIIssue]:
         """Add a comment to an issue"""
         if error_id in self._issues:
             issue = self._issues[error_id]
@@ -322,7 +329,11 @@ class IssueManager:
 
     def get_open_issues(self) -> List[CIIssue]:
         """Get all open issues"""
-        open_statuses = {IssueStatus.OPEN, IssueStatus.IN_PROGRESS, IssueStatus.FIX_ATTEMPTED}
+        open_statuses = {
+            IssueStatus.OPEN,
+            IssueStatus.IN_PROGRESS,
+            IssueStatus.FIX_ATTEMPTED,
+        }
         return [i for i in self._issues.values() if i.status in open_statuses]
 
     def check_duplicate(self, error: CIError) -> Optional[CIIssue]:
diff --git a/workspace/src/core/cloud_agent_delegation/cloud_provider_adapter.py b/workspace/src/core/cloud_agent_delegation/cloud_provider_adapter.py
index 47539dd..349ba6a 100644
--- a/workspace/src/core/cloud_agent_delegation/cloud_provider_adapter.py
+++ b/workspace/src/core/cloud_agent_delegation/cloud_provider_adapter.py
@@ -167,7 +167,9 @@ class CloudProviderAdapter:
             result.result = execution_result
             result.status = "success"
             result.completed_at = datetime.now(timezone.utc)
-            result.duration_ms = (result.completed_at - result.started_at).total_seconds() * 1000
+            result.duration_ms = (
+                result.completed_at - result.started_at
+            ).total_seconds() * 1000
 
             self._last_execution = datetime.now(timezone.utc)
 
@@ -229,7 +231,9 @@ class CloudProviderAdapter:
             "execution_count": self._execution_count,
             "error_count": self._error_count,
             "error_rate": self._error_count / max(self._execution_count, 1),
-            "last_execution": self._last_execution.isoformat() if self._last_execution else None,
+            "last_execution": (
+                self._last_execution.isoformat() if self._last_execution else None
+            ),
             "config": self.config.to_dict(),
         }
 
@@ -305,7 +309,9 @@ class AWSLambdaAdapter(CloudProviderAdapter):
     """Adapter for AWS Lambda"""
 
     def __init__(self, name: str, region: str = "us-east-1", **kwargs):
-        config = ProviderConfig(name=name, provider_type=ProviderType.AWS, region=region, **kwargs)
+        config = ProviderConfig(
+            name=name, provider_type=ProviderType.AWS, region=region, **kwargs
+        )
         super().__init__(config)
 
 
@@ -317,7 +323,9 @@ class GCPCloudFunctionsAdapter(CloudProviderAdapter):
         if "runtime" not in kwargs:
             kwargs["runtime"] = "nodejs18"
 
-        config = ProviderConfig(name=name, provider_type=ProviderType.GCP, region=region, **kwargs)
+        config = ProviderConfig(
+            name=name, provider_type=ProviderType.GCP, region=region, **kwargs
+        )
         super().__init__(config)
 
 
@@ -350,6 +358,8 @@ def create_provider_adapter(
         return CloudProviderAdapter(config)
 
 
-def create_provider_config(name: str, provider_type: ProviderType, **kwargs) -> ProviderConfig:
+def create_provider_config(
+    name: str, provider_type: ProviderType, **kwargs
+) -> ProviderConfig:
     """Create a provider configuration"""
     return ProviderConfig(name=name, provider_type=provider_type, **kwargs)
diff --git a/workspace/src/core/cloud_agent_delegation/delegation_manager.py b/workspace/src/core/cloud_agent_delegation/delegation_manager.py
index 4442956..70031eb 100644
--- a/workspace/src/core/cloud_agent_delegation/delegation_manager.py
+++ b/workspace/src/core/cloud_agent_delegation/delegation_manager.py
@@ -347,7 +347,9 @@ class DelegationManager:
         tasks = list(self._tasks.values())
 
         if status:
-            task_ids = [tid for tid, result in self._results.items() if result.status == status]
+            task_ids = [
+                tid for tid, result in self._results.items() if result.status == status
+            ]
             tasks = [t for t in tasks if t.id in task_ids]
 
         if task_type:
@@ -365,7 +367,9 @@ class DelegationManager:
         provider_counts = {}
         for result in self._results.values():
             if result.provider:
-                provider_counts[result.provider] = provider_counts.get(result.provider, 0) + 1
+                provider_counts[result.provider] = (
+                    provider_counts.get(result.provider, 0) + 1
+                )
 
         total_duration = sum(r.duration_ms for r in self._results.values())
         avg_duration = total_duration / max(len(self._results), 1)
@@ -400,7 +404,9 @@ class DelegationManager:
             attempts = 0
             last_error = None
 
-            while attempts < (self.config.max_retries if self.config.retry_enabled else 1):
+            while attempts < (
+                self.config.max_retries if self.config.retry_enabled else 1
+            ):
                 attempts += 1
                 result.attempts = attempts
 
@@ -419,7 +425,9 @@ class DelegationManager:
                     self._running_tasks[task.id] = exec_task
 
                     # Wait with timeout
-                    execution_result = await asyncio.wait_for(exec_task, timeout=task.timeout)
+                    execution_result = await asyncio.wait_for(
+                        exec_task, timeout=task.timeout
+                    )
 
                     result.result = execution_result
                     result.status = DelegationStatus.COMPLETED
@@ -428,7 +436,9 @@ class DelegationManager:
                         result.completed_at - result.started_at
                     ).total_seconds() * 1000
 
-                    await self._emit_event("task_completed", {"result": result.to_dict()})
+                    await self._emit_event(
+                        "task_completed", {"result": result.to_dict()}
+                    )
                     break
 
                 except asyncio.TimeoutError:
diff --git a/workspace/src/core/cloud_agent_delegation/load_balancer.py b/workspace/src/core/cloud_agent_delegation/load_balancer.py
index 6b12006..6b38545 100644
--- a/workspace/src/core/cloud_agent_delegation/load_balancer.py
+++ b/workspace/src/core/cloud_agent_delegation/load_balancer.py
@@ -163,7 +163,9 @@ class LoadBalancer:
 
         # Initialize health status
         self._health[name] = ProviderHealth(
-            provider=name, status=HealthStatus.UNKNOWN, last_check=datetime.now(timezone.utc)
+            provider=name,
+            status=HealthStatus.UNKNOWN,
+            last_check=datetime.now(timezone.utc),
         )
 
         self._rebuild_weighted_list()
@@ -376,7 +378,8 @@ class LoadBalancer:
                         # Perform health check
                         if hasattr(provider, "health_check"):
                             result = await asyncio.wait_for(
-                                provider.health_check(), timeout=self.config.health_check_timeout
+                                provider.health_check(),
+                                timeout=self.config.health_check_timeout,
                             )
                             healthy = result.get("healthy", True)
                         else:
@@ -390,7 +393,9 @@ class LoadBalancer:
                         self.update_health(name, healthy, latency_ms)
 
                     except asyncio.TimeoutError:
-                        self.update_health(name, False, self.config.health_check_timeout * 1000)
+                        self.update_health(
+                            name, False, self.config.health_check_timeout * 1000
+                        )
                     except Exception as e:
                         logger.error(f"Health check failed for {name}: {e}")
                         self.update_health(name, False)
diff --git a/workspace/src/core/cloud_agent_delegation/task_router.py b/workspace/src/core/cloud_agent_delegation/task_router.py
index 0338a23..e2930d2 100644
--- a/workspace/src/core/cloud_agent_delegation/task_router.py
+++ b/workspace/src/core/cloud_agent_delegation/task_router.py
@@ -225,9 +225,9 @@ class TaskRouter:
         for condition_type, condition_value in conditions.items():
             if condition_type == "min_priority":
                 task_priority = context.get("priority", "medium")
-                if self._priority_order.index(task_priority) > self._priority_order.index(
-                    condition_value
-                ):
+                if self._priority_order.index(
+                    task_priority
+                ) > self._priority_order.index(condition_value):
                     return False
 
             elif condition_type == "max_payload_size":
@@ -257,7 +257,9 @@ class TaskRouter:
         rule_counts = {}
 
         for result in self._routing_history:
-            provider_counts[result.provider] = provider_counts.get(result.provider, 0) + 1
+            provider_counts[result.provider] = (
+                provider_counts.get(result.provider, 0) + 1
+            )
             if result.rule_name:
                 rule_counts[result.rule_name] = rule_counts.get(result.rule_name, 0) + 1
 
@@ -300,16 +302,23 @@ class TaskRouter:
 
 # Factory functions
 def create_task_router(
-    default_provider: str = "default", strategy: RoutingStrategy = RoutingStrategy.PATTERN_MATCH
+    default_provider: str = "default",
+    strategy: RoutingStrategy = RoutingStrategy.PATTERN_MATCH,
 ) -> TaskRouter:
     """Create a new TaskRouter instance"""
     return TaskRouter(default_provider, strategy)
 
 
-def create_routing_rule(name: str, pattern: str, preferred_provider: str, **kwargs) -> RoutingRule:
+def create_routing_rule(
+    name: str, pattern: str, preferred_provider: str, **kwargs
+) -> RoutingRule:
     """Create a new RoutingRule"""
     return RoutingRule(
-        id=str(uuid4()), name=name, pattern=pattern, preferred_provider=preferred_provider, **kwargs
+        id=str(uuid4()),
+        name=name,
+        pattern=pattern,
+        preferred_provider=preferred_provider,
+        **kwargs,
     )
 
 
diff --git a/workspace/src/core/context_understanding_engine.py b/workspace/src/core/context_understanding_engine.py
index 9da3c62..71df2ab 100644
--- a/workspace/src/core/context_understanding_engine.py
+++ b/workspace/src/core/context_understanding_engine.py
@@ -135,7 +135,13 @@ class ContextUnderstandingEngine:
                 "éŒ¯èª¤",
                 "å•é¡Œ",
             ],
-            IntentCategory.REFACTORING: ["é‡æ§‹", "refactor", "restructure", "clean", "æ•´ç†"],
+            IntentCategory.REFACTORING: [
+                "é‡æ§‹",
+                "refactor",
+                "restructure",
+                "clean",
+                "æ•´ç†",
+            ],
             IntentCategory.NEW_FEATURE: [
                 "æ–°å¢",
                 "add",
@@ -153,15 +159,36 @@ class ContextUnderstandingEngine:
                 "æ¼æ´",
                 "åŠ å¯†",
             ],
-            IntentCategory.DOCUMENTATION: ["æ–‡æª”", "document", "readme", "èªªæ˜", "è¨»è§£", "comment"],
+            IntentCategory.DOCUMENTATION: [
+                "æ–‡æª”",
+                "document",
+                "readme",
+                "èªªæ˜",
+                "è¨»è§£",
+                "comment",
+            ],
             IntentCategory.TESTING: ["æ¸¬è©¦", "test", "unit", "integration", "é©—è­‰"],
             IntentCategory.DEPLOYMENT: ["éƒ¨ç½²", "deploy", "release", "ç™¼å¸ƒ", "ä¸Šç·š"],
-            IntentCategory.QUERY: ["æŸ¥è©¢", "query", "find", "search", "get", "æŸ¥æ‰¾", "ç²å–"],
+            IntentCategory.QUERY: [
+                "æŸ¥è©¢",
+                "query",
+                "find",
+                "search",
+                "get",
+                "æŸ¥æ‰¾",
+                "ç²å–",
+            ],
         }
 
         # éš±å«éœ€æ±‚æ¨¡å¼
         self._implicit_patterns = {
-            "performance": ["å¤§é‡æ•¸æ“š", "high volume", "scalability", "concurrent", "ä¸¦ç™¼"],
+            "performance": [
+                "å¤§é‡æ•¸æ“š",
+                "high volume",
+                "scalability",
+                "concurrent",
+                "ä¸¦ç™¼",
+            ],
             "security": ["ç”¨æˆ¶è³‡æ–™", "user data", "password", "token", "æ•æ„Ÿ"],
             "reliability": ["ç”Ÿç”¢ç’°å¢ƒ", "production", "critical", "é‡è¦", "24/7"],
             "pagination": ["åˆ—è¡¨", "list", "all", "å…¨éƒ¨", "findMany"],
@@ -190,7 +217,9 @@ class ContextUnderstandingEngine:
         relevant_contexts = self._get_relevant_contexts(user_id, request)
 
         # 3. è­˜åˆ¥éš±å«éœ€æ±‚
-        implicit_requirements = self._identify_implicit_requirements(request, relevant_contexts)
+        implicit_requirements = self._identify_implicit_requirements(
+            request, relevant_contexts
+        )
         parsed_intent.implicit_requirements = implicit_requirements
 
         # 4. æª¢æ¸¬æ­§ç¾©
@@ -200,7 +229,9 @@ class ContextUnderstandingEngine:
         clarification_needed = self._generate_clarifications(ambiguities, parsed_intent)
 
         # 6. æ¨è–¦æ–¹æ¡ˆ
-        recommended_approach = self._recommend_approach(parsed_intent, relevant_contexts)
+        recommended_approach = self._recommend_approach(
+            parsed_intent, relevant_contexts
+        )
 
         # 7. è¨ˆç®—ç†è§£ç½®ä¿¡åº¦
         understanding_confidence = self._calculate_understanding_confidence(
@@ -239,12 +270,18 @@ class ContextUnderstandingEngine:
         # æ’åºæ‰¾å‡ºä¸»è¦å’Œæ¬¡è¦æ„åœ–
         sorted_intents = sorted(intent_scores.items(), key=lambda x: x[1], reverse=True)
 
-        primary_intent = sorted_intents[0][0] if sorted_intents[0][1] > 0 else IntentCategory.QUERY
-        secondary_intents = [intent for intent, score in sorted_intents[1:4] if score > 0]
+        primary_intent = (
+            sorted_intents[0][0] if sorted_intents[0][1] > 0 else IntentCategory.QUERY
+        )
+        secondary_intents = [
+            intent for intent, score in sorted_intents[1:4] if score > 0
+        ]
 
         # è¨ˆç®—ç½®ä¿¡åº¦
         total_score = sum(intent_scores.values())
-        confidence = sorted_intents[0][1] / max(total_score, 1.0) if total_score > 0 else 0.5
+        confidence = (
+            sorted_intents[0][1] / max(total_score, 1.0) if total_score > 0 else 0.5
+        )
 
         # æå–å¯¦é«”
         entities = self._extract_entities(request)
@@ -269,7 +306,9 @@ class ContextUnderstandingEngine:
         entities: dict[str, Any] = {}
 
         # æå–ç³»çµ±/æœå‹™åç¨±
-        system_pattern = r"(èˆŠ|æ–°|è€|source|target|from|to)\s*(ç³»çµ±|system|service|æœå‹™)"
+        system_pattern = (
+            r"(èˆŠ|æ–°|è€|source|target|from|to)\s*(ç³»çµ±|system|service|æœå‹™)"
+        )
         matches = re.findall(system_pattern, request, re.IGNORECASE)
         if matches:
             entities["systems"] = [f"{m[0]}_{m[1]}" for m in matches]
@@ -287,7 +326,9 @@ class ContextUnderstandingEngine:
             entities["quantities"] = [{"value": m[0], "unit": m[1]} for m in matches]
 
         # æå–æ™‚é–“ç›¸é—œ
-        time_pattern = r"(æ¯\s*å¤©|daily|æ¯\s*å°æ™‚|hourly|å¯¦æ™‚|real.?time|å®šæœŸ|scheduled)"
+        time_pattern = (
+            r"(æ¯\s*å¤©|daily|æ¯\s*å°æ™‚|hourly|å¯¦æ™‚|real.?time|å®šæœŸ|scheduled)"
+        )
         matches = re.findall(time_pattern, request, re.IGNORECASE)
         if matches:
             entities["timing"] = list(set(matches))
@@ -362,7 +403,9 @@ class ContextUnderstandingEngine:
 
         return implicit
 
-    def _detect_ambiguities(self, request: str, parsed_intent: ParsedIntent) -> list[str]:
+    def _detect_ambiguities(
+        self, request: str, parsed_intent: ParsedIntent
+    ) -> list[str]:
         """Detect ambiguities in the request (æª¢æ¸¬è«‹æ±‚ä¸­çš„æ­§ç¾©)"""
         ambiguities = []
 
@@ -383,7 +426,10 @@ class ContextUnderstandingEngine:
                 ambiguities.append("Timing/frequency of operation not specified")
 
         # è¡çªçš„ç´„æŸ
-        if "fast" in parsed_intent.constraints and "validation" in parsed_intent.constraints:
+        if (
+            "fast" in parsed_intent.constraints
+            and "validation" in parsed_intent.constraints
+        ):
             ambiguities.append("Speed vs validation trade-off needs clarification")
 
         return ambiguities
@@ -414,7 +460,9 @@ class ContextUnderstandingEngine:
 
         return clarifications
 
-    def _recommend_approach(self, parsed_intent: ParsedIntent, contexts: list[ContextEntry]) -> str:
+    def _recommend_approach(
+        self, parsed_intent: ParsedIntent, contexts: list[ContextEntry]
+    ) -> str:
         """Recommend the best approach based on understanding (æ¨è–¦æœ€ä½³æ–¹æ¡ˆ)"""
         intent = parsed_intent.primary_intent
 
@@ -456,7 +504,10 @@ class ContextUnderstandingEngine:
         return base_recommendation.strip()
 
     def _calculate_understanding_confidence(
-        self, parsed_intent: ParsedIntent, ambiguities: list[str], clarifications: list[str]
+        self,
+        parsed_intent: ParsedIntent,
+        ambiguities: list[str],
+        clarifications: list[str],
     ) -> float:
         """Calculate confidence in understanding (è¨ˆç®—ç†è§£ç½®ä¿¡åº¦)"""
         base_confidence = parsed_intent.confidence
@@ -489,7 +540,9 @@ class ContextUnderstandingEngine:
 
         # éæ¿¾éæœŸçš„ä¸Šä¸‹æ–‡
         now = datetime.now()
-        valid_contexts = [c for c in user_contexts if c.expires_at is None or c.expires_at > now]
+        valid_contexts = [
+            c for c in user_contexts if c.expires_at is None or c.expires_at > now
+        ]
 
         # æŒ‰ç›¸é—œæ€§æ’åº
         # é€™è£¡ä½¿ç”¨ç°¡å–®çš„æ™‚é–“æ’åºï¼Œå¯¦éš›å¯ä»¥ä½¿ç”¨æ›´è¤‡é›œçš„ç›¸é—œæ€§è¨ˆç®—
@@ -522,7 +575,9 @@ class ContextUnderstandingEngine:
 
         return context_id
 
-    def _record_conversation(self, user_id: str, request: str, parsed_intent: ParsedIntent) -> None:
+    def _record_conversation(
+        self, user_id: str, request: str, parsed_intent: ParsedIntent
+    ) -> None:
         """Record conversation for context memory (è¨˜éŒ„å°è©±ç”¨æ–¼ä¸Šä¸‹æ–‡è¨˜æ†¶)"""
         if user_id not in self._conversation_history:
             self._conversation_history[user_id] = []
@@ -537,7 +592,9 @@ class ContextUnderstandingEngine:
 
         # ä¿ç•™æœ€è¿‘ 50 æ¢å°è©±
         if len(self._conversation_history[user_id]) > 50:
-            self._conversation_history[user_id] = self._conversation_history[user_id][-50:]
+            self._conversation_history[user_id] = self._conversation_history[user_id][
+                -50:
+            ]
 
     def add_project_context(self, user_id: str, project_info: dict[str, Any]) -> str:
         """Add project context (æ·»åŠ é …ç›®ä¸Šä¸‹æ–‡)"""
diff --git a/workspace/src/core/contract_engine.py b/workspace/src/core/contract_engine.py
index eea748b..b785ae6 100644
--- a/workspace/src/core/contract_engine.py
+++ b/workspace/src/core/contract_engine.py
@@ -251,9 +251,13 @@ class ContractRegistry:
 
         # Build dependency graph
         if contract.metadata.dependencies:
-            self._dependency_graph[contract.contract_id] = set(contract.metadata.dependencies)
+            self._dependency_graph[contract.contract_id] = set(
+                contract.metadata.dependencies
+            )
 
-        logger.info(f"Contract registered: {contract.contract_id} ({contract.metadata.name})")
+        logger.info(
+            f"Contract registered: {contract.contract_id} ({contract.metadata.name})"
+        )
         return contract.contract_id
 
     def get(self, contract_id: str) -> Optional[ContractDefinition]:
@@ -273,7 +277,9 @@ class ContractRegistry:
         contract_ids = self._type_index.get(contract_type, [])
         return [self._contracts[cid] for cid in contract_ids if cid in self._contracts]
 
-    def list_all(self, status: Optional[ContractStatus] = None) -> List[ContractDefinition]:
+    def list_all(
+        self, status: Optional[ContractStatus] = None
+    ) -> List[ContractDefinition]:
         """List all contracts, optionally filtered by status"""
         contracts = list(self._contracts.values())
         if status:
@@ -290,7 +296,9 @@ class ContractRegistry:
         contract.status = new_status
         contract.metadata.updated_at = datetime.utcnow()
 
-        logger.info(f"Contract status updated: {contract_id} {old_status} -> {new_status}")
+        logger.info(
+            f"Contract status updated: {contract_id} {old_status} -> {new_status}"
+        )
         return True
 
     def resolve_dependencies(self, contract_id: str) -> List[str]:
@@ -389,7 +397,9 @@ class ContractValidator:
             except Exception as e:
                 errors.append(f"Validator error: {str(e)}")
 
-        is_valid = len(errors) == 0 if self.execution_mode == ExecutionMode.STRICT else True
+        is_valid = (
+            len(errors) == 0 if self.execution_mode == ExecutionMode.STRICT else True
+        )
         severity = (
             ValidationSeverity.CRITICAL
             if errors
@@ -446,7 +456,9 @@ class ContractValidator:
         if metadata.version:
             parts = metadata.version.split(".")
             if len(parts) != 3 or not all(p.isdigit() for p in parts):
-                errors.append(f"Invalid version format: {metadata.version} (expected semver)")
+                errors.append(
+                    f"Invalid version format: {metadata.version} (expected semver)"
+                )
 
         return ValidationResult(
             is_valid=len(errors) == 0,
@@ -574,7 +586,10 @@ class ContractExecutor:
     """
 
     def __init__(
-        self, registry: ContractRegistry, validator: ContractValidator, timeout_seconds: int = 30
+        self,
+        registry: ContractRegistry,
+        validator: ContractValidator,
+        timeout_seconds: int = 30,
     ):
         """
         Initialize contract executor
@@ -598,7 +613,10 @@ class ContractExecutor:
         logger.info(f"Registered handler for contract type: {contract_type}")
 
     async def execute(
-        self, contract_id: str, input_data: Dict[str, Any], context: Optional[Dict[str, Any]] = None
+        self,
+        contract_id: str,
+        input_data: Dict[str, Any],
+        context: Optional[Dict[str, Any]] = None,
     ) -> ExecutionResult:
         """
         Execute contract
@@ -644,7 +662,8 @@ class ContractExecutor:
 
             # Execute with timeout
             output = await asyncio.wait_for(
-                handler(contract, input_data, context or {}), timeout=self.timeout_seconds
+                handler(contract, input_data, context or {}),
+                timeout=self.timeout_seconds,
             )
 
             # Post-execution validation
@@ -721,7 +740,10 @@ class ContractLifecycleManager:
     """
 
     def __init__(
-        self, registry: ContractRegistry, deprecation_period_days: int = 90, max_versions: int = 5
+        self,
+        registry: ContractRegistry,
+        deprecation_period_days: int = 90,
+        max_versions: int = 5,
     ):
         """
         Initialize lifecycle manager
@@ -788,7 +810,10 @@ class ContractLifecycleManager:
         return self.registry.update_status(contract_id, ContractStatus.RETIRED)
 
     def upgrade(
-        self, old_contract_id: str, new_contract: ContractDefinition, validate: bool = True
+        self,
+        old_contract_id: str,
+        new_contract: ContractDefinition,
+        validate: bool = True,
     ) -> Tuple[bool, Optional[str]]:
         """
         Upgrade a contract to a new version
@@ -833,7 +858,9 @@ class ContractLifecycleManager:
             new_contract_id = self.registry.register(new_contract)
 
             # Deprecate old version
-            self.deprecate(old_contract_id, f"Upgraded to version {new_contract.metadata.version}")
+            self.deprecate(
+                old_contract_id, f"Upgraded to version {new_contract.metadata.version}"
+            )
 
             logger.info(f"Contract upgraded: {old_contract_id} -> {new_contract_id}")
             return True, new_contract_id
@@ -908,11 +935,15 @@ class ContractEngine:
 
         status_counts = {}
         for status in ContractStatus:
-            status_counts[status.value] = sum(1 for c in contracts if c.status == status)
+            status_counts[status.value] = sum(
+                1 for c in contracts if c.status == status
+            )
 
         type_counts = {}
         for contract_type in ContractType:
-            type_counts[contract_type.value] = len(self.registry.get_by_type(contract_type))
+            type_counts[contract_type.value] = len(
+                self.registry.get_by_type(contract_type)
+            )
 
         return {
             "total_contracts": len(contracts),
@@ -937,7 +968,9 @@ def main():
 
     parser = argparse.ArgumentParser(description="SynergyMesh Contract Engine")
     parser.add_argument("--config", type=str, help="Configuration file path")
-    parser.add_argument("--stats", action="store_true", help="Display engine statistics")
+    parser.add_argument(
+        "--stats", action="store_true", help="Display engine statistics"
+    )
 
     args = parser.parse_args()
 
@@ -954,6 +987,7 @@ def main():
 
 if __name__ == "__main__":
     logging.basicConfig(
-        level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+        level=logging.INFO,
+        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
     )
     main()
diff --git a/workspace/src/core/crypto/quantum_safe_crypto.py b/workspace/src/core/crypto/quantum_safe_crypto.py
index e72e597..1eb7286 100644
--- a/workspace/src/core/crypto/quantum_safe_crypto.py
+++ b/workspace/src/core/crypto/quantum_safe_crypto.py
@@ -117,7 +117,9 @@ class QuantumSafeCrypto:
         # Placeholder decryption
         return base64.b64decode(ciphertext)
 
-    def hash(self, data: bytes, algorithm: CryptoAlgorithm = CryptoAlgorithm.SHA3_256) -> str:
+    def hash(
+        self, data: bytes, algorithm: CryptoAlgorithm = CryptoAlgorithm.SHA3_256
+    ) -> str:
         """Compute cryptographic hash."""
         if algorithm == CryptoAlgorithm.SHA3_256:
             return hashlib.sha3_256(data).hexdigest()
diff --git a/workspace/src/core/digital-twin/simulation/simulation_engine.py b/workspace/src/core/digital-twin/simulation/simulation_engine.py
index b0cdfa5..424c252 100644
--- a/workspace/src/core/digital-twin/simulation/simulation_engine.py
+++ b/workspace/src/core/digital-twin/simulation/simulation_engine.py
@@ -84,7 +84,9 @@ class SimulationEngine:
         self.config = config or {}
         self.mode = SimulationMode.DISCRETE
         self._time_step = (
-            timedelta(seconds=config.get("time_step", 1)) if config else timedelta(seconds=1)
+            timedelta(seconds=config.get("time_step", 1))
+            if config
+            else timedelta(seconds=1)
         )
         self._models: Dict[str, Callable] = {}
         self._current_state: Optional[SimulationState] = None
@@ -185,7 +187,9 @@ class SimulationEngine:
         for name, model in self._models.items():
             await model(self._current_state, scenario)
 
-    async def _model_load(self, state: SimulationState, scenario: SimulationScenario) -> None:
+    async def _model_load(
+        self, state: SimulationState, scenario: SimulationScenario
+    ) -> None:
         """Model load changes over time."""
         noise = random.gauss(0, 0.02)
         for component in state.components.values():
@@ -193,22 +197,32 @@ class SimulationEngine:
             # Mean reversion with noise
             component["load"] = max(0, min(1, load + noise))
 
-    async def _model_latency(self, state: SimulationState, scenario: SimulationScenario) -> None:
+    async def _model_latency(
+        self, state: SimulationState, scenario: SimulationScenario
+    ) -> None:
         """Model latency based on load."""
-        avg_load = sum(c.get("load", 0) for c in state.components.values()) / len(state.components)
+        avg_load = sum(c.get("load", 0) for c in state.components.values()) / len(
+            state.components
+        )
 
         # Latency increases with load
         base_latency = 50
         state.metrics["latency_p50"] = base_latency * (1 + avg_load)
         state.metrics["latency_p99"] = state.metrics["latency_p50"] * 4
 
-    async def _model_resource(self, state: SimulationState, scenario: SimulationScenario) -> None:
+    async def _model_resource(
+        self, state: SimulationState, scenario: SimulationScenario
+    ) -> None:
         """Model resource usage."""
-        avg_load = sum(c.get("load", 0) for c in state.components.values()) / len(state.components)
+        avg_load = sum(c.get("load", 0) for c in state.components.values()) / len(
+            state.components
+        )
         state.metrics["cpu_usage"] = 0.2 + avg_load * 0.6
         state.metrics["memory_usage"] = 0.3 + avg_load * 0.4
 
-    async def _model_failure(self, state: SimulationState, scenario: SimulationScenario) -> None:
+    async def _model_failure(
+        self, state: SimulationState, scenario: SimulationScenario
+    ) -> None:
         """Model failure probability."""
         # Higher load = higher failure probability
         for name, component in state.components.items():
@@ -259,11 +273,15 @@ class SimulationEngine:
 
         # Check resource usage
         if metrics.get("cpu_usage", {}).get("max", 0) > 0.8:
-            recommendations.append("CPU usage peaked high - consider horizontal scaling")
+            recommendations.append(
+                "CPU usage peaked high - consider horizontal scaling"
+            )
 
         # Check failures
         if len(events) > 0:
-            recommendations.append(f"Detected {len(events)} failure events - review resilience")
+            recommendations.append(
+                f"Detected {len(events)} failure events - review resilience"
+            )
 
         return recommendations
 
diff --git a/workspace/src/core/engine/action_executor.py b/workspace/src/core/engine/action_executor.py
index ca015ec..c232bbb 100644
--- a/workspace/src/core/engine/action_executor.py
+++ b/workspace/src/core/engine/action_executor.py
@@ -292,12 +292,16 @@ class ActionExecutor:
             # æª¢æŸ¥æ˜¯å¦æœ‰å¤±æ•—
             if plan.stop_on_failure:
                 failed = any(
-                    r.status == StepStatus.FAILED for r in results if isinstance(r, StepResult)
+                    r.status == StepStatus.FAILED
+                    for r in results
+                    if isinstance(r, StepResult)
                 )
                 if failed:
                     break
 
-    def _build_execution_layers(self, steps: List[ActionStep]) -> List[List[ActionStep]]:
+    def _build_execution_layers(
+        self, steps: List[ActionStep]
+    ) -> List[List[ActionStep]]:
         """æ§‹å»ºåŸ·è¡Œå±¤æ¬¡ï¼ˆæŒ‰ä¾è³´é—œä¿‚ï¼‰"""
 
         # è¨ˆç®—æ¯å€‹æ­¥é©Ÿçš„ä¾è³´æ•¸
@@ -349,7 +353,9 @@ class ActionExecutor:
 
         try:
             # ç²å–è™•ç†å™¨
-            handler = step.handler or self._handlers.get(step.name, self._handlers["default"])
+            handler = step.handler or self._handlers.get(
+                step.name, self._handlers["default"]
+            )
 
             # åŸ·è¡Œè™•ç†å™¨
             output = await self._safe_call(handler, step.params, completed_steps)
@@ -376,14 +382,18 @@ class ActionExecutor:
 
         finally:
             step.completed_at = datetime.now()
-            step.duration_ms = int((step.completed_at - step.started_at).total_seconds() * 1000)
+            step.duration_ms = int(
+                (step.completed_at - step.started_at).total_seconds() * 1000
+            )
 
             result.completed_at = step.completed_at
             result.duration_ms = step.duration_ms
 
         return result
 
-    def _check_dependencies(self, step: ActionStep, completed_steps: Dict[str, StepResult]) -> bool:
+    def _check_dependencies(
+        self, step: ActionStep, completed_steps: Dict[str, StepResult]
+    ) -> bool:
         """æª¢æŸ¥æ­¥é©Ÿä¾è³´æ˜¯å¦æ»¿è¶³"""
 
         for dep_id in step.depends_on:
@@ -460,7 +470,9 @@ class ActionExecutor:
 
         return True
 
-    def create_plan(self, name: str, steps: List[Dict[str, Any]], **kwargs) -> ActionPlan:
+    def create_plan(
+        self, name: str, steps: List[Dict[str, Any]], **kwargs
+    ) -> ActionPlan:
         """
         å‰µå»ºè¡Œå‹•è¨ˆåŠƒ
 
diff --git a/workspace/src/core/engine/agent_orchestration.py b/workspace/src/core/engine/agent_orchestration.py
index 9ed7668..3eebfc0 100644
--- a/workspace/src/core/engine/agent_orchestration.py
+++ b/workspace/src/core/engine/agent_orchestration.py
@@ -77,7 +77,9 @@ class ExecutionPlan:
 
     def get_ready_steps(self) -> List[ExecutionStep]:
         """Get steps that are ready to execute (all dependencies completed)"""
-        completed_ids = {s.step_id for s in self.steps if s.status == StepStatus.COMPLETED}
+        completed_ids = {
+            s.step_id for s in self.steps if s.status == StepStatus.COMPLETED
+        }
         ready = []
         for step in self.steps:
             if step.status == StepStatus.PENDING:
@@ -104,7 +106,12 @@ class ExecutionContext:
         """Set a context variable"""
         self._variables[key] = value
         self._history.append(
-            {"action": "set", "key": key, "value": value, "timestamp": datetime.now().isoformat()}
+            {
+                "action": "set",
+                "key": key,
+                "value": value,
+                "timestamp": datetime.now().isoformat(),
+            }
         )
 
     def get(self, key: str, default: Any = None) -> Any:
@@ -120,7 +127,11 @@ class ExecutionContext:
         if key in self._variables:
             del self._variables[key]
             self._history.append(
-                {"action": "delete", "key": key, "timestamp": datetime.now().isoformat()}
+                {
+                    "action": "delete",
+                    "key": key,
+                    "timestamp": datetime.now().isoformat(),
+                }
             )
 
     def has(self, key: str) -> bool:
@@ -179,7 +190,9 @@ class TaskPlanner:
         self._templates: Dict[str, List[Dict[str, Any]]] = {}
         self._plans: Dict[str, ExecutionPlan] = {}
 
-    def register_template(self, template_name: str, steps: List[Dict[str, Any]]) -> None:
+    def register_template(
+        self, template_name: str, steps: List[Dict[str, Any]]
+    ) -> None:
         """Register a plan template"""
         self._templates[template_name] = steps
 
@@ -213,7 +226,9 @@ class TaskPlanner:
         self._plans[plan.plan_id] = plan
         return plan
 
-    def decompose_task(self, task_description: str, available_tools: List[str]) -> ExecutionPlan:
+    def decompose_task(
+        self, task_description: str, available_tools: List[str]
+    ) -> ExecutionPlan:
         """
         Decompose a task description into executable steps
         Uses heuristics to break down complex tasks
@@ -280,7 +295,9 @@ class TaskPlanner:
             )
 
         return self.create_plan(
-            name=f"Plan for: {task_description[:50]}...", description=task_description, steps=steps
+            name=f"Plan for: {task_description[:50]}...",
+            description=task_description,
+            steps=steps,
         )
 
     def get_plan(self, plan_id: str) -> Optional[ExecutionPlan]:
@@ -395,8 +412,12 @@ class AgentOrchestrator:
 
                 try:
                     if step.tool_name and tool_executor:
-                        result = await tool_executor.execute(step.tool_name, step.params)
-                        step.result = result.output if hasattr(result, "output") else result
+                        result = await tool_executor.execute(
+                            step.tool_name, step.params
+                        )
+                        step.result = (
+                            result.output if hasattr(result, "output") else result
+                        )
                     else:
                         step.result = f"Executed {step.name} (simulated)"
 
@@ -429,7 +450,10 @@ class AgentOrchestrator:
         }
 
     async def orchestrate_task(
-        self, task_description: str, available_tools: List[str], tool_executor: Any = None
+        self,
+        task_description: str,
+        available_tools: List[str],
+        tool_executor: Any = None,
     ) -> Dict[str, Any]:
         """
         High-level task orchestration
diff --git a/workspace/src/core/engine/capability_registry.py b/workspace/src/core/engine/capability_registry.py
index aff30de..1fc2eb9 100644
--- a/workspace/src/core/engine/capability_registry.py
+++ b/workspace/src/core/engine/capability_registry.py
@@ -315,7 +315,9 @@ class CapabilityRegistry:
     def get_by_category(self, category: str) -> List[Capability]:
         """æŒ‰é¡åˆ¥ç²å–èƒ½åŠ›"""
         names = self._category_index.get(category, set())
-        return [self._capabilities[name] for name in names if name in self._capabilities]
+        return [
+            self._capabilities[name] for name in names if name in self._capabilities
+        ]
 
     def get_all(self) -> List[Capability]:
         """ç²å–æ‰€æœ‰èƒ½åŠ›"""
@@ -324,7 +326,9 @@ class CapabilityRegistry:
     def get_available(self) -> List[Capability]:
         """ç²å–æ‰€æœ‰å¯ç”¨èƒ½åŠ›"""
         return [
-            cap for cap in self._capabilities.values() if cap.status == CapabilityStatus.AVAILABLE
+            cap
+            for cap in self._capabilities.values()
+            if cap.status == CapabilityStatus.AVAILABLE
         ]
 
     def check_requirements(self, name: str) -> Dict[str, Any]:
@@ -446,7 +450,11 @@ class CapabilityRegistry:
 
         total = len(self._capabilities)
         available = len(
-            [c for c in self._capabilities.values() if c.status == CapabilityStatus.AVAILABLE]
+            [
+                c
+                for c in self._capabilities.values()
+                if c.status == CapabilityStatus.AVAILABLE
+            ]
         )
 
         return {
diff --git a/workspace/src/core/engine/connector_manager.py b/workspace/src/core/engine/connector_manager.py
index 773d417..fe06523 100644
--- a/workspace/src/core/engine/connector_manager.py
+++ b/workspace/src/core/engine/connector_manager.py
@@ -164,7 +164,10 @@ class ConnectorManager:
         self._factories[ConnectorType.MESSAGE_QUEUE] = self._create_mq_connector
 
     async def create(
-        self, name: str, connector_type: ConnectorType, config: Optional[ConnectionConfig] = None
+        self,
+        name: str,
+        connector_type: ConnectorType,
+        config: Optional[ConnectionConfig] = None,
     ) -> Connector:
         """
         å‰µå»ºé€£æ¥å™¨
@@ -305,7 +308,9 @@ class ConnectorManager:
                 return True
 
             # ç­‰å¾…é‡è©¦
-            delay = config.retry_delay_seconds * (config.retry_backoff_multiplier**attempt)
+            delay = config.retry_delay_seconds * (
+                config.retry_backoff_multiplier**attempt
+            )
             await asyncio.sleep(delay)
 
         return False
@@ -336,7 +341,11 @@ class ConnectorManager:
 
     def get_connected(self) -> List[Connector]:
         """ç²å–æ‰€æœ‰å·²é€£æ¥çš„é€£æ¥å™¨"""
-        return [c for c in self._connectors.values() if c.status == ConnectionStatus.CONNECTED]
+        return [
+            c
+            for c in self._connectors.values()
+            if c.status == ConnectionStatus.CONNECTED
+        ]
 
     async def remove(self, name: str) -> bool:
         """
@@ -369,7 +378,9 @@ class ConnectorManager:
 
         return True
 
-    async def execute(self, name: str, operation: str, params: Dict[str, Any]) -> Dict[str, Any]:
+    async def execute(
+        self, name: str, operation: str, params: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """
         é€šéé€£æ¥å™¨åŸ·è¡Œæ“ä½œ
 
@@ -412,7 +423,9 @@ class ConnectorManager:
             # æ›´æ–°å¹³å‡å»¶é²
             total = connector.total_requests
             current_avg = connector.average_latency_ms
-            connector.average_latency_ms = (current_avg * (total - 1) + latency_ms) / total
+            connector.average_latency_ms = (
+                current_avg * (total - 1) + latency_ms
+            ) / total
 
             return {
                 "success": True,
@@ -525,23 +538,33 @@ class ConnectorManager:
 
         total = len(self._connectors)
         connected = len(
-            [c for c in self._connectors.values() if c.status == ConnectionStatus.CONNECTED]
+            [
+                c
+                for c in self._connectors.values()
+                if c.status == ConnectionStatus.CONNECTED
+            ]
         )
         healthy = len([c for c in self._connectors.values() if c.is_healthy])
 
         total_requests = sum(c.total_requests for c in self._connectors.values())
-        successful_requests = sum(c.successful_requests for c in self._connectors.values())
+        successful_requests = sum(
+            c.successful_requests for c in self._connectors.values()
+        )
 
         return {
             "total_connectors": total,
             "connected_connectors": connected,
             "healthy_connectors": healthy,
             "disconnected_connectors": total - connected,
-            "connectors_by_type": {t.value: len(names) for t, names in self._type_index.items()},
+            "connectors_by_type": {
+                t.value: len(names) for t, names in self._type_index.items()
+            },
             "total_requests": total_requests,
             "successful_requests": successful_requests,
             "success_rate": (
-                round(successful_requests / total_requests, 4) * 100 if total_requests > 0 else 0
+                round(successful_requests / total_requests, 4) * 100
+                if total_requests > 0
+                else 0
             ),
         }
 
@@ -570,7 +593,9 @@ class ConnectorManager:
 
     # ============ é»˜èªé€£æ¥å·¥å»  ============
 
-    async def _create_database_connector(self, config: ConnectionConfig) -> Dict[str, Any]:
+    async def _create_database_connector(
+        self, config: ConnectionConfig
+    ) -> Dict[str, Any]:
         """å‰µå»ºæ•¸æ“šåº«é€£æ¥å™¨"""
         return {
             "type": "database",
@@ -587,7 +612,9 @@ class ConnectorManager:
             "timeout": config.read_timeout_seconds,
         }
 
-    async def _create_kubernetes_connector(self, config: ConnectionConfig) -> Dict[str, Any]:
+    async def _create_kubernetes_connector(
+        self, config: ConnectionConfig
+    ) -> Dict[str, Any]:
         """å‰µå»º Kubernetes é€£æ¥å™¨"""
         return {
             "type": "kubernetes",
@@ -595,14 +622,18 @@ class ConnectorManager:
             "namespace": config.extra.get("namespace", "default"),
         }
 
-    async def _create_docker_connector(self, config: ConnectionConfig) -> Dict[str, Any]:
+    async def _create_docker_connector(
+        self, config: ConnectionConfig
+    ) -> Dict[str, Any]:
         """å‰µå»º Docker é€£æ¥å™¨"""
         return {
             "type": "docker",
             "socket": config.extra.get("socket", "/var/run/docker.sock"),
         }
 
-    async def _create_filesystem_connector(self, config: ConnectionConfig) -> Dict[str, Any]:
+    async def _create_filesystem_connector(
+        self, config: ConnectionConfig
+    ) -> Dict[str, Any]:
         """å‰µå»ºæ–‡ä»¶ç³»çµ±é€£æ¥å™¨"""
         return {
             "type": "filesystem",
diff --git a/workspace/src/core/engine/dag_engine.py b/workspace/src/core/engine/dag_engine.py
index bc7dcd1..989d525 100644
--- a/workspace/src/core/engine/dag_engine.py
+++ b/workspace/src/core/engine/dag_engine.py
@@ -229,7 +229,9 @@ class DAGEngine:
                         or self.nodes[nid].status == NodeStatus.COMPLETED
                     ]
                 ):
-                    results[node_id] = level_results[i] if i < len(level_results) else None
+                    results[node_id] = (
+                        level_results[i] if i < len(level_results) else None
+                    )
 
         return results
 
diff --git a/workspace/src/core/engine/execution_engine.py b/workspace/src/core/engine/execution_engine.py
index 8a3f963..55c95ca 100644
--- a/workspace/src/core/engine/execution_engine.py
+++ b/workspace/src/core/engine/execution_engine.py
@@ -221,11 +221,15 @@ class ExecutionEngine:
 
             # éšæ®µ 2ï¼šåŸ·è¡Œå‰ç½®è™•ç†
             for pre_processor in self._pre_processors:
-                await self._safe_call(pre_processor, action_type, action_params, context)
+                await self._safe_call(
+                    pre_processor, action_type, action_params, context
+                )
 
             # éšæ®µ 3ï¼šæ§‹å»ºåŸ·è¡Œè¨ˆåŠƒ
             result.status = ExecutionStatus.PLANNING
-            execution_plan = await self._build_execution_plan(action_type, action_params, context)
+            execution_plan = await self._build_execution_plan(
+                action_type, action_params, context
+            )
             result.steps_total = len(execution_plan.get("steps", []))
 
             # éšæ®µ 4ï¼šåŸ·è¡Œè¡Œå‹•ï¼ˆæˆ–æ¨¡æ“¬åŸ·è¡Œï¼‰
@@ -233,7 +237,9 @@ class ExecutionEngine:
 
             if context.dry_run:
                 # æ¨¡æ“¬åŸ·è¡Œ
-                output = await self._simulate_execution(action_type, action_params, execution_plan)
+                output = await self._simulate_execution(
+                    action_type, action_params, execution_plan
+                )
             else:
                 # å¯¦éš›åŸ·è¡Œ
                 output = await self._execute_action(
@@ -245,7 +251,9 @@ class ExecutionEngine:
 
             # éšæ®µ 5ï¼šé©—è­‰åŸ·è¡Œçµæœ
             result.status = ExecutionStatus.VERIFYING
-            verification = await self._verify_execution(action_type, action_params, output, context)
+            verification = await self._verify_execution(
+                action_type, action_params, output, context
+            )
             result.verification_passed = verification.get("passed", False)
             result.verification_details = verification
 
@@ -275,12 +283,16 @@ class ExecutionEngine:
             }
 
             # è¨˜éŒ„å­¸ç¿’ç¶“é©—
-            result.lessons_learned.append(f"Execution failed due to: {type(e).__name__}: {str(e)}")
+            result.lessons_learned.append(
+                f"Execution failed due to: {type(e).__name__}: {str(e)}"
+            )
 
         finally:
             # è¨˜éŒ„å®Œæˆæ™‚é–“
             result.completed_at = datetime.now()
-            result.duration_ms = int((result.completed_at - started_at).total_seconds() * 1000)
+            result.duration_ms = int(
+                (result.completed_at - started_at).total_seconds() * 1000
+            )
 
             # æ›´æ–°çµ±è¨ˆ
             self._update_stats(result)
@@ -291,7 +303,10 @@ class ExecutionEngine:
         return result
 
     async def _validate_capability(
-        self, action_type: ActionType, action_params: Dict[str, Any], context: ExecutionContext
+        self,
+        action_type: ActionType,
+        action_params: Dict[str, Any],
+        context: ExecutionContext,
     ) -> bool:
         """é©—è­‰åŸ·è¡Œèƒ½åŠ› - ç¢ºä¿æˆ‘å€‘çœŸçš„èƒ½åŸ·è¡Œé€™å€‹è¡Œå‹•"""
 
@@ -300,7 +315,9 @@ class ExecutionEngine:
             raise ValueError(f"No executor registered for action type: {action_type}")
 
         # æª¢æŸ¥æ¬Šé™
-        required_permissions = self._get_required_permissions(action_type, action_params)
+        required_permissions = self._get_required_permissions(
+            action_type, action_params
+        )
         for perm in required_permissions:
             if perm not in context.permissions:
                 raise PermissionError(f"Missing required permission: {perm}")
@@ -321,7 +338,10 @@ class ExecutionEngine:
         return True
 
     async def _build_execution_plan(
-        self, action_type: ActionType, action_params: Dict[str, Any], context: ExecutionContext
+        self,
+        action_type: ActionType,
+        action_params: Dict[str, Any],
+        context: ExecutionContext,
     ) -> Dict[str, Any]:
         """æ§‹å»ºåŸ·è¡Œè¨ˆåŠƒ"""
 
@@ -596,7 +616,10 @@ class ExecutionEngine:
         return await executor(action_params, context, execution_plan)
 
     async def _simulate_execution(
-        self, action_type: ActionType, action_params: Dict[str, Any], execution_plan: Dict[str, Any]
+        self,
+        action_type: ActionType,
+        action_params: Dict[str, Any],
+        execution_plan: Dict[str, Any],
     ) -> Dict[str, Any]:
         """æ¨¡æ“¬åŸ·è¡Œï¼ˆDry Runï¼‰"""
 
@@ -701,7 +724,9 @@ class ExecutionEngine:
 
         return rollback_result
 
-    async def _execute_rollback_step(self, step: Dict[str, Any], context: ExecutionContext):
+    async def _execute_rollback_step(
+        self, step: Dict[str, Any], context: ExecutionContext
+    ):
         """åŸ·è¡Œå–®å€‹å›æ»¾æ­¥é©Ÿ"""
         # æ¨¡æ“¬å›æ»¾åŸ·è¡Œ
         await asyncio.sleep(0.01)
@@ -900,7 +925,9 @@ class ExecutionEngine:
         """è¨»å†Šé€£æ¥å™¨"""
         self._connectors[name] = connector
 
-    def register_capability_validator(self, action_type: ActionType, validator: Callable):
+    def register_capability_validator(
+        self, action_type: ActionType, validator: Callable
+    ):
         """è¨»å†Šèƒ½åŠ›é©—è­‰å™¨"""
         self._capability_validators[action_type] = validator
 
diff --git a/workspace/src/core/engine/function_calling.py b/workspace/src/core/engine/function_calling.py
index 59da77e..401d160 100644
--- a/workspace/src/core/engine/function_calling.py
+++ b/workspace/src/core/engine/function_calling.py
@@ -452,7 +452,9 @@ class FunctionDefinition:
                 expected_type = properties[key].get("type")
                 if expected_type and expected_type in type_map:
                     if not isinstance(value, type_map[expected_type]):
-                        errors.append(f"Invalid type for {key}: expected {expected_type}")
+                        errors.append(
+                            f"Invalid type for {key}: expected {expected_type}"
+                        )
 
         return errors
 
@@ -951,7 +953,9 @@ class FunctionCallHandler:
         self._call_history.append(result)
         return result
 
-    def parse_openai_tool_call(self, tool_call: Dict[str, Any]) -> tuple[str, Dict[str, Any]]:
+    def parse_openai_tool_call(
+        self, tool_call: Dict[str, Any]
+    ) -> tuple[str, Dict[str, Any]]:
         """Parse an OpenAI tool call response"""
         function_name = tool_call.get("function", {}).get("name", "")
         arguments_str = tool_call.get("function", {}).get("arguments", "{}")
@@ -1265,7 +1269,10 @@ def create_api_function(
             "type": "object",
             "properties": {
                 "url": {"type": "string", "description": "The URL to call"},
-                "method": {"type": "string", "description": "HTTP method (GET, POST, etc.)"},
+                "method": {
+                    "type": "string",
+                    "description": "HTTP method (GET, POST, etc.)",
+                },
                 "body": {"type": "object", "description": "Request body"},
             },
             "required": ["url", "method"],
diff --git a/workspace/src/core/engine/langchain_integration.py b/workspace/src/core/engine/langchain_integration.py
index 5d8cfd1..5929600 100644
--- a/workspace/src/core/engine/langchain_integration.py
+++ b/workspace/src/core/engine/langchain_integration.py
@@ -174,21 +174,34 @@ class ReActAgentBuilder:
                 # Step 2: Action - Select tool (simplified)
                 if agent["tools"]:
                     selected_tool = agent["tools"][0]
-                    action = {"tool": selected_tool.name, "tool_input": {"query": current_input}}
+                    action = {
+                        "tool": selected_tool.name,
+                        "tool_input": {"query": current_input},
+                    }
                     intermediate_steps.append(
-                        {"type": "action", "content": action, "iteration": iteration + 1}
+                        {
+                            "type": "action",
+                            "content": action,
+                            "iteration": iteration + 1,
+                        }
                     )
 
                     # Step 3: Observation - Execute tool
                     if selected_tool.coroutine:
-                        observation = await selected_tool.coroutine(action["tool_input"])
+                        observation = await selected_tool.coroutine(
+                            action["tool_input"]
+                        )
                     elif selected_tool.func:
                         observation = selected_tool.func(action["tool_input"])
                     else:
                         observation = f"Tool {selected_tool.name} executed (simulated)"
 
                     intermediate_steps.append(
-                        {"type": "observation", "content": observation, "iteration": iteration + 1}
+                        {
+                            "type": "observation",
+                            "content": observation,
+                            "iteration": iteration + 1,
+                        }
                     )
 
                     # Check if task is complete
@@ -278,7 +291,9 @@ class ChainBuilder:
         self._chains[chain_name].append(step)
         return self
 
-    async def run_chain(self, chain_name: str, initial_input: Dict[str, Any]) -> Dict[str, Any]:
+    async def run_chain(
+        self, chain_name: str, initial_input: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Run a chain of tools"""
         if chain_name not in self._chains:
             return {"error": f"Chain not found: {chain_name}"}
@@ -301,17 +316,27 @@ class ChainBuilder:
             # Execute step
             try:
                 if self.tool_executor:
-                    result = await self.tool_executor.execute(step.tool_name, step_input)
+                    result = await self.tool_executor.execute(
+                        step.tool_name, step_input
+                    )
                     step_output = result.output if hasattr(result, "output") else result
                 else:
                     step_output = f"Executed {step.tool_name} (simulated)"
 
                 context[step.output_key] = step_output
-                results.append({"tool": step.tool_name, "output": step_output, "success": True})
+                results.append(
+                    {"tool": step.tool_name, "output": step_output, "success": True}
+                )
             except Exception as e:
                 if not step.continue_on_error:
-                    return {"error": str(e), "failed_at": step.tool_name, "results": results}
-                results.append({"tool": step.tool_name, "error": str(e), "success": False})
+                    return {
+                        "error": str(e),
+                        "failed_at": step.tool_name,
+                        "results": results,
+                    }
+                results.append(
+                    {"tool": step.tool_name, "error": str(e), "success": False}
+                )
 
         return {"success": True, "results": results, "final_context": context}
 
diff --git a/workspace/src/core/engine/mcp_integration.py b/workspace/src/core/engine/mcp_integration.py
index 507e259..14906e5 100644
--- a/workspace/src/core/engine/mcp_integration.py
+++ b/workspace/src/core/engine/mcp_integration.py
@@ -122,7 +122,9 @@ class MCPToolProvider:
         count = 0
         for tool in tool_registry.list_all():
             mcp_tool = MCPTool(
-                name=tool.name, description=tool.description, input_schema=tool.input_schema
+                name=tool.name,
+                description=tool.description,
+                input_schema=tool.input_schema,
             )
             self.register_tool(mcp_tool, tool.execute)
             count += 1
@@ -140,13 +142,17 @@ class MCPToolProvider:
         """Handle a tool call request"""
         if call.name not in self._tools:
             return MCPToolResult(
-                call_id=call.call_id, success=False, error=f"Tool not found: {call.name}"
+                call_id=call.call_id,
+                success=False,
+                error=f"Tool not found: {call.name}",
             )
 
         handler = self._handlers.get(call.name)
         if not handler:
             return MCPToolResult(
-                call_id=call.call_id, success=False, error=f"No handler for tool: {call.name}"
+                call_id=call.call_id,
+                success=False,
+                error=f"No handler for tool: {call.name}",
             )
 
         try:
@@ -168,13 +174,21 @@ class MCPToolProvider:
         """Handle an incoming MCP message"""
         msg_type = message.get("type", "")
 
-        if msg_type == MCPMessageType.TOOL_LIST.value or message.get("method") == "tools/list":
+        if (
+            msg_type == MCPMessageType.TOOL_LIST.value
+            or message.get("method") == "tools/list"
+        ):
             return self.handle_list_tools()
 
-        elif msg_type == MCPMessageType.TOOL_CALL.value or message.get("method") == "tools/call":
+        elif (
+            msg_type == MCPMessageType.TOOL_CALL.value
+            or message.get("method") == "tools/call"
+        ):
             call = MCPToolCall(
                 name=message.get("name", message.get("params", {}).get("name", "")),
-                arguments=message.get("arguments", message.get("params", {}).get("arguments", {})),
+                arguments=message.get(
+                    "arguments", message.get("params", {}).get("arguments", {})
+                ),
                 call_id=message.get("id", str(uuid.uuid4())),
             )
             result = await self.handle_tool_call(call)
@@ -264,7 +278,9 @@ class MCPToolConsumer:
 
     def get_all_tools(self) -> Dict[str, List[MCPTool]]:
         """Get all tools from all servers"""
-        return {server: list(tools.values()) for server, tools in self._remote_tools.items()}
+        return {
+            server: list(tools.values()) for server, tools in self._remote_tools.items()
+        }
 
     def find_tool(self, tool_name: str) -> Optional[tuple[str, MCPTool]]:
         """Find a tool across all servers"""
@@ -315,7 +331,9 @@ class MCPBridge:
     """
 
     def __init__(
-        self, provider: Optional[MCPToolProvider] = None, consumer: Optional[MCPToolConsumer] = None
+        self,
+        provider: Optional[MCPToolProvider] = None,
+        consumer: Optional[MCPToolConsumer] = None,
     ):
         self.provider = provider or MCPToolProvider()
         self.consumer = consumer or MCPToolConsumer()
@@ -357,12 +375,17 @@ class MCPBridge:
             return await self.consumer.call_tool(server_name, tool_name, arguments)
 
         return MCPToolResult(
-            call_id=str(uuid.uuid4()), success=False, error=f"Tool not found: {tool_name}"
+            call_id=str(uuid.uuid4()),
+            success=False,
+            error=f"Tool not found: {tool_name}",
         )
 
     def get_all_tools(self) -> Dict[str, Any]:
         """Get all available tools (local and remote)"""
-        return {"local": self.provider.get_tool_list(), "remote": self.consumer.get_all_tools()}
+        return {
+            "local": self.provider.get_tool_list(),
+            "remote": self.consumer.get_all_tools(),
+        }
 
     def get_provider(self) -> MCPToolProvider:
         """Get the tool provider"""
diff --git a/workspace/src/core/engine/partial_rollback.py b/workspace/src/core/engine/partial_rollback.py
index 7312973..bf41972 100644
--- a/workspace/src/core/engine/partial_rollback.py
+++ b/workspace/src/core/engine/partial_rollback.py
@@ -93,7 +93,11 @@ class PartialRollbackManager:
         self.checkpoint_order: List[str] = []  # Maintain checkpoint sequence
 
     def create_checkpoint(
-        self, checkpoint_id: str, level: RollbackLevel, state: Dict[str, Any], **metadata
+        self,
+        checkpoint_id: str,
+        level: RollbackLevel,
+        state: Dict[str, Any],
+        **metadata,
     ) -> Checkpoint:
         """
         Create a checkpoint for potential rollback
@@ -137,7 +141,9 @@ class PartialRollbackManager:
         """
         return self.checkpoints.get(checkpoint_id)
 
-    def list_checkpoints(self, level: Optional[RollbackLevel] = None) -> List[Checkpoint]:
+    def list_checkpoints(
+        self, level: Optional[RollbackLevel] = None
+    ) -> List[Checkpoint]:
         """
         List all checkpoints, optionally filtered by level
 
@@ -148,7 +154,9 @@ class PartialRollbackManager:
             List of checkpoints
         """
         checkpoints = [
-            self.checkpoints[cid] for cid in self.checkpoint_order if cid in self.checkpoints
+            self.checkpoints[cid]
+            for cid in self.checkpoint_order
+            if cid in self.checkpoints
         ]
 
         if level:
@@ -320,7 +328,9 @@ class PartialRollbackManager:
         return {
             "total_checkpoints": len(self.checkpoints),
             "checkpoints_by_level": {
-                level.value: len([cp for cp in self.checkpoints.values() if cp.level == level])
+                level.value: len(
+                    [cp for cp in self.checkpoints.values() if cp.level == level]
+                )
                 for level in RollbackLevel
             },
             "total_operations": len(self.operations),
diff --git a/workspace/src/core/engine/rollback_manager.py b/workspace/src/core/engine/rollback_manager.py
index 1e38e8d..eadb586 100644
--- a/workspace/src/core/engine/rollback_manager.py
+++ b/workspace/src/core/engine/rollback_manager.py
@@ -220,7 +220,11 @@ class RollbackManager:
         """ç²å–åŸ·è¡Œç›¸é—œçš„æ‰€æœ‰æª¢æŸ¥é»"""
 
         checkpoint_ids = self._execution_checkpoints.get(execution_id, [])
-        return [self._checkpoints[cp_id] for cp_id in checkpoint_ids if cp_id in self._checkpoints]
+        return [
+            self._checkpoints[cp_id]
+            for cp_id in checkpoint_ids
+            if cp_id in self._checkpoints
+        ]
 
     def delete_checkpoint(self, checkpoint_id: str) -> bool:
         """åˆªé™¤æª¢æŸ¥é»"""
@@ -232,13 +236,17 @@ class RollbackManager:
 
         # æ›´æ–°åŸ·è¡Œç´¢å¼•
         if checkpoint.execution_id:
-            exec_checkpoints = self._execution_checkpoints.get(checkpoint.execution_id, [])
+            exec_checkpoints = self._execution_checkpoints.get(
+                checkpoint.execution_id, []
+            )
             if checkpoint_id in exec_checkpoints:
                 exec_checkpoints.remove(checkpoint_id)
 
         return True
 
-    def cleanup_old_checkpoints(self, max_age_hours: int = 24, max_count: int = 1000) -> int:
+    def cleanup_old_checkpoints(
+        self, max_age_hours: int = 24, max_count: int = 1000
+    ) -> int:
         """
         æ¸…ç†èˆŠæª¢æŸ¥é»
 
@@ -254,7 +262,9 @@ class RollbackManager:
         deleted = 0
 
         # æŒ‰æ™‚é–“æ’åº
-        sorted_checkpoints = sorted(self._checkpoints.values(), key=lambda c: c.created_at)
+        sorted_checkpoints = sorted(
+            self._checkpoints.values(), key=lambda c: c.created_at
+        )
 
         for checkpoint in sorted_checkpoints:
             # æª¢æŸ¥å¹´é½¡
@@ -316,7 +326,9 @@ class RollbackManager:
         return plan
 
     async def rollback_execution(
-        self, execution_id: str, strategy: RollbackStrategy = RollbackStrategy.INCREMENTAL
+        self,
+        execution_id: str,
+        strategy: RollbackStrategy = RollbackStrategy.INCREMENTAL,
     ) -> RollbackPlan:
         """
         å›æ»¾æ•´å€‹åŸ·è¡Œ
@@ -348,7 +360,9 @@ class RollbackManager:
         )
 
         # æŒ‰æ™‚é–“é€†åºè™•ç†æª¢æŸ¥é»
-        sorted_checkpoints = sorted(checkpoints, key=lambda c: c.created_at, reverse=True)
+        sorted_checkpoints = sorted(
+            checkpoints, key=lambda c: c.created_at, reverse=True
+        )
 
         # æ§‹å»ºå›æ»¾æ­¥é©Ÿ
         for checkpoint in sorted_checkpoints:
diff --git a/workspace/src/core/engine/state_machine.py b/workspace/src/core/engine/state_machine.py
index 58754d7..061cf03 100644
--- a/workspace/src/core/engine/state_machine.py
+++ b/workspace/src/core/engine/state_machine.py
@@ -102,7 +102,9 @@ class StateMachine:
         """
         self.listeners[state].append(callback)
 
-    async def transition_to(self, new_state: ExecutionState, reason: str = "", **metadata) -> bool:
+    async def transition_to(
+        self, new_state: ExecutionState, reason: str = "", **metadata
+    ) -> bool:
         """
         Transition to a new state
 
@@ -120,7 +122,8 @@ class StateMachine:
         # Check if transition is valid
         if new_state not in self.VALID_TRANSITIONS.get(self.current_state, []):
             raise ValueError(
-                f"Invalid transition from {self.current_state.value} " f"to {new_state.value}"
+                f"Invalid transition from {self.current_state.value} "
+                f"to {new_state.value}"
             )
 
         # Record transition
@@ -209,7 +212,9 @@ class ExecutionOrchestrator:
     async def start(self) -> None:
         """Start execution"""
         self.start_time = datetime.now()
-        await self.state_machine.transition_to(ExecutionState.RUNNING, reason="Execution started")
+        await self.state_machine.transition_to(
+            ExecutionState.RUNNING, reason="Execution started"
+        )
 
     async def pause(self, reason: str = "") -> None:
         """Pause execution"""
@@ -219,7 +224,9 @@ class ExecutionOrchestrator:
 
     async def resume(self) -> None:
         """Resume execution"""
-        await self.state_machine.transition_to(ExecutionState.RESUMED, reason="Execution resumed")
+        await self.state_machine.transition_to(
+            ExecutionState.RESUMED, reason="Execution resumed"
+        )
         # Transition back to running
         await self.state_machine.transition_to(
             ExecutionState.RUNNING, reason="Resumed to running state"
diff --git a/workspace/src/core/engine/tool_system.py b/workspace/src/core/engine/tool_system.py
index 7104b79..925c765 100644
--- a/workspace/src/core/engine/tool_system.py
+++ b/workspace/src/core/engine/tool_system.py
@@ -143,7 +143,9 @@ class Tool:
             if key in properties:
                 expected_type = properties[key].get("type")
                 if expected_type and not self._check_type(value, expected_type):
-                    raise ValueError(f"Invalid type for {key}: expected {expected_type}")
+                    raise ValueError(
+                        f"Invalid type for {key}: expected {expected_type}"
+                    )
 
     def _check_type(self, value: Any, expected_type: str) -> bool:
         """Check if value matches expected JSON Schema type"""
@@ -188,7 +190,9 @@ class ToolRegistry:
 
     def __init__(self):
         self._tools: Dict[str, Tool] = {}
-        self._categories: Dict[ToolCategory, List[str]] = {cat: [] for cat in ToolCategory}
+        self._categories: Dict[ToolCategory, List[str]] = {
+            cat: [] for cat in ToolCategory
+        }
         self._tags: Dict[str, List[str]] = {}
 
     def register(self, tool: Tool) -> None:
@@ -239,7 +243,10 @@ class ToolRegistry:
         query_lower = query.lower()
         results = []
         for tool in self._tools.values():
-            if query_lower in tool.name.lower() or query_lower in tool.description.lower():
+            if (
+                query_lower in tool.name.lower()
+                or query_lower in tool.description.lower()
+            ):
                 results.append(tool)
         return results
 
@@ -265,7 +272,9 @@ class ToolExecutor:
         tool = self.registry.get(tool_name)
         if not tool:
             return ToolResult(
-                tool_name=tool_name, status=ToolStatus.FAILURE, error=f"Tool not found: {tool_name}"
+                tool_name=tool_name,
+                status=ToolStatus.FAILURE,
+                error=f"Tool not found: {tool_name}",
             )
 
         attempts = tool.max_retries if retry_on_failure else 1
@@ -290,7 +299,10 @@ class ToolExecutor:
     ) -> List[ToolResult]:
         """Execute multiple tools"""
         if parallel:
-            tasks = [self.execute(call["tool_name"], call.get("params", {})) for call in tool_calls]
+            tasks = [
+                self.execute(call["tool_name"], call.get("params", {}))
+                for call in tool_calls
+            ]
             return await asyncio.gather(*tasks)
         else:
             results = []
@@ -310,7 +322,10 @@ class ToolExecutor:
 
 # Pre-built tool factories for common operations
 def create_database_tool(
-    name: str, description: str, execute_fn: Callable, input_schema: Optional[Dict] = None
+    name: str,
+    description: str,
+    execute_fn: Callable,
+    input_schema: Optional[Dict] = None,
 ) -> Tool:
     """Factory for creating database tools"""
     return Tool(
@@ -324,7 +339,10 @@ def create_database_tool(
 
 
 def create_api_tool(
-    name: str, description: str, execute_fn: Callable, input_schema: Optional[Dict] = None
+    name: str,
+    description: str,
+    execute_fn: Callable,
+    input_schema: Optional[Dict] = None,
 ) -> Tool:
     """Factory for creating API tools"""
     return Tool(
@@ -338,7 +356,10 @@ def create_api_tool(
 
 
 def create_code_tool(
-    name: str, description: str, execute_fn: Callable, input_schema: Optional[Dict] = None
+    name: str,
+    description: str,
+    execute_fn: Callable,
+    input_schema: Optional[Dict] = None,
 ) -> Tool:
     """Factory for creating code execution tools"""
     return Tool(
diff --git a/workspace/src/core/engine/verification_engine.py b/workspace/src/core/engine/verification_engine.py
index c0a98bf..8ec7820 100644
--- a/workspace/src/core/engine/verification_engine.py
+++ b/workspace/src/core/engine/verification_engine.py
@@ -175,7 +175,9 @@ class VerificationEngine:
                 check = VerificationCheck(
                     name=check_def.get("name", "custom_check"),
                     description=check_def.get("description", ""),
-                    strategy=VerificationStrategy(check_def.get("strategy", "exact_match")),
+                    strategy=VerificationStrategy(
+                        check_def.get("strategy", "exact_match")
+                    ),
                     expected=check_def.get("expected"),
                     actual=check_def.get("actual", actual),
                     severity=VerificationSeverity(check_def.get("severity", "error")),
@@ -188,7 +190,11 @@ class VerificationEngine:
         result.total_checks = len(result.checks)
         result.passed_checks = len([c for c in result.checks if c.passed])
         result.failed_checks = len(
-            [c for c in result.checks if not c.passed and c.severity == VerificationSeverity.ERROR]
+            [
+                c
+                for c in result.checks
+                if not c.passed and c.severity == VerificationSeverity.ERROR
+            ]
         )
         result.warning_checks = len(
             [
@@ -357,7 +363,9 @@ class VerificationEngine:
         # æª¢æŸ¥èªç¾©ç›¸ä¼¼æ€§
         # é€™æ˜¯ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›æ‡‰ä½¿ç”¨ NLP
         return (
-            actual_str == expected_str or expected_str in actual_str or actual_str in expected_str
+            actual_str == expected_str
+            or expected_str in actual_str
+            or actual_str in expected_str
         )
 
     def _statistical_match(self, actual: Any, expected: Any) -> bool:
@@ -400,7 +408,9 @@ class VerificationEngine:
 
         return False
 
-    def verify_output(self, output: Any, rules: List[Dict[str, Any]]) -> VerificationResult:
+    def verify_output(
+        self, output: Any, rules: List[Dict[str, Any]]
+    ) -> VerificationResult:
         """
         ä½¿ç”¨è¦å‰‡åˆ—è¡¨é©—è­‰è¼¸å‡º
 
@@ -504,7 +514,9 @@ class VerificationEngine:
             value = str(value)
 
         passed = bool(re.match(pattern, value))
-        message = f"Pattern check {'passed' if passed else 'failed'}: " f"pattern={pattern}"
+        message = (
+            f"Pattern check {'passed' if passed else 'failed'}: " f"pattern={pattern}"
+        )
         return passed, message
 
     def _validate_contains(self, value: Any, rule: Dict[str, Any]) -> tuple:
@@ -521,7 +533,8 @@ class VerificationEngine:
             passed = False
 
         message = (
-            f"Contains check {'passed' if passed else 'failed'}: " f"expected '{expected}' in value"
+            f"Contains check {'passed' if passed else 'failed'}: "
+            f"expected '{expected}' in value"
         )
         return passed, message
 
diff --git a/workspace/src/core/instant_generation/agents/__init__.py b/workspace/src/core/instant_generation/agents/__init__.py
index 584b4ac..747da32 100644
--- a/workspace/src/core/instant_generation/agents/__init__.py
+++ b/workspace/src/core/instant_generation/agents/__init__.py
@@ -5,12 +5,6 @@ AI Agents Network for Instant Generation
 6å€‹å°ˆæ¥­åŒ–AIä»£ç†å¯¦ç¾ä¸¦è¡Œè™•ç†ï¼Œæ¯å€‹ä»£ç†å°ˆæ³¨æ–¼ç‰¹å®šé ˜åŸŸ
 """
 
-from .architecture_design_agent import ArchitectureDesignAgent
-from .testing_agent import TestingAgent
-from .optimization_agent import OptimizationAgent
-from .input_analysis_agent import InputAnalysisAgent
-from .deployment_agent import DeploymentAgent
-from .code_generation_agent import CodeGenerationAgent
 import asyncio
 import logging
 from abc import ABC, abstractmethod
@@ -18,6 +12,13 @@ from dataclasses import dataclass
 from enum import Enum
 from typing import Any, Dict, List, Optional
 
+from .architecture_design_agent import ArchitectureDesignAgent
+from .code_generation_agent import CodeGenerationAgent
+from .deployment_agent import DeploymentAgent
+from .input_analysis_agent import InputAnalysisAgent
+from .optimization_agent import OptimizationAgent
+from .testing_agent import TestingAgent
+
 
 class AgentType(Enum):
     """ä»£ç†é¡å‹æšèˆ‰"""
@@ -75,7 +76,9 @@ class BaseAgent(ABC):
     async def execute_with_timeout(self, task: AgentTask) -> AgentResult:
         """å¸¶è¶…æ™‚æ§åˆ¶çš„ä»»å‹™åŸ·è¡Œ"""
         try:
-            result = await asyncio.wait_for(self.process_task(task), timeout=task.timeout)
+            result = await asyncio.wait_for(
+                self.process_task(task), timeout=task.timeout
+            )
             return result
         except asyncio.TimeoutError:
             self.logger.error(f"Task {task.task_id} timed out")
diff --git a/workspace/src/core/instant_generation/agents/architecture_design_agent.py b/workspace/src/core/instant_generation/agents/architecture_design_agent.py
index f86b276..bdb93d7 100644
--- a/workspace/src/core/instant_generation/agents/architecture_design_agent.py
+++ b/workspace/src/core/instant_generation/agents/architecture_design_agent.py
@@ -35,14 +35,20 @@ class ArchitectureDesignAgent(BaseAgent):
 
         try:
             # æå–åˆ†æçµæœå’ŒæŠ€è¡“è¦æ ¼
-            input_analysis = task.input_data.get("input_analysis", {}).get("output_data", {})
+            input_analysis = task.input_data.get("input_analysis", {}).get(
+                "output_data", {}
+            )
             tech_specs = task.input_data.get("tech_specs", {})
 
             # è¨­è¨ˆç³»çµ±æ¶æ§‹
-            system_architecture = await self._design_system_architecture(input_analysis, tech_specs)
+            system_architecture = await self._design_system_architecture(
+                input_analysis, tech_specs
+            )
 
             # è¨­è¨ˆAPIçµæ§‹
-            api_design = await self._design_api_structure(system_architecture, input_analysis)
+            api_design = await self._design_api_structure(
+                system_architecture, input_analysis
+            )
 
             # è¨­è¨ˆæ•¸æ“šæ¶æ§‹
             data_architecture = await self._design_data_architecture(
@@ -75,7 +81,9 @@ class ArchitectureDesignAgent(BaseAgent):
                     "architecture_diagram": self._generate_architecture_diagram(
                         system_architecture
                     ),
-                    "complexity_analysis": self._analyze_complexity(system_architecture),
+                    "complexity_analysis": self._analyze_complexity(
+                        system_architecture
+                    ),
                 },
                 execution_time=execution_time,
             )
@@ -137,7 +145,11 @@ class ArchitectureDesignAgent(BaseAgent):
                 "codes": [400, 401, 403, 404, 500],
                 "messages": "structured",
             },
-            "rate_limiting": {"enabled": True, "requests_per_minute": 100, "burst_limit": 200},
+            "rate_limiting": {
+                "enabled": True,
+                "requests_per_minute": 100,
+                "burst_limit": 200,
+            },
             "documentation": {
                 "type": "OpenAPI 3.0",
                 "auto_generate": True,
@@ -150,12 +162,18 @@ class ArchitectureDesignAgent(BaseAgent):
     ) -> Dict[str, Any]:
         """è¨­è¨ˆæ•¸æ“šæ¶æ§‹"""
         return {
-            "database_type": tech_specs.get("backend", {}).get("database", "postgresql"),
+            "database_type": tech_specs.get("backend", {}).get(
+                "database", "postgresql"
+            ),
             "data_model": "relational",
             "tables": self._define_data_tables(architecture),
             "relationships": self._define_relationships(architecture),
             "indexes": self._define_indexes(architecture),
-            "backup_strategy": {"frequency": "daily", "retention": "30_days", "encryption": True},
+            "backup_strategy": {
+                "frequency": "daily",
+                "retention": "30_days",
+                "encryption": True,
+            },
             "migration_approach": "versioned",
         }
 
@@ -164,7 +182,11 @@ class ArchitectureDesignAgent(BaseAgent):
     ) -> Dict[str, Any]:
         """è¨­è¨ˆå®‰å…¨æ¶æ§‹"""
         return {
-            "authentication": {"method": "JWT", "token_expiry": "24h", "refresh_tokens": True},
+            "authentication": {
+                "method": "JWT",
+                "token_expiry": "24h",
+                "refresh_tokens": True,
+            },
             "authorization": {
                 "model": "RBAC",
                 "roles": ["admin", "user", "guest"],
@@ -176,7 +198,11 @@ class ArchitectureDesignAgent(BaseAgent):
                 "sensitive_data_masking": True,
             },
             "security_headers": {"CSP": True, "HSTS": True, "XSS_Protection": True},
-            "audit_logging": {"enabled": True, "log_level": "INFO", "retention": "90_days"},
+            "audit_logging": {
+                "enabled": True,
+                "log_level": "INFO",
+                "retention": "90_days",
+            },
         }
 
     async def _design_deployment_architecture(
@@ -184,7 +210,9 @@ class ArchitectureDesignAgent(BaseAgent):
     ) -> Dict[str, Any]:
         """è¨­è¨ˆéƒ¨ç½²æ¶æ§‹"""
         return {
-            "deployment_method": tech_specs.get("infrastructure", {}).get("deployment", "docker"),
+            "deployment_method": tech_specs.get("infrastructure", {}).get(
+                "deployment", "docker"
+            ),
             "orchestration": tech_specs.get("infrastructure", {}).get(
                 "orchestration", "kubernetes"
             ),
@@ -203,7 +231,9 @@ class ArchitectureDesignAgent(BaseAgent):
             "scaling": {"horizontal": True, "vertical": True, "auto_scaling": True},
         }
 
-    def _define_components(self, domain: str, tech_specs: Dict[str, Any]) -> List[Dict[str, Any]]:
+    def _define_components(
+        self, domain: str, tech_specs: Dict[str, Any]
+    ) -> List[Dict[str, Any]]:
         """å®šç¾©ç³»çµ±çµ„ä»¶"""
         components = []
 
@@ -300,7 +330,9 @@ class ArchitectureDesignAgent(BaseAgent):
             },
         ]
 
-    def _define_relationships(self, architecture: Dict[str, Any]) -> List[Dict[str, str]]:
+    def _define_relationships(
+        self, architecture: Dict[str, Any]
+    ) -> List[Dict[str, str]]:
         """å®šç¾©é—œä¿‚"""
         return [
             {
diff --git a/workspace/src/core/instant_generation/agents/code_generation_agent.py b/workspace/src/core/instant_generation/agents/code_generation_agent.py
index c9b101e..b843a81 100644
--- a/workspace/src/core/instant_generation/agents/code_generation_agent.py
+++ b/workspace/src/core/instant_generation/agents/code_generation_agent.py
@@ -67,8 +67,12 @@ class CodeGenerationAgent(BaseAgent):
                     "config_files": config_files,
                     "deployment_manifest": deployment_manifest,
                     "documentation": documentation,
-                    "generated_files": self._count_generated_files(code_components, config_files),
-                    "code_quality_score": self._calculate_quality_score(code_components),
+                    "generated_files": self._count_generated_files(
+                        code_components, config_files
+                    ),
+                    "code_quality_score": self._calculate_quality_score(
+                        code_components
+                    ),
                 },
                 execution_time=execution_time,
             )
@@ -92,11 +96,15 @@ class CodeGenerationAgent(BaseAgent):
 
         # ç”Ÿæˆå‰ç«¯çµ„ä»¶
         if "frontend" in tech_specs:
-            components["frontend"] = await self._generate_frontend(tech_specs["frontend"], analysis)
+            components["frontend"] = await self._generate_frontend(
+                tech_specs["frontend"], analysis
+            )
 
         # ç”Ÿæˆå¾Œç«¯çµ„ä»¶
         if "backend" in tech_specs:
-            components["backend"] = await self._generate_backend(tech_specs["backend"], analysis)
+            components["backend"] = await self._generate_backend(
+                tech_specs["backend"], analysis
+            )
 
         # ç”Ÿæˆæ•¸æ“šåº«è…³æœ¬
         if "backend" in tech_specs and "database" in tech_specs["backend"]:
@@ -579,7 +587,9 @@ def get_db():
         db.close()
 """
 
-    async def _generate_database_scripts(self, database_config: Dict[str, Any]) -> Dict[str, str]:
+    async def _generate_database_scripts(
+        self, database_config: Dict[str, Any]
+    ) -> Dict[str, str]:
         """ç”Ÿæˆæ•¸æ“šåº«è…³æœ¬"""
         return {
             "init.sql": """
@@ -618,7 +628,9 @@ CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
 
         return configs
 
-    async def _generate_docker_configs(self, tech_specs: Dict[str, Any]) -> Dict[str, str]:
+    async def _generate_docker_configs(
+        self, tech_specs: Dict[str, Any]
+    ) -> Dict[str, str]:
         """ç”ŸæˆDockeré…ç½®"""
         return {
             "Dockerfile": self._generate_dockerfile(tech_specs),
@@ -721,7 +733,9 @@ ACCESS_TOKEN_EXPIRE_MINUTES=30
             "DEPLOYMENT.md": self._generate_deployment_guide(tech_specs),
         }
 
-    def _generate_readme(self, tech_specs: Dict[str, Any], analysis: Dict[str, Any]) -> str:
+    def _generate_readme(
+        self, tech_specs: Dict[str, Any], analysis: Dict[str, Any]
+    ) -> str:
         """ç”ŸæˆREADME"""
         return """
 # Generated Application
@@ -833,12 +847,21 @@ cp .env.example .env
 - API docs: http://localhost:8000/docs
 """
 
-    def _extract_env_vars(self, components: Dict[str, Any], configs: Dict[str, Any]) -> List[str]:
+    def _extract_env_vars(
+        self, components: Dict[str, Any], configs: Dict[str, Any]
+    ) -> List[str]:
         """æå–ç’°å¢ƒè®Šé‡"""
-        env_vars = ["DATABASE_URL", "SECRET_KEY", "ALGORITHM", "ACCESS_TOKEN_EXPIRE_MINUTES"]
+        env_vars = [
+            "DATABASE_URL",
+            "SECRET_KEY",
+            "ALGORITHM",
+            "ACCESS_TOKEN_EXPIRE_MINUTES",
+        ]
         return env_vars
 
-    def _count_generated_files(self, components: Dict[str, Any], configs: Dict[str, Any]) -> int:
+    def _count_generated_files(
+        self, components: Dict[str, Any], configs: Dict[str, Any]
+    ) -> int:
         """è¨ˆç®—ç”Ÿæˆçš„æ–‡ä»¶æ•¸é‡"""
         count = 0
         for component in components.values():
@@ -847,7 +870,9 @@ cp .env.example .env
                 # éæ­¸è¨ˆç®—å­ç›®éŒ„ä¸­çš„æ–‡ä»¶
                 for sub_component in component.values():
                     if isinstance(sub_component, dict):
-                        count += len([k for k, v in sub_component.items() if isinstance(v, str)])
+                        count += len(
+                            [k for k, v in sub_component.items() if isinstance(v, str)]
+                        )
 
         for config in configs.values():
             if isinstance(config, dict):
diff --git a/workspace/src/core/instant_generation/agents/deployment_agent.py b/workspace/src/core/instant_generation/agents/deployment_agent.py
index 6c6c089..6a842e7 100644
--- a/workspace/src/core/instant_generation/agents/deployment_agent.py
+++ b/workspace/src/core/instant_generation/agents/deployment_agent.py
@@ -36,14 +36,18 @@ class DeploymentAgent(BaseAgent):
 
         try:
             # æå–ç›¸é—œæ•¸æ“š
-            code_generation = task.input_data.get("code_generation", {}).get("output_data", {})
+            code_generation = task.input_data.get("code_generation", {}).get(
+                "output_data", {}
+            )
             testing = task.input_data.get("testing", {}).get("output_data", {})
             architecture_design = task.input_data.get("architecture_design", {}).get(
                 "output_data", {}
             )
 
             # ç¢ºå®šéƒ¨ç½²ç­–ç•¥
-            deployment_strategy = self._determine_deployment_strategy(architecture_design)
+            deployment_strategy = self._determine_deployment_strategy(
+                architecture_design
+            )
 
             # ç”Ÿæˆéƒ¨ç½²é…ç½®
             deployment_config = await self.deployment_strategies[deployment_strategy](
@@ -56,13 +60,19 @@ class DeploymentAgent(BaseAgent):
             )
 
             # è¨­ç½®ç›£æ§å’Œæ—¥èªŒ
-            monitoring_setup = await self._setup_monitoring(deployment_config, architecture_design)
+            monitoring_setup = await self._setup_monitoring(
+                deployment_config, architecture_design
+            )
 
             # é…ç½®CI/CDç®¡é“
-            cicd_pipeline = await self._configure_cicd_pipeline(deployment_config, testing)
+            cicd_pipeline = await self._configure_cicd_pipeline(
+                deployment_config, testing
+            )
 
             # ç”Ÿæˆéƒ¨ç½²è…³æœ¬
-            deployment_scripts = await self._generate_deployment_scripts(deployment_config)
+            deployment_scripts = await self._generate_deployment_scripts(
+                deployment_config
+            )
 
             # å‰µå»ºéƒ¨ç½²æ¸…å–®
             deployment_manifest = await self._create_deployment_manifest(
@@ -84,7 +94,9 @@ class DeploymentAgent(BaseAgent):
                     "cicd_pipeline": cicd_pipeline,
                     "deployment_scripts": deployment_scripts,
                     "deployment_manifest": deployment_manifest,
-                    "estimated_deployment_time": self._estimate_deployment_time(deployment_config),
+                    "estimated_deployment_time": self._estimate_deployment_time(
+                        deployment_config
+                    ),
                     "resource_requirements": self._calculate_resource_requirements(
                         deployment_config
                     ),
@@ -205,7 +217,11 @@ class DeploymentAgent(BaseAgent):
                 "application": "Custom metrics",
                 "infrastructure": "Node Exporter",
             },
-            "logging": {"framework": "ELK Stack", "log_level": "INFO", "retention": "30 days"},
+            "logging": {
+                "framework": "ELK Stack",
+                "log_level": "INFO",
+                "retention": "30 days",
+            },
             "alerting": {
                 "tool": "Grafana + Alertmanager",
                 "channels": ["email", "slack"],
@@ -224,8 +240,15 @@ class DeploymentAgent(BaseAgent):
             "stages": [
                 {"name": "lint", "commands": ["npm run lint", "flake8 ."]},
                 {"name": "test", "commands": ["npm test", "pytest"]},
-                {"name": "build", "commands": ["npm run build", "docker build -t app ."]},
-                {"name": "deploy", "commands": ["docker-compose up -d"], "environment": "staging"},
+                {
+                    "name": "build",
+                    "commands": ["npm run build", "docker build -t app ."],
+                },
+                {
+                    "name": "deploy",
+                    "commands": ["docker-compose up -d"],
+                    "environment": "staging",
+                },
             ],
             "artifacts": ["build/", "dist/", "coverage/"],
             "notifications": ["slack", "email"],
@@ -244,7 +267,10 @@ class DeploymentAgent(BaseAgent):
         }
 
     async def _create_deployment_manifest(
-        self, config: Dict[str, Any], env_configs: Dict[str, str], monitoring: Dict[str, Any]
+        self,
+        config: Dict[str, Any],
+        env_configs: Dict[str, str],
+        monitoring: Dict[str, Any],
     ) -> Dict[str, Any]:
         """å‰µå»ºéƒ¨ç½²æ¸…å–®"""
         return {
@@ -259,7 +285,11 @@ class DeploymentAgent(BaseAgent):
                 "frontend": "/",
                 "database": "connection_check",
             },
-            "rollback_plan": {"enabled": True, "retention": "3_versions", "automatic": False},
+            "rollback_plan": {
+                "enabled": True,
+                "retention": "3_versions",
+                "automatic": False,
+            },
             "scaling": {"min_replicas": 2, "max_replicas": 10, "target_cpu": 70},
         }
 
@@ -377,8 +407,18 @@ networks:
     def _generate_health_checks(self, components: Dict[str, Any]) -> Dict[str, Any]:
         """ç”Ÿæˆå¥åº·æª¢æŸ¥"""
         return {
-            "backend": {"endpoint": "/health", "interval": "30s", "timeout": "10s", "retries": 3},
-            "frontend": {"endpoint": "/", "interval": "30s", "timeout": "5s", "retries": 3},
+            "backend": {
+                "endpoint": "/health",
+                "interval": "30s",
+                "timeout": "10s",
+                "retries": 3,
+            },
+            "frontend": {
+                "endpoint": "/",
+                "interval": "30s",
+                "timeout": "5s",
+                "retries": 3,
+            },
         }
 
     def _estimate_deployment_time(self, config: Dict[str, Any]) -> Dict[str, int]:
@@ -390,9 +430,16 @@ networks:
             "total_time_minutes": 6,
         }
 
-    def _calculate_resource_requirements(self, config: Dict[str, Any]) -> Dict[str, Any]:
+    def _calculate_resource_requirements(
+        self, config: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """è¨ˆç®—è³‡æºéœ€æ±‚"""
-        return {"cpu": "2 cores", "memory": "4GB RAM", "storage": "20GB SSD", "network": "100Mbps"}
+        return {
+            "cpu": "2 cores",
+            "memory": "4GB RAM",
+            "storage": "20GB SSD",
+            "network": "100Mbps",
+        }
 
     # é…ç½®æ–‡ä»¶ç”Ÿæˆæ–¹æ³•
     def _generate_dev_env(self) -> str:
diff --git a/workspace/src/core/instant_generation/agents/input_analysis_agent.py b/workspace/src/core/instant_generation/agents/input_analysis_agent.py
index d2d5082..ed52f79 100644
--- a/workspace/src/core/instant_generation/agents/input_analysis_agent.py
+++ b/workspace/src/core/instant_generation/agents/input_analysis_agent.py
@@ -78,7 +78,9 @@ class InputAnalysisAgent(BaseAgent):
                 error_message=str(e),
             )
 
-    async def _analyze_input(self, user_input: str, context: Dict[str, Any]) -> Dict[str, Any]:
+    async def _analyze_input(
+        self, user_input: str, context: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """æ·±åº¦åˆ†æç”¨æˆ¶è¼¸å…¥"""
         analysis = {
             "original_input": user_input,
@@ -116,8 +118,16 @@ class InputAnalysisAgent(BaseAgent):
         """ç”ŸæˆæŠ€è¡“è¦æ ¼"""
         tech_specs = {
             "architecture": "microservices",
-            "frontend": {"framework": "react", "styling": "tailwind", "state_management": "redux"},
-            "backend": {"framework": "fastapi", "database": "postgresql", "cache": "redis"},
+            "frontend": {
+                "framework": "react",
+                "styling": "tailwind",
+                "state_management": "redux",
+            },
+            "backend": {
+                "framework": "fastapi",
+                "database": "postgresql",
+                "cache": "redis",
+            },
             "infrastructure": {
                 "deployment": "docker",
                 "orchestration": "kubernetes",
@@ -135,7 +145,9 @@ class InputAnalysisAgent(BaseAgent):
 
         return tech_specs
 
-    async def _create_execution_plan(self, tech_specs: Dict[str, Any]) -> Dict[str, Any]:
+    async def _create_execution_plan(
+        self, tech_specs: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """å‰µå»ºåŸ·è¡Œè¨ˆåŠƒ"""
         return {
             "phases": [
diff --git a/workspace/src/core/instant_generation/agents/optimization_agent.py b/workspace/src/core/instant_generation/agents/optimization_agent.py
index 5accb18..a986a65 100644
--- a/workspace/src/core/instant_generation/agents/optimization_agent.py
+++ b/workspace/src/core/instant_generation/agents/optimization_agent.py
@@ -28,7 +28,12 @@ class OptimizationAgent(BaseAgent):
 
     def validate_input(self, input_data: Dict[str, Any]) -> bool:
         """é©—è­‰è¼¸å…¥æ•¸æ“šæ ¼å¼"""
-        required_fields = ["deployment", "testing", "code_generation", "architecture_design"]
+        required_fields = [
+            "deployment",
+            "testing",
+            "code_generation",
+            "architecture_design",
+        ]
         return all(field in input_data for field in required_fields)
 
     async def process_task(self, task: AgentTask) -> AgentResult:
@@ -39,7 +44,9 @@ class OptimizationAgent(BaseAgent):
             # æå–ç›¸é—œæ•¸æ“š
             deployment = task.input_data.get("deployment", {}).get("output_data", {})
             testing = task.input_data.get("testing", {}).get("output_data", {})
-            code_generation = task.input_data.get("code_generation", {}).get("output_data", {})
+            code_generation = task.input_data.get("code_generation", {}).get(
+                "output_data", {}
+            )
             architecture_design = task.input_data.get("architecture_design", {}).get(
                 "output_data", {}
             )
@@ -57,20 +64,24 @@ class OptimizationAgent(BaseAgent):
                     optimization_results[opt_type] = {"success": False, "error": str(e)}
 
             # ç”Ÿæˆå„ªåŒ–å ±å‘Š
-            optimization_report = await self._generate_optimization_report(optimization_results)
+            optimization_report = await self._generate_optimization_report(
+                optimization_results
+            )
 
             # å‰µå»ºå„ªåŒ–å»ºè­°
-            optimization_recommendations = await self._create_optimization_recommendations(
-                optimization_results
+            optimization_recommendations = (
+                await self._create_optimization_recommendations(optimization_results)
             )
 
             # ç”ŸæˆæŒçºŒå„ªåŒ–è¨ˆåŠƒ
-            continuous_optimization_plan = await self._create_continuous_optimization_plan(
-                optimization_results
+            continuous_optimization_plan = (
+                await self._create_continuous_optimization_plan(optimization_results)
             )
 
             # è¨ˆç®—æ•´é«”æ”¹é€²æŒ‡æ¨™
-            improvement_metrics = await self._calculate_improvement_metrics(optimization_results)
+            improvement_metrics = await self._calculate_improvement_metrics(
+                optimization_results
+            )
 
             end_time = datetime.now()
             execution_time = (end_time - start_time).total_seconds()
@@ -86,7 +97,11 @@ class OptimizationAgent(BaseAgent):
                     "continuous_optimization_plan": continuous_optimization_plan,
                     "improvement_metrics": improvement_metrics,
                     "optimizations_applied": len(
-                        [r for r in optimization_results.values() if r.get("success", False)]
+                        [
+                            r
+                            for r in optimization_results.values()
+                            if r.get("success", False)
+                        ]
                     ),
                     "expected_improvements": self._calculate_expected_improvements(
                         optimization_results
@@ -211,7 +226,9 @@ class OptimizationAgent(BaseAgent):
                 },
             },
             "security_improvements": {
-                "vulnerabilities_fixed": len([k for k, v in security_checks.items() if not v]),
+                "vulnerabilities_fixed": len(
+                    [k for k, v in security_checks.items() if not v]
+                ),
                 "security_score": "+25%",
                 "compliance_level": "Enhanced",
             },
@@ -285,9 +302,13 @@ class OptimizationAgent(BaseAgent):
             },
         }
 
-    async def _generate_optimization_report(self, results: Dict[str, Any]) -> Dict[str, Any]:
+    async def _generate_optimization_report(
+        self, results: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """ç”Ÿæˆå„ªåŒ–å ±å‘Š"""
-        successful_optimizations = [k for k, v in results.items() if v.get("success", False)]
+        successful_optimizations = [
+            k for k, v in results.items() if v.get("success", False)
+        ]
 
         return {
             "summary": {
@@ -348,7 +369,9 @@ class OptimizationAgent(BaseAgent):
 
         return recommendations
 
-    async def _create_continuous_optimization_plan(self, results: Dict[str, Any]) -> Dict[str, Any]:
+    async def _create_continuous_optimization_plan(
+        self, results: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """å‰µå»ºæŒçºŒå„ªåŒ–è¨ˆåŠƒ"""
         return {
             "daily": [
@@ -373,7 +396,9 @@ class OptimizationAgent(BaseAgent):
             ],
         }
 
-    async def _calculate_improvement_metrics(self, results: Dict[str, Any]) -> Dict[str, Any]:
+    async def _calculate_improvement_metrics(
+        self, results: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """è¨ˆç®—æ”¹é€²æŒ‡æ¨™"""
         metrics = {
             "performance_improvement": 0,
@@ -390,7 +415,9 @@ class OptimizationAgent(BaseAgent):
                 if isinstance(improvements, dict):
                     for key, value in improvements.items():
                         if "performance" in key.lower() or "response" in key.lower():
-                            metrics["performance_improvement"] += abs(int(value.replace("%", "")))
+                            metrics["performance_improvement"] += abs(
+                                int(value.replace("%", ""))
+                            )
                         elif "cost" in key.lower():
                             metrics["cost_savings"] += abs(int(value.replace("%", "")))
                         elif "security" in key.lower():
@@ -398,11 +425,15 @@ class OptimizationAgent(BaseAgent):
                                 int(value.replace("%", ""))
                             )
                         elif "scalability" in key.lower():
-                            metrics["scalability_increase"] += abs(int(value.replace("%", "")))
+                            metrics["scalability_increase"] += abs(
+                                int(value.replace("%", ""))
+                            )
 
         return metrics
 
-    def _calculate_expected_improvements(self, results: Dict[str, Any]) -> Dict[str, str]:
+    def _calculate_expected_improvements(
+        self, results: Dict[str, Any]
+    ) -> Dict[str, str]:
         """è¨ˆç®—é æœŸæ”¹é€²"""
         return {
             "performance": "30-50% faster response times",
diff --git a/workspace/src/core/instant_generation/agents/testing_agent.py b/workspace/src/core/instant_generation/agents/testing_agent.py
index 0737022..f0c850f 100644
--- a/workspace/src/core/instant_generation/agents/testing_agent.py
+++ b/workspace/src/core/instant_generation/agents/testing_agent.py
@@ -37,11 +37,15 @@ class TestingAgent(BaseAgent):
 
         try:
             # æå–ä»£ç¢¼å’Œæ¶æ§‹ä¿¡æ¯
-            code_generation = task.input_data.get("code_generation", {}).get("output_data", {})
+            code_generation = task.input_data.get("code_generation", {}).get(
+                "output_data", {}
+            )
             architecture_design = task.input_data.get("architecture_design", {}).get(
                 "output_data", {}
             )
-            input_analysis = task.input_data.get("input_analysis", {}).get("output_data", {})
+            input_analysis = task.input_data.get("input_analysis", {}).get(
+                "output_data", {}
+            )
 
             # ç”Ÿæˆæ¸¬è©¦å¥—ä»¶
             test_suite = await self._generate_test_suite(
@@ -96,14 +100,21 @@ class TestingAgent(BaseAgent):
             )
 
     async def _generate_test_suite(
-        self, code: Dict[str, Any], architecture: Dict[str, Any], analysis: Dict[str, Any]
+        self,
+        code: Dict[str, Any],
+        architecture: Dict[str, Any],
+        analysis: Dict[str, Any],
     ) -> Dict[str, Any]:
         """ç”Ÿæˆå®Œæ•´æ¸¬è©¦å¥—ä»¶"""
         test_suite = {
             "unit_tests": await self.test_types["unit"](code, architecture),
-            "integration_tests": await self.test_types["integration"](code, architecture),
+            "integration_tests": await self.test_types["integration"](
+                code, architecture
+            ),
             "api_tests": await self.test_types["api"](code, architecture),
-            "performance_tests": await self.test_types["performance"](code, architecture),
+            "performance_tests": await self.test_types["performance"](
+                code, architecture
+            ),
             "security_tests": await self.test_types["security"](code, architecture),
         }
 
@@ -125,7 +136,12 @@ class TestingAgent(BaseAgent):
                     "components/Home.test.js": self._generate_home_test(),
                     "App.test.js": self._generate_app_test(),
                 },
-                "coverage": {"statements": 90, "branches": 85, "functions": 90, "lines": 90},
+                "coverage": {
+                    "statements": 90,
+                    "branches": 85,
+                    "functions": 90,
+                    "lines": 90,
+                },
             }
 
         # å¾Œç«¯APIæ¸¬è©¦
@@ -137,7 +153,12 @@ class TestingAgent(BaseAgent):
                     "test_auth.py": self._generate_auth_api_test(),
                     "test_models.py": self._generate_models_test(),
                 },
-                "coverage": {"statements": 85, "branches": 80, "functions": 85, "lines": 85},
+                "coverage": {
+                    "statements": 85,
+                    "branches": 80,
+                    "functions": 85,
+                    "lines": 85,
+                },
             }
 
         return tests
@@ -197,8 +218,18 @@ class TestingAgent(BaseAgent):
             "load_testing": {
                 "tool": "Locust",
                 "scenarios": [
-                    {"name": "normal_load", "users": 100, "spawn_rate": 10, "duration": "10m"},
-                    {"name": "stress_test", "users": 1000, "spawn_rate": 50, "duration": "5m"},
+                    {
+                        "name": "normal_load",
+                        "users": 100,
+                        "spawn_rate": 10,
+                        "duration": "10m",
+                    },
+                    {
+                        "name": "stress_test",
+                        "users": 1000,
+                        "spawn_rate": 50,
+                        "duration": "5m",
+                    },
                 ],
                 "targets": {
                     "response_time_p95": "<500ms",
@@ -283,8 +314,11 @@ class TestingAgent(BaseAgent):
 
         checks = {
             "authentication": {
-                "implemented": security_arch.get("authentication", {}).get("method") == "JWT",
-                "token_expiry": security_arch.get("authentication", {}).get("token_expiry")
+                "implemented": security_arch.get("authentication", {}).get("method")
+                == "JWT",
+                "token_expiry": security_arch.get("authentication", {}).get(
+                    "token_expiry"
+                )
                 == "24h",
                 "refresh_tokens": security_arch.get("authentication", {}).get(
                     "refresh_tokens", False
@@ -292,7 +326,8 @@ class TestingAgent(BaseAgent):
             },
             "authorization": {
                 "model": security_arch.get("authorization", {}).get("model"),
-                "rbac_implemented": security_arch.get("authorization", {}).get("model") == "RBAC",
+                "rbac_implemented": security_arch.get("authorization", {}).get("model")
+                == "RBAC",
             },
             "data_protection": {
                 "encryption_at_rest": security_arch.get("data_protection", {}).get(
@@ -577,7 +612,11 @@ class TestModels:
                     total_checks += 1
                     if isinstance(value, bool) and value:
                         score += 1
-                    elif isinstance(value, str) and value.lower() in ["jwt", "rbac", "true"]:
+                    elif isinstance(value, str) and value.lower() in [
+                        "jwt",
+                        "rbac",
+                        "true",
+                    ]:
                         score += 1
 
         return (score / total_checks * 100) if total_checks > 0 else 0
diff --git a/workspace/src/core/instant_generation/main.py b/workspace/src/core/instant_generation/main.py
index 1177d7b..b8553ec 100644
--- a/workspace/src/core/instant_generation/main.py
+++ b/workspace/src/core/instant_generation/main.py
@@ -88,7 +88,10 @@ class InstantGenerationSystem:
             )
 
             # åŸ·è¡Œè‡ªæˆ‘ä¿®å¾©ï¼ˆå¦‚æœéœ€è¦ï¼‰
-            if not workflow_result.get("success", False) and self.config["self_healing_enabled"]:
+            if (
+                not workflow_result.get("success", False)
+                and self.config["self_healing_enabled"]
+            ):
                 self.logger.info("Attempting self-healing...")
                 healing_result = await self.self_healing.heal_workflow(
                     workflow_result, user_input, context
@@ -97,13 +100,20 @@ class InstantGenerationSystem:
                     workflow_result = healing_result
 
             # æ€§èƒ½å„ªåŒ–
-            if workflow_result.get("success", False) and self.config["optimization_enabled"]:
+            if (
+                workflow_result.get("success", False)
+                and self.config["optimization_enabled"]
+            ):
                 self.logger.info("Optimizing generated system...")
-                optimization_result = await self.optimizer.optimize_system(workflow_result)
+                optimization_result = await self.optimizer.optimize_system(
+                    workflow_result
+                )
                 workflow_result["optimization"] = optimization_result
 
             # ç”Ÿæˆæœ€çµ‚è¼¸å‡º
-            final_output = await self._generate_final_output(workflow_result, generation_id)
+            final_output = await self._generate_final_output(
+                workflow_result, generation_id
+            )
 
             # æ›´æ–°çµ±è¨ˆ
             execution_time = time.time() - start_time
@@ -120,13 +130,16 @@ class InstantGenerationSystem:
                 },
             )
 
-            self.logger.info(f"Generation {generation_id} completed in {execution_time:.2f}s")
+            self.logger.info(
+                f"Generation {generation_id} completed in {execution_time:.2f}s"
+            )
 
             return {
                 "success": True,
                 "generation_id": generation_id,
                 "execution_time_seconds": execution_time,
-                "target_time_met": execution_time <= (self.config["target_time_minutes"] * 60),
+                "target_time_met": execution_time
+                <= (self.config["target_time_minutes"] * 60),
                 "output": final_output,
                 "workflow_result": workflow_result,
             }
@@ -141,7 +154,10 @@ class InstantGenerationSystem:
                 "generation_id": generation_id,
                 "execution_time_seconds": execution_time,
                 "error": str(e),
-                "debug_info": {"config": self.config, "system_status": self.get_system_status()},
+                "debug_info": {
+                    "config": self.config,
+                    "system_status": self.get_system_status(),
+                },
             }
 
         finally:
@@ -172,22 +188,36 @@ class InstantGenerationSystem:
                 "complexity": analysis_result.get("output_data", {}).get(
                     "complexity_score", "medium"
                 ),
-                "generated_files": code_result.get("output_data", {}).get("generated_files", 0),
+                "generated_files": code_result.get("output_data", {}).get(
+                    "generated_files", 0
+                ),
             },
             "generated_components": {
-                "source_code": code_result.get("output_data", {}).get("code_components", {}),
-                "configuration": code_result.get("output_data", {}).get("config_files", {}),
-                "documentation": code_result.get("output_data", {}).get("documentation", {}),
+                "source_code": code_result.get("output_data", {}).get(
+                    "code_components", {}
+                ),
+                "configuration": code_result.get("output_data", {}).get(
+                    "config_files", {}
+                ),
+                "documentation": code_result.get("output_data", {}).get(
+                    "documentation", {}
+                ),
             },
             "deployment_info": {
-                "manifest": code_result.get("output_data", {}).get("deployment_manifest", {}),
+                "manifest": code_result.get("output_data", {}).get(
+                    "deployment_manifest", {}
+                ),
                 "deployment_status": deployment_result.get("output_data", {}).get(
                     "deployment_status", "ready"
                 ),
-                "access_urls": deployment_result.get("output_data", {}).get("access_urls", []),
+                "access_urls": deployment_result.get("output_data", {}).get(
+                    "access_urls", []
+                ),
             },
             "performance_metrics": {
-                "code_quality": code_result.get("output_data", {}).get("code_quality_score", 0),
+                "code_quality": code_result.get("output_data", {}).get(
+                    "code_quality_score", 0
+                ),
                 "optimization_applied": optimization_result.get("success", False),
                 "performance_improvements": optimization_result.get("improvements", []),
             },
@@ -226,7 +256,9 @@ class InstantGenerationSystem:
             "is_running": self.is_running,
             "start_time": self.start_time.isoformat() if self.start_time else None,
             "uptime_seconds": (
-                (datetime.now() - self.start_time).total_seconds() if self.start_time else 0
+                (datetime.now() - self.start_time).total_seconds()
+                if self.start_time
+                else 0
             ),
             "statistics": self.stats.copy(),
             "workflow_stats": self.workflow_engine.get_stats(),
@@ -273,7 +305,9 @@ class InstantGenerationSystem:
 
         return health_status
 
-    async def save_output(self, output: Dict[str, Any], output_dir: str = "output") -> str:
+    async def save_output(
+        self, output: Dict[str, Any], output_dir: str = "output"
+    ) -> str:
         """ä¿å­˜ç”Ÿæˆçµæœåˆ°æ–‡ä»¶"""
         output_path = Path(output_dir)
         output_path.mkdir(exist_ok=True)
@@ -290,12 +324,16 @@ class InstantGenerationSystem:
         if "output" in output and "generated_components" in output["output"]:
             code_dir = output_path / f"{generation_id}_{timestamp}_code"
             code_dir.mkdir(exist_ok=True)
-            await self._save_code_files(output["output"]["generated_components"], code_dir)
+            await self._save_code_files(
+                output["output"]["generated_components"], code_dir
+            )
 
         self.logger.info(f"Output saved to {main_file}")
         return str(main_file)
 
-    async def _save_code_files(self, components: Dict[str, Any], base_dir: Path) -> None:
+    async def _save_code_files(
+        self, components: Dict[str, Any], base_dir: Path
+    ) -> None:
         """ä¿å­˜ä»£ç¢¼æ–‡ä»¶åˆ°ç›®éŒ„çµæ§‹"""
         import os
 
@@ -330,7 +368,9 @@ def get_system(config: Dict[str, Any] = None) -> InstantGenerationSystem:
 # ä¾¿æ·å‡½æ•¸
 
 
-async def generate_system(user_input: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
+async def generate_system(
+    user_input: str, context: Dict[str, Any] = None
+) -> Dict[str, Any]:
     """ä¾¿æ·å‡½æ•¸ï¼šç”Ÿæˆç³»çµ±"""
     system = get_system()
     return await system.generate_system(user_input, context)
diff --git a/workspace/src/core/instant_generation/monitoring/__init__.py b/workspace/src/core/instant_generation/monitoring/__init__.py
index 902173c..06c7d03 100644
--- a/workspace/src/core/instant_generation/monitoring/__init__.py
+++ b/workspace/src/core/instant_generation/monitoring/__init__.py
@@ -246,7 +246,9 @@ class RealTimeMonitor:
                 )
 
         # æª¢æŸ¥å…§å­˜ä½¿ç”¨ç‡
-        memory_metrics = list(self.metrics_store.get(f"{session_id}_system_memory_usage", []))
+        memory_metrics = list(
+            self.metrics_store.get(f"{session_id}_system_memory_usage", [])
+        )
         if memory_metrics:
             latest_memory = memory_metrics[-1].value
             if latest_memory > self.alert_thresholds.get("memory_warning", 85):
@@ -390,7 +392,9 @@ class RealTimeMonitor:
 
         return current_metrics
 
-    def get_recent_alerts(self, session_id: str = None, hours: int = 24) -> List[Dict[str, Any]]:
+    def get_recent_alerts(
+        self, session_id: str = None, hours: int = 24
+    ) -> List[Dict[str, Any]]:
         """ç²å–æœ€è¿‘è­¦å ±"""
         cutoff_time = datetime.now() - timedelta(hours=hours)
 
@@ -403,10 +407,16 @@ class RealTimeMonitor:
     async def health_check(self) -> Dict[str, Any]:
         """ç›£æ§ç³»çµ±å¥åº·æª¢æŸ¥"""
         return {
-            "status": "healthy" if self.is_monitoring or len(self.active_sessions) > 0 else "idle",
+            "status": (
+                "healthy"
+                if self.is_monitoring or len(self.active_sessions) > 0
+                else "idle"
+            ),
             "is_monitoring": self.is_monitoring,
             "active_sessions": len(self.active_sessions),
-            "total_metrics": sum(len(metrics) for metrics in self.metrics_store.values()),
+            "total_metrics": sum(
+                len(metrics) for metrics in self.metrics_store.values()
+            ),
             "active_alerts": len([a for a in self.alerts if not a.resolved]),
             "last_collection": datetime.now().isoformat(),
         }
@@ -420,7 +430,9 @@ class PerformanceTracker:
         self.performance_history: List[Dict[str, Any]] = []
         self.generation_metrics: Dict[str, PerformanceMetric] = {}
 
-    async def record_generation(self, generation_id: str, metrics: Dict[str, Any]) -> None:
+    async def record_generation(
+        self, generation_id: str, metrics: Dict[str, Any]
+    ) -> None:
         """è¨˜éŒ„ç”ŸæˆæŒ‡æ¨™"""
         record = {
             "generation_id": generation_id,
@@ -472,8 +484,12 @@ class PerformanceTracker:
 
         # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
         scores = [r["performance_score"] for r in recent_records]
-        execution_times = [r["metrics"].get("execution_time", 0) for r in recent_records]
-        success_count = sum(1 for r in recent_records if r["metrics"].get("success", False))
+        execution_times = [
+            r["metrics"].get("execution_time", 0) for r in recent_records
+        ]
+        success_count = sum(
+            1 for r in recent_records if r["metrics"].get("success", False)
+        )
 
         return {
             "total_generations": len(recent_records),
@@ -519,7 +535,9 @@ class PerformanceTracker:
             "metric": metric_name,
             "current_value": values[-1] if values else None,
             "average_value": sum(values) / len(values),
-            "trend": "increasing" if trend > 0 else "decreasing" if trend < 0 else "stable",
+            "trend": (
+                "increasing" if trend > 0 else "decreasing" if trend < 0 else "stable"
+            ),
             "data_points": len(values),
             "period_hours": hours,
         }
diff --git a/workspace/src/core/instant_generation/optimization/__init__.py b/workspace/src/core/instant_generation/optimization/__init__.py
index 2ecdd41..a05f3a4 100644
--- a/workspace/src/core/instant_generation/optimization/__init__.py
+++ b/workspace/src/core/instant_generation/optimization/__init__.py
@@ -81,17 +81,23 @@ class SelfHealingSystem:
             healing_strategy = await self._determine_healing_strategy(failure_analysis)
 
             # åŸ·è¡Œä¿®å¾©å‹•ä½œ
-            healing_result = await self._execute_healing_strategy(healing_strategy, workflow_result)
+            healing_result = await self._execute_healing_strategy(
+                healing_strategy, workflow_result
+            )
 
             # è¨˜éŒ„ä¿®å¾©æ­·å²
-            self._record_healing(healing_id, failure_analysis, healing_strategy, healing_result)
+            self._record_healing(
+                healing_id, failure_analysis, healing_strategy, healing_result
+            )
 
             if healing_result.get("success", False):
                 return {
                     "success": True,
                     "healing_id": healing_id,
                     "healed_workflow": healing_result.get("workflow_result"),
-                    "healing_actions_taken": healing_result.get("actions_performed", []),
+                    "healing_actions_taken": healing_result.get(
+                        "actions_performed", []
+                    ),
                     "improvements": healing_result.get("improvements", {}),
                 }
             else:
@@ -99,7 +105,9 @@ class SelfHealingSystem:
                     "success": False,
                     "healing_id": healing_id,
                     "error": healing_result.get("error", "Healing failed"),
-                    "alternative_suggestions": await self._suggest_alternatives(failure_analysis),
+                    "alternative_suggestions": await self._suggest_alternatives(
+                        failure_analysis
+                    ),
                 }
 
         except Exception as e:
@@ -146,7 +154,9 @@ class SelfHealingSystem:
 
         return analysis
 
-    async def _determine_healing_strategy(self, failure_analysis: Dict[str, Any]) -> Dict[str, Any]:
+    async def _determine_healing_strategy(
+        self, failure_analysis: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """ç¢ºå®šä¿®å¾©ç­–ç•¥"""
         strategy = {
             "primary_strategy": HealingStrategy.RETRY,
@@ -173,7 +183,10 @@ class SelfHealingSystem:
             strategy["estimated_success_rate"] = 0.7
 
         # æ·»åŠ å‚™ç”¨ç­–ç•¥
-        strategy["fallback_strategies"] = [HealingStrategy.RESTART, HealingStrategy.MANUAL]
+        strategy["fallback_strategies"] = [
+            HealingStrategy.RESTART,
+            HealingStrategy.MANUAL,
+        ]
 
         return strategy
 
@@ -188,7 +201,9 @@ class SelfHealingSystem:
             if primary_strategy == HealingStrategy.RETRY:
                 return await self._execute_retry_strategy(workflow_result, parameters)
             elif primary_strategy == HealingStrategy.FALLBACK:
-                return await self._execute_fallback_strategy(workflow_result, parameters)
+                return await self._execute_fallback_strategy(
+                    workflow_result, parameters
+                )
             elif primary_strategy == HealingStrategy.SCALING:
                 return await self._execute_scaling_strategy(workflow_result, parameters)
             elif primary_strategy == HealingStrategy.RESTART:
@@ -242,7 +257,9 @@ class SelfHealingSystem:
             "improvements": {"stability": "+20%"},
         }
 
-    async def _suggest_alternatives(self, failure_analysis: Dict[str, Any]) -> List[str]:
+    async def _suggest_alternatives(
+        self, failure_analysis: Dict[str, Any]
+    ) -> List[str]:
         """å»ºè­°æ›¿ä»£æ–¹æ¡ˆ"""
         alternatives = [
             "Reduce system complexity",
@@ -279,7 +296,8 @@ class SelfHealingSystem:
         recent_healings = [
             h
             for h in self.healing_history
-            if datetime.fromisoformat(h["timestamp"]) > datetime.now() - timedelta(hours=24)
+            if datetime.fromisoformat(h["timestamp"])
+            > datetime.now() - timedelta(hours=24)
         ]
 
         success_rate = (
@@ -293,7 +311,9 @@ class SelfHealingSystem:
             "success_rate_24h": success_rate,
             "total_healings": len(self.healing_history),
             "active_healings": len(self.active_healings),
-            "last_healing": self.healing_history[-1]["timestamp"] if self.healing_history else None,
+            "last_healing": (
+                self.healing_history[-1]["timestamp"] if self.healing_history else None
+            ),
         }
 
 
@@ -314,10 +334,14 @@ class PerformanceOptimizer:
             bottlenecks = await self._analyze_performance_bottlenecks(workflow_result)
 
             # ç”Ÿæˆå„ªåŒ–å»ºè­°
-            recommendations = await self._generate_optimization_recommendations(bottlenecks)
+            recommendations = await self._generate_optimization_recommendations(
+                bottlenecks
+            )
 
             # æ‡‰ç”¨è‡ªå‹•å„ªåŒ–
-            applied_optimizations = await self._apply_automatic_optimizations(recommendations)
+            applied_optimizations = await self._apply_automatic_optimizations(
+                recommendations
+            )
 
             # è¨˜éŒ„å„ªåŒ–æ­·å²
             self._record_optimization(
@@ -337,7 +361,11 @@ class PerformanceOptimizer:
 
         except Exception as e:
             self.logger.error(f"Performance optimization {optimization_id} failed: {e}")
-            return {"success": False, "optimization_id": optimization_id, "error": str(e)}
+            return {
+                "success": False,
+                "optimization_id": optimization_id,
+                "error": str(e),
+            }
 
     async def _analyze_performance_bottlenecks(
         self, workflow_result: Dict[str, Any]
@@ -465,7 +493,8 @@ class PerformanceOptimizer:
         recent_optimizations = [
             o
             for o in self.optimization_history
-            if datetime.fromisoformat(o["timestamp"]) > datetime.now() - timedelta(hours=24)
+            if datetime.fromisoformat(o["timestamp"])
+            > datetime.now() - timedelta(hours=24)
         ]
 
         return {
@@ -473,7 +502,9 @@ class PerformanceOptimizer:
             "total_optimizations": len(self.optimization_history),
             "recent_optimizations": len(recent_optimizations),
             "last_optimization": (
-                self.optimization_history[-1]["timestamp"] if self.optimization_history else None
+                self.optimization_history[-1]["timestamp"]
+                if self.optimization_history
+                else None
             ),
         }
 
@@ -496,7 +527,9 @@ class ResourceManager:
         }
 
         # è¨˜éŒ„è³‡æºä½¿ç”¨
-        self.resource_usage[f"alloc_{datetime.now().strftime('%Y%m%d_%H%M%S')}"] = allocation
+        self.resource_usage[f"alloc_{datetime.now().strftime('%Y%m%d_%H%M%S')}"] = (
+            allocation
+        )
 
         return {
             "success": True,
@@ -513,7 +546,11 @@ class ResourceManager:
             + allocation["storage_gb"] * 0.001
         )
 
-        return {"hourly": hourly_cost, "daily": hourly_cost * 24, "monthly": hourly_cost * 24 * 30}
+        return {
+            "hourly": hourly_cost,
+            "daily": hourly_cost * 24,
+            "monthly": hourly_cost * 24 * 30,
+        }
 
 
 __all__ = [
diff --git a/workspace/src/core/instant_generation/workflows/__init__.py b/workspace/src/core/instant_generation/workflows/__init__.py
index b9dbbd5..6bb0ec1 100644
--- a/workspace/src/core/instant_generation/workflows/__init__.py
+++ b/workspace/src/core/instant_generation/workflows/__init__.py
@@ -195,7 +195,9 @@ class ParallelProcessor:
         processed_results = []
         for i, result in enumerate(results):
             if isinstance(result, Exception):
-                self.logger.error(f"Task {tasks[i].task_id} failed with exception: {result}")
+                self.logger.error(
+                    f"Task {tasks[i].task_id} failed with exception: {result}"
+                )
                 processed_results.append(
                     AgentResult(
                         task_id=tasks[i].task_id,
@@ -395,7 +397,8 @@ class InstantGenerationWorkflow:
                 if not ready_tasks:
                     # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰ä»»å‹™éƒ½å·²å®Œæˆ
                     all_completed = all(
-                        task.status in [TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.SKIPPED]
+                        task.status
+                        in [TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.SKIPPED]
                         for task in workflow.tasks.values()
                     )
 
@@ -435,7 +438,9 @@ class InstantGenerationWorkflow:
             workflow.completed_at = datetime.now()
             workflow.results = results
 
-            execution_time = (workflow.completed_at - workflow.started_at).total_seconds()
+            execution_time = (
+                workflow.completed_at - workflow.started_at
+            ).total_seconds()
 
             return {
                 "success": True,
diff --git a/workspace/src/core/integrations/__init__.py b/workspace/src/core/integrations/__init__.py
index 6197fbb..f5b1022 100644
--- a/workspace/src/core/integrations/__init__.py
+++ b/workspace/src/core/integrations/__init__.py
@@ -12,9 +12,24 @@ Key Components:
 """
 
 from .mcp_server_manager import MCPServer, MCPServerConfig, MCPServerManager
-from .realtime_connector import ConnectionConfig, ConnectionStatus, RealTimeConnector, TransportType
-from .tool_registry import ToolCategory, ToolDefinition, ToolExecutionResult, ToolRegistry
-from .workflow_orchestrator import Workflow, WorkflowOrchestrator, WorkflowResult, WorkflowStep
+from .realtime_connector import (
+    ConnectionConfig,
+    ConnectionStatus,
+    RealTimeConnector,
+    TransportType,
+)
+from .tool_registry import (
+    ToolCategory,
+    ToolDefinition,
+    ToolExecutionResult,
+    ToolRegistry,
+)
+from .workflow_orchestrator import (
+    Workflow,
+    WorkflowOrchestrator,
+    WorkflowResult,
+    WorkflowStep,
+)
 
 __all__ = [
     "MCPServerManager",
diff --git a/workspace/src/core/integrations/cli_bridge.py b/workspace/src/core/integrations/cli_bridge.py
index 736d436..00d44ca 100644
--- a/workspace/src/core/integrations/cli_bridge.py
+++ b/workspace/src/core/integrations/cli_bridge.py
@@ -176,7 +176,8 @@ class CLIBridge:
         # Validate operation
         if operation not in self._allowed_operations:
             raise ValueError(
-                f"Operation '{operation}' not allowed. " f"Allowed: {self._allowed_operations}"
+                f"Operation '{operation}' not allowed. "
+                f"Allowed: {self._allowed_operations}"
             )
 
         # Create task
@@ -195,7 +196,8 @@ class CLIBridge:
             task.error = f"Safety check failed: {safety_result.violations}"
             self._task_history.append(task)
             raise PermissionError(
-                f"Safety check failed for task {task.task_id}: " f"{safety_result.violations}"
+                f"Safety check failed for task {task.task_id}: "
+                f"{safety_result.violations}"
             )
 
         # Check if approval required
@@ -332,11 +334,16 @@ class CLIBridge:
             value_str = str(value).lower()
             for pattern in dangerous_patterns:
                 if pattern in value_str:
-                    violations.append(f"Dangerous pattern detected in '{key}': {pattern}")
+                    violations.append(
+                        f"Dangerous pattern detected in '{key}': {pattern}"
+                    )
                     risk_score += 0.5
 
         # Check for production targets
-        if "prod" in task.target_path.lower() or "production" in task.target_path.lower():
+        if (
+            "prod" in task.target_path.lower()
+            or "production" in task.target_path.lower()
+        ):
             recommendations.append("Consider using staging environment first")
             risk_score += 0.2
 
@@ -458,7 +465,9 @@ class CLIBridge:
             "target": task.target_path,
             "invoked_by": task.invoked_by,
             "started_at": task.started_at.isoformat() if task.started_at else None,
-            "completed_at": task.completed_at.isoformat() if task.completed_at else None,
+            "completed_at": (
+                task.completed_at.isoformat() if task.completed_at else None
+            ),
             "status": task.status.value,
             "result_summary": (
                 task.result.get("output") if isinstance(task.result, dict) else None
diff --git a/workspace/src/core/integrations/cognitive_processor.py b/workspace/src/core/integrations/cognitive_processor.py
index ade2194..52206aa 100644
--- a/workspace/src/core/integrations/cognitive_processor.py
+++ b/workspace/src/core/integrations/cognitive_processor.py
@@ -198,7 +198,11 @@ class PerceptionLayer:
         self._baselines: Dict[str, Any] = {}
 
         # Statistics
-        self._stats = {"signals_processed": 0, "anomalies_detected": 0, "drifts_detected": 0}
+        self._stats = {
+            "signals_processed": 0,
+            "anomalies_detected": 0,
+            "drifts_detected": 0,
+        }
 
         logger.debug("PerceptionLayer initialized - æ„ŸçŸ¥å±¤å·²åˆå§‹åŒ–")
 
@@ -333,7 +337,11 @@ class ReasoningLayer:
         self._causal_relationships: Dict[str, List[str]] = {}
 
         # Statistics
-        self._stats = {"signals_processed": 0, "decisions_made": 0, "risk_assessments": 0}
+        self._stats = {
+            "signals_processed": 0,
+            "decisions_made": 0,
+            "risk_assessments": 0,
+        }
 
         logger.debug("ReasoningLayer initialized - æ¨ç†å±¤å·²åˆå§‹åŒ–")
 
@@ -487,7 +495,9 @@ class ReasoningLayer:
                     result = evaluator(signal, risk, context)
 
                 if result and result.get("score", 0) > confidence_score:
-                    alternatives.append({"action": best_action, "score": confidence_score})
+                    alternatives.append(
+                        {"action": best_action, "score": confidence_score}
+                    )
                     best_action = result.get("action", "monitor")
                     confidence_score = result.get("score", 0.5)
                     reasoning.extend(result.get("reasoning", []))
@@ -538,7 +548,9 @@ class ReasoningLayer:
             auto_execute=not requires_approval and confidence_score >= 0.85,
         )
 
-    def _generate_mitigations(self, level: RiskLevel, factors: List[Dict[str, Any]]) -> List[str]:
+    def _generate_mitigations(
+        self, level: RiskLevel, factors: List[Dict[str, Any]]
+    ) -> List[str]:
         """Generate mitigation recommendations"""
         mitigations = []
 
@@ -759,7 +771,10 @@ class ProofLayer:
         logger.debug("ProofLayer initialized - è­‰æ˜å±¤å·²åˆå§‹åŒ–")
 
     async def generate_evidence(
-        self, signals: List[CognitiveSignal], decisions: List[Decision], context: CognitiveContext
+        self,
+        signals: List[CognitiveSignal],
+        decisions: List[Decision],
+        context: CognitiveContext,
     ) -> List[CognitiveSignal]:
         """
         Generate evidence for the cognitive processing
@@ -839,9 +854,13 @@ class ProofLayer:
             "confidence_score": decision.confidence_score,
             "reasoning": decision.reasoning,
             "risk_level": (
-                decision.risk_assessment.level.value if decision.risk_assessment else None
+                decision.risk_assessment.level.value
+                if decision.risk_assessment
+                else None
+            ),
+            "risk_score": (
+                decision.risk_assessment.score if decision.risk_assessment else None
             ),
-            "risk_score": decision.risk_assessment.score if decision.risk_assessment else None,
             "requires_approval": decision.requires_approval,
             "auto_execute": decision.auto_execute,
             "context_id": context.context_id,
@@ -915,14 +934,20 @@ class EnhancedCognitiveProcessor:
 
         # Processing state
         self._is_running = False
-        self._signal_queue: asyncio.Queue = asyncio.Queue(maxsize=self.config.max_signal_queue)
+        self._signal_queue: asyncio.Queue = asyncio.Queue(
+            maxsize=self.config.max_signal_queue
+        )
         self._processor_task: Optional[asyncio.Task] = None
 
         # Contexts
         self._contexts: Dict[str, CognitiveContext] = {}
 
         # Statistics
-        self._stats = {"signals_received": 0, "signals_processed": 0, "processing_errors": 0}
+        self._stats = {
+            "signals_received": 0,
+            "signals_processed": 0,
+            "processing_errors": 0,
+        }
 
         logger.info("EnhancedCognitiveProcessor initialized - å¢å¼·èªçŸ¥è™•ç†å™¨å·²åˆå§‹åŒ–")
 
@@ -1012,7 +1037,9 @@ class EnhancedCognitiveProcessor:
 
         # L2: Reasoning
         if self.config.enable_reasoning:
-            decisions, reasoning_signals = await self.reasoning.process(perception_signals, context)
+            decisions, reasoning_signals = await self.reasoning.process(
+                perception_signals, context
+            )
             result["layers_processed"].append("reasoning")
             result["decisions"].extend([d.to_dict() for d in decisions])
             result["signals"].extend([s.to_dict() for s in reasoning_signals])
@@ -1032,7 +1059,9 @@ class EnhancedCognitiveProcessor:
         # L4: Proof
         if self.config.enable_proof:
             all_signals = perception_signals + reasoning_signals + action_signals
-            evidence_signals = await self.proof.generate_evidence(all_signals, decisions, context)
+            evidence_signals = await self.proof.generate_evidence(
+                all_signals, decisions, context
+            )
             result["layers_processed"].append("proof")
             result["evidence"].extend([s.to_dict() for s in evidence_signals])
 
diff --git a/workspace/src/core/integrations/configuration_manager.py b/workspace/src/core/integrations/configuration_manager.py
index f1e026e..dbb9f3f 100644
--- a/workspace/src/core/integrations/configuration_manager.py
+++ b/workspace/src/core/integrations/configuration_manager.py
@@ -96,7 +96,11 @@ class SystemConfiguration:
             "enable_slsa_provenance": self.enable_slsa_provenance,
             "enable_cloud_delegation": self.enable_cloud_delegation,
             "phase_configs": {
-                k: {"phase_id": v.phase_id, "enabled": v.enabled, "settings": v.settings}
+                k: {
+                    "phase_id": v.phase_id,
+                    "enabled": v.enabled,
+                    "settings": v.settings,
+                }
                 for k, v in self.phase_configs.items()
             },
             "custom_settings": self.custom_settings,
@@ -207,12 +211,24 @@ class ConfigurationManager:
             "MAX_CONCURRENT_TASKS": ("max_concurrent_tasks", int),
             "TASK_TIMEOUT": ("task_timeout_seconds", int),
             "HEALTH_CHECK_INTERVAL": ("health_check_interval_seconds", int),
-            "ENABLE_SAFETY": ("enable_safety_mechanisms", lambda x: x.lower() == "true"),
-            "ENABLE_CIRCUIT_BREAKER": ("enable_circuit_breaker", lambda x: x.lower() == "true"),
-            "ENABLE_AUTO_REMEDIATION": ("enable_auto_remediation", lambda x: x.lower() == "true"),
+            "ENABLE_SAFETY": (
+                "enable_safety_mechanisms",
+                lambda x: x.lower() == "true",
+            ),
+            "ENABLE_CIRCUIT_BREAKER": (
+                "enable_circuit_breaker",
+                lambda x: x.lower() == "true",
+            ),
+            "ENABLE_AUTO_REMEDIATION": (
+                "enable_auto_remediation",
+                lambda x: x.lower() == "true",
+            ),
             "ENABLE_MCP_SERVERS": ("enable_mcp_servers", lambda x: x.lower() == "true"),
             "ENABLE_SLSA": ("enable_slsa_provenance", lambda x: x.lower() == "true"),
-            "ENABLE_CLOUD_DELEGATION": ("enable_cloud_delegation", lambda x: x.lower() == "true"),
+            "ENABLE_CLOUD_DELEGATION": (
+                "enable_cloud_delegation",
+                lambda x: x.lower() == "true",
+            ),
         }
 
         for env_suffix, (attr, converter) in env_mappings.items():
@@ -247,7 +263,10 @@ class ConfigurationManager:
                 value = getattr(value, part)
             elif isinstance(value, dict) and part in value:
                 value = value[part]
-            elif hasattr(self._config, "custom_settings") and part in self._config.custom_settings:
+            elif (
+                hasattr(self._config, "custom_settings")
+                and part in self._config.custom_settings
+            ):
                 return self._config.custom_settings[part]
             else:
                 return default
diff --git a/workspace/src/core/integrations/configuration_optimizer.py b/workspace/src/core/integrations/configuration_optimizer.py
index 6b495fc..adfa5e3 100644
--- a/workspace/src/core/integrations/configuration_optimizer.py
+++ b/workspace/src/core/integrations/configuration_optimizer.py
@@ -351,7 +351,9 @@ class ConfigurationOptimizer:
         return self._rules.pop(rule_id, None) is not None
 
     def validate(
-        self, config: Dict[str, Any], categories: Optional[List[OptimizationCategory]] = None
+        self,
+        config: Dict[str, Any],
+        categories: Optional[List[OptimizationCategory]] = None,
     ) -> ValidationResult:
         """
         Validate configuration against all applicable rules
@@ -403,7 +405,9 @@ class ConfigurationOptimizer:
                     }
                 )
 
-        return ValidationResult(is_valid=len(issues) == 0, issues=issues, warnings=warnings)
+        return ValidationResult(
+            is_valid=len(issues) == 0, issues=issues, warnings=warnings
+        )
 
     def analyze(
         self, config: Dict[str, Any], metrics: Optional[Dict[str, Any]] = None
@@ -523,7 +527,9 @@ class ConfigurationOptimizer:
             Baseline snapshot
         """
         self._baseline_snapshot = ConfigurationSnapshot(
-            snapshot_id=f"baseline-{uuid4().hex[:8]}", config=config.copy(), source="baseline"
+            snapshot_id=f"baseline-{uuid4().hex[:8]}",
+            config=config.copy(),
+            source="baseline",
         )
         return self._baseline_snapshot
 
@@ -610,7 +616,9 @@ class ConfigurationOptimizer:
 
         # Keep only last 100 entries per key
         if len(self._performance_metrics[config_key]) > 100:
-            self._performance_metrics[config_key] = self._performance_metrics[config_key][-100:]
+            self._performance_metrics[config_key] = self._performance_metrics[
+                config_key
+            ][-100:]
 
     def get_recommendations(
         self, category: Optional[OptimizationCategory] = None
@@ -642,7 +650,9 @@ class ConfigurationOptimizer:
 
     # ========== Helper Methods ==========
 
-    def _flatten_config(self, config: Dict[str, Any], prefix: str = "") -> Dict[str, Any]:
+    def _flatten_config(
+        self, config: Dict[str, Any], prefix: str = ""
+    ) -> Dict[str, Any]:
         """Flatten nested configuration to dot-notation keys"""
         result = {}
 
@@ -656,7 +666,9 @@ class ConfigurationOptimizer:
 
         return result
 
-    def _apply_config_change(self, config: Dict[str, Any], key: str, value: Any) -> Dict[str, Any]:
+    def _apply_config_change(
+        self, config: Dict[str, Any], key: str, value: Any
+    ) -> Dict[str, Any]:
         """Apply a configuration change using dot-notation key"""
         result = config.copy()
         parts = key.split(".")
@@ -875,7 +887,9 @@ class ConfigurationOptimizer:
             prod_thresholds = CONCURRENCY_THRESHOLDS["production"]
             if current_value < prod_thresholds["min_recommended"]:
                 recommended_value = prod_thresholds["default_recommended"]
-                reasoning.append("Production environments typically need higher concurrency")
+                reasoning.append(
+                    "Production environments typically need higher concurrency"
+                )
             elif current_value > prod_thresholds["upper_warning_threshold"]:
                 recommended_value = prod_thresholds["max_recommended"]
                 reasoning.append("Very high concurrency may cause resource contention")
@@ -883,7 +897,9 @@ class ConfigurationOptimizer:
             dev_thresholds = CONCURRENCY_THRESHOLDS["development"]
             if current_value > dev_thresholds["warning_threshold"]:
                 recommended_value = dev_thresholds["recommended"]
-                reasoning.append("Development environments work well with lower concurrency")
+                reasoning.append(
+                    "Development environments work well with lower concurrency"
+                )
 
         if recommended_value == current_value:
             return None
diff --git a/workspace/src/core/integrations/deep_execution_system.py b/workspace/src/core/integrations/deep_execution_system.py
index d027b25..44e8ca4 100644
--- a/workspace/src/core/integrations/deep_execution_system.py
+++ b/workspace/src/core/integrations/deep_execution_system.py
@@ -167,7 +167,9 @@ class ExecutionContext:
             "operations_count": len(self.operations),
             "child_contexts_count": len(self.child_contexts),
             "created_at": self.created_at.isoformat(),
-            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
+            "completed_at": (
+                self.completed_at.isoformat() if self.completed_at else None
+            ),
             "metadata": self.metadata,
         }
 
@@ -240,9 +242,15 @@ class OperationValidator:
             ValidationLevel.DEEP: [],
             ValidationLevel.STRICT: [],
         }
-        self._stats = {"validations_performed": 0, "validations_passed": 0, "validations_failed": 0}
+        self._stats = {
+            "validations_performed": 0,
+            "validations_passed": 0,
+            "validations_failed": 0,
+        }
 
-    async def validate(self, operation: Operation, context: ExecutionContext) -> dict[str, Any]:
+    async def validate(
+        self, operation: Operation, context: ExecutionContext
+    ) -> dict[str, Any]:
         """
         Validate an operation before execution
 
@@ -264,7 +272,9 @@ class OperationValidator:
 
         try:
             # Always run shallow validation
-            await self._run_level_validation(ValidationLevel.SHALLOW, operation, context, results)
+            await self._run_level_validation(
+                ValidationLevel.SHALLOW, operation, context, results
+            )
 
             # Run standard validation if level is standard or higher
             if operation.validation_level in [
@@ -277,8 +287,13 @@ class OperationValidator:
                 )
 
             # Run deep validation if level is deep or strict
-            if operation.validation_level in [ValidationLevel.DEEP, ValidationLevel.STRICT]:
-                await self._run_level_validation(ValidationLevel.DEEP, operation, context, results)
+            if operation.validation_level in [
+                ValidationLevel.DEEP,
+                ValidationLevel.STRICT,
+            ]:
+                await self._run_level_validation(
+                    ValidationLevel.DEEP, operation, context, results
+                )
 
             # Run strict validation if level is strict
             if operation.validation_level == ValidationLevel.STRICT:
@@ -330,7 +345,9 @@ class OperationValidator:
                         )
                     else:
                         results["valid"] = False
-                        results["errors"].append(result.get("error", "Validation failed"))
+                        results["errors"].append(
+                            result.get("error", "Validation failed")
+                        )
                         results["checks"].append(
                             {
                                 "level": level.value,
@@ -342,7 +359,9 @@ class OperationValidator:
             except TimeoutError:
                 results["warnings"].append(f"Validator at {level.value} timed out")
             except Exception as e:
-                results["warnings"].append(f"Validator error at {level.value}: {str(e)}")
+                results["warnings"].append(
+                    f"Validator error at {level.value}: {str(e)}"
+                )
 
     async def _run_builtin_validations(
         self, operation: Operation, context: ExecutionContext, results: dict[str, Any]
@@ -354,7 +373,9 @@ class OperationValidator:
             results["errors"].append("Operation handler is not callable")
             return
 
-        results["checks"].append({"level": "builtin", "name": "handler_callable", "passed": True})
+        results["checks"].append(
+            {"level": "builtin", "name": "handler_callable", "passed": True}
+        )
 
         # Check context depth
         if context.depth_level >= self.config.max_context_depth:
@@ -364,14 +385,22 @@ class OperationValidator:
             )
             return
 
-        results["checks"].append({"level": "builtin", "name": "context_depth", "passed": True})
+        results["checks"].append(
+            {"level": "builtin", "name": "context_depth", "passed": True}
+        )
 
         # Check timeout is reasonable
         if operation.timeout_seconds <= 0:
-            results["warnings"].append("Operation timeout is not positive, using default")
+            results["warnings"].append(
+                "Operation timeout is not positive, using default"
+            )
 
         results["checks"].append(
-            {"level": "builtin", "name": "timeout_valid", "passed": operation.timeout_seconds > 0}
+            {
+                "level": "builtin",
+                "name": "timeout_valid",
+                "passed": operation.timeout_seconds > 0,
+            }
         )
 
     def add_validator(self, level: ValidationLevel, validator: Callable) -> None:
@@ -399,7 +428,11 @@ class OperationScheduler:
         self._running: dict[str, asyncio.Task] = {}
         self._completed: dict[str, OperationResult] = {}
         self._semaphore = asyncio.Semaphore(max_concurrent)
-        self._stats = {"operations_scheduled": 0, "operations_completed": 0, "operations_failed": 0}
+        self._stats = {
+            "operations_scheduled": 0,
+            "operations_completed": 0,
+            "operations_failed": 0,
+        }
 
     async def schedule(self, operation: Operation) -> None:
         """Schedule an operation for execution"""
@@ -435,7 +468,11 @@ class OperationScheduler:
     def get_stats(self) -> dict[str, Any]:
         """Get scheduler statistics"""
         queue_sizes = {p.name: self._queues[p].qsize() for p in OperationPriority}
-        return {**self._stats, "running_count": len(self._running), "queue_sizes": queue_sizes}
+        return {
+            **self._stats,
+            "running_count": len(self._running),
+            "queue_sizes": queue_sizes,
+        }
 
 
 class AuditLogger:
@@ -681,7 +718,9 @@ class DeepExecutionSystem:
             if parent:
                 depth_level = parent.depth_level + 1
                 if depth_level > self.config.max_context_depth:
-                    raise ValueError(f"Max context depth {self.config.max_context_depth} exceeded")
+                    raise ValueError(
+                        f"Max context depth {self.config.max_context_depth} exceeded"
+                    )
 
         context = ExecutionContext(
             context_id=f"ctx-{uuid4().hex[:8]}",
@@ -777,7 +816,10 @@ class DeepExecutionSystem:
         return result
 
     async def _execute_operation(
-        self, operation: Operation, context: ExecutionContext, user_id: str | None = None
+        self,
+        operation: Operation,
+        context: ExecutionContext,
+        user_id: str | None = None,
     ) -> OperationResult:
         """Execute a single operation"""
         start_time = datetime.now(UTC)
@@ -838,7 +880,12 @@ class DeepExecutionSystem:
             # Log audit entry for execution start
             if self.config.enable_audit_logging:
                 self.audit_logger.log(
-                    operation, context, "execute_start", OperationStatus.EXECUTING, None, user_id
+                    operation,
+                    context,
+                    "execute_start",
+                    OperationStatus.EXECUTING,
+                    None,
+                    user_id,
                 )
 
             # Add to rollback stack if rollback handler provided
@@ -850,7 +897,8 @@ class DeepExecutionSystem:
             try:
                 if asyncio.iscoroutinefunction(operation.handler):
                     output = await asyncio.wait_for(
-                        operation.handler(**operation.args), timeout=operation.timeout_seconds
+                        operation.handler(**operation.args),
+                        timeout=operation.timeout_seconds,
                     )
                 else:
                     output = operation.handler(**operation.args)
@@ -896,7 +944,12 @@ class DeepExecutionSystem:
             # Log final audit entry
             if self.config.enable_audit_logging:
                 result.audit_entry_id = self.audit_logger.log(
-                    operation, context, "execute_complete", result.status, result, user_id
+                    operation,
+                    context,
+                    "execute_complete",
+                    result.status,
+                    result,
+                    user_id,
                 )
 
             # Update scheduler
@@ -904,7 +957,9 @@ class DeepExecutionSystem:
 
         return result
 
-    async def _rollback_operation(self, operation: Operation, context: ExecutionContext) -> bool:
+    async def _rollback_operation(
+        self, operation: Operation, context: ExecutionContext
+    ) -> bool:
         """Rollback an operation"""
         if not operation.rollback_handler:
             return False
@@ -922,7 +977,12 @@ class DeepExecutionSystem:
             # Log rollback audit entry
             if self.config.enable_audit_logging:
                 self.audit_logger.log(
-                    operation, context, "rollback", OperationStatus.ROLLED_BACK, None, None
+                    operation,
+                    context,
+                    "rollback",
+                    OperationStatus.ROLLED_BACK,
+                    None,
+                    None,
                 )
 
             return True
@@ -1021,7 +1081,9 @@ class DeepExecutionSystem:
 
 
 # Factory function
-def create_deep_execution_system(config: DeepExecutionConfig | None = None) -> DeepExecutionSystem:
+def create_deep_execution_system(
+    config: DeepExecutionConfig | None = None,
+) -> DeepExecutionSystem:
     """Create a new DeepExecutionSystem instance"""
     return DeepExecutionSystem(config)
 
diff --git a/workspace/src/core/integrations/integration_hub.py b/workspace/src/core/integrations/integration_hub.py
index e917084..86e2685 100644
--- a/workspace/src/core/integrations/integration_hub.py
+++ b/workspace/src/core/integrations/integration_hub.py
@@ -274,7 +274,9 @@ class IntegrationHub:
         if future and not future.done():
             future.set_result(payload)
 
-    async def broadcast(self, source_phase: int, event_type: str, payload: Dict[str, Any]) -> int:
+    async def broadcast(
+        self, source_phase: int, event_type: str, payload: Dict[str, Any]
+    ) -> int:
         """
         Broadcast an event to all subscribed phases
 
@@ -374,7 +376,9 @@ class IntegrationHub:
 
     def get_stats(self) -> Dict[str, Any]:
         """Get hub statistics"""
-        queue_sizes = {phase_id: queue.qsize() for phase_id, queue in self._queues.items()}
+        queue_sizes = {
+            phase_id: queue.qsize() for phase_id, queue in self._queues.items()
+        }
 
         return {
             "registered_phases": len(self._queues),
@@ -431,6 +435,8 @@ class IntegrationHub:
 
 
 # Factory function
-def create_integration_hub(config: Optional[IntegrationConfig] = None) -> IntegrationHub:
+def create_integration_hub(
+    config: Optional[IntegrationConfig] = None,
+) -> IntegrationHub:
     """Create a new IntegrationHub instance"""
     return IntegrationHub(config)
diff --git a/workspace/src/core/integrations/mcp_server_manager.py b/workspace/src/core/integrations/mcp_server_manager.py
index 397f72c..2c1ca83 100644
--- a/workspace/src/core/integrations/mcp_server_manager.py
+++ b/workspace/src/core/integrations/mcp_server_manager.py
@@ -209,7 +209,9 @@ class MCPServerManager:
             return self._servers.get(server_id)
         return None
 
-    async def execute_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
+    async def execute_tool(
+        self, tool_name: str, arguments: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """
         Execute a tool on the appropriate server
 
@@ -251,7 +253,11 @@ class MCPServerManager:
             if server.status == ServerStatus.HEALTHY:
                 for tool in server.tools:
                     tools.append(
-                        {**tool, "server_id": server.id, "server_name": server.config.name}
+                        {
+                            **tool,
+                            "server_id": server.id,
+                            "server_name": server.config.name,
+                        }
                     )
         return tools
 
@@ -360,8 +366,14 @@ class MCPServerManager:
                     "inputSchema": {
                         "type": "object",
                         "properties": {
-                            "code": {"type": "string", "description": "Source code to analyze"},
-                            "language": {"type": "string", "description": "Programming language"},
+                            "code": {
+                                "type": "string",
+                                "description": "Source code to analyze",
+                            },
+                            "language": {
+                                "type": "string",
+                                "description": "Programming language",
+                            },
                             "metrics": {"type": "array", "items": {"type": "string"}},
                         },
                         "required": ["code"],
@@ -374,7 +386,10 @@ class MCPServerManager:
                         "type": "object",
                         "properties": {
                             "code": {"type": "string"},
-                            "pattern_types": {"type": "array", "items": {"type": "string"}},
+                            "pattern_types": {
+                                "type": "array",
+                                "items": {"type": "string"},
+                            },
                         },
                         "required": ["code"],
                     },
@@ -406,7 +421,10 @@ class MCPServerManager:
                                 "type": "string",
                                 "description": "Package manifest file content",
                             },
-                            "ecosystem": {"type": "string", "enum": ["npm", "pip", "maven", "go"]},
+                            "ecosystem": {
+                                "type": "string",
+                                "enum": ["npm", "pip", "maven", "go"],
+                            },
                         },
                         "required": ["manifest"],
                     },
@@ -432,7 +450,10 @@ class MCPServerManager:
                         "type": "object",
                         "properties": {
                             "provenance": {"type": "object"},
-                            "targetLevel": {"type": "string", "enum": ["1", "2", "3", "4"]},
+                            "targetLevel": {
+                                "type": "string",
+                                "enum": ["1", "2", "3", "4"],
+                            },
                         },
                         "required": ["provenance"],
                     },
@@ -450,7 +471,11 @@ class MCPServerManager:
                                 "type": "string",
                                 "enum": ["jest", "pytest", "mocha", "junit"],
                             },
-                            "coverage_target": {"type": "number", "minimum": 0, "maximum": 100},
+                            "coverage_target": {
+                                "type": "number",
+                                "minimum": 0,
+                                "maximum": 100,
+                            },
                         },
                         "required": ["code"],
                     },
diff --git a/workspace/src/core/integrations/realtime_connector.py b/workspace/src/core/integrations/realtime_connector.py
index 016284a..d16b422 100644
--- a/workspace/src/core/integrations/realtime_connector.py
+++ b/workspace/src/core/integrations/realtime_connector.py
@@ -81,8 +81,12 @@ class Connection:
             "status": self.status.value,
             "host": self.config.host,
             "port": self.config.port,
-            "last_activity": self.last_activity.isoformat() if self.last_activity else None,
-            "connect_time": self.connect_time.isoformat() if self.connect_time else None,
+            "last_activity": (
+                self.last_activity.isoformat() if self.last_activity else None
+            ),
+            "connect_time": (
+                self.connect_time.isoformat() if self.connect_time else None
+            ),
             "reconnect_count": self.reconnect_count,
             "error_count": self.error_count,
             "messages_sent": self.messages_sent,
@@ -206,7 +210,9 @@ class RealTimeConnector:
             Connection instance
         """
         conn_id = str(uuid4())
-        connection = Connection(id=conn_id, config=config, status=ConnectionStatus.CONNECTING)
+        connection = Connection(
+            id=conn_id, config=config, status=ConnectionStatus.CONNECTING
+        )
 
         self._connections[conn_id] = connection
 
@@ -276,7 +282,9 @@ class RealTimeConnector:
                 return conn
         return None
 
-    def list_connections(self, status: Optional[ConnectionStatus] = None) -> List[Connection]:
+    def list_connections(
+        self, status: Optional[ConnectionStatus] = None
+    ) -> List[Connection]:
         """List all connections, optionally filtered by status"""
         connections = list(self._connections.values())
         if status:
@@ -353,7 +361,9 @@ class RealTimeConnector:
         if connection.status != ConnectionStatus.CONNECTED:
             raise ConnectionError(f"Connection not active: {connection.status.value}")
 
-        message = Message(id=str(uuid4()), type="notification", method=method, params=params)
+        message = Message(
+            id=str(uuid4()), type="notification", method=method, params=params
+        )
 
         await self._send_message(connection, message)
         connection.messages_sent += 1
@@ -404,18 +414,24 @@ class RealTimeConnector:
             pass
 
         # Simulate sending
-        logger.debug(f"Sent message to {connection.config.server_name}: {message.method}")
+        logger.debug(
+            f"Sent message to {connection.config.server_name}: {message.method}"
+        )
 
         # Simulate response for requests
         if message.type == "request":
             asyncio.create_task(self._simulate_response(connection, message))
 
-    async def _simulate_response(self, connection: Connection, request: Message) -> None:
+    async def _simulate_response(
+        self, connection: Connection, request: Message
+    ) -> None:
         """Simulate a response for testing"""
         await asyncio.sleep(0.05)  # Simulate latency
 
         response = Message(
-            id=request.id, type="response", result={"status": "success", "method": request.method}
+            id=request.id,
+            type="response",
+            result={"status": "success", "method": request.method},
         )
 
         await self._handle_response(response)
@@ -426,7 +442,9 @@ class RealTimeConnector:
         future = self._pending_requests.get(message.id)
         if future and not future.done():
             if message.error:
-                future.set_exception(Exception(message.error.get("message", "Unknown error")))
+                future.set_exception(
+                    Exception(message.error.get("message", "Unknown error"))
+                )
             else:
                 future.set_result(message.result)
 
@@ -446,7 +464,9 @@ class RealTimeConnector:
                         connection.id, "ping", {"timestamp": datetime.now().isoformat()}
                     )
                 except Exception as e:
-                    logger.warning(f"Heartbeat failed for {connection.config.server_name}: {e}")
+                    logger.warning(
+                        f"Heartbeat failed for {connection.config.server_name}: {e}"
+                    )
                     connection.error_count += 1
 
                     if connection.error_count >= 3:
@@ -462,7 +482,9 @@ class RealTimeConnector:
     def _schedule_reconnect(self, connection: Connection) -> None:
         """Schedule a reconnection attempt"""
         if connection.reconnect_count >= connection.config.max_reconnect_attempts:
-            logger.error(f"Max reconnect attempts reached for {connection.config.server_name}")
+            logger.error(
+                f"Max reconnect attempts reached for {connection.config.server_name}"
+            )
             return
 
         connection.status = ConnectionStatus.RECONNECTING
@@ -482,7 +504,9 @@ class RealTimeConnector:
                 logger.info(f"Reconnected to {connection.config.server_name}")
 
             except Exception as e:
-                logger.error(f"Reconnect failed for {connection.config.server_name}: {e}")
+                logger.error(
+                    f"Reconnect failed for {connection.config.server_name}: {e}"
+                )
                 self._schedule_reconnect(connection)
 
         self._reconnect_tasks[connection.id] = asyncio.create_task(reconnect())
diff --git a/workspace/src/core/integrations/service_registry.py b/workspace/src/core/integrations/service_registry.py
index bcc2759..c5ea42f 100644
--- a/workspace/src/core/integrations/service_registry.py
+++ b/workspace/src/core/integrations/service_registry.py
@@ -129,14 +129,18 @@ class ServiceMetadata:
             "health": {
                 "status": self.health.status.value,
                 "last_check": (
-                    self.health.last_check.isoformat() if self.health.last_check else None
+                    self.health.last_check.isoformat()
+                    if self.health.last_check
+                    else None
                 ),
                 "consecutive_failures": self.health.consecutive_failures,
                 "latency_ms": self.health.latency_ms,
                 "details": self.health.details,
             },
             "registered_at": self.registered_at.isoformat(),
-            "last_heartbeat": self.last_heartbeat.isoformat() if self.last_heartbeat else None,
+            "last_heartbeat": (
+                self.last_heartbeat.isoformat() if self.last_heartbeat else None
+            ),
             "config": self.config,
         }
 
@@ -221,7 +225,9 @@ class ServiceRegistry:
         self._is_running = True
         self._health_check_task = asyncio.create_task(self._health_check_loop())
 
-        await self._emit_event("registry_started", {"timestamp": datetime.now(timezone.utc)})
+        await self._emit_event(
+            "registry_started", {"timestamp": datetime.now(timezone.utc)}
+        )
         logger.info("ServiceRegistry started - æœå‹™è¨»å†Šè¡¨å·²å•Ÿå‹•")
 
     async def stop(self) -> None:
@@ -235,7 +241,9 @@ class ServiceRegistry:
             except asyncio.CancelledError:
                 pass
 
-        await self._emit_event("registry_stopped", {"timestamp": datetime.now(timezone.utc)})
+        await self._emit_event(
+            "registry_stopped", {"timestamp": datetime.now(timezone.utc)}
+        )
         logger.info("ServiceRegistry stopped - æœå‹™è¨»å†Šè¡¨å·²åœæ­¢")
 
     def register_service(
@@ -360,7 +368,9 @@ class ServiceRegistry:
             "service_deregistered", {"service_id": service_id, "name": service.name}
         )
 
-        logger.info(f"Service deregistered: {service.name} ({service_id}) - æœå‹™å·²å–æ¶ˆè¨»å†Š")
+        logger.info(
+            f"Service deregistered: {service.name} ({service_id}) - æœå‹™å·²å–æ¶ˆè¨»å†Š"
+        )
         return True
 
     def get_service(self, service_id: str) -> Optional[ServiceMetadata]:
@@ -406,7 +416,9 @@ class ServiceRegistry:
         self._stats["discoveries"] += 1
         return [service for service in self._services.values() if tag in service.tags]
 
-    def discover_healthy(self, category: Optional[ServiceCategory] = None) -> List[ServiceMetadata]:
+    def discover_healthy(
+        self, category: Optional[ServiceCategory] = None
+    ) -> List[ServiceMetadata]:
         """
         Discover healthy services
 
@@ -417,9 +429,15 @@ class ServiceRegistry:
 
         if category:
             service_ids = self._services_by_category.get(category, set())
-            services = [self._services[sid] for sid in service_ids if sid in self._services]
+            services = [
+                self._services[sid] for sid in service_ids if sid in self._services
+            ]
 
-        return [service for service in services if service.health.status == ServiceStatus.HEALTHY]
+        return [
+            service
+            for service in services
+            if service.health.status == ServiceStatus.HEALTHY
+        ]
 
     def heartbeat(self, service_id: str) -> bool:
         """
@@ -483,7 +501,9 @@ class ServiceRegistry:
 
         return True
 
-    def resolve_dependencies(self, service_id: str) -> Dict[str, Optional[ServiceMetadata]]:
+    def resolve_dependencies(
+        self, service_id: str
+    ) -> Dict[str, Optional[ServiceMetadata]]:
         """
         Resolve dependencies for a service
 
@@ -499,7 +519,9 @@ class ServiceRegistry:
         resolved = {}
         for dep_name in service.dependencies:
             candidates = self.discover_healthy()
-            matching = [s for s in candidates if s.name == dep_name or dep_name in s.provides]
+            matching = [
+                s for s in candidates if s.name == dep_name or dep_name in s.provides
+            ]
             resolved[dep_name] = matching[0] if matching else None
 
         return resolved
@@ -522,7 +544,10 @@ class ServiceRegistry:
 
         ç²å–æœå‹™ä¾è³´åœ–
         """
-        return {service_id: service.dependencies for service_id, service in self._services.items()}
+        return {
+            service_id: service.dependencies
+            for service_id, service in self._services.items()
+        }
 
     def on(self, event: str, handler: Callable) -> None:
         """Register an event handler"""
@@ -588,7 +613,9 @@ class ServiceRegistry:
                     latency_ms = (asyncio.get_event_loop().time() - start_time) * 1000
 
                     if isinstance(result, bool):
-                        status = ServiceStatus.HEALTHY if result else ServiceStatus.UNHEALTHY
+                        status = (
+                            ServiceStatus.HEALTHY if result else ServiceStatus.UNHEALTHY
+                        )
                     elif isinstance(result, dict):
                         status = ServiceStatus(result.get("status", "healthy"))
                     else:
diff --git a/workspace/src/core/integrations/system_orchestrator.py b/workspace/src/core/integrations/system_orchestrator.py
index 6c87c2a..d9b2f11 100644
--- a/workspace/src/core/integrations/system_orchestrator.py
+++ b/workspace/src/core/integrations/system_orchestrator.py
@@ -94,7 +94,9 @@ class Workflow:
             "current_step": self.current_step,
             "total_steps": len(self.steps),
             "started_at": self.started_at.isoformat() if self.started_at else None,
-            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
+            "completed_at": (
+                self.completed_at.isoformat() if self.completed_at else None
+            ),
             "results": self.results,
             "error": self.error,
             "metadata": self.metadata,
@@ -143,13 +145,17 @@ class SystemOrchestrator:
 
         self._is_running = True
         self._startup_time = datetime.now(timezone.utc)
-        self._workflow_semaphore = asyncio.Semaphore(self.config.max_concurrent_workflows)
+        self._workflow_semaphore = asyncio.Semaphore(
+            self.config.max_concurrent_workflows
+        )
         self._task_semaphore = asyncio.Semaphore(self.config.max_concurrent_tasks)
 
         # Start scheduler
         self._scheduler_task = asyncio.create_task(self._scheduler_loop())
 
-        await self._emit_event("orchestrator_started", {"timestamp": self._startup_time})
+        await self._emit_event(
+            "orchestrator_started", {"timestamp": self._startup_time}
+        )
         logger.info("SystemOrchestrator started")
 
     async def stop(self) -> None:
@@ -173,11 +179,16 @@ class SystemOrchestrator:
 
         self._running_workflows.clear()
 
-        await self._emit_event("orchestrator_stopped", {"timestamp": datetime.now(timezone.utc)})
+        await self._emit_event(
+            "orchestrator_stopped", {"timestamp": datetime.now(timezone.utc)}
+        )
         logger.info("SystemOrchestrator stopped")
 
     async def execute_workflow(
-        self, name: str, steps: List[Dict[str, Any]], metadata: Optional[Dict[str, Any]] = None
+        self,
+        name: str,
+        steps: List[Dict[str, Any]],
+        metadata: Optional[Dict[str, Any]] = None,
     ) -> Workflow:
         """
         Execute a workflow
@@ -190,7 +201,9 @@ class SystemOrchestrator:
         Returns:
             Workflow object
         """
-        workflow = Workflow(id=str(uuid4()), name=name, steps=steps, metadata=metadata or {})
+        workflow = Workflow(
+            id=str(uuid4()), name=name, steps=steps, metadata=metadata or {}
+        )
 
         self._workflows[workflow.id] = workflow
 
@@ -200,7 +213,10 @@ class SystemOrchestrator:
         return workflow
 
     async def execute_workflow_async(
-        self, name: str, steps: List[Dict[str, Any]], metadata: Optional[Dict[str, Any]] = None
+        self,
+        name: str,
+        steps: List[Dict[str, Any]],
+        metadata: Optional[Dict[str, Any]] = None,
     ) -> str:
         """
         Execute a workflow asynchronously
@@ -208,7 +224,9 @@ class SystemOrchestrator:
         Returns:
             Workflow ID
         """
-        workflow = Workflow(id=str(uuid4()), name=name, steps=steps, metadata=metadata or {})
+        workflow = Workflow(
+            id=str(uuid4()), name=name, steps=steps, metadata=metadata or {}
+        )
 
         self._workflows[workflow.id] = workflow
 
@@ -327,7 +345,9 @@ class SystemOrchestrator:
             "running_workflows": len(self._running_workflows),
             "workflow_states": workflow_states,
             "scheduled_tasks": len(self._scheduled_tasks),
-            "enabled_tasks": sum(1 for t in self._scheduled_tasks.values() if t.enabled),
+            "enabled_tasks": sum(
+                1 for t in self._scheduled_tasks.values() if t.enabled
+            ),
         }
 
     async def _run_workflow_with_semaphore(self, workflow: Workflow) -> None:
@@ -374,7 +394,8 @@ class SystemOrchestrator:
             workflow.completed_at = datetime.now(timezone.utc)
 
             await self._emit_event(
-                "workflow_completed", {"workflow_id": workflow.id, "results": workflow.results}
+                "workflow_completed",
+                {"workflow_id": workflow.id, "results": workflow.results},
             )
 
         except asyncio.CancelledError:
@@ -387,7 +408,9 @@ class SystemOrchestrator:
             workflow.error = str(e)
             workflow.completed_at = datetime.now(timezone.utc)
 
-            await self._emit_event("workflow_failed", {"workflow_id": workflow.id, "error": str(e)})
+            await self._emit_event(
+                "workflow_failed", {"workflow_id": workflow.id, "error": str(e)}
+            )
 
             logger.error(f"Workflow {workflow.id} failed: {e}")
 
@@ -449,6 +472,8 @@ class SystemOrchestrator:
 
 
 # Factory function
-def create_system_orchestrator(config: Optional[OrchestratorConfig] = None) -> SystemOrchestrator:
+def create_system_orchestrator(
+    config: Optional[OrchestratorConfig] = None,
+) -> SystemOrchestrator:
     """Create a new SystemOrchestrator instance"""
     return SystemOrchestrator(config)
diff --git a/workspace/src/core/integrations/tool_registry.py b/workspace/src/core/integrations/tool_registry.py
index 8288117..de7ad49 100644
--- a/workspace/src/core/integrations/tool_registry.py
+++ b/workspace/src/core/integrations/tool_registry.py
@@ -101,7 +101,9 @@ class ToolDefinition:
 
         return {"valid": len(errors) == 0, "errors": errors}
 
-    def _validate_type(self, field_name: str, value: Any, schema: Dict[str, Any]) -> Optional[str]:
+    def _validate_type(
+        self, field_name: str, value: Any, schema: Dict[str, Any]
+    ) -> Optional[str]:
         """Validate a single field type"""
         expected_type = schema.get("type")
 
@@ -217,7 +219,9 @@ class ToolRegistry:
                 self._server_index[tool.server_name].remove(tool_name)
 
         # Remove aliases
-        aliases_to_remove = [alias for alias, name in self._aliases.items() if name == tool_name]
+        aliases_to_remove = [
+            alias for alias, name in self._aliases.items() if name == tool_name
+        ]
         for alias in aliases_to_remove:
             del self._aliases[alias]
 
@@ -308,12 +312,17 @@ class ToolRegistry:
                 continue
 
             # Search in name and description
-            if query_lower in tool.name.lower() or query_lower in tool.description.lower():
+            if (
+                query_lower in tool.name.lower()
+                or query_lower in tool.description.lower()
+            ):
                 results.append(tool)
 
         return results
 
-    def validate_arguments(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
+    def validate_arguments(
+        self, tool_name: str, arguments: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """
         Validate arguments for a tool
 
@@ -376,7 +385,10 @@ def get_default_tool_definitions() -> List[ToolDefinition]:
                 "type": "object",
                 "properties": {
                     "code": {"type": "string", "description": "Source code to analyze"},
-                    "language": {"type": "string", "description": "Programming language"},
+                    "language": {
+                        "type": "string",
+                        "description": "Programming language",
+                    },
                     "metrics": {
                         "type": "array",
                         "items": {"type": "string"},
@@ -426,7 +438,10 @@ def get_default_tool_definitions() -> List[ToolDefinition]:
                 "type": "object",
                 "properties": {
                     "code": {"type": "string"},
-                    "framework": {"type": "string", "enum": ["jest", "pytest", "mocha", "junit"]},
+                    "framework": {
+                        "type": "string",
+                        "enum": ["jest", "pytest", "mocha", "junit"],
+                    },
                     "coverage_target": {"type": "number", "minimum": 0, "maximum": 100},
                 },
                 "required": ["code"],
diff --git a/workspace/src/core/integrations/unified_controller.py b/workspace/src/core/integrations/unified_controller.py
index 56dd58e..d0a4804 100644
--- a/workspace/src/core/integrations/unified_controller.py
+++ b/workspace/src/core/integrations/unified_controller.py
@@ -328,7 +328,9 @@ class UnifiedSystemController:
 
             self._state = SystemState.READY
             self._startup_time = datetime.now(timezone.utc)
-            await self._emit_event("system_initialized", {"timestamp": self._startup_time})
+            await self._emit_event(
+                "system_initialized", {"timestamp": self._startup_time}
+            )
             logger.info("SynergyMesh Unified System initialized successfully")
             return True
 
@@ -355,7 +357,9 @@ class UnifiedSystemController:
 
             self._state = SystemState.RUNNING
             self._is_running = True
-            await self._emit_event("system_started", {"timestamp": datetime.now(timezone.utc)})
+            await self._emit_event(
+                "system_started", {"timestamp": datetime.now(timezone.utc)}
+            )
             logger.info("SynergyMesh Unified System started")
             return True
 
@@ -382,7 +386,9 @@ class UnifiedSystemController:
 
             self._state = SystemState.OFFLINE
             self._is_running = False
-            await self._emit_event("system_stopped", {"timestamp": datetime.now(timezone.utc)})
+            await self._emit_event(
+                "system_stopped", {"timestamp": datetime.now(timezone.utc)}
+            )
             logger.info("SynergyMesh Unified System stopped")
             return True
 
@@ -457,7 +463,9 @@ class UnifiedSystemController:
                 "request_count": phase_state.request_count,
                 "error_count": phase_state.error_count,
                 "last_activity": (
-                    phase_state.last_activity.isoformat() if phase_state.last_activity else None
+                    phase_state.last_activity.isoformat()
+                    if phase_state.last_activity
+                    else None
                 ),
             }
 
@@ -498,10 +506,14 @@ class UnifiedSystemController:
             "request_count": phase_state.request_count,
             "error_count": phase_state.error_count,
             "initialized_at": (
-                phase_state.initialized_at.isoformat() if phase_state.initialized_at else None
+                phase_state.initialized_at.isoformat()
+                if phase_state.initialized_at
+                else None
             ),
             "last_activity": (
-                phase_state.last_activity.isoformat() if phase_state.last_activity else None
+                phase_state.last_activity.isoformat()
+                if phase_state.last_activity
+                else None
             ),
             "dependencies": phase_def.dependencies,
             "critical": phase_def.critical,
@@ -551,7 +563,9 @@ class UnifiedSystemController:
         phase_state.last_activity = datetime.now(timezone.utc)
         return True
 
-    async def _invoke_phase(self, phase_id: int, request: Dict[str, Any]) -> Dict[str, Any]:
+    async def _invoke_phase(
+        self, phase_id: int, request: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Invoke a phase to process a request"""
         phase_state = self._phases.get(phase_id)
         phase_def = self._get_phase_definition(phase_id)
@@ -628,7 +642,8 @@ class UnifiedSystemController:
             if phase_state.status == "running" and phase_state.health_score >= 80:
                 healthy += 1
             elif (
-                phase_state.status in ("initialized", "running") and phase_state.health_score >= 50
+                phase_state.status in ("initialized", "running")
+                and phase_state.health_score >= 50
             ):
                 degraded += 1
             else:
diff --git a/workspace/src/core/integrations/work_configuration_manager.py b/workspace/src/core/integrations/work_configuration_manager.py
index b8ee5d9..b06bef3 100644
--- a/workspace/src/core/integrations/work_configuration_manager.py
+++ b/workspace/src/core/integrations/work_configuration_manager.py
@@ -425,7 +425,9 @@ class WorkConfigurationManager:
             )
         )
 
-        logger.debug(f"Initialized {len(self._capability_registry)} default capabilities")
+        logger.debug(
+            f"Initialized {len(self._capability_registry)} default capabilities"
+        )
 
     def create_configuration(
         self,
@@ -650,7 +652,9 @@ class WorkConfigurationManager:
         )
 
         configs = (
-            [self._configurations[config_id]] if config_id else list(self._configurations.values())
+            [self._configurations[config_id]]
+            if config_id
+            else list(self._configurations.values())
         )
 
         all_capabilities = set()
@@ -702,7 +706,9 @@ class WorkConfigurationManager:
 
         for provider, caps in provider_capabilities.items():
             if len(caps) > 1:
-                report.duplicate_providers.append({"provider": provider, "capabilities": caps})
+                report.duplicate_providers.append(
+                    {"provider": provider, "capabilities": caps}
+                )
 
         return report
 
@@ -752,7 +758,9 @@ class WorkConfigurationManager:
         """Get a strategy policy by ID"""
         return self._strategy_policies.get(policy_id)
 
-    def list_strategy_policies(self, category: Optional[str] = None) -> List[StrategyPolicy]:
+    def list_strategy_policies(
+        self, category: Optional[str] = None
+    ) -> List[StrategyPolicy]:
         """List strategy policies with optional category filter"""
         policies = list(self._strategy_policies.values())
         if category:
@@ -791,7 +799,9 @@ class WorkConfigurationManager:
                 )
                 self.register_capability(cap)
 
-        logger.info(f"Loaded module mappings with {len(self._module_mappings)} categories")
+        logger.info(
+            f"Loaded module mappings with {len(self._module_mappings)} categories"
+        )
 
     def get_stats(self) -> Dict[str, Any]:
         """Get manager statistics"""
@@ -864,7 +874,9 @@ class WorkConfigurationManager:
 
         return {"warnings": warnings, "errors": errors}
 
-    def _evaluate_policy(self, policy: StrategyPolicy, config: WorkConfiguration) -> Dict[str, Any]:
+    def _evaluate_policy(
+        self, policy: StrategyPolicy, config: WorkConfiguration
+    ) -> Dict[str, Any]:
         """Evaluate a policy against a configuration"""
         violations = []
 
diff --git a/workspace/src/core/integrations/workflow_orchestrator.py b/workspace/src/core/integrations/workflow_orchestrator.py
index 57213ac..de0fa1f 100644
--- a/workspace/src/core/integrations/workflow_orchestrator.py
+++ b/workspace/src/core/integrations/workflow_orchestrator.py
@@ -101,7 +101,9 @@ class StepResult:
             "duration_ms": self.duration_ms,
             "attempts": self.attempts,
             "started_at": self.started_at.isoformat() if self.started_at else None,
-            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
+            "completed_at": (
+                self.completed_at.isoformat() if self.completed_at else None
+            ),
         }
 
 
@@ -129,7 +131,9 @@ class WorkflowResult:
             "steps": [s.to_dict() for s in self.steps],
             "total_duration_ms": self.total_duration_ms,
             "started_at": self.started_at.isoformat() if self.started_at else None,
-            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
+            "completed_at": (
+                self.completed_at.isoformat() if self.completed_at else None
+            ),
             "output": self.output,
             "error": self.error,
             "metadata": self.metadata,
@@ -244,7 +248,8 @@ class WorkflowOrchestrator:
             # Check if all steps succeeded
             failed_steps = [s for s in step_results if s.status == StepStatus.FAILED]
             if failed_steps and not all(
-                self._get_step(workflow, s.step_id).continue_on_failure for s in failed_steps
+                self._get_step(workflow, s.step_id).continue_on_failure
+                for s in failed_steps
             ):
                 result.status = WorkflowStatus.FAILED
                 result.error = f"{len(failed_steps)} step(s) failed"
@@ -313,7 +318,9 @@ class WorkflowOrchestrator:
             self._event_handlers[event] = []
         self._event_handlers[event].append(handler)
 
-    async def _execute_steps(self, workflow: Workflow, context: Dict[str, Any]) -> List[StepResult]:
+    async def _execute_steps(
+        self, workflow: Workflow, context: Dict[str, Any]
+    ) -> List[StepResult]:
         """Execute all steps in a workflow"""
         results: Dict[str, StepResult] = {}
         completed: Set[str] = set()
@@ -322,7 +329,9 @@ class WorkflowOrchestrator:
         while pending_steps:
             # Find steps that can be executed (all dependencies met)
             ready_steps = [
-                step for step in pending_steps if all(dep in completed for dep in step.dependencies)
+                step
+                for step in pending_steps
+                if all(dep in completed for dep in step.dependencies)
             ]
 
             if not ready_steps:
@@ -339,7 +348,9 @@ class WorkflowOrchestrator:
             # Execute ready steps in parallel (with limit)
             parallel_batch = ready_steps[: workflow.max_parallel]
 
-            batch_tasks = [self._execute_step(step, context, results) for step in parallel_batch]
+            batch_tasks = [
+                self._execute_step(step, context, results) for step in parallel_batch
+            ]
 
             batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
 
@@ -365,7 +376,10 @@ class WorkflowOrchestrator:
         return list(results.values())
 
     async def _execute_step(
-        self, step: WorkflowStep, context: Dict[str, Any], previous_results: Dict[str, StepResult]
+        self,
+        step: WorkflowStep,
+        context: Dict[str, Any],
+        previous_results: Dict[str, StepResult],
     ) -> StepResult:
         """Execute a single workflow step"""
         result = StepResult(
@@ -393,7 +407,8 @@ class WorkflowOrchestrator:
             try:
                 start_time = datetime.now()
                 tool_result = await asyncio.wait_for(
-                    self._tool_executor(step.tool, arguments), timeout=step.timeout / 1000.0
+                    self._tool_executor(step.tool, arguments),
+                    timeout=step.timeout / 1000.0,
                 )
                 end_time = datetime.now()
 
@@ -473,7 +488,9 @@ class WorkflowOrchestrator:
                 condition = condition.replace(f"${{{key}}}", repr(value))
             # Basic safety check - only allow simple comparisons
             allowed_chars = set("0123456789.!=<>andornotTrueFalse\"' ")
-            if not all(c in allowed_chars or c.isalnum() or c == "_" for c in condition):
+            if not all(
+                c in allowed_chars or c.isalnum() or c == "_" for c in condition
+            ):
                 logger.warning(f"Unsafe condition blocked: {condition}")
                 return True
             # For framework demonstration, return True
@@ -489,7 +506,11 @@ class WorkflowOrchestrator:
         """Substitute context values into arguments"""
         result = {}
         for key, value in arguments.items():
-            if isinstance(value, str) and value.startswith("${") and value.endswith("}"):
+            if (
+                isinstance(value, str)
+                and value.startswith("${")
+                and value.endswith("}")
+            ):
                 # Context reference
                 ref = value[2:-1]
                 result[key] = context.get(ref, value)
@@ -532,7 +553,9 @@ class WorkflowOrchestrator:
         except Exception as e:
             logger.error(f"Callback error: {e}")
 
-    async def _default_executor(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
+    async def _default_executor(
+        self, tool_name: str, arguments: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """Default tool executor (for testing)"""
         return {
             "success": True,
@@ -543,7 +566,9 @@ class WorkflowOrchestrator:
 
 
 # Factory functions
-def create_workflow_orchestrator(tool_executor: Callable = None) -> WorkflowOrchestrator:
+def create_workflow_orchestrator(
+    tool_executor: Callable = None,
+) -> WorkflowOrchestrator:
     """Create a new WorkflowOrchestrator instance"""
     return WorkflowOrchestrator(tool_executor)
 
@@ -553,10 +578,16 @@ def create_workflow(name: str, steps: List[WorkflowStep], **kwargs) -> Workflow:
     return Workflow(id=str(uuid4()), name=name, steps=steps, **kwargs)
 
 
-def create_step(name: str, tool: str, arguments: Dict[str, Any], **kwargs) -> WorkflowStep:
+def create_step(
+    name: str, tool: str, arguments: Dict[str, Any], **kwargs
+) -> WorkflowStep:
     """Create a new WorkflowStep instance"""
     return WorkflowStep(
-        id=kwargs.pop("id", str(uuid4())), name=name, tool=tool, arguments=arguments, **kwargs
+        id=kwargs.pop("id", str(uuid4())),
+        name=name,
+        tool=tool,
+        arguments=arguments,
+        **kwargs,
     )
 
 
diff --git a/workspace/src/core/island_ai_runtime/agent_framework.py b/workspace/src/core/island_ai_runtime/agent_framework.py
index 8c1d181..69a8334 100644
--- a/workspace/src/core/island_ai_runtime/agent_framework.py
+++ b/workspace/src/core/island_ai_runtime/agent_framework.py
@@ -97,7 +97,9 @@ class Agent(ABC):
         """è™•ç†è¨Šæ¯"""
         pass
 
-    def send_message(self, receiver: str, content: str, msg_type: str = "request") -> None:
+    def send_message(
+        self, receiver: str, content: str, msg_type: str = "request"
+    ) -> None:
         """ç™¼é€è¨Šæ¯"""
         message = AgentMessage(
             sender=self.name, receiver=receiver, content=content, message_type=msg_type
@@ -116,7 +118,10 @@ class ArchitectAgent(Agent):
         """åŸ·è¡Œæ¶æ§‹è¨­è¨ˆä»»å‹™"""
         self.status = AgentStatus.WORKING
         # å¯¦éš›å¯¦ç¾æœƒèª¿ç”¨ LLM
-        result = {"design": "Architecture design for " + task.name, "recommendations": []}
+        result = {
+            "design": "Architecture design for " + task.name,
+            "recommendations": [],
+        }
         self.status = AgentStatus.COMPLETED
         return result
 
diff --git a/workspace/src/core/island_ai_runtime/knowledge_engine.py b/workspace/src/core/island_ai_runtime/knowledge_engine.py
index 176cb7a..71f48e2 100644
--- a/workspace/src/core/island_ai_runtime/knowledge_engine.py
+++ b/workspace/src/core/island_ai_runtime/knowledge_engine.py
@@ -90,7 +90,9 @@ class RepoGraph:
         """ç²å–ç¯€é»"""
         return self.nodes.get(node_id)
 
-    def get_neighbors(self, node_id: str, edge_type: EdgeType | None = None) -> list[GraphNode]:
+    def get_neighbors(
+        self, node_id: str, edge_type: EdgeType | None = None
+    ) -> list[GraphNode]:
         """ç²å–é„°å±…ç¯€é»"""
         neighbors = []
         for edge in self.edges:
@@ -109,7 +111,11 @@ class RepoGraph:
                 for n in self.nodes.values()
             ],
             "edges": [
-                {"source": e.source_id, "target": e.target_id, "type": e.edge_type.value}
+                {
+                    "source": e.source_id,
+                    "target": e.target_id,
+                    "type": e.edge_type.value,
+                }
                 for e in self.edges
             ],
         }
@@ -167,7 +173,9 @@ class VectorStore:
         self.vectors: dict[str, list[float]] = {}
         self.metadata: dict[str, dict[str, Any]] = {}
 
-    def upsert(self, id: str, vector: list[float], metadata: dict[str, Any] | None = None) -> None:
+    def upsert(
+        self, id: str, vector: list[float], metadata: dict[str, Any] | None = None
+    ) -> None:
         """æ’å…¥æˆ–æ›´æ–°å‘é‡"""
         self.vectors[id] = vector
         self.metadata[id] = metadata or {}
@@ -177,7 +185,9 @@ class VectorStore:
         self.vectors.pop(id, None)
         self.metadata.pop(id, None)
 
-    def search(self, query_vector: list[float], top_k: int = 10) -> list[tuple[str, float]]:
+    def search(
+        self, query_vector: list[float], top_k: int = 10
+    ) -> list[tuple[str, float]]:
         """æœç´¢æœ€ç›¸ä¼¼çš„å‘é‡"""
         scores = []
         for id, vector in self.vectors.items():
@@ -266,7 +276,9 @@ class KnowledgeEngine:
             if node:
                 search_results.append(
                     SearchResult(
-                        node=node, score=score, context=node.content[:500] if node.content else ""
+                        node=node,
+                        score=score,
+                        context=node.content[:500] if node.content else "",
                     )
                 )
 
@@ -295,7 +307,11 @@ class KnowledgeEngine:
         # ç²å–é„°å±…
         for neighbor in self.repo_graph.get_neighbors(node_id):
             context["neighbors"].append(
-                {"id": neighbor.id, "name": neighbor.name, "type": neighbor.node_type.value}
+                {
+                    "id": neighbor.id,
+                    "name": neighbor.name,
+                    "type": neighbor.node_type.value,
+                }
             )
 
         return context
diff --git a/workspace/src/core/island_ai_runtime/model_gateway.py b/workspace/src/core/island_ai_runtime/model_gateway.py
index 99fa6b6..e5f1fc6 100644
--- a/workspace/src/core/island_ai_runtime/model_gateway.py
+++ b/workspace/src/core/island_ai_runtime/model_gateway.py
@@ -181,7 +181,9 @@ class ModelGateway:
         self, messages: list[dict[str, str]], model: str | None = None, **kwargs: Any
     ) -> AsyncIterator[str]:
         """åŸ·è¡Œä¸²æµå®Œæˆè«‹æ±‚"""
-        request = CompletionRequest(messages=messages, model=model, stream=True, **kwargs)
+        request = CompletionRequest(
+            messages=messages, model=model, stream=True, **kwargs
+        )
 
         provider = self._get_provider_for_model(model)
         client = self.clients.get(provider)
diff --git a/workspace/src/core/island_ai_runtime/runtime.py b/workspace/src/core/island_ai_runtime/runtime.py
index fa9cd53..3e704c4 100644
--- a/workspace/src/core/island_ai_runtime/runtime.py
+++ b/workspace/src/core/island_ai_runtime/runtime.py
@@ -111,7 +111,9 @@ class IslandAIRuntime:
                     },
                     "anthropic": {
                         "api_key": os.getenv("ANTHROPIC_API_KEY"),
-                        "model": os.getenv("ANTHROPIC_MODEL", "claude-sonnet-4-20250514"),
+                        "model": os.getenv(
+                            "ANTHROPIC_MODEL", "claude-sonnet-4-20250514"
+                        ),
                     },
                 },
             }
@@ -139,7 +141,9 @@ class IslandAIRuntime:
             self.status.errors.append(str(e))
             return False
 
-    async def complete(self, prompt: str, system_prompt: str | None = None, **kwargs: Any) -> str:
+    async def complete(
+        self, prompt: str, system_prompt: str | None = None, **kwargs: Any
+    ) -> str:
         """åŸ·è¡Œ LLM å®Œæˆ"""
         # å®‰å…¨æª¢æŸ¥
         safety_result = self.safety_constitution.check_content(prompt)
@@ -153,7 +157,9 @@ class IslandAIRuntime:
         context = self.session_memory.get_context()
 
         # å‰µå»ºè«‹æ±‚
-        request = CompletionRequest(messages=context, system_prompt=system_prompt, **kwargs)
+        request = CompletionRequest(
+            messages=context, system_prompt=system_prompt, **kwargs
+        )
 
         # èª¿ç”¨ Model Gateway
         response = await self.model_gateway.complete(request)
@@ -181,15 +187,24 @@ class IslandAIRuntime:
         self.status.total_requests += 1
         return results
 
-    async def search_knowledge(self, query: str, top_k: int = 10) -> list[dict[str, Any]]:
+    async def search_knowledge(
+        self, query: str, top_k: int = 10
+    ) -> list[dict[str, Any]]:
         """æœç´¢çŸ¥è­˜åº«"""
         results = await self.knowledge_engine.search(query, top_k)
         return [
-            {"path": r.node.path, "name": r.node.name, "score": r.score, "context": r.context}
+            {
+                "path": r.node.path,
+                "name": r.node.name,
+                "score": r.score,
+                "context": r.context,
+            }
             for r in results
         ]
 
-    async def execute_code(self, code: str, language: str = "python") -> ExecutionResult:
+    async def execute_code(
+        self, code: str, language: str = "python"
+    ) -> ExecutionResult:
         """åŸ·è¡Œä»£ç¢¼"""
         # å®‰å…¨æª¢æŸ¥
         safety_result = self.safety_constitution.check_content(code)
diff --git a/workspace/src/core/island_ai_runtime/safety_constitution.py b/workspace/src/core/island_ai_runtime/safety_constitution.py
index c969a1d..42fad2a 100644
--- a/workspace/src/core/island_ai_runtime/safety_constitution.py
+++ b/workspace/src/core/island_ai_runtime/safety_constitution.py
@@ -263,7 +263,9 @@ class AIConstitution:
 
         return result
 
-    def _violates_principle(self, action: dict[str, Any], principle: dict[str, Any]) -> bool:
+    def _violates_principle(
+        self, action: dict[str, Any], principle: dict[str, Any]
+    ) -> bool:
         """æª¢æŸ¥è¡Œå‹•æ˜¯å¦é•åç‰¹å®šæº–å‰‡"""
         # ç°¡åŒ–çš„é•è¦æª¢æ¸¬é‚è¼¯
         action_type = action.get("type", "")
diff --git a/workspace/src/core/island_ai_runtime/session_memory.py b/workspace/src/core/island_ai_runtime/session_memory.py
index a5c91d4..3d0b494 100644
--- a/workspace/src/core/island_ai_runtime/session_memory.py
+++ b/workspace/src/core/island_ai_runtime/session_memory.py
@@ -105,7 +105,9 @@ class ShortTermMemory:
 
     def to_messages(self) -> list[dict[str, str]]:
         """è½‰æ›ç‚º LLM è¨Šæ¯æ ¼å¼"""
-        return [{"role": msg.role.value, "content": msg.content} for msg in self.messages]
+        return [
+            {"role": msg.role.value, "content": msg.content} for msg in self.messages
+        ]
 
 
 class WorkingMemory:
@@ -240,13 +242,20 @@ class SessionMemory:
 
     def __init__(self, config: dict[str, Any] | None = None):
         self.config = config or {}
-        self.short_term = ShortTermMemory(max_messages=self.config.get("max_messages", 100))
+        self.short_term = ShortTermMemory(
+            max_messages=self.config.get("max_messages", 100)
+        )
         self.working = WorkingMemory()
         self.planner = Planner()
-        self.context_window = ContextWindow(max_tokens=self.config.get("max_tokens", 128000))
+        self.context_window = ContextWindow(
+            max_tokens=self.config.get("max_tokens", 128000)
+        )
 
     def add_message(
-        self, role: str | MessageRole, content: str, metadata: dict[str, Any] | None = None
+        self,
+        role: str | MessageRole,
+        content: str,
+        metadata: dict[str, Any] | None = None,
     ) -> None:
         """æ·»åŠ è¨Šæ¯åˆ°è¨˜æ†¶"""
         if isinstance(role, str):
@@ -291,10 +300,15 @@ class SessionMemory:
                 "message_count": len(self.short_term.messages),
                 "recent_topics": self._extract_topics(),
             },
-            "working": {"focus": self.working.focus, "data_keys": list(self.working.data.keys())},
+            "working": {
+                "focus": self.working.focus,
+                "data_keys": list(self.working.data.keys()),
+            },
             "planning": {
                 "current_plan": (
-                    self.planner.current_plan.goal if self.planner.current_plan else None
+                    self.planner.current_plan.goal
+                    if self.planner.current_plan
+                    else None
                 ),
                 "plan_count": len(self.planner.plans),
             },
diff --git a/workspace/src/core/island_ai_runtime/tool_executor.py b/workspace/src/core/island_ai_runtime/tool_executor.py
index adc211a..a5f4a25 100644
--- a/workspace/src/core/island_ai_runtime/tool_executor.py
+++ b/workspace/src/core/island_ai_runtime/tool_executor.py
@@ -108,7 +108,9 @@ class CodeRunner(Tool):
     }
 
     def __init__(self, config: ToolConfig | None = None):
-        super().__init__(config or ToolConfig(name="code_runner", tool_type=ToolType.CODE_RUNNER))
+        super().__init__(
+            config or ToolConfig(name="code_runner", tool_type=ToolType.CODE_RUNNER)
+        )
 
     def _resolve_working_dir(self, working_dir: str | None) -> str | None:
         """Normalize and validate working directory against allowed paths."""
@@ -138,7 +140,9 @@ class CodeRunner(Tool):
             f"Working directory '{normalized}' is not allowed; allowed roots: {[str(r) for r in allowed_roots]}"
         )
 
-    def _build_execution_command(self, lang_config: dict[str, str], temp_file: str) -> list[str]:
+    def _build_execution_command(
+        self, lang_config: dict[str, str], temp_file: str
+    ) -> list[str]:
         """
         Build a two-element subprocess command array from a validated language configuration.
         `lang_config` must include a `cmd` entry sourced from SUPPORTED_LANGUAGES.
@@ -160,7 +164,8 @@ class CodeRunner(Tool):
 
         if not lang_config:
             return ExecutionResult(
-                status=ExecutionStatus.FAILURE, error=f"Unsupported language: {language}"
+                status=ExecutionStatus.FAILURE,
+                error=f"Unsupported language: {language}",
             )
 
         try:
@@ -188,7 +193,9 @@ class CodeRunner(Tool):
 
             return ExecutionResult(
                 status=(
-                    ExecutionStatus.SUCCESS if result.returncode == 0 else ExecutionStatus.FAILURE
+                    ExecutionStatus.SUCCESS
+                    if result.returncode == 0
+                    else ExecutionStatus.FAILURE
                 ),
                 output=result.stdout,
                 error=result.stderr,
@@ -363,9 +370,12 @@ class FilesystemSandbox(Tool):
     å®‰å…¨åœ°é€²è¡Œæ–‡ä»¶æ“ä½œã€‚
     """
 
-    def __init__(self, config: ToolConfig | None = None, sandbox_root: str | None = None):
+    def __init__(
+        self, config: ToolConfig | None = None, sandbox_root: str | None = None
+    ):
         super().__init__(
-            config or ToolConfig(name="filesystem_sandbox", tool_type=ToolType.FILE_SYSTEM)
+            config
+            or ToolConfig(name="filesystem_sandbox", tool_type=ToolType.FILE_SYSTEM)
         )
         self.sandbox_root = sandbox_root or tempfile.mkdtemp(prefix="island_sandbox_")
 
@@ -391,21 +401,28 @@ class FilesystemSandbox(Tool):
                 os.makedirs(os.path.dirname(path), exist_ok=True)
                 with open(path, "w") as f:
                     f.write(content)
-                return ExecutionResult(status=ExecutionStatus.SUCCESS, output=f"Written to {path}")
+                return ExecutionResult(
+                    status=ExecutionStatus.SUCCESS, output=f"Written to {path}"
+                )
 
             elif operation == "list":
                 path = self._safe_path(args[0] if args else "")
                 files = os.listdir(path)
-                return ExecutionResult(status=ExecutionStatus.SUCCESS, output=json.dumps(files))
+                return ExecutionResult(
+                    status=ExecutionStatus.SUCCESS, output=json.dumps(files)
+                )
 
             elif operation == "delete":
                 path = self._safe_path(args[0])
                 os.remove(path)
-                return ExecutionResult(status=ExecutionStatus.SUCCESS, output=f"Deleted {path}")
+                return ExecutionResult(
+                    status=ExecutionStatus.SUCCESS, output=f"Deleted {path}"
+                )
 
             else:
                 return ExecutionResult(
-                    status=ExecutionStatus.FAILURE, error=f"Unknown operation: {operation}"
+                    status=ExecutionStatus.FAILURE,
+                    error=f"Unknown operation: {operation}",
                 )
 
         except Exception as e:
@@ -498,7 +515,9 @@ class ToolExecutor:
 
         return result
 
-    async def execute_file_operation(self, operation: str, *args: str) -> ExecutionResult:
+    async def execute_file_operation(
+        self, operation: str, *args: str
+    ) -> ExecutionResult:
         """åŸ·è¡Œæ–‡ä»¶æ“ä½œ"""
         request = ExecutionRequest(
             tool_type=ToolType.FILE_SYSTEM, command=operation, args=list(args)
@@ -509,7 +528,9 @@ class ToolExecutor:
 
         return result
 
-    async def call_mcp_tool(self, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
+    async def call_mcp_tool(
+        self, tool_name: str, args: dict[str, Any]
+    ) -> dict[str, Any]:
         """èª¿ç”¨ MCP å·¥å…·"""
         result = await self.mcp_client.call_tool(tool_name, args)
 
diff --git a/workspace/src/core/main_system/automation_pipeline.py b/workspace/src/core/main_system/automation_pipeline.py
index 16a18d7..b357685 100644
--- a/workspace/src/core/main_system/automation_pipeline.py
+++ b/workspace/src/core/main_system/automation_pipeline.py
@@ -200,7 +200,9 @@ class AutomationPipeline:
 
         # Check dependencies
         for i, task in enumerate(self._queue):
-            deps_satisfied = all(dep_id in self._completed for dep_id in task.dependencies)
+            deps_satisfied = all(
+                dep_id in self._completed for dep_id in task.dependencies
+            )
             if deps_satisfied:
                 return self._queue.pop(i)
 
@@ -250,7 +252,9 @@ class AutomationPipeline:
 
         return phases
 
-    def execute_task(self, task: PipelineTask, handler: Optional[Callable] = None) -> TaskResult:
+    def execute_task(
+        self, task: PipelineTask, handler: Optional[Callable] = None
+    ) -> TaskResult:
         """
         Execute a task
 
@@ -264,7 +268,9 @@ class AutomationPipeline:
         self.logger.info(f"Executing task: {task.id}")
 
         started_at = datetime.now()
-        result = TaskResult(task_id=task.id, status=TaskStatus.RUNNING, started_at=started_at)
+        result = TaskResult(
+            task_id=task.id, status=TaskStatus.RUNNING, started_at=started_at
+        )
 
         # Track running task
         self._running[task.id] = task
@@ -307,7 +313,10 @@ class AutomationPipeline:
             self.logger.error(f"Task failed: {task.id} - {e}")
 
             # Retry if enabled
-            if self.config.enable_retries and result.retry_count < self.config.max_retries:
+            if (
+                self.config.enable_retries
+                and result.retry_count < self.config.max_retries
+            ):
                 result.retry_count += 1
                 result.status = TaskStatus.RETRYING
                 self.submit_task(task)
@@ -335,7 +344,10 @@ class AutomationPipeline:
 
         for keyword in dangerous_keywords:
             if keyword in task_str:
-                return {"safe": False, "reason": f"Task contains dangerous keyword: {keyword}"}
+                return {
+                    "safe": False,
+                    "reason": f"Task contains dangerous keyword: {keyword}",
+                }
 
         return {"safe": True, "reason": None}
 
@@ -399,7 +411,9 @@ class AutomationPipeline:
             "completed": len(self._completed),
             "queue_capacity": self.config.queue_size,
             "utilization": (
-                len(self._queue) / self.config.queue_size if self.config.queue_size > 0 else 0
+                len(self._queue) / self.config.queue_size
+                if self.config.queue_size > 0
+                else 0
             ),
         }
 
diff --git a/workspace/src/core/main_system/phase_orchestrator.py b/workspace/src/core/main_system/phase_orchestrator.py
index 57e3681..80cc337 100644
--- a/workspace/src/core/main_system/phase_orchestrator.py
+++ b/workspace/src/core/main_system/phase_orchestrator.py
@@ -376,12 +376,16 @@ class PhaseOrchestrator:
             if result.state == PhaseState.FAILED:
                 phase = self._phases.get(phase_id)
                 if phase and phase.enabled:
-                    self.logger.error(f"Stopping execution due to phase failure: {phase_id}")
+                    self.logger.error(
+                        f"Stopping execution due to phase failure: {phase_id}"
+                    )
                     break
 
         return results
 
-    def transition(self, from_phase: str, to_phase: str, trigger: str) -> PhaseTransition:
+    def transition(
+        self, from_phase: str, to_phase: str, trigger: str
+    ) -> PhaseTransition:
         """
         Record a phase transition
 
diff --git a/workspace/src/core/main_system/synergymesh_core.py b/workspace/src/core/main_system/synergymesh_core.py
index fd7d1d7..1439805 100644
--- a/workspace/src/core/main_system/synergymesh_core.py
+++ b/workspace/src/core/main_system/synergymesh_core.py
@@ -141,7 +141,9 @@ class SynergyMeshCore:
         ]
 
         for phase_id, name, description in phase_definitions:
-            self._phases[phase_id] = PhaseInfo(id=phase_id, name=name, description=description)
+            self._phases[phase_id] = PhaseInfo(
+                id=phase_id, name=name, description=description
+            )
 
     def initialize(self) -> bool:
         """
diff --git a/workspace/src/core/main_system/system_bootstrap.py b/workspace/src/core/main_system/system_bootstrap.py
index 9618110..b0ee38c 100644
--- a/workspace/src/core/main_system/system_bootstrap.py
+++ b/workspace/src/core/main_system/system_bootstrap.py
@@ -274,7 +274,9 @@ class SystemBootstrap:
             for service_name in order:
                 if not self._initialize_service(service_name):
                     if self.config.fail_fast:
-                        self.logger.error(f"Failed to initialize {service_name}, failing fast")
+                        self.logger.error(
+                            f"Failed to initialize {service_name}, failing fast"
+                        )
                         return False
 
             self._initialized = True
@@ -307,7 +309,11 @@ class SystemBootstrap:
             if definition.config:
                 instance = definition.service_class(**definition.config, **deps)
             else:
-                instance = definition.service_class(**deps) if deps else definition.service_class()
+                instance = (
+                    definition.service_class(**deps)
+                    if deps
+                    else definition.service_class()
+                )
 
             # Register instance
             self.registry.set_instance(name, instance)
@@ -391,7 +397,10 @@ class SystemBootstrap:
 
         # Check service states
         for name, service in self.registry.get_all().items():
-            is_healthy = service.lifecycle in [ServiceLifecycle.READY, ServiceLifecycle.RUNNING]
+            is_healthy = service.lifecycle in [
+                ServiceLifecycle.READY,
+                ServiceLifecycle.RUNNING,
+            ]
             results["services"][name] = {
                 "healthy": is_healthy,
                 "lifecycle": service.lifecycle.value,
diff --git a/workspace/src/core/merkle/merkle_foundation.py b/workspace/src/core/merkle/merkle_foundation.py
index 8a70808..f0a6389 100644
--- a/workspace/src/core/merkle/merkle_foundation.py
+++ b/workspace/src/core/merkle/merkle_foundation.py
@@ -84,7 +84,9 @@ class MerkleTree:
         # Full implementation would traverse tree
         return proof
 
-    def verify_proof(self, leaf_hash: str, proof: List[Dict[str, str]], root_hash: str) -> bool:
+    def verify_proof(
+        self, leaf_hash: str, proof: List[Dict[str, str]], root_hash: str
+    ) -> bool:
         """Verify a Merkle proof."""
         current = leaf_hash
         for step in proof:
diff --git a/workspace/src/core/monitoring/auto_diagnosis.py b/workspace/src/core/monitoring/auto_diagnosis.py
index 58f7e54..fdf2ca0 100644
--- a/workspace/src/core/monitoring/auto_diagnosis.py
+++ b/workspace/src/core/monitoring/auto_diagnosis.py
@@ -107,7 +107,9 @@ class AutoDiagnosisEngine:
     """
 
     def __init__(self):
-        self._diagnosis_rules: Dict[str, Callable[[DiagnosisContext], List[RootCause]]] = {}
+        self._diagnosis_rules: Dict[
+            str, Callable[[DiagnosisContext], List[RootCause]]
+        ] = {}
         self._component_dependencies: Dict[str, List[str]] = {}
         self._history: List[DiagnosisResult] = []
 
@@ -117,14 +119,23 @@ class AutoDiagnosisEngine:
         """Register a diagnosis rule"""
         self._diagnosis_rules[name] = rule
 
-    def set_component_dependencies(self, component: str, dependencies: List[str]) -> None:
+    def set_component_dependencies(
+        self, component: str, dependencies: List[str]
+    ) -> None:
         """Set dependencies for a component"""
         self._component_dependencies[component] = dependencies
 
     def _analyze_logs(self, logs: List[str]) -> List[str]:
         """Analyze logs for evidence"""
         evidence = []
-        error_keywords = ["error", "exception", "failed", "timeout", "refused", "unavailable"]
+        error_keywords = [
+            "error",
+            "exception",
+            "failed",
+            "timeout",
+            "refused",
+            "unavailable",
+        ]
 
         for log in logs:
             log_lower = log.lower()
@@ -159,7 +170,9 @@ class AutoDiagnosisEngine:
 
         return causes
 
-    def _analyze_dependencies(self, component: str, context: DiagnosisContext) -> List[RootCause]:
+    def _analyze_dependencies(
+        self, component: str, context: DiagnosisContext
+    ) -> List[RootCause]:
         """Analyze component dependencies"""
         causes = []
         dependencies = self._component_dependencies.get(component, [])
@@ -192,7 +205,9 @@ class AutoDiagnosisEngine:
         start_time = time.time()
 
         result = DiagnosisResult(
-            anomaly_id=context.anomaly_id, status=DiagnosisStatus.IN_PROGRESS, context=context
+            anomaly_id=context.anomaly_id,
+            status=DiagnosisStatus.IN_PROGRESS,
+            context=context,
         )
 
         try:
@@ -226,7 +241,9 @@ class AutoDiagnosisEngine:
 
             # Analyze dependencies
             component = (
-                context.metric_name.split(".")[0] if "." in context.metric_name else "unknown"
+                context.metric_name.split(".")[0]
+                if "." in context.metric_name
+                else "unknown"
             )
             dep_causes = self._analyze_dependencies(component, context)
             root_causes.extend(dep_causes)
@@ -248,7 +265,9 @@ class AutoDiagnosisEngine:
                 top_cause = root_causes[0]
                 result.summary = f"Most likely cause: {top_cause.description} (confidence: {top_cause.confidence.value})"
             else:
-                result.summary = "No root cause identified. Further investigation needed."
+                result.summary = (
+                    "No root cause identified. Further investigation needed."
+                )
 
             # Generate recommendations
             result.recommendations = RecommendationGenerator().generate(result)
@@ -301,7 +320,11 @@ class RecommendationGenerator:
                 "Check database connections",
                 "Optimize database indexes",
             ],
-            "default": ["Review system logs", "Check recent changes", "Monitor the situation"],
+            "default": [
+                "Review system logs",
+                "Check recent changes",
+                "Monitor the situation",
+            ],
         }
 
     def generate(self, diagnosis: DiagnosisResult) -> List[str]:
diff --git a/workspace/src/core/monitoring/auto_remediation.py b/workspace/src/core/monitoring/auto_remediation.py
index 385f31c..77242fe 100644
--- a/workspace/src/core/monitoring/auto_remediation.py
+++ b/workspace/src/core/monitoring/auto_remediation.py
@@ -182,7 +182,9 @@ class RemediationExecutor:
 
         try:
             # Execute with timeout
-            result = await asyncio.wait_for(handler(action), timeout=action.timeout_seconds)
+            result = await asyncio.wait_for(
+                handler(action), timeout=action.timeout_seconds
+            )
 
             if result:
                 # Check post-conditions
@@ -234,7 +236,10 @@ class AutoRemediationEngine:
             if playbook.is_in_cooldown():
                 continue
             for condition in playbook.trigger_conditions:
-                if condition.lower() in trigger.lower() or trigger.lower() in condition.lower():
+                if (
+                    condition.lower() in trigger.lower()
+                    or trigger.lower() in condition.lower()
+                ):
                     matching.append(playbook)
                     break
 
diff --git a/workspace/src/core/monitoring/intelligent_monitoring.py b/workspace/src/core/monitoring/intelligent_monitoring.py
index fda7145..97a3172 100644
--- a/workspace/src/core/monitoring/intelligent_monitoring.py
+++ b/workspace/src/core/monitoring/intelligent_monitoring.py
@@ -119,10 +119,13 @@ class MetricsCollector:
         if name not in self._metrics:
             self._metrics[name] = []
 
-    def collect(self, name: str, value: float, labels: Optional[Dict[str, str]] = None) -> Metric:
+    def collect(
+        self, name: str, value: float, labels: Optional[Dict[str, str]] = None
+    ) -> Metric:
         """Manually collect a metric value"""
         config = self._collectors.get(
-            name, {"type": MetricType.GAUGE, "labels": {}, "unit": "", "description": ""}
+            name,
+            {"type": MetricType.GAUGE, "labels": {}, "unit": "", "description": ""},
         )
 
         metric = Metric(
@@ -319,9 +322,15 @@ class IntelligentMonitoringSystem:
     def get_health_status(self) -> Dict[str, Any]:
         """Get overall system health status"""
         active_alerts = self.get_active_alerts()
-        critical_count = len([a for a in active_alerts if a.severity == AlertSeverity.CRITICAL])
-        error_count = len([a for a in active_alerts if a.severity == AlertSeverity.ERROR])
-        warning_count = len([a for a in active_alerts if a.severity == AlertSeverity.WARNING])
+        critical_count = len(
+            [a for a in active_alerts if a.severity == AlertSeverity.CRITICAL]
+        )
+        error_count = len(
+            [a for a in active_alerts if a.severity == AlertSeverity.ERROR]
+        )
+        warning_count = len(
+            [a for a in active_alerts if a.severity == AlertSeverity.WARNING]
+        )
 
         if critical_count > 0:
             status = "CRITICAL"
@@ -341,7 +350,9 @@ class IntelligentMonitoringSystem:
             "timestamp": datetime.now().isoformat(),
         }
 
-    async def start(self, collection_interval: float = 10.0, check_interval: float = 30.0) -> None:
+    async def start(
+        self, collection_interval: float = 10.0, check_interval: float = 30.0
+    ) -> None:
         """Start the monitoring system"""
         self._running = True
 
diff --git a/workspace/src/core/monitoring/observability_platform.py b/workspace/src/core/monitoring/observability_platform.py
index 5002d2f..731ed6c 100644
--- a/workspace/src/core/monitoring/observability_platform.py
+++ b/workspace/src/core/monitoring/observability_platform.py
@@ -101,7 +101,11 @@ class TraceSpan:
     def add_event(self, name: str, attributes: Optional[Dict[str, Any]] = None) -> None:
         """Add an event to the span"""
         self.events.append(
-            {"name": name, "timestamp": datetime.now().isoformat(), "attributes": attributes or {}}
+            {
+                "name": name,
+                "timestamp": datetime.now().isoformat(),
+                "attributes": attributes or {},
+            }
         )
 
     def to_dict(self) -> Dict[str, Any]:
@@ -174,7 +178,9 @@ class CorrelationEngine:
     ) -> CorrelatedEvent:
         """Correlate events by time proximity"""
         event = CorrelatedEvent(
-            event_type=EventType.INCIDENT, title="Time-correlated event", timestamp=reference_time
+            event_type=EventType.INCIDENT,
+            title="Time-correlated event",
+            timestamp=reference_time,
         )
 
         # Find logs within time window
diff --git a/workspace/src/core/monitoring/self_learning.py b/workspace/src/core/monitoring/self_learning.py
index 3528f5a..8059edb 100644
--- a/workspace/src/core/monitoring/self_learning.py
+++ b/workspace/src/core/monitoring/self_learning.py
@@ -148,14 +148,19 @@ class PatternLearner:
 
         return intersection / union if union > 0 else 0.0
 
-    def find_similar_pattern(self, conditions: List[Dict[str, Any]]) -> Optional[IncidentPattern]:
+    def find_similar_pattern(
+        self, conditions: List[Dict[str, Any]]
+    ) -> Optional[IncidentPattern]:
         """Find a similar existing pattern"""
         best_match = None
         best_similarity = 0.0
 
         for pattern in self._patterns.values():
             similarity = self._calculate_similarity(conditions, pattern.conditions)
-            if similarity > best_similarity and similarity >= self._similarity_threshold:
+            if (
+                similarity > best_similarity
+                and similarity >= self._similarity_threshold
+            ):
                 best_similarity = similarity
                 best_match = pattern
 
@@ -351,7 +356,8 @@ class SelfLearningEngine:
     def analyze_and_learn(self) -> LearningOutcome:
         """Analyze data and generate learning outcomes"""
         outcome = LearningOutcome(
-            source=LearningSource.MONITORING, description="Periodic analysis of monitoring data"
+            source=LearningSource.MONITORING,
+            description="Periodic analysis of monitoring data",
         )
 
         # Count patterns
@@ -384,7 +390,9 @@ class SelfLearningEngine:
 
         return outcome
 
-    def get_recommended_playbook(self, conditions: List[Dict[str, Any]]) -> Optional[str]:
+    def get_recommended_playbook(
+        self, conditions: List[Dict[str, Any]]
+    ) -> Optional[str]:
         """Get recommended playbook based on learned patterns"""
         pattern = self._pattern_learner.find_similar_pattern(conditions)
 
diff --git a/workspace/src/core/monitoring/smart_anomaly_detector.py b/workspace/src/core/monitoring/smart_anomaly_detector.py
index f4fc72f..336d8ec 100644
--- a/workspace/src/core/monitoring/smart_anomaly_detector.py
+++ b/workspace/src/core/monitoring/smart_anomaly_detector.py
@@ -181,7 +181,9 @@ class SmartAnomalyDetector:
         else:
             return AnomalyCategory.UNKNOWN
 
-    def _calculate_severity(self, deviation: float, confidence: float) -> AnomalySeverity:
+    def _calculate_severity(
+        self, deviation: float, confidence: float
+    ) -> AnomalySeverity:
         """Calculate severity based on deviation and confidence"""
         score = deviation * confidence
 
@@ -194,7 +196,9 @@ class SmartAnomalyDetector:
         else:
             return AnomalySeverity.LOW
 
-    def detect_statistical(self, metric_name: str, value: float) -> Optional[DetectedAnomaly]:
+    def detect_statistical(
+        self, metric_name: str, value: float
+    ) -> Optional[DetectedAnomaly]:
         """Detect anomaly using statistical method (Z-score)"""
         baseline = self._baselines.get(metric_name)
         if not baseline or baseline["stdev"] == 0:
@@ -287,7 +291,10 @@ class SmartAnomalyDetector:
         return None
 
     def detect(
-        self, metric_name: str, value: float, strategy: Optional[AnomalyDetectionStrategy] = None
+        self,
+        metric_name: str,
+        value: float,
+        strategy: Optional[AnomalyDetectionStrategy] = None,
     ) -> Optional[DetectedAnomaly]:
         """
         Detect anomaly using specified or default strategy
diff --git a/workspace/src/core/new/automation/workflow_engine.py b/workspace/src/core/new/automation/workflow_engine.py
index d6789da..2ba98cd 100644
--- a/workspace/src/core/new/automation/workflow_engine.py
+++ b/workspace/src/core/new/automation/workflow_engine.py
@@ -71,7 +71,9 @@ class AutomationEngine:
         self, name: str, description: str, tasks: List[WorkflowTask]
     ) -> Workflow:
         """å‰µå»ºå·¥ä½œæµ"""
-        workflow = Workflow(id=str(uuid.uuid4()), name=name, description=description, tasks=tasks)
+        workflow = Workflow(
+            id=str(uuid.uuid4()), name=name, description=description, tasks=tasks
+        )
 
         self.workflows[workflow.id] = workflow
         logger.info(f"ğŸ“ å‰µå»ºå·¥ä½œæµ: {name}")
diff --git a/workspace/src/core/new/runtime/engine.py b/workspace/src/core/new/runtime/engine.py
index 53d0e86..4419669 100644
--- a/workspace/src/core/new/runtime/engine.py
+++ b/workspace/src/core/new/runtime/engine.py
@@ -70,7 +70,12 @@ class MachineNativeOpsEngine:
         self, name: str, handler: Callable, parameters: Dict[str, Any] = None
     ) -> str:
         """æäº¤ä»»å‹™"""
-        task = Task(id=str(uuid.uuid4()), name=name, handler=handler, parameters=parameters or {})
+        task = Task(
+            id=str(uuid.uuid4()),
+            name=name,
+            handler=handler,
+            parameters=parameters or {},
+        )
 
         self.tasks[task.id] = task
 
diff --git a/workspace/src/core/orchestrators/__init__.py b/workspace/src/core/orchestrators/__init__.py
index d4254ec..88e62e1 100644
--- a/workspace/src/core/orchestrators/__init__.py
+++ b/workspace/src/core/orchestrators/__init__.py
@@ -14,7 +14,9 @@ from pathlib import Path
 
 
 # ===== å·¥å…·å‡½æ•¸ï¼šå‹•æ…‹å°å…¥ kebab-case æ¨¡å¡Š =====
-def _import_kebab_module(module_alias: str, file_name: str, legacy_alias: str | None = None):
+def _import_kebab_module(
+    module_alias: str, file_name: str, legacy_alias: str | None = None
+):
     """
     å‹•æ…‹å°å…¥ kebab-case çš„ Python æ¨¡å¡Šä¸¦è¨»å†Šå‘½åç©ºé–“åˆ¥åã€‚
 
@@ -92,7 +94,9 @@ enterprise_mesh = _import_kebab_module(
     legacy_alias="enterprise_synergy_mesh_orchestrator",
 )
 if enterprise_mesh:
-    EnterpriseSynergyMeshOrchestrator = enterprise_mesh.EnterpriseSynergyMeshOrchestrator
+    EnterpriseSynergyMeshOrchestrator = (
+        enterprise_mesh.EnterpriseSynergyMeshOrchestrator
+    )
     TenantConfig = enterprise_mesh.TenantConfig
     TenantTier = enterprise_mesh.TenantTier
     ResourceQuota = enterprise_mesh.ResourceQuota
diff --git a/workspace/src/core/orchestrators/dependency-resolver.py b/workspace/src/core/orchestrators/dependency-resolver.py
index c85cb4d..3a3f265 100644
--- a/workspace/src/core/orchestrators/dependency-resolver.py
+++ b/workspace/src/core/orchestrators/dependency-resolver.py
@@ -64,7 +64,11 @@ class DependencyResolver:
         logger.info("ğŸ”„ DependencyResolver åˆå§‹åŒ–å®Œæˆ")
 
     def add_component(
-        self, component_id: str, component_type: str, priority: int = 0, weight: float = 1.0
+        self,
+        component_id: str,
+        component_type: str,
+        priority: int = 0,
+        weight: float = 1.0,
     ) -> bool:
         """æ·»åŠ çµ„ä»¶"""
         try:
@@ -150,7 +154,9 @@ class DependencyResolver:
 
         while queue:
             # æŒ‰å„ªå…ˆç´šæ’åº
-            queue_list = sorted(queue, key=lambda x: (self.nodes[x].priority, x), reverse=True)
+            queue_list = sorted(
+                queue, key=lambda x: (self.nodes[x].priority, x), reverse=True
+            )
             current = queue_list.pop(0)
             queue = deque(queue_list)
             result.append(current)
@@ -194,7 +200,9 @@ class DependencyResolver:
                 break
 
             # è¨ˆç®—åŸ·è¡Œæ™‚é–“
-            estimated_time = sum(self.nodes[comp].weight * 100 for comp in current_phase)
+            estimated_time = sum(
+                self.nodes[comp].weight * 100 for comp in current_phase
+            )
 
             phase = ExecutionPhase(
                 phase_number=phase_number,
@@ -298,7 +306,9 @@ class DependencyResolver:
         if not dependencies:
             return 1
 
-        max_dep_depth = max(self._calculate_depth(dep, visited.copy()) for dep in dependencies)
+        max_dep_depth = max(
+            self._calculate_depth(dep, visited.copy()) for dep in dependencies
+        )
 
         return 1 + max_dep_depth
 
diff --git a/workspace/src/core/orchestrators/enterprise-synergy-mesh-orchestrator.py b/workspace/src/core/orchestrators/enterprise-synergy-mesh-orchestrator.py
index fe425a8..10c8097 100644
--- a/workspace/src/core/orchestrators/enterprise-synergy-mesh-orchestrator.py
+++ b/workspace/src/core/orchestrators/enterprise-synergy-mesh-orchestrator.py
@@ -80,7 +80,9 @@ class RetryPolicy:
 
     def get_delay(self, attempt: int) -> float:
         """è¨ˆç®—é‡è©¦å»¶é²ï¼ˆæŒ‡æ•¸é€€é¿ï¼‰"""
-        delay = min(self.initial_delay * (self.exponential_base**attempt), self.max_delay)
+        delay = min(
+            self.initial_delay * (self.exponential_base**attempt), self.max_delay
+        )
         return delay
 
 
@@ -410,7 +412,10 @@ class EnterpriseSynergyMeshOrchestrator:
             return False
 
     def _has_circular_dependency(
-        self, component_id: str, new_dependencies: List[str], visited: Optional[Set[str]] = None
+        self,
+        component_id: str,
+        new_dependencies: List[str],
+        visited: Optional[Set[str]] = None,
     ) -> bool:
         """æª¢æ¸¬å¾ªç’°ä¾è³´"""
         if visited is None:
@@ -465,10 +470,17 @@ class EnterpriseSynergyMeshOrchestrator:
     # ========================================================================
 
     async def execute_with_retry(
-        self, func, component_id: str, tenant_id: str, max_retries: Optional[int] = None, **kwargs
+        self,
+        func,
+        component_id: str,
+        tenant_id: str,
+        max_retries: Optional[int] = None,
+        **kwargs,
     ) -> ExecutionResult:
         """å¸¶é‡è©¦çš„åŸ·è¡Œ"""
-        policy = self.retry_policies.get(component_id, RetryPolicy(max_retries=max_retries or 3))
+        policy = self.retry_policies.get(
+            component_id, RetryPolicy(max_retries=max_retries or 3)
+        )
 
         start_time = datetime.now()
         last_error = None
@@ -477,7 +489,9 @@ class EnterpriseSynergyMeshOrchestrator:
             try:
                 if attempt > 0:
                     delay = policy.get_delay(attempt - 1)
-                    logger.info(f"â³ é‡è©¦ {component_id} (ç¬¬ {attempt} æ¬¡ï¼Œå»¶é² {delay}s)")
+                    logger.info(
+                        f"â³ é‡è©¦ {component_id} (ç¬¬ {attempt} æ¬¡ï¼Œå»¶é² {delay}s)"
+                    )
                     await asyncio.sleep(delay)
                     self.metrics["total_retry_attempts"] += 1
 
@@ -546,7 +560,9 @@ class EnterpriseSynergyMeshOrchestrator:
             self.rate_limiters[tenant_id] = (1, now)
             return True
 
-    def check_resource_quota(self, tenant_id: str, resource_type: str = "tasks") -> bool:
+    def check_resource_quota(
+        self, tenant_id: str, resource_type: str = "tasks"
+    ) -> bool:
         """æª¢æŸ¥è³‡æºé…é¡"""
         if tenant_id not in self.tenants:
             return True
@@ -555,7 +571,9 @@ class EnterpriseSynergyMeshOrchestrator:
         quota = tenant.quota
 
         if resource_type == "concurrent":
-            active_count = len([t for t in self.active_tasks if t.startswith(tenant_id)])
+            active_count = len(
+                [t for t in self.active_tasks if t.startswith(tenant_id)]
+            )
             return active_count < quota.max_concurrent_tasks
 
         return True
@@ -592,7 +610,9 @@ class EnterpriseSynergyMeshOrchestrator:
         cutoff = datetime.now() - timedelta(hours=hours)
 
         return [
-            log for log in self.audit_logs if log.tenant_id == tenant_id and log.timestamp >= cutoff
+            log
+            for log in self.audit_logs
+            if log.tenant_id == tenant_id and log.timestamp >= cutoff
         ]
 
     # ========================================================================
@@ -663,12 +683,16 @@ class EnterpriseSynergyMeshOrchestrator:
 
     def get_tenant_health(self, tenant_id: str) -> Dict[str, Any]:
         """ç²å–ç§Ÿæˆ¶å¥åº·ç‹€æ…‹"""
-        tenant_logs = [log for log in self.execution_results if log.tenant_id == tenant_id]
+        tenant_logs = [
+            log for log in self.execution_results if log.tenant_id == tenant_id
+        ]
 
         if not tenant_logs:
             return {"status": "no_data"}
 
-        successful = len([l for l in tenant_logs if l.status == ExecutionStatus.SUCCESS])
+        successful = len(
+            [l for l in tenant_logs if l.status == ExecutionStatus.SUCCESS]
+        )
         total = len(tenant_logs)
 
         return {
@@ -676,7 +700,9 @@ class EnterpriseSynergyMeshOrchestrator:
             "total_executions": total,
             "successful": successful,
             "uptime_percent": (successful / max(total, 1)) * 100,
-            "last_execution": tenant_logs[-1].end_time.isoformat() if tenant_logs else None,
+            "last_execution": (
+                tenant_logs[-1].end_time.isoformat() if tenant_logs else None
+            ),
         }
 
 
diff --git a/workspace/src/core/orchestrators/language-island-orchestrator.py b/workspace/src/core/orchestrators/language-island-orchestrator.py
index 2162de7..8d64239 100644
--- a/workspace/src/core/orchestrators/language-island-orchestrator.py
+++ b/workspace/src/core/orchestrators/language-island-orchestrator.py
@@ -73,7 +73,9 @@ class LanguageIslandOrchestrator:
     def load_config(self) -> bool:
         """è¼‰å…¥é…ç½®"""
         try:
-            config_module = importlib.import_module("bridges.language-islands.config.island-config")
+            config_module = importlib.import_module(
+                "bridges.language-islands.config.island-config"
+            )
             IslandConfig = config_module.IslandConfig
             island_config = IslandConfig.load()
             self.config = {
@@ -203,11 +205,15 @@ class LanguageIslandOrchestrator:
 
         for lang, (cmd, arg) in language_tools.items():
             try:
-                result = subprocess.run([cmd, arg], capture_output=True, text=True, timeout=5)
+                result = subprocess.run(
+                    [cmd, arg], capture_output=True, text=True, timeout=5
+                )
                 analysis["tools"][lang] = {
                     "installed": result.returncode == 0,
                     "version": (
-                        result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+                        result.stdout.strip().split("\n")[0]
+                        if result.returncode == 0
+                        else None
                     ),
                 }
             except (FileNotFoundError, subprocess.TimeoutExpired):
diff --git a/workspace/src/core/orchestrators/synergy-mesh-orchestrator.py b/workspace/src/core/orchestrators/synergy-mesh-orchestrator.py
index abb02c9..a3e10f4 100644
--- a/workspace/src/core/orchestrators/synergy-mesh-orchestrator.py
+++ b/workspace/src/core/orchestrators/synergy-mesh-orchestrator.py
@@ -141,7 +141,9 @@ class SynergyMeshOrchestrator:
 
         logger.info("ğŸ”§ SynergyMeshOrchestrator åˆå§‹åŒ–å®Œæˆ")
 
-    def register_agent(self, agent_id: str, agent: Any, auto_start: bool = False) -> bool:
+    def register_agent(
+        self, agent_id: str, agent: Any, auto_start: bool = False
+    ) -> bool:
         """
         è¨»å†Š Agent
 
@@ -171,7 +173,9 @@ class SynergyMeshOrchestrator:
             logger.error(f"âŒ è¨»å†Š Agent å¤±æ•— {agent_id}: {e}")
             return False
 
-    def register_island(self, island_id: str, island: Any, auto_activate: bool = False) -> bool:
+    def register_island(
+        self, island_id: str, island: Any, auto_activate: bool = False
+    ) -> bool:
         """
         è¨»å†Š Island
 
@@ -418,10 +422,16 @@ class SynergyMeshOrchestrator:
     def _generate_report(self) -> Dict[str, Any]:
         """ç”ŸæˆåŸ·è¡Œå ±å‘Š"""
         end_time = datetime.now()
-        duration = (end_time - self.start_time).total_seconds() if self.start_time else 0
+        duration = (
+            (end_time - self.start_time).total_seconds() if self.start_time else 0
+        )
 
-        successful = sum(1 for r in self.execution_results if r.status == ExecutionStatus.SUCCESS)
-        failed = sum(1 for r in self.execution_results if r.status == ExecutionStatus.FAILED)
+        successful = sum(
+            1 for r in self.execution_results if r.status == ExecutionStatus.SUCCESS
+        )
+        failed = sum(
+            1 for r in self.execution_results if r.status == ExecutionStatus.FAILED
+        )
 
         report = {
             "timestamp": end_time.isoformat(),
@@ -454,13 +464,19 @@ class SynergyMeshOrchestrator:
         Returns:
             ç³»çµ±ç‹€æ…‹
         """
-        successful = sum(1 for r in self.execution_results if r.status == ExecutionStatus.SUCCESS)
-        failed = sum(1 for r in self.execution_results if r.status == ExecutionStatus.FAILED)
+        successful = sum(
+            1 for r in self.execution_results if r.status == ExecutionStatus.SUCCESS
+        )
+        failed = sum(
+            1 for r in self.execution_results if r.status == ExecutionStatus.FAILED
+        )
 
         return SystemStatus(
             timestamp=datetime.now(),
             total_components=len(self.agents) + len(self.islands),
-            active_components=len([a for a in self.agents.values() if a["status"] != "stopped"])
+            active_components=len(
+                [a for a in self.agents.values() if a["status"] != "stopped"]
+            )
             + len([i for i in self.islands.values() if i["status"] != "dormant"]),
             successful_executions=successful,
             failed_executions=failed,
diff --git a/workspace/src/core/phase4/__init__.py b/workspace/src/core/phase4/__init__.py
index 36fd4a2..4ff03c6 100644
--- a/workspace/src/core/phase4/__init__.py
+++ b/workspace/src/core/phase4/__init__.py
@@ -138,7 +138,10 @@ class Phase4System:
             return {"success": False, "error": str(e)}
 
     async def generate_multi_language_project(
-        self, user_input: str, target_languages: List[str] = None, frameworks: List[str] = None
+        self,
+        user_input: str,
+        target_languages: List[str] = None,
+        frameworks: List[str] = None,
     ) -> Dict[str, Any]:
         """ç”Ÿæˆå¤šèªè¨€é …ç›®"""
         if not self.is_initialized:
@@ -151,8 +154,12 @@ class Phase4System:
             analysis = await self.language_manager.analyze_requirements(user_input)
 
             # ç¢ºå®šç›®æ¨™èªè¨€å’Œæ¡†æ¶
-            languages = target_languages or self.language_manager.suggest_languages(analysis)
-            selected_frameworks = frameworks or self.language_manager.suggest_frameworks(analysis)
+            languages = target_languages or self.language_manager.suggest_languages(
+                analysis
+            )
+            selected_frameworks = (
+                frameworks or self.language_manager.suggest_frameworks(analysis)
+            )
 
             # ç”Ÿæˆå¤šèªè¨€ä»£ç¢¼
             project_results = {}
@@ -163,10 +170,14 @@ class Phase4System:
                 project_results[language] = code_result
 
             # çµ±ä¸€APIæ¥å£
-            unified_api = await self.language_manager.create_unified_api(project_results)
+            unified_api = await self.language_manager.create_unified_api(
+                project_results
+            )
 
             # èªè¨€æª¢æ¸¬å’Œæœ€ä½³åŒ–
-            optimized_results = await self.language_manager.optimize_cross_language(project_results)
+            optimized_results = await self.language_manager.optimize_cross_language(
+                project_results
+            )
 
             return {
                 "success": True,
@@ -177,7 +188,9 @@ class Phase4System:
                 "results": project_results,
                 "unified_api": unified_api,
                 "optimization": optimized_results,
-                "generated_files": sum(r.get("file_count", 0) for r in project_results.values()),
+                "generated_files": sum(
+                    r.get("file_count", 0) for r in project_results.values()
+                ),
             }
 
         except Exception as e:
@@ -195,10 +208,14 @@ class Phase4System:
             self.logger.info(f"Generating mobile application: {user_input}")
 
             # åˆ†æç§»å‹•æ‡‰ç”¨éœ€æ±‚
-            mobile_analysis = await self.mobile_generator.analyze_mobile_requirements(user_input)
+            mobile_analysis = await self.mobile_generator.analyze_mobile_requirements(
+                user_input
+            )
 
             # ç¢ºå®šç›®æ¨™å¹³å°
-            target_platforms = platforms or self.mobile_generator.suggest_platforms(mobile_analysis)
+            target_platforms = platforms or self.mobile_generator.suggest_platforms(
+                mobile_analysis
+            )
 
             # ç”Ÿæˆç§»å‹•æ‡‰ç”¨ä»£ç¢¼
             app_results = {}
@@ -212,7 +229,9 @@ class Phase4System:
             pwa_support = await self.mobile_generator.generate_pwa_support(user_input)
 
             # è¨­å‚™é©é…
-            device_adaptation = await self.mobile_generator.create_device_adaptation(app_results)
+            device_adaptation = await self.mobile_generator.create_device_adaptation(
+                app_results
+            )
 
             return {
                 "success": True,
@@ -223,7 +242,9 @@ class Phase4System:
                 "results": app_results,
                 "pwa_support": pwa_support,
                 "device_adaptation": device_adaptation,
-                "generated_screens": sum(r.get("screen_count", 0) for r in app_results.values()),
+                "generated_screens": sum(
+                    r.get("screen_count", 0) for r in app_results.values()
+                ),
             }
 
         except Exception as e:
@@ -241,7 +262,9 @@ class Phase4System:
             self.logger.info(f"Creating visual configuration: {user_input}")
 
             # åˆ†æé…ç½®éœ€æ±‚
-            config_analysis = await self.visual_editor.analyze_config_requirements(user_input)
+            config_analysis = await self.visual_editor.analyze_config_requirements(
+                user_input
+            )
 
             # ç”Ÿæˆå¯è¦–åŒ–é…ç½®å™¨
             visual_config = await self.visual_editor.create_visual_configurator(
@@ -252,7 +275,9 @@ class Phase4System:
             live_preview = await self.visual_editor.enable_live_preview(visual_config)
 
             # æ¨¡æ¿åº«
-            template_library = await self.visual_editor.create_template_library(project_type)
+            template_library = await self.visual_editor.create_template_library(
+                project_type
+            )
 
             # å°å…¥å°å‡ºåŠŸèƒ½
             import_export = await self.visual_editor.setup_import_export()
@@ -283,18 +308,24 @@ class Phase4System:
             self.logger.info(f"Setting up enterprise version: {user_input}")
 
             # ä¼æ¥­éœ€æ±‚åˆ†æ
-            enterprise_analysis = await self.enterprise_manager.analyze_enterprise_needs(
-                user_input, company_size
+            enterprise_analysis = (
+                await self.enterprise_manager.analyze_enterprise_needs(
+                    user_input, company_size
+                )
             )
 
             # é«˜ç´šç®¡ç†ç•Œé¢
             admin_interface = await self.enterprise_manager.create_admin_interface()
 
             # SaaSåŒ–æ¶æ§‹
-            saas_architecture = await self.saas_platform.setup_multi_tenant_architecture()
+            saas_architecture = (
+                await self.saas_platform.setup_multi_tenant_architecture()
+            )
 
             # è¨ˆè²»ç³»çµ±
-            billing_system = await self.billing_manager.setup_billing_system(company_size)
+            billing_system = await self.billing_manager.setup_billing_system(
+                company_size
+            )
 
             # ç›£æ§Dashboard
             monitoring_dashboard = await self.dashboard.create_enterprise_dashboard()
@@ -323,13 +354,17 @@ class Phase4System:
             "components": {
                 "language_manager": {
                     "status": "active" if self.language_manager else "inactive",
-                    "supported_languages": len(self.config.get("supported_languages", [])),
+                    "supported_languages": len(
+                        self.config.get("supported_languages", [])
+                    ),
                 },
                 "mobile_generator": {
                     "status": "active" if self.mobile_generator else "inactive",
                     "platforms": len(self.config.get("mobile_platforms", [])),
                 },
-                "visual_editor": {"status": "active" if self.visual_editor else "inactive"},
+                "visual_editor": {
+                    "status": "active" if self.visual_editor else "inactive"
+                },
                 "enterprise_manager": {
                     "status": "active" if self.enterprise_manager else "inactive",
                     "features_enabled": self.config.get("enterprise_features", False),
@@ -383,7 +418,10 @@ class Phase4System:
                 else:
                     health_status["components"][name] = {"status": "healthy"}
             except Exception as e:
-                health_status["components"][name] = {"status": "unhealthy", "error": str(e)}
+                health_status["components"][name] = {
+                    "status": "unhealthy",
+                    "error": str(e),
+                }
                 all_healthy = False
 
         health_status["overall_status"] = "healthy" if all_healthy else "degraded"
@@ -428,7 +466,9 @@ class Phase4System:
             self.logger.error(f"Visual configuration creation failed: {e}")
             return {"success": False, "error": str(e)}
 
-    async def setup_enterprise_features(self, company_size: str = "medium") -> Dict[str, Any]:
+    async def setup_enterprise_features(
+        self, company_size: str = "medium"
+    ) -> Dict[str, Any]:
         """è¨­ç½®ä¼æ¥­ç‰ˆåŠŸèƒ½"""
         try:
             self.logger.info(f"Setting up enterprise features: {company_size}")
@@ -465,7 +505,9 @@ async def generate_multi_language_project(
 ) -> Dict[str, Any]:
     """ä¾¿æ·å‡½æ•¸ï¼šç”Ÿæˆå¤šèªè¨€é …ç›®"""
     system = get_phase4_system()
-    return await system.generate_multi_language_project(user_input, target_languages, frameworks)
+    return await system.generate_multi_language_project(
+        user_input, target_languages, frameworks
+    )
 
 
 async def generate_mobile_application(
@@ -476,13 +518,17 @@ async def generate_mobile_application(
     return await system.generate_mobile_application(user_input, platforms, framework)
 
 
-async def create_visual_configuration(user_input: str, project_type: str = "web") -> Dict[str, Any]:
+async def create_visual_configuration(
+    user_input: str, project_type: str = "web"
+) -> Dict[str, Any]:
     """ä¾¿æ·å‡½æ•¸ï¼šå‰µå»ºå¯è¦–åŒ–é…ç½®"""
     system = get_phase4_system()
     return await system.create_visual_configuration(user_input, project_type)
 
 
-async def setup_enterprise_version(user_input: str, company_size: str = "medium") -> Dict[str, Any]:
+async def setup_enterprise_version(
+    user_input: str, company_size: str = "medium"
+) -> Dict[str, Any]:
     """ä¾¿æ·å‡½æ•¸ï¼šè¨­ç½®ä¼æ¥­ç‰ˆ"""
     system = get_phase4_system()
     return await system.setup_enterprise_version(user_input, company_size)
diff --git a/workspace/src/core/phase4/billing_system/__init__.py b/workspace/src/core/phase4/billing_system/__init__.py
index 7d112be..0f52be8 100644
--- a/workspace/src/core/phase4/billing_system/__init__.py
+++ b/workspace/src/core/phase4/billing_system/__init__.py
@@ -38,7 +38,9 @@ class BillingManager:
         """åˆå§‹åŒ–è¨ˆè²»ç®¡ç†å™¨"""
         self.logger.info("Billing Manager initialized")
 
-    async def setup_billing_system(self, company_size: str = "medium") -> Dict[str, Any]:
+    async def setup_billing_system(
+        self, company_size: str = "medium"
+    ) -> Dict[str, Any]:
         """è¨­ç½®è¨ˆè²»ç³»çµ±"""
         plans = [
             {
diff --git a/workspace/src/core/phase4/enterprise_features/__init__.py b/workspace/src/core/phase4/enterprise_features/__init__.py
index d8e1b86..9b3e84b 100644
--- a/workspace/src/core/phase4/enterprise_features/__init__.py
+++ b/workspace/src/core/phase4/enterprise_features/__init__.py
@@ -185,7 +185,9 @@ class EnterpriseManager:
             user_management_ui = await self.admin_interface.create_user_management_ui()
 
             # å‰µå»ºå…¬å¸ç®¡ç†ç•Œé¢
-            company_management_ui = await self.admin_interface.create_company_management_ui()
+            company_management_ui = (
+                await self.admin_interface.create_company_management_ui()
+            )
 
             # å‰µå»ºç³»çµ±è¨­ç½®ç•Œé¢
             system_settings_ui = await self.admin_interface.create_system_settings_ui()
@@ -234,7 +236,11 @@ class EnterpriseManager:
                 "storage_gb": 200,
                 "api_calls_per_month": 250000,
                 "support_level": "business_hours_priority",
-                "features": ["advanced_analytics", "priority_support", "custom_integration"],
+                "features": [
+                    "advanced_analytics",
+                    "priority_support",
+                    "custom_integration",
+                ],
             },
             CompanySize.LARGE: {
                 "max_users": 1000,
@@ -242,7 +248,11 @@ class EnterpriseManager:
                 "storage_gb": 1000,
                 "api_calls_per_month": 1000000,
                 "support_level": "24_7",
-                "features": ["enterprise_analytics", "24_7_support", "dedicated_account_manager"],
+                "features": [
+                    "enterprise_analytics",
+                    "24_7_support",
+                    "dedicated_account_manager",
+                ],
             },
             CompanySize.ENTERPRISE: {
                 "max_users": -1,  # unlimited
@@ -261,7 +271,9 @@ class EnterpriseManager:
 
         return {
             "size": company_size,
-            "configuration": size_configs.get(size_enum, size_configs[CompanySize.MEDIUM]),
+            "configuration": size_configs.get(
+                size_enum, size_configs[CompanySize.MEDIUM]
+            ),
         }
 
     def _analyze_enterprise_features(self, user_input: str) -> Dict[str, bool]:
@@ -270,35 +282,43 @@ class EnterpriseManager:
 
         features = {
             "multi_tenant": any(
-                word in user_input_lower for word in ["multi-tenant", "multiple companies", "saaS"]
+                word in user_input_lower
+                for word in ["multi-tenant", "multiple companies", "saaS"]
             ),
             "single_sign_on": any(
                 word in user_input_lower
                 for word in ["sso", "single sign on", "ldap", "active directory"]
             ),
             "audit_logs": any(
-                word in user_input_lower for word in ["audit", "logs", "compliance", "tracking"]
+                word in user_input_lower
+                for word in ["audit", "logs", "compliance", "tracking"]
             ),
             "role_management": any(
-                word in user_input_lower for word in ["roles", "permissions", "access control"]
+                word in user_input_lower
+                for word in ["roles", "permissions", "access control"]
             ),
             "api_management": any(
-                word in user_input_lower for word in ["api", "rate limiting", "api keys"]
+                word in user_input_lower
+                for word in ["api", "rate limiting", "api keys"]
             ),
             "data_export": any(
                 word in user_input_lower for word in ["export", "data export", "backup"]
             ),
             "custom_branding": any(
-                word in user_input_lower for word in ["branding", "white label", "custom"]
+                word in user_input_lower
+                for word in ["branding", "white label", "custom"]
             ),
             "advanced_analytics": any(
-                word in user_input_lower for word in ["analytics", "reporting", "metrics"]
+                word in user_input_lower
+                for word in ["analytics", "reporting", "metrics"]
             ),
             "workflow_automation": any(
-                word in user_input_lower for word in ["workflow", "automation", "process"]
+                word in user_input_lower
+                for word in ["workflow", "automation", "process"]
             ),
             "integration_platform": any(
-                word in user_input_lower for word in ["integration", "connectors", "apis"]
+                word in user_input_lower
+                for word in ["integration", "connectors", "apis"]
             ),
         }
 
@@ -310,7 +330,8 @@ class EnterpriseManager:
 
         security_needs = {
             "encryption": any(
-                word in user_input_lower for word in ["encryption", "encrypted", "security"]
+                word in user_input_lower
+                for word in ["encryption", "encrypted", "security"]
             ),
             "two_factor_auth": any(
                 word in user_input_lower for word in ["2fa", "two factor", "mfa"]
@@ -328,10 +349,12 @@ class EnterpriseManager:
                 word in user_input_lower for word in ["vulnerability", "security scan"]
             ),
             "compliance_reporting": any(
-                word in user_input_lower for word in ["compliance", "regulation", "audit"]
+                word in user_input_lower
+                for word in ["compliance", "regulation", "audit"]
             ),
             "data_retention": any(
-                word in user_input_lower for word in ["retention", "data retention", "privacy"]
+                word in user_input_lower
+                for word in ["retention", "data retention", "privacy"]
             ),
         }
 
@@ -403,7 +426,9 @@ class SaaSPlatformManager:
             tenant_isolation = await self.multi_tenant_manager.create_tenant_isolation()
 
             # è¨­ç½®æ•¸æ“šåº«åˆ†é›¢
-            database_separation = await self.multi_tenant_manager.setup_database_separation()
+            database_separation = (
+                await self.multi_tenant_manager.setup_database_separation()
+            )
 
             # é…ç½®è³‡æºé…é¡
             resource_quotas = await self.resource_manager.setup_resource_quotas()
@@ -412,7 +437,9 @@ class SaaSPlatformManager:
             tenant_routing = await self.multi_tenant_manager.create_tenant_routing()
 
             # è¨­ç½®å®‰å…¨éš”é›¢
-            security_isolation = await self.multi_tenant_manager.setup_security_isolation()
+            security_isolation = (
+                await self.multi_tenant_manager.setup_security_isolation()
+            )
 
             return {
                 "success": True,
@@ -467,7 +494,9 @@ class BillingManager:
             self.logger.error(f"Failed to initialize Billing Manager: {e}")
             raise
 
-    async def setup_billing_system(self, company_size: str = "medium") -> Dict[str, Any]:
+    async def setup_billing_system(
+        self, company_size: str = "medium"
+    ) -> Dict[str, Any]:
         """è¨­ç½®è¨ˆè²»ç³»çµ±"""
         try:
             self.logger.info(f"Setting up billing system for {company_size}")
@@ -512,7 +541,12 @@ class BillingManager:
                 "currency": "USD",
                 "billing_cycle": "monthly",
                 "features": ["5 users", "10 projects", "10GB storage", "10K API calls"],
-                "limits": {"users": 5, "projects": 10, "storage_gb": 10, "api_calls": 10000},
+                "limits": {
+                    "users": 5,
+                    "projects": 10,
+                    "storage_gb": 10,
+                    "api_calls": 10000,
+                },
             },
             {
                 "plan_id": "professional",
@@ -527,7 +561,12 @@ class BillingManager:
                     "50K API calls",
                     "priority support",
                 ],
-                "limits": {"users": 20, "projects": 50, "storage_gb": 50, "api_calls": 50000},
+                "limits": {
+                    "users": 20,
+                    "projects": 50,
+                    "storage_gb": 50,
+                    "api_calls": 50000,
+                },
             },
             {
                 "plan_id": "business",
@@ -542,7 +581,12 @@ class BillingManager:
                     "250K API calls",
                     "24/7 support",
                 ],
-                "limits": {"users": 100, "projects": 200, "storage_gb": 200, "api_calls": 250000},
+                "limits": {
+                    "users": 100,
+                    "projects": 200,
+                    "storage_gb": 200,
+                    "api_calls": 250000,
+                },
             },
             {
                 "plan_id": "enterprise",
@@ -557,7 +601,12 @@ class BillingManager:
                     "1M API calls",
                     "premium support",
                 ],
-                "limits": {"users": -1, "projects": -1, "storage_gb": 1000, "api_calls": 1000000},
+                "limits": {
+                    "users": -1,
+                    "projects": -1,
+                    "storage_gb": 1000,
+                    "api_calls": 1000000,
+                },
             },
         ]
 
diff --git a/workspace/src/core/phase4/mobile_support/__init__.py b/workspace/src/core/phase4/mobile_support/__init__.py
index cb16d80..5451895 100644
--- a/workspace/src/core/phase4/mobile_support/__init__.py
+++ b/workspace/src/core/phase4/mobile_support/__init__.py
@@ -254,7 +254,9 @@ class MobileAppGenerator:
             # æ ¹æ“šåŠŸèƒ½éœ€æ±‚èª¿æ•´
             if feature_requirements.get("native_performance", False):
                 candidates = [MobilePlatform.IOS, MobilePlatform.ANDROID] + [
-                    p for p in candidates if p not in [MobilePlatform.IOS, MobilePlatform.ANDROID]
+                    p
+                    for p in candidates
+                    if p not in [MobilePlatform.IOS, MobilePlatform.ANDROID]
                 ]
 
             if feature_requirements.get("cross_platform", True):
@@ -293,7 +295,9 @@ class MobileAppGenerator:
             selected_framework = framework or platform_info["frameworks"][0]
 
             # å‰µå»ºæ‡‰ç”¨è¦æ ¼
-            app_spec = await self._create_app_spec(user_input, platform, selected_framework)
+            app_spec = await self._create_app_spec(
+                user_input, platform, selected_framework
+            )
 
             # ç”Ÿæˆæ‡‰ç”¨ä»£ç¢¼
             generation_result = await self._generate_app_code(
@@ -301,7 +305,9 @@ class MobileAppGenerator:
             )
 
             # ç”ŸæˆUIçµ„ä»¶
-            ui_components = await self.ui_component_library.generate_components(app_spec, platform)
+            ui_components = await self.ui_component_library.generate_components(
+                app_spec, platform
+            )
 
             # ç”Ÿæˆé…ç½®æ–‡ä»¶
             configuration = await self._generate_configuration(app_spec, platform)
@@ -360,7 +366,9 @@ class MobileAppGenerator:
             self.logger.error(f"PWA support generation failed: {e}")
             return {"success": False, "error": str(e)}
 
-    async def create_device_adaptation(self, app_results: Dict[str, Any]) -> Dict[str, Any]:
+    async def create_device_adaptation(
+        self, app_results: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """å‰µå»ºè¨­å‚™é©é…"""
         try:
             self.logger.info("Creating device adaptation...")
@@ -375,7 +383,9 @@ class MobileAppGenerator:
             device_styles = await self.device_adapter.generate_device_styles()
 
             # ç”Ÿæˆäº¤äº’é©é…
-            interaction_adaptation = await self.device_adapter.generate_interaction_adaptation()
+            interaction_adaptation = (
+                await self.device_adapter.generate_interaction_adaptation()
+            )
 
             return {
                 "success": True,
@@ -451,9 +461,12 @@ class MobileAppGenerator:
         user_input_lower = user_input.lower()
 
         features = {
-            "camera": any(word in user_input_lower for word in ["camera", "photo", "video"]),
+            "camera": any(
+                word in user_input_lower for word in ["camera", "photo", "video"]
+            ),
             "gps": any(
-                word in user_input_lower for word in ["gps", "location", "map", "navigation"]
+                word in user_input_lower
+                for word in ["gps", "location", "map", "navigation"]
             ),
             "push_notifications": any(
                 word in user_input_lower for word in ["push", "notification", "alert"]
@@ -465,16 +478,29 @@ class MobileAppGenerator:
                 word in user_input_lower for word in ["login", "auth", "security"]
             ),
             "payment": any(
-                word in user_input_lower for word in ["payment", "purchase", "buy", "shop"]
+                word in user_input_lower
+                for word in ["payment", "purchase", "buy", "shop"]
+            ),
+            "social": any(
+                word in user_input_lower for word in ["social", "share", "connect"]
             ),
-            "social": any(word in user_input_lower for word in ["social", "share", "connect"]),
             "media": any(
-                word in user_input_lower for word in ["media", "video", "audio", "streaming"]
+                word in user_input_lower
+                for word in ["media", "video", "audio", "streaming"]
+            ),
+            "cloud": any(
+                word in user_input_lower for word in ["cloud", "sync", "backup"]
+            ),
+            "ar_vr": any(
+                word in user_input_lower
+                for word in ["ar", "vr", "augmented", "virtual"]
+            ),
+            "wearable": any(
+                word in user_input_lower for word in ["watch", "wearable", "fitness"]
+            ),
+            "iot": any(
+                word in user_input_lower for word in ["iot", "smart", "connected"]
             ),
-            "cloud": any(word in user_input_lower for word in ["cloud", "sync", "backup"]),
-            "ar_vr": any(word in user_input_lower for word in ["ar", "vr", "augmented", "virtual"]),
-            "wearable": any(word in user_input_lower for word in ["watch", "wearable", "fitness"]),
-            "iot": any(word in user_input_lower for word in ["iot", "smart", "connected"]),
         }
 
         return features
@@ -485,10 +511,18 @@ class MobileAppGenerator:
 
         # è¨­å‚™é¡å‹
         device_types = {
-            DeviceType.PHONE: any(word in user_input_lower for word in ["phone", "mobile"]),
-            DeviceType.TABLET: any(word in user_input_lower for word in ["tablet", "ipad"]),
-            DeviceType.WEARABLE: any(word in user_input_lower for word in ["watch", "wearable"]),
-            DeviceType.TV: any(word in user_input_lower for word in ["tv", "television"]),
+            DeviceType.PHONE: any(
+                word in user_input_lower for word in ["phone", "mobile"]
+            ),
+            DeviceType.TABLET: any(
+                word in user_input_lower for word in ["tablet", "ipad"]
+            ),
+            DeviceType.WEARABLE: any(
+                word in user_input_lower for word in ["watch", "wearable"]
+            ),
+            DeviceType.TV: any(
+                word in user_input_lower for word in ["tv", "television"]
+            ),
         }
 
         # å±å¹•æ–¹å‘
@@ -504,12 +538,17 @@ class MobileAppGenerator:
         }
 
         return {
-            "device_types": [device for device, required in device_types.items() if required],
+            "device_types": [
+                device for device, required in device_types.items() if required
+            ],
             "orientations": [
-                orientation for orientation, required in orientations.items() if required
+                orientation
+                for orientation, required in orientations.items()
+                if required
             ],
             "responsive_design": any(
-                word in user_input_lower for word in ["responsive", "adaptive", "flexible"]
+                word in user_input_lower
+                for word in ["responsive", "adaptive", "flexible"]
             ),
         }
 
@@ -846,14 +885,20 @@ app.start();
 
         return permissions
 
-    def _generate_build_commands(self, platform: MobilePlatform, framework: str) -> List[str]:
+    def _generate_build_commands(
+        self, platform: MobilePlatform, framework: str
+    ) -> List[str]:
         """ç”Ÿæˆæ§‹å»ºå‘½ä»¤"""
         commands = []
 
         if platform == MobilePlatform.FLUTTER:
             commands = ["flutter pub get", "flutter build apk", "flutter build ios"]
         elif platform == MobilePlatform.REACT_NATIVE:
-            commands = ["npm install", "npx react-native run-android", "npx react-native run-ios"]
+            commands = [
+                "npm install",
+                "npx react-native run-android",
+                "npx react-native run-ios",
+            ]
         elif platform == MobilePlatform.IOS:
             commands = [
                 "xcodebuild -workspace MyApp.xcworkspace -scheme MyApp -configuration Debug build"
@@ -948,7 +993,10 @@ class UIComponentLibrary:
                 component_type="interactive",
                 props={"text": "Get Started"},
                 styles={"padding": "16px", "borderRadius": "8px"},
-                responsive_config={"phone": {"fontSize": 16}, "tablet": {"fontSize": 18}},
+                responsive_config={
+                    "phone": {"fontSize": 16},
+                    "tablet": {"fontSize": 18},
+                },
             )
         )
 
diff --git a/workspace/src/core/phase4/multi_language/__init__.py b/workspace/src/core/phase4/multi_language/__init__.py
index 64780e2..e43a759 100644
--- a/workspace/src/core/phase4/multi_language/__init__.py
+++ b/workspace/src/core/phase4/multi_language/__init__.py
@@ -148,7 +148,14 @@ class MultiLanguageManager:
                 True,
             ),
             "Svelte": LanguageInfo(
-                "Svelte", LanguageCategory.FRONTEND, ".svelte", ["SvelteKit"], 70, 3, True, True
+                "Svelte",
+                LanguageCategory.FRONTEND,
+                ".svelte",
+                ["SvelteKit"],
+                70,
+                3,
+                True,
+                True,
             ),
             # Backend Languages
             "Python": LanguageInfo(
@@ -182,7 +189,14 @@ class MultiLanguageManager:
                 True,
             ),
             "Go": LanguageInfo(
-                "Go", LanguageCategory.BACKEND, ".go", ["Gin", "Echo", "Fiber"], 80, 3, True, True
+                "Go",
+                LanguageCategory.BACKEND,
+                ".go",
+                ["Gin", "Echo", "Fiber"],
+                80,
+                3,
+                True,
+                True,
             ),
             "Node.js": LanguageInfo(
                 "Node.js",
@@ -205,7 +219,14 @@ class MultiLanguageManager:
                 True,
             ),
             "Ruby": LanguageInfo(
-                "Ruby", LanguageCategory.BACKEND, ".rb", ["Rails", "Sinatra"], 70, 3, True, True
+                "Ruby",
+                LanguageCategory.BACKEND,
+                ".rb",
+                ["Rails", "Sinatra"],
+                70,
+                3,
+                True,
+                True,
             ),
             "Rust": LanguageInfo(
                 "Rust",
@@ -218,14 +239,35 @@ class MultiLanguageManager:
                 True,
             ),
             "Elixir": LanguageInfo(
-                "Elixir", LanguageCategory.BACKEND, ".ex", ["Phoenix", "Ecto"], 65, 4, True, True
+                "Elixir",
+                LanguageCategory.BACKEND,
+                ".ex",
+                ["Phoenix", "Ecto"],
+                65,
+                4,
+                True,
+                True,
             ),
             "Erlang": LanguageInfo(
-                "Erlang", LanguageCategory.BACKEND, ".erl", ["OTP", "Cowboy"], 60, 5, True, True
+                "Erlang",
+                LanguageCategory.BACKEND,
+                ".erl",
+                ["OTP", "Cowboy"],
+                60,
+                5,
+                True,
+                True,
             ),
             # Mobile Languages
             "Swift": LanguageInfo(
-                "Swift", LanguageCategory.MOBILE, ".swift", ["SwiftUI", "UIKit"], 80, 4, True, True
+                "Swift",
+                LanguageCategory.MOBILE,
+                ".swift",
+                ["SwiftUI", "UIKit"],
+                80,
+                4,
+                True,
+                True,
             ),
             "Kotlin": LanguageInfo(
                 "Kotlin",
@@ -269,10 +311,24 @@ class MultiLanguageManager:
                 True,
             ),
             "C": LanguageInfo(
-                "C", LanguageCategory.DESKTOP, ".c", ["GTK", "SDL", "OpenGL"], 80, 5, True, True
+                "C",
+                LanguageCategory.DESKTOP,
+                ".c",
+                ["GTK", "SDL", "OpenGL"],
+                80,
+                5,
+                True,
+                True,
             ),
             "JavaFX": LanguageInfo(
-                "JavaFX", LanguageCategory.DESKTOP, ".java", ["JavaFX", "Swing"], 70, 4, True, True
+                "JavaFX",
+                LanguageCategory.DESKTOP,
+                ".java",
+                ["JavaFX", "Swing"],
+                70,
+                4,
+                True,
+                True,
             ),
             "Electron": LanguageInfo(
                 "Electron",
@@ -307,7 +363,14 @@ class MultiLanguageManager:
             ),
             # DevOps Languages
             "Bash": LanguageInfo(
-                "Bash", LanguageCategory.DEVOPS, ".sh", ["Docker", "Kubernetes"], 85, 2, True, True
+                "Bash",
+                LanguageCategory.DEVOPS,
+                ".sh",
+                ["Docker", "Kubernetes"],
+                85,
+                2,
+                True,
+                True,
             ),
             "PowerShell": LanguageInfo(
                 "PowerShell",
@@ -341,26 +404,75 @@ class MultiLanguageManager:
             ),
             # Scripting Languages
             "Perl": LanguageInfo(
-                "Perl", LanguageCategory.SCRIPTING, ".pl", ["Moose", "Catalyst"], 60, 3, True, True
+                "Perl",
+                LanguageCategory.SCRIPTING,
+                ".pl",
+                ["Moose", "Catalyst"],
+                60,
+                3,
+                True,
+                True,
             ),
             "Lua": LanguageInfo(
-                "Lua", LanguageCategory.SCRIPTING, ".lua", ["LuaJIT", "Love2D"], 65, 2, True, True
+                "Lua",
+                LanguageCategory.SCRIPTING,
+                ".lua",
+                ["LuaJIT", "Love2D"],
+                65,
+                2,
+                True,
+                True,
             ),
             "R": LanguageInfo(
-                "R", LanguageCategory.SCRIPTING, ".r", ["Tidyverse", "Shiny"], 70, 3, True, True
+                "R",
+                LanguageCategory.SCRIPTING,
+                ".r",
+                ["Tidyverse", "Shiny"],
+                70,
+                3,
+                True,
+                True,
             ),
             # System Languages
             "Assembly": LanguageInfo(
-                "Assembly", LanguageCategory.SYSTEM, ".asm", ["NASM", "MASM"], 50, 5, True, False
+                "Assembly",
+                LanguageCategory.SYSTEM,
+                ".asm",
+                ["NASM", "MASM"],
+                50,
+                5,
+                True,
+                False,
             ),
             "Zig": LanguageInfo(
-                "Zig", LanguageCategory.SYSTEM, ".zig", ["Zig Standard Lib"], 60, 4, True, True
+                "Zig",
+                LanguageCategory.SYSTEM,
+                ".zig",
+                ["Zig Standard Lib"],
+                60,
+                4,
+                True,
+                True,
             ),
             "Nim": LanguageInfo(
-                "Nim", LanguageCategory.SYSTEM, ".nim", ["Nimble", "Jester"], 65, 3, True, True
+                "Nim",
+                LanguageCategory.SYSTEM,
+                ".nim",
+                ["Nimble", "Jester"],
+                65,
+                3,
+                True,
+                True,
             ),
             "V": LanguageInfo(
-                "V", LanguageCategory.SYSTEM, ".v", ["V Stdlib", "VWeb"], 60, 3, True, True
+                "V",
+                LanguageCategory.SYSTEM,
+                ".v",
+                ["V Stdlib", "VWeb"],
+                60,
+                3,
+                True,
+                True,
             ),
             "D": LanguageInfo(
                 "D", LanguageCategory.SYSTEM, ".d", ["DUB", "Vibe.d"], 65, 4, True, True
@@ -377,7 +489,14 @@ class MultiLanguageManager:
                 True,
             ),
             "F#": LanguageInfo(
-                "F#", LanguageCategory.FUNCTIONAL, ".fs", [".NET Core", "Suave"], 65, 4, True, True
+                "F#",
+                LanguageCategory.FUNCTIONAL,
+                ".fs",
+                [".NET Core", "Suave"],
+                65,
+                4,
+                True,
+                True,
             ),
             "Clojure": LanguageInfo(
                 "Clojure",
@@ -400,7 +519,14 @@ class MultiLanguageManager:
                 True,
             ),
             "OCaml": LanguageInfo(
-                "OCaml", LanguageCategory.FUNCTIONAL, ".ml", ["Dune", "Core"], 60, 4, True, True
+                "OCaml",
+                LanguageCategory.FUNCTIONAL,
+                ".ml",
+                ["Dune", "Core"],
+                60,
+                4,
+                True,
+                True,
             ),
             "Lisp": LanguageInfo(
                 "Lisp",
@@ -424,7 +550,14 @@ class MultiLanguageManager:
                 True,
             ),
             "Julia": LanguageInfo(
-                "Julia", LanguageCategory.SCIENTIFIC, ".jl", ["JuMP", "Plots.jl"], 70, 3, True, True
+                "Julia",
+                LanguageCategory.SCIENTIFIC,
+                ".jl",
+                ["JuMP", "Plots.jl"],
+                70,
+                3,
+                True,
+                True,
             ),
             "Fortran": LanguageInfo(
                 "Fortran",
@@ -437,7 +570,14 @@ class MultiLanguageManager:
                 True,
             ),
             "Ada": LanguageInfo(
-                "Ada", LanguageCategory.SCIENTIFIC, ".adb", ["GNAT", "AdaCore"], 55, 4, True, True
+                "Ada",
+                LanguageCategory.SCIENTIFIC,
+                ".adb",
+                ["GNAT", "AdaCore"],
+                55,
+                4,
+                True,
+                True,
             ),
             "COBOL": LanguageInfo(
                 "COBOL",
@@ -479,7 +619,13 @@ class MultiLanguageManager:
                 "framework": ["Qt", "GTK", "WinForms", "WPF"],
             },
             "api": {
-                "rest": ["Express", "FastAPI", "Spring Boot", "ASP.NET Core", "Django REST"],
+                "rest": [
+                    "Express",
+                    "FastAPI",
+                    "Spring Boot",
+                    "ASP.NET Core",
+                    "Django REST",
+                ],
                 "graphql": ["Apollo Server", "GraphQL Yoga", "Strawberry", "Graphene"],
                 "grpc": ["gRPC", "Connect", "Twirp"],
             },
@@ -505,7 +651,9 @@ class MultiLanguageManager:
             await self.language_analyzer.initialize(self.supported_languages)
 
             # åˆå§‹åŒ–ä»£ç¢¼ç”Ÿæˆå™¨
-            await self.code_generator.initialize(self.supported_languages, self.framework_mappings)
+            await self.code_generator.initialize(
+                self.supported_languages, self.framework_mappings
+            )
 
             # åˆå§‹åŒ–APIçµ±ä¸€å™¨
             await self.api_unifier.initialize()
@@ -592,7 +740,9 @@ class MultiLanguageManager:
                 if requirements.get("frontend", False):
                     frameworks.extend(["React", "Vue", "Angular"])
                 if requirements.get("backend", False):
-                    frameworks.extend(["Django", "Flask", "FastAPI", "Express", "Spring Boot"])
+                    frameworks.extend(
+                        ["Django", "Flask", "FastAPI", "Express", "Spring Boot"]
+                    )
             elif project_type == "mobile":
                 frameworks.extend(["Flutter", "React Native"])
             elif project_type == "api":
@@ -611,16 +761,22 @@ class MultiLanguageManager:
     ) -> Dict[str, Any]:
         """ç”ŸæˆæŒ‡å®šèªè¨€çš„ä»£ç¢¼"""
         try:
-            self.logger.info(f"Generating {language} code with frameworks: {frameworks}")
+            self.logger.info(
+                f"Generating {language} code with frameworks: {frameworks}"
+            )
 
             if language not in self.supported_languages:
                 raise ValueError(f"Unsupported language: {language}")
 
             # ç”Ÿæˆä»£ç¢¼
-            generation_result = await self.code_generator.generate(user_input, language, frameworks)
+            generation_result = await self.code_generator.generate(
+                user_input, language, frameworks
+            )
 
             # ä»£ç¢¼è³ªé‡æª¢æŸ¥
-            quality_check = await self._perform_quality_check(generation_result, language)
+            quality_check = await self._perform_quality_check(
+                generation_result, language
+            )
 
             # ä¾è³´ç®¡ç†å’Œæ§‹å»ºé…ç½®
             build_config = await self._generate_build_config(
@@ -645,7 +801,9 @@ class MultiLanguageManager:
             self.logger.error(f"Code generation failed for {language}: {e}")
             return {"success": False, "error": str(e)}
 
-    async def create_unified_api(self, project_results: Dict[str, Any]) -> Dict[str, Any]:
+    async def create_unified_api(
+        self, project_results: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """å‰µå»ºçµ±ä¸€APIæ¥å£"""
         try:
             self.logger.info("Creating unified API interface...")
@@ -654,10 +812,14 @@ class MultiLanguageManager:
             project_structure = await self._analyze_project_structure(project_results)
 
             # ç”ŸæˆAPIè¦ç¯„
-            api_specification = await self.api_unifier.generate_specification(project_structure)
+            api_specification = await self.api_unifier.generate_specification(
+                project_structure
+            )
 
             # å‰µå»ºAPIç¶²é—œé…ç½®
-            gateway_config = await self.api_unifier.create_gateway_config(api_specification)
+            gateway_config = await self.api_unifier.create_gateway_config(
+                api_specification
+            )
 
             # ç”Ÿæˆå®¢æˆ¶ç«¯SDK
             client_sdks = await self.api_unifier.generate_client_sdks(api_specification)
@@ -676,7 +838,9 @@ class MultiLanguageManager:
             self.logger.error(f"Unified API creation failed: {e}")
             return {"success": False, "error": str(e)}
 
-    async def optimize_cross_language(self, project_results: Dict[str, Any]) -> Dict[str, Any]:
+    async def optimize_cross_language(
+        self, project_results: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """è·¨èªè¨€æœ€ä½³åŒ–"""
         try:
             self.logger.info("Performing cross-language optimization...")
@@ -699,7 +863,9 @@ class MultiLanguageManager:
                 "consistency_check": consistency_check,
                 "dependency_resolution": dependency_resolution,
                 "test_suites": test_suites,
-                "optimizations_applied": len(performance_optimization.get("applied", [])),
+                "optimizations_applied": len(
+                    performance_optimization.get("applied", [])
+                ),
             }
 
         except Exception as e:
@@ -711,15 +877,37 @@ class MultiLanguageManager:
         user_input_lower = user_input.lower()
 
         # Webé …ç›®é—œéµè©
-        web_keywords = ["website", "web", "frontend", "backend", "api", "webapp", "online"]
+        web_keywords = [
+            "website",
+            "web",
+            "frontend",
+            "backend",
+            "api",
+            "webapp",
+            "online",
+        ]
         # ç§»å‹•é …ç›®é—œéµè©
         mobile_keywords = ["mobile", "app", "ios", "android", "smartphone", "tablet"]
         # æ¡Œé¢é …ç›®é—œéµè©
-        desktop_keywords = ["desktop", "application", "software", "windows", "mac", "linux"]
+        desktop_keywords = [
+            "desktop",
+            "application",
+            "software",
+            "windows",
+            "mac",
+            "linux",
+        ]
         # APIé …ç›®é—œéµè©
         api_keywords = ["api", "service", "microservice", "backend", "rest", "graphql"]
         # æ•¸æ“šé …ç›®é—œéµè©
-        data_keywords = ["data", "analytics", "machine learning", "ai", "ml", "statistics"]
+        data_keywords = [
+            "data",
+            "analytics",
+            "machine learning",
+            "ai",
+            "ml",
+            "statistics",
+        ]
 
         keyword_scores = {
             "web": sum(1 for kw in web_keywords if kw in user_input_lower),
@@ -792,7 +980,10 @@ class MultiLanguageManager:
         }
 
     async def _generate_build_config(
-        self, generation_result: CodeGenerationResult, language: str, frameworks: List[str]
+        self,
+        generation_result: CodeGenerationResult,
+        language: str,
+        frameworks: List[str],
     ) -> List[str]:
         """ç”Ÿæˆæ§‹å»ºé…ç½®"""
         commands = []
@@ -814,11 +1005,15 @@ class MultiLanguageManager:
 
         return commands
 
-    async def _analyze_project_structure(self, project_results: Dict[str, Any]) -> Dict[str, Any]:
+    async def _analyze_project_structure(
+        self, project_results: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """åˆ†æé …ç›®çµæ§‹"""
         structure = {
             "languages": list(project_results.keys()),
-            "total_files": sum(result.get("file_count", 0) for result in project_results.values()),
+            "total_files": sum(
+                result.get("file_count", 0) for result in project_results.values()
+            ),
             "frameworks": [],
             "api_endpoints": 0,
             "components": [],
@@ -833,7 +1028,9 @@ class MultiLanguageManager:
 
         return structure
 
-    async def _optimize_performance(self, project_results: Dict[str, Any]) -> Dict[str, Any]:
+    async def _optimize_performance(
+        self, project_results: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """æ€§èƒ½æœ€ä½³åŒ–"""
         return {
             "applied": [
@@ -846,7 +1043,9 @@ class MultiLanguageManager:
             "memory_reduction": "15%",
         }
 
-    async def _check_consistency(self, project_results: Dict[str, Any]) -> Dict[str, Any]:
+    async def _check_consistency(
+        self, project_results: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """ä»£ç¢¼ä¸€è‡´æ€§æª¢æŸ¥"""
         return {
             "consistent": True,
@@ -856,7 +1055,9 @@ class MultiLanguageManager:
             "code_structure": "uniform",
         }
 
-    async def _resolve_dependencies(self, project_results: Dict[str, Any]) -> Dict[str, Any]:
+    async def _resolve_dependencies(
+        self, project_results: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """ä¾è³´è§£æ"""
         return {
             "resolved": True,
@@ -865,7 +1066,9 @@ class MultiLanguageManager:
             "security_vulnerabilities": 0,
         }
 
-    async def _generate_test_suites(self, project_results: Dict[str, Any]) -> Dict[str, Any]:
+    async def _generate_test_suites(
+        self, project_results: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """ç”Ÿæˆæ¸¬è©¦å¥—ä»¶"""
         return {
             "unit_tests": True,
@@ -935,7 +1138,14 @@ class LanguageRequirementAnalyzer:
 
     def _detect_backend_needs(self, user_input: str) -> bool:
         """æª¢æ¸¬å¾Œç«¯éœ€æ±‚"""
-        backend_keywords = ["backend", "server", "api", "database", "business logic", "processing"]
+        backend_keywords = [
+            "backend",
+            "server",
+            "api",
+            "database",
+            "business logic",
+            "processing",
+        ]
         return any(keyword in user_input.lower() for keyword in backend_keywords)
 
     def _detect_mobile_needs(self, user_input: str) -> bool:
@@ -945,7 +1155,14 @@ class LanguageRequirementAnalyzer:
 
     def _detect_desktop_needs(self, user_input: str) -> bool:
         """æª¢æ¸¬æ¡Œé¢ç«¯éœ€æ±‚"""
-        desktop_keywords = ["desktop", "application", "software", "windows", "mac", "linux"]
+        desktop_keywords = [
+            "desktop",
+            "application",
+            "software",
+            "windows",
+            "mac",
+            "linux",
+        ]
         return any(keyword in user_input.lower() for keyword in desktop_keywords)
 
     def _detect_api_needs(self, user_input: str) -> bool:
@@ -960,7 +1177,13 @@ class LanguageRequirementAnalyzer:
 
     def _detect_enterprise_needs(self, user_input: str) -> bool:
         """æª¢æ¸¬ä¼æ¥­ç´šéœ€æ±‚"""
-        enterprise_keywords = ["enterprise", "business", "corporate", "scalable", "production"]
+        enterprise_keywords = [
+            "enterprise",
+            "business",
+            "corporate",
+            "scalable",
+            "production",
+        ]
         return any(keyword in user_input.lower() for keyword in enterprise_keywords)
 
     def _detect_cloud_needs(self, user_input: str) -> bool:
@@ -975,7 +1198,13 @@ class LanguageRequirementAnalyzer:
 
     def _detect_security_needs(self, user_input: str) -> bool:
         """æª¢æ¸¬å®‰å…¨éœ€æ±‚"""
-        security_keywords = ["security", "authentication", "authorization", "encryption", "secure"]
+        security_keywords = [
+            "security",
+            "authentication",
+            "authorization",
+            "encryption",
+            "secure",
+        ]
         return any(keyword in user_input.lower() for keyword in security_keywords)
 
 
@@ -1040,7 +1269,9 @@ if __name__ == "__main__":
 
         # æ ¹æ“šæ¨¡æ¿ç”Ÿæˆä»£ç¢¼
         main_code = self.templates.get(language, {}).get("main", f"# {project_name}")
-        main_code = main_code.format(project_name=project_name, ProjectName=project_name.title())
+        main_code = main_code.format(
+            project_name=project_name, ProjectName=project_name.title()
+        )
 
         # ç”Ÿæˆæ–‡ä»¶çµæ§‹
         files = {
@@ -1161,7 +1392,9 @@ class UnifiedAPIGenerator:
         """åˆå§‹åŒ–APIç”Ÿæˆå™¨"""
         self.logger.info("Unified API Generator initialized")
 
-    async def generate_specification(self, project_structure: Dict[str, Any]) -> Dict[str, Any]:
+    async def generate_specification(
+        self, project_structure: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """ç”ŸæˆAPIè¦ç¯„"""
         # ç°¡åŒ–çš„APIè¦ç¯„ç”Ÿæˆ
         specification = {
@@ -1169,7 +1402,10 @@ class UnifiedAPIGenerator:
             "info": {"title": "Unified API", "version": "1.0.0"},
             "paths": {
                 "/api/health": {
-                    "get": {"summary": "Health check", "responses": {"200": {"description": "OK"}}}
+                    "get": {
+                        "summary": "Health check",
+                        "responses": {"200": {"description": "OK"}},
+                    }
                 }
             },
             "components": {"schemas": {}},
@@ -1177,7 +1413,9 @@ class UnifiedAPIGenerator:
 
         return specification
 
-    async def create_gateway_config(self, api_specification: Dict[str, Any]) -> Dict[str, Any]:
+    async def create_gateway_config(
+        self, api_specification: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """å‰µå»ºAPIç¶²é—œé…ç½®"""
         return {
             "gateway_type": "nginx",
@@ -1188,7 +1426,9 @@ class UnifiedAPIGenerator:
             "middleware": ["cors", "auth", "rate_limit"],
         }
 
-    async def generate_client_sdks(self, api_specification: Dict[str, Any]) -> Dict[str, str]:
+    async def generate_client_sdks(
+        self, api_specification: Dict[str, Any]
+    ) -> Dict[str, str]:
         """ç”Ÿæˆå®¢æˆ¶ç«¯SDK"""
         sdks = {}
 
diff --git a/workspace/src/core/phase4/visual_config/__init__.py b/workspace/src/core/phase4/visual_config/__init__.py
index 7c3cb82..8f29823 100644
--- a/workspace/src/core/phase4/visual_config/__init__.py
+++ b/workspace/src/core/phase4/visual_config/__init__.py
@@ -138,7 +138,9 @@ class VisualConfigEditor:
     async def analyze_config_requirements(self, user_input: str) -> Dict[str, Any]:
         """åˆ†æé…ç½®éœ€æ±‚"""
         try:
-            self.logger.info(f"Analyzing configuration requirements: {user_input[:100]}...")
+            self.logger.info(
+                f"Analyzing configuration requirements: {user_input[:100]}..."
+            )
 
             # é …ç›®é¡å‹åˆ†æ
             project_type = self._analyze_project_type(user_input)
@@ -179,7 +181,9 @@ class VisualConfigEditor:
             config_id = f"config_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
 
             # ç²å–é …ç›®çµ„ä»¶
-            project_components = await self.component_library.get_components_for_type(project_type)
+            project_components = await self.component_library.get_components_for_type(
+                project_type
+            )
 
             # å‰µå»ºé…ç½®é¸é …
             config_options = await self._create_config_options(analysis, project_type)
@@ -211,16 +215,22 @@ class VisualConfigEditor:
             self.logger.error(f"Visual configurator creation failed: {e}")
             return {"success": False, "error": str(e)}
 
-    async def enable_live_preview(self, visual_config: Dict[str, Any]) -> Dict[str, Any]:
+    async def enable_live_preview(
+        self, visual_config: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """å•Ÿç”¨å¯¦æ™‚é è¦½"""
         try:
             self.logger.info("Enabling live preview...")
 
             # å‰µå»ºé è¦½é…ç½®
-            preview_config = await self.preview_engine.create_preview_config(visual_config)
+            preview_config = await self.preview_engine.create_preview_config(
+                visual_config
+            )
 
             # ç”Ÿæˆé è¦½HTML
-            preview_html = await self.preview_engine.generate_preview_html(visual_config)
+            preview_html = await self.preview_engine.generate_preview_html(
+                visual_config
+            )
 
             # å•Ÿå‹•å¯¦æ™‚æ›´æ–°æ©Ÿåˆ¶
             live_update = await self.preview_engine.enable_live_updates(visual_config)
@@ -251,13 +261,17 @@ class VisualConfigEditor:
             self.logger.info(f"Creating template library for {project_type}")
 
             # ç²å–é è¨­æ¨¡æ¿
-            preset_templates = await self.template_manager.get_preset_templates(project_type)
+            preset_templates = await self.template_manager.get_preset_templates(
+                project_type
+            )
 
             # ç²å–è‡ªå®šç¾©æ¨¡æ¿
             custom_templates = await self.template_manager.get_custom_templates()
 
             # å‰µå»ºæ¨¡æ¿åˆ†é¡
-            template_categories = await self._create_template_categories(preset_templates)
+            template_categories = await self._create_template_categories(
+                preset_templates
+            )
 
             # ç”Ÿæˆæ¨¡æ¿é è¦½
             template_previews = await self._generate_template_previews(preset_templates)
@@ -295,7 +309,9 @@ class VisualConfigEditor:
             supported_formats = await self.import_export_handler.get_supported_formats()
 
             # é©—è­‰é…ç½®
-            validation_config = await self.import_export_handler.create_validation_config()
+            validation_config = (
+                await self.import_export_handler.create_validation_config()
+            )
 
             return {
                 "success": True,
@@ -351,7 +367,8 @@ class VisualConfigEditor:
                 word in user_input_lower for word in ["security", "auth", "login"]
             ),
             "performance_configuration": any(
-                word in user_input_lower for word in ["performance", "speed", "optimize"]
+                word in user_input_lower
+                for word in ["performance", "speed", "optimize"]
             ),
             "integration_configuration": any(
                 word in user_input_lower for word in ["integration", "api", "connect"]
@@ -363,7 +380,8 @@ class VisualConfigEditor:
                 word in user_input_lower for word in ["layout", "structure", "arrange"]
             ),
             "workflow_configuration": any(
-                word in user_input_lower for word in ["workflow", "process", "automation"]
+                word in user_input_lower
+                for word in ["workflow", "process", "automation"]
             ),
         }
 
@@ -396,15 +414,25 @@ class VisualConfigEditor:
         user_input_lower = user_input.lower()
 
         theme_needs = {
-            "dark_mode": any(word in user_input_lower for word in ["dark", "night", "black"]),
-            "light_mode": any(word in user_input_lower for word in ["light", "white", "bright"]),
-            "custom_colors": any(word in user_input_lower for word in ["color", "theme", "custom"]),
+            "dark_mode": any(
+                word in user_input_lower for word in ["dark", "night", "black"]
+            ),
+            "light_mode": any(
+                word in user_input_lower for word in ["light", "white", "bright"]
+            ),
+            "custom_colors": any(
+                word in user_input_lower for word in ["color", "theme", "custom"]
+            ),
             "responsive": any(
-                word in user_input_lower for word in ["responsive", "mobile", "adaptive"]
+                word in user_input_lower
+                for word in ["responsive", "mobile", "adaptive"]
+            ),
+            "branding": any(
+                word in user_input_lower for word in ["brand", "logo", "identity"]
             ),
-            "branding": any(word in user_input_lower for word in ["brand", "logo", "identity"]),
             "accessibility": any(
-                word in user_input_lower for word in ["accessibility", "a11y", "accessible"]
+                word in user_input_lower
+                for word in ["accessibility", "a11y", "accessible"]
             ),
         }
 
@@ -464,7 +492,12 @@ class VisualConfigEditor:
                         description="Main font family",
                         category=ConfigCategory.APPEARANCE,
                         validation_rules={
-                            "options": ["Arial", "Helvetica", "Times New Roman", "Georgia"]
+                            "options": [
+                                "Arial",
+                                "Helvetica",
+                                "Times New Roman",
+                                "Georgia",
+                            ]
                         },
                     ),
                 ]
@@ -481,7 +514,9 @@ class VisualConfigEditor:
                     default_value="SQLite",
                     description="Type of database to use",
                     category=ConfigCategory.FUNCTIONALITY,
-                    validation_rules={"options": ["SQLite", "MySQL", "PostgreSQL", "MongoDB"]},
+                    validation_rules={
+                        "options": ["SQLite", "MySQL", "PostgreSQL", "MongoDB"]
+                    },
                 )
             )
 
@@ -506,7 +541,11 @@ class VisualConfigEditor:
                 "tab_bar_height": 50,
             }
         else:
-            return {"layout_type": "flexible", "container_width": "1200px", "spacing_unit": "8px"}
+            return {
+                "layout_type": "flexible",
+                "container_width": "1200px",
+                "spacing_unit": "8px",
+            }
 
     async def _create_theme_config(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
         """å‰µå»ºä¸»é¡Œé…ç½®"""
@@ -530,7 +569,9 @@ class VisualConfigEditor:
             },
         }
 
-    async def _create_drag_drop_config(self, components: List[DragDropComponent]) -> Dict[str, Any]:
+    async def _create_drag_drop_config(
+        self, components: List[DragDropComponent]
+    ) -> Dict[str, Any]:
         """å‰µå»ºæ‹–æ‹½é…ç½®"""
         return {
             "drag_enabled": True,
@@ -539,7 +580,9 @@ class VisualConfigEditor:
                 "layout": [c for c in components if c.type == ComponentType.LAYOUT],
                 "form": [c for c in components if c.type == ComponentType.FORM],
                 "display": [c for c in components if c.type == ComponentType.DISPLAY],
-                "interaction": [c for c in components if c.type == ComponentType.INTERACTION],
+                "interaction": [
+                    c for c in components if c.type == ComponentType.INTERACTION
+                ],
             },
             "grid_snap": True,
             "grid_size": 8,
@@ -561,7 +604,9 @@ class VisualConfigEditor:
 
         return categories
 
-    async def _generate_template_previews(self, templates: List[ConfigTemplate]) -> Dict[str, str]:
+    async def _generate_template_previews(
+        self, templates: List[ConfigTemplate]
+    ) -> Dict[str, str]:
         """ç”Ÿæˆæ¨¡æ¿é è¦½"""
         previews = {}
 
@@ -581,7 +626,9 @@ class VisualConfigEditor:
 
         return previews
 
-    async def _create_template_search(self, templates: List[ConfigTemplate]) -> Dict[str, Any]:
+    async def _create_template_search(
+        self, templates: List[ConfigTemplate]
+    ) -> Dict[str, Any]:
         """å‰µå»ºæ¨¡æ¿æœç´¢åŠŸèƒ½"""
         return {
             "search_fields": ["name", "description", "tags"],
@@ -669,7 +716,9 @@ class ComponentLibrary:
 
         return components
 
-    async def get_components_for_type(self, project_type: str) -> List[DragDropComponent]:
+    async def get_components_for_type(
+        self, project_type: str
+    ) -> List[DragDropComponent]:
         """æ ¹æ“šé …ç›®é¡å‹ç²å–çµ„ä»¶"""
         if project_type == "web":
             return [
@@ -687,7 +736,8 @@ class ComponentLibrary:
             return [
                 c
                 for c in self.components
-                if c.type in [ComponentType.LAYOUT, ComponentType.FORM, ComponentType.NAVIGATION]
+                if c.type
+                in [ComponentType.LAYOUT, ComponentType.FORM, ComponentType.NAVIGATION]
             ]
         else:
             return self.components
@@ -752,7 +802,11 @@ class TemplateManager:
 
     async def get_preset_templates(self, project_type: str) -> List[ConfigTemplate]:
         """ç²å–é è¨­æ¨¡æ¿"""
-        return [t for t in self.templates if t.category == project_type or t.category == "web"]
+        return [
+            t
+            for t in self.templates
+            if t.category == project_type or t.category == "web"
+        ]
 
     async def get_custom_templates(self) -> List[ConfigTemplate]:
         """ç²å–è‡ªå®šç¾©æ¨¡æ¿"""
@@ -770,7 +824,9 @@ class PreviewEngine:
         """åˆå§‹åŒ–é è¦½å¼•æ“"""
         self.logger.info("Preview Engine initialized")
 
-    async def create_preview_config(self, visual_config: Dict[str, Any]) -> Dict[str, Any]:
+    async def create_preview_config(
+        self, visual_config: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """å‰µå»ºé è¦½é…ç½®"""
         return {
             "auto_refresh": True,
@@ -850,7 +906,9 @@ class PreviewEngine:
         });
         """
 
-    async def enable_live_updates(self, visual_config: Dict[str, Any]) -> Dict[str, Any]:
+    async def enable_live_updates(
+        self, visual_config: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """å•Ÿç”¨å¯¦æ™‚æ›´æ–°"""
         return {
             "websocket_url": f"ws://localhost:8080/preview/{visual_config.get('config_id')}",
@@ -892,10 +950,22 @@ class ImportExportHandler:
     async def get_supported_formats(self) -> List[Dict[str, Any]]:
         """ç²å–æ”¯æŒçš„æ ¼å¼"""
         return [
-            {"format": "json", "mime_type": "application/json", "description": "JSON format"},
+            {
+                "format": "json",
+                "mime_type": "application/json",
+                "description": "JSON format",
+            },
             {"format": "yaml", "mime_type": "text/yaml", "description": "YAML format"},
-            {"format": "xml", "mime_type": "application/xml", "description": "XML format"},
-            {"format": "zip", "mime_type": "application/zip", "description": "ZIP archive"},
+            {
+                "format": "xml",
+                "mime_type": "application/xml",
+                "description": "XML format",
+            },
+            {
+                "format": "zip",
+                "mime_type": "application/zip",
+                "description": "ZIP archive",
+            },
         ]
 
     async def create_validation_config(self) -> Dict[str, Any]:
diff --git a/workspace/src/core/plugins/ai_constitution/adaptive_guidelines.py b/workspace/src/core/plugins/ai_constitution/adaptive_guidelines.py
index b7e2645..9de8255 100644
--- a/workspace/src/core/plugins/ai_constitution/adaptive_guidelines.py
+++ b/workspace/src/core/plugins/ai_constitution/adaptive_guidelines.py
@@ -211,7 +211,9 @@ class DomainGuideline:
 
         if "resource_constrained" in context and context["resource_constrained"]:
             if key == "batch_size":
-                recommendation = max(guideline.get("min", 100), guideline.get("value", 1000) // 2)
+                recommendation = max(
+                    guideline.get("min", 100), guideline.get("value", 1000) // 2
+                )
                 confidence = 0.75
 
         return GuidelineEvaluation(
@@ -239,7 +241,9 @@ class DomainGuideline:
             if feedback_type == "too_strict":
                 if "options" in guideline:
                     options = guideline["options"]
-                    current_idx = options.index(old_value) if old_value in options else 0
+                    current_idx = (
+                        options.index(old_value) if old_value in options else 0
+                    )
                     if current_idx > 0:
                         new_value = options[current_idx - 1]
                 elif isinstance(old_value, (int, float)):
@@ -248,7 +252,9 @@ class DomainGuideline:
             elif feedback_type == "too_lenient":
                 if "options" in guideline:
                     options = guideline["options"]
-                    current_idx = options.index(old_value) if old_value in options else 0
+                    current_idx = (
+                        options.index(old_value) if old_value in options else 0
+                    )
                     if current_idx < len(options) - 1:
                         new_value = options[current_idx + 1]
                 elif isinstance(old_value, (int, float)):
@@ -380,7 +386,11 @@ class LearningGuideline:
             self._learning_data[operation_type] = []
 
         self._learning_data[operation_type].append(
-            {"operation": operation, "outcome": outcome, "timestamp": datetime.utcnow().isoformat()}
+            {
+                "operation": operation,
+                "outcome": outcome,
+                "timestamp": datetime.utcnow().isoformat(),
+            }
         )
 
         # ç•¶æ•¸æ“šè¶³å¤ æ™‚è§¸ç™¼å­¸ç¿’
@@ -422,7 +432,9 @@ class LearningGuideline:
             for key, value in first_op.items():
                 if key not in ["type", "timestamp", "id"]:
                     # æª¢æŸ¥æ­¤åƒæ•¸åœ¨æ‰€æœ‰æˆåŠŸæ¡ˆä¾‹ä¸­æ˜¯å¦ä¸€è‡´
-                    consistent = all(r.get("operation", {}).get(key) == value for r in records)
+                    consistent = all(
+                        r.get("operation", {}).get(key) == value for r in records
+                    )
                     if consistent:
                         common_params[key] = value
 
@@ -551,7 +563,10 @@ class AdaptiveGuidelineEngine:
         return result
 
     def _merge_recommendations(
-        self, domain: dict[str, Any], contextual: dict[str, Any], learned: dict[str, Any]
+        self,
+        domain: dict[str, Any],
+        contextual: dict[str, Any],
+        learned: dict[str, Any],
     ) -> dict[str, Any]:
         """åˆä½µæ‰€æœ‰ä¾†æºçš„å»ºè­°"""
         merged = {}
@@ -574,7 +589,9 @@ class AdaptiveGuidelineEngine:
 
         return merged
 
-    def record_operation_outcome(self, operation: dict[str, Any], outcome: dict[str, Any]):
+    def record_operation_outcome(
+        self, operation: dict[str, Any], outcome: dict[str, Any]
+    ):
         """è¨˜éŒ„æ“ä½œçµæœä¾›å­¸ç¿’"""
         self.learning.record_outcome(operation, outcome)
 
@@ -590,7 +607,9 @@ class AdaptiveGuidelineEngine:
         return {
             "domains": list(self._domain_guidelines.keys()),
             "learned_patterns": len(self.learning.get_learned_patterns()),
-            "active_contextual_guidelines": len(self.contextual.get_all_active_guidelines()),
+            "active_contextual_guidelines": len(
+                self.contextual.get_all_active_guidelines()
+            ),
         }
 
 
diff --git a/workspace/src/core/plugins/ai_constitution/constitution_engine.py b/workspace/src/core/plugins/ai_constitution/constitution_engine.py
index 3e347f7..e40b04a 100644
--- a/workspace/src/core/plugins/ai_constitution/constitution_engine.py
+++ b/workspace/src/core/plugins/ai_constitution/constitution_engine.py
@@ -67,7 +67,9 @@ class ConstitutionVerdict:
     priority: VerdictPriority
 
     # ä¸‰å±¤é©—è­‰çµæœ
-    fundamental_law_results: dict[str, LawVerificationResult] = field(default_factory=dict)
+    fundamental_law_results: dict[str, LawVerificationResult] = field(
+        default_factory=dict
+    )
     operational_rule_results: dict[str, RuleCheckResult] = field(default_factory=dict)
     guideline_recommendations: dict[str, Any] = field(default_factory=dict)
 
@@ -235,7 +237,9 @@ class ConstitutionEngine:
         data = f"{proposal.proposal_id}{datetime.utcnow().isoformat()}"
         return f"VERDICT_{hashlib.sha256(data.encode()).hexdigest()[:12]}"
 
-    def _check_absolute_violations(self, results: dict[str, LawVerificationResult]) -> list[str]:
+    def _check_absolute_violations(
+        self, results: dict[str, LawVerificationResult]
+    ) -> list[str]:
         """æª¢æŸ¥æ˜¯å¦æœ‰çµ•å°é•è¦"""
         violations = []
 
@@ -245,7 +249,9 @@ class ConstitutionEngine:
 
         return violations
 
-    def _check_operational_rules(self, proposal: ActionProposal) -> dict[str, RuleCheckResult]:
+    def _check_operational_rules(
+        self, proposal: ActionProposal
+    ) -> dict[str, RuleCheckResult]:
         """æª¢æŸ¥æ“ä½œè¦å‰‡"""
         results = {}
 
@@ -259,7 +265,9 @@ class ConstitutionEngine:
             "requestor": proposal.requestor,
             "encrypted": proposal.parameters.get("encrypted", False),
             "access_logged": proposal.parameters.get("access_logged", False),
-            "authorization_verified": proposal.parameters.get("authorization_verified", False),
+            "authorization_verified": proposal.parameters.get(
+                "authorization_verified", False
+            ),
         }
 
         # æª¢æŸ¥æ‰€æœ‰é©ç”¨è¦å‰‡
@@ -514,9 +522,12 @@ class ConstitutionEngine:
 
         if stats["total_verdicts"] > 0:
             stats["approval_rate"] = round(
-                (stats["approved"] + stats["modified"]) / stats["total_verdicts"] * 100, 2
+                (stats["approved"] + stats["modified"]) / stats["total_verdicts"] * 100,
+                2,
+            )
+            stats["denial_rate"] = round(
+                stats["denied"] / stats["total_verdicts"] * 100, 2
             )
-            stats["denial_rate"] = round(stats["denied"] / stats["total_verdicts"] * 100, 2)
         else:
             stats["approval_rate"] = 0
             stats["denial_rate"] = 0
diff --git a/workspace/src/core/plugins/ai_constitution/fundamental_laws.py b/workspace/src/core/plugins/ai_constitution/fundamental_laws.py
index de8aa1d..2875f08 100644
--- a/workspace/src/core/plugins/ai_constitution/fundamental_laws.py
+++ b/workspace/src/core/plugins/ai_constitution/fundamental_laws.py
@@ -219,7 +219,9 @@ class LawOne:
 
     def _detect_harm(self, action: ProposedAction, keywords: list[str]) -> str | None:
         """åµæ¸¬è¡Œå‹•ä¸­çš„å‚·å®³é—œéµå­—"""
-        action_text = f"{action.action_type} {action.description} {action.target}".lower()
+        action_text = (
+            f"{action.action_type} {action.description} {action.target}".lower()
+        )
         for keyword in keywords:
             if keyword in action_text:
                 return keyword
@@ -327,7 +329,9 @@ class LawTwo:
         self._verification_history.append(result)
         return result
 
-    def _log_command(self, action: ProposedAction, is_human_command: bool, will_execute: bool):
+    def _log_command(
+        self, action: ProposedAction, is_human_command: bool, will_execute: bool
+    ):
         """è¨˜éŒ„å‘½ä»¤"""
         self._command_log.append(
             {
@@ -402,7 +406,9 @@ class LawThree:
         # æª¢æŸ¥è³‡æºæ¶ˆè€—
         resource_impact = self._assess_resource_impact(action)
         if resource_impact > 0.8:
-            recommendations.append(f"è­¦å‘Šï¼šæ­¤è¡Œå‹•å¯èƒ½æ¶ˆè€— {resource_impact*100:.1f}% ç³»çµ±è³‡æº")
+            recommendations.append(
+                f"è­¦å‘Šï¼šæ­¤è¡Œå‹•å¯èƒ½æ¶ˆè€— {resource_impact*100:.1f}% ç³»çµ±è³‡æº"
+            )
 
         result = LawVerificationResult(
             law_id=self.LAW_ID,
@@ -492,7 +498,9 @@ class FundamentalLaws:
 
         self._verification_cache: dict[str, LawVerificationResult] = {}
 
-    async def verify_all(self, action: ProposedAction) -> dict[str, LawVerificationResult]:
+    async def verify_all(
+        self, action: ProposedAction
+    ) -> dict[str, LawVerificationResult]:
         """
         é©—è­‰è¡Œå‹•æ˜¯å¦ç¬¦åˆæ‰€æœ‰æ ¹æœ¬æ³•å‰‡
         æŒ‰å„ªå…ˆç´šé †åºé©—è­‰ï¼Œä¸€æ—¦é•åå³åœæ­¢
diff --git a/workspace/src/core/plugins/ai_constitution/guardrails.py b/workspace/src/core/plugins/ai_constitution/guardrails.py
index 2df9c2e..00f3fe0 100644
--- a/workspace/src/core/plugins/ai_constitution/guardrails.py
+++ b/workspace/src/core/plugins/ai_constitution/guardrails.py
@@ -663,7 +663,9 @@ class GuardrailSystem:
             stats["total_failures"] += guardrail.fail_count
 
         if stats["total_checks"] > 0:
-            stats["pass_rate"] = round(stats["total_passes"] / stats["total_checks"] * 100, 2)
+            stats["pass_rate"] = round(
+                stats["total_passes"] / stats["total_checks"] * 100, 2
+            )
         else:
             stats["pass_rate"] = 0
 
diff --git a/workspace/src/core/plugins/ai_constitution/operational_rules.py b/workspace/src/core/plugins/ai_constitution/operational_rules.py
index 6d6b461..daba2af 100644
--- a/workspace/src/core/plugins/ai_constitution/operational_rules.py
+++ b/workspace/src/core/plugins/ai_constitution/operational_rules.py
@@ -136,7 +136,10 @@ class DataHandlingRule:
                         rule_name="åŠ å¯†è¦æ±‚",
                         severity=RuleSeverity.CRITICAL,
                         description=f"æ•æ„Ÿæ•¸æ“š {data_type} å¿…é ˆåŠ å¯†",
-                        context={"data_type": data_type, "category": sensitive_category},
+                        context={
+                            "data_type": data_type,
+                            "category": sensitive_category,
+                        },
                     )
                 )
                 auto_corrections.append("auto_encrypt_data")
@@ -169,7 +172,8 @@ class DataHandlingRule:
 
         result = RuleCheckResult(
             rule_id=self.RULE_ID,
-            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL]) == 0,
+            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL])
+            == 0,
             violations=violations,
             warnings=warnings,
             auto_corrections=auto_corrections,
@@ -188,7 +192,9 @@ class DataHandlingRule:
                 return category
         return None
 
-    def apply_auto_correction(self, correction: str, data: dict[str, Any]) -> dict[str, Any]:
+    def apply_auto_correction(
+        self, correction: str, data: dict[str, Any]
+    ) -> dict[str, Any]:
         """æ‡‰ç”¨è‡ªå‹•ä¿®æ­£"""
         if correction == "auto_encrypt_data":
             # æ¨¡æ“¬åŠ å¯†
@@ -196,7 +202,9 @@ class DataHandlingRule:
             data["encryption_algorithm"] = "AES-256-GCM"
         elif correction == "enable_access_logging":
             data["access_logged"] = True
-            data["log_id"] = hashlib.sha256(str(datetime.utcnow()).encode()).hexdigest()[:16]
+            data["log_id"] = hashlib.sha256(
+                str(datetime.utcnow()).encode()
+            ).hexdigest()[:16]
 
         return data
 
@@ -295,7 +303,8 @@ class SystemAccessRule:
 
         result = RuleCheckResult(
             rule_id=self.RULE_ID,
-            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL]) == 0,
+            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL])
+            == 0,
             violations=violations,
             warnings=warnings,
             auto_corrections=auto_corrections,
@@ -308,7 +317,10 @@ class SystemAccessRule:
     def _is_prohibited_resource(self, resource: str) -> bool:
         """æª¢æŸ¥æ˜¯å¦ç‚ºç¦æ­¢è³‡æº"""
         resource_lower = resource.lower()
-        return any(prohibited.lower() in resource_lower for prohibited in self.PROHIBITED_RESOURCES)
+        return any(
+            prohibited.lower() in resource_lower
+            for prohibited in self.PROHIBITED_RESOURCES
+        )
 
     def _categorize_resource(self, resource: str) -> str:
         """åˆ†é¡è³‡æº"""
@@ -441,7 +453,8 @@ class ResourceUsageRule:
 
         result = RuleCheckResult(
             rule_id=self.RULE_ID,
-            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL]) == 0,
+            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL])
+            == 0,
             violations=violations,
             warnings=warnings,
             auto_corrections=auto_corrections,
@@ -573,7 +586,8 @@ class CommunicationRule:
 
         result = RuleCheckResult(
             rule_id=self.RULE_ID,
-            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL]) == 0,
+            passed=len([v for v in violations if v.severity == RuleSeverity.CRITICAL])
+            == 0,
             violations=violations,
             warnings=warnings,
             auto_corrections=auto_corrections,
@@ -591,9 +605,9 @@ class CommunicationRule:
             "recipient_count": len(communication.get("recipients", [])),
             "content_size": len(communication.get("content", "")),
             "timestamp": datetime.utcnow().isoformat(),
-            "log_id": hashlib.sha256(f"{communication}{datetime.utcnow()}".encode()).hexdigest()[
-                :16
-            ],
+            "log_id": hashlib.sha256(
+                f"{communication}{datetime.utcnow()}".encode()
+            ).hexdigest()[:16],
         }
         self._communication_log.append(safe_comm)
 
@@ -632,7 +646,9 @@ class OperationalRuleEngine:
             RuleCategory.COMMUNICATION: self.communication,
         }
 
-    def check_operation(self, category: RuleCategory, operation: dict[str, Any]) -> RuleCheckResult:
+    def check_operation(
+        self, category: RuleCategory, operation: dict[str, Any]
+    ) -> RuleCheckResult:
         """æª¢æŸ¥ç‰¹å®šé¡åˆ¥çš„æ“ä½œ"""
         rule = self._all_rules.get(category)
         if rule:
diff --git a/workspace/src/core/plugins/ai_constitution/policy_as_prompt.py b/workspace/src/core/plugins/ai_constitution/policy_as_prompt.py
index 6f3c1b3..b671e10 100644
--- a/workspace/src/core/plugins/ai_constitution/policy_as_prompt.py
+++ b/workspace/src/core/plugins/ai_constitution/policy_as_prompt.py
@@ -200,7 +200,9 @@ class PolicyEnforcer:
 
         # æŒ‰å„ªå…ˆç´šæ’åºè­·æ¬„
         sorted_guardrails = sorted(
-            self._guardrails.values(), key=lambda g: g.policy_prompt.priority, reverse=True
+            self._guardrails.values(),
+            key=lambda g: g.policy_prompt.priority,
+            reverse=True,
         )
 
         for guardrail in sorted_guardrails:
@@ -217,7 +219,9 @@ class PolicyEnforcer:
                 # æ ¹æ“šåŸ·è¡Œå‹•ä½œæ±ºå®šè™•ç†
                 action = guardrail.policy_prompt.enforcement_action
                 if action == EnforcementAction.DENY:
-                    results["actions_taken"].append(f"æ‹’çµ•: {guardrail.policy_prompt.policy_name}")
+                    results["actions_taken"].append(
+                        f"æ‹’çµ•: {guardrail.policy_prompt.policy_name}"
+                    )
                     break  # ç«‹å³åœæ­¢
                 elif action == EnforcementAction.WARN:
                     results["warnings"].extend(check_result["violations"])
@@ -264,7 +268,9 @@ class PolicyEnforcer:
                 1 for g in self._guardrails.values() if g.policy_prompt.enabled
             ),
             "total_checks": sum(g.check_count for g in self._guardrails.values()),
-            "total_violations": sum(g.violation_count for g in self._guardrails.values()),
+            "total_violations": sum(
+                g.violation_count for g in self._guardrails.values()
+            ),
         }
 
         if stats["total_checks"] > 0:
@@ -513,7 +519,9 @@ class PolicyAsPrompt:
         patterns.extend(prohibit_matches)
 
         # æŸ¥æ‰¾è‹±æ–‡é—œéµè©
-        english_matches = re.findall(r"prohibit[ed]?\s+([a-zA-Z_]+)", document, re.IGNORECASE)
+        english_matches = re.findall(
+            r"prohibit[ed]?\s+([a-zA-Z_]+)", document, re.IGNORECASE
+        )
         patterns.extend(english_matches)
 
         return patterns
@@ -531,7 +539,9 @@ class PolicyAsPrompt:
         else:
             return EnforcementAction.WARN
 
-    def enforce_policies(self, content: str, context: dict[str, Any] = None) -> dict[str, Any]:
+    def enforce_policies(
+        self, content: str, context: dict[str, Any] = None
+    ) -> dict[str, Any]:
         """åŸ·è¡Œæ‰€æœ‰æ”¿ç­–"""
         return self.enforcer.enforce(content, context)
 
diff --git a/workspace/src/core/plugins/ci_error_handler/auto_fix_engine.py b/workspace/src/core/plugins/ci_error_handler/auto_fix_engine.py
index 5227f18..35bd08c 100644
--- a/workspace/src/core/plugins/ci_error_handler/auto_fix_engine.py
+++ b/workspace/src/core/plugins/ci_error_handler/auto_fix_engine.py
@@ -250,7 +250,9 @@ Provide:
     def _generate_attempt_id(self) -> str:
         """Generate unique attempt ID"""
         self._attempt_counter += 1
-        return f"FIX-{datetime.now().strftime('%Y%m%d%H%M%S')}-{self._attempt_counter:04d}"
+        return (
+            f"FIX-{datetime.now().strftime('%Y%m%d%H%M%S')}-{self._attempt_counter:04d}"
+        )
 
     def analyze_fix_options(self, error: CIError) -> dict[str, Any]:
         """
@@ -285,7 +287,9 @@ Provide:
 
         # Determine recommended strategy
         if options["matching_rules"]:
-            safe_rules = [r for r in options["matching_rules"] if r["safe_to_auto_apply"]]
+            safe_rules = [
+                r for r in options["matching_rules"] if r["safe_to_auto_apply"]
+            ]
             if safe_rules:
                 options["recommended_strategy"] = FixStrategy.AUTO_FIX
             else:
diff --git a/workspace/src/core/plugins/ci_error_handler/ci_error_analyzer.py b/workspace/src/core/plugins/ci_error_handler/ci_error_analyzer.py
index 12f023c..81b405c 100644
--- a/workspace/src/core/plugins/ci_error_handler/ci_error_analyzer.py
+++ b/workspace/src/core/plugins/ci_error_handler/ci_error_analyzer.py
@@ -285,7 +285,9 @@ class CIErrorAnalyzer:
     def _generate_error_id(self) -> str:
         """Generate a unique error ID"""
         self._error_counter += 1
-        return f"ERR-{datetime.now().strftime('%Y%m%d%H%M%S')}-{self._error_counter:04d}"
+        return (
+            f"ERR-{datetime.now().strftime('%Y%m%d%H%M%S')}-{self._error_counter:04d}"
+        )
 
     def analyze_log(self, log_content: str, source: str = "unknown") -> list[CIError]:
         """
@@ -344,7 +346,9 @@ class CIErrorAnalyzer:
 
         return errors
 
-    def _extract_file_info(self, log_content: str, category: ErrorCategory) -> dict[str, Any]:
+    def _extract_file_info(
+        self, log_content: str, category: ErrorCategory
+    ) -> dict[str, Any]:
         """Extract file path and line number from log content"""
         # Common patterns for file:line:column format
         patterns = [
@@ -366,7 +370,9 @@ class CIErrorAnalyzer:
 
         return {}
 
-    def _extract_code_snippet(self, log_content: str, file_info: dict[str, Any]) -> str | None:
+    def _extract_code_snippet(
+        self, log_content: str, file_info: dict[str, Any]
+    ) -> str | None:
         """Extract code snippet from log content if available"""
         # Look for code snippet markers
         snippet_patterns = [
diff --git a/workspace/src/core/plugins/ci_error_handler/fix_status_tracker.py b/workspace/src/core/plugins/ci_error_handler/fix_status_tracker.py
index 90e4159..ff4a856 100644
--- a/workspace/src/core/plugins/ci_error_handler/fix_status_tracker.py
+++ b/workspace/src/core/plugins/ci_error_handler/fix_status_tracker.py
@@ -407,13 +407,19 @@ class FixStatusTracker:
 
     def get_pending_fixes(self) -> list[TrackedFix]:
         """Get all pending fixes"""
-        pending_statuses = {FixStatus.PENDING, FixStatus.IN_PROGRESS, FixStatus.PR_CREATED}
+        pending_statuses = {
+            FixStatus.PENDING,
+            FixStatus.IN_PROGRESS,
+            FixStatus.PR_CREATED,
+        }
         return [f for f in self._tracked_fixes.values() if f.status in pending_statuses]
 
     def get_resolved_fixes(self) -> list[TrackedFix]:
         """Get all resolved fixes"""
         resolved_statuses = {FixStatus.VERIFIED, FixStatus.PR_MERGED}
-        return [f for f in self._tracked_fixes.values() if f.status in resolved_statuses]
+        return [
+            f for f in self._tracked_fixes.values() if f.status in resolved_statuses
+        ]
 
     def calculate_metrics(self, since: datetime | None = None) -> FixMetrics:
         """
diff --git a/workspace/src/core/plugins/ci_error_handler/issue_manager.py b/workspace/src/core/plugins/ci_error_handler/issue_manager.py
index 74bc163..92236b4 100644
--- a/workspace/src/core/plugins/ci_error_handler/issue_manager.py
+++ b/workspace/src/core/plugins/ci_error_handler/issue_manager.py
@@ -220,7 +220,10 @@ class IssueManager:
         self._issues: dict[str, CIIssue] = {}
 
     def create_issue_content(
-        self, error: CIError, workflow_info: dict[str, Any], template_id: str = "default"
+        self,
+        error: CIError,
+        workflow_info: dict[str, Any],
+        template_id: str = "default",
     ) -> dict[str, Any]:
         """
         Create issue content from error
@@ -286,7 +289,9 @@ class IssueManager:
             return issue
         return None
 
-    def add_fix_attempt(self, error_id: str, fix_info: dict[str, Any]) -> CIIssue | None:
+    def add_fix_attempt(
+        self, error_id: str, fix_info: dict[str, Any]
+    ) -> CIIssue | None:
         """Add a fix attempt to an issue"""
         if error_id in self._issues:
             issue = self._issues[error_id]
@@ -297,7 +302,9 @@ class IssueManager:
             return issue
         return None
 
-    def add_comment(self, error_id: str, comment: str, author: str = "bot") -> CIIssue | None:
+    def add_comment(
+        self, error_id: str, comment: str, author: str = "bot"
+    ) -> CIIssue | None:
         """Add a comment to an issue"""
         if error_id in self._issues:
             issue = self._issues[error_id]
@@ -322,7 +329,11 @@ class IssueManager:
 
     def get_open_issues(self) -> list[CIIssue]:
         """Get all open issues"""
-        open_statuses = {IssueStatus.OPEN, IssueStatus.IN_PROGRESS, IssueStatus.FIX_ATTEMPTED}
+        open_statuses = {
+            IssueStatus.OPEN,
+            IssueStatus.IN_PROGRESS,
+            IssueStatus.FIX_ATTEMPTED,
+        }
         return [i for i in self._issues.values() if i.status in open_statuses]
 
     def check_duplicate(self, error: CIError) -> CIIssue | None:
diff --git a/workspace/src/core/plugins/cloud_agent_delegation/cloud_provider_adapter.py b/workspace/src/core/plugins/cloud_agent_delegation/cloud_provider_adapter.py
index e1e34bf..82a0be6 100644
--- a/workspace/src/core/plugins/cloud_agent_delegation/cloud_provider_adapter.py
+++ b/workspace/src/core/plugins/cloud_agent_delegation/cloud_provider_adapter.py
@@ -167,7 +167,9 @@ class CloudProviderAdapter:
             result.result = execution_result
             result.status = "success"
             result.completed_at = datetime.now(UTC)
-            result.duration_ms = (result.completed_at - result.started_at).total_seconds() * 1000
+            result.duration_ms = (
+                result.completed_at - result.started_at
+            ).total_seconds() * 1000
 
             self._last_execution = datetime.now(UTC)
 
@@ -229,7 +231,9 @@ class CloudProviderAdapter:
             "execution_count": self._execution_count,
             "error_count": self._error_count,
             "error_rate": self._error_count / max(self._execution_count, 1),
-            "last_execution": self._last_execution.isoformat() if self._last_execution else None,
+            "last_execution": (
+                self._last_execution.isoformat() if self._last_execution else None
+            ),
             "config": self.config.to_dict(),
         }
 
@@ -305,7 +309,9 @@ class AWSLambdaAdapter(CloudProviderAdapter):
     """Adapter for AWS Lambda"""
 
     def __init__(self, name: str, region: str = "us-east-1", **kwargs):
-        config = ProviderConfig(name=name, provider_type=ProviderType.AWS, region=region, **kwargs)
+        config = ProviderConfig(
+            name=name, provider_type=ProviderType.AWS, region=region, **kwargs
+        )
         super().__init__(config)
 
 
@@ -317,7 +323,9 @@ class GCPCloudFunctionsAdapter(CloudProviderAdapter):
         if "runtime" not in kwargs:
             kwargs["runtime"] = "nodejs18"
 
-        config = ProviderConfig(name=name, provider_type=ProviderType.GCP, region=region, **kwargs)
+        config = ProviderConfig(
+            name=name, provider_type=ProviderType.GCP, region=region, **kwargs
+        )
         super().__init__(config)
 
 
@@ -350,6 +358,8 @@ def create_provider_adapter(
         return CloudProviderAdapter(config)
 
 
-def create_provider_config(name: str, provider_type: ProviderType, **kwargs) -> ProviderConfig:
+def create_provider_config(
+    name: str, provider_type: ProviderType, **kwargs
+) -> ProviderConfig:
     """Create a provider configuration"""
     return ProviderConfig(name=name, provider_type=provider_type, **kwargs)
diff --git a/workspace/src/core/plugins/cloud_agent_delegation/delegation_manager.py b/workspace/src/core/plugins/cloud_agent_delegation/delegation_manager.py
index d9d8e87..fc5e9dc 100644
--- a/workspace/src/core/plugins/cloud_agent_delegation/delegation_manager.py
+++ b/workspace/src/core/plugins/cloud_agent_delegation/delegation_manager.py
@@ -147,7 +147,10 @@ class DelegationManager:
     """
 
     def __init__(
-        self, config: DelegationConfig, router: Any | None = None, load_balancer: Any | None = None
+        self,
+        config: DelegationConfig,
+        router: Any | None = None,
+        load_balancer: Any | None = None,
     ):
         """
         Initialize the delegation manager
@@ -344,7 +347,9 @@ class DelegationManager:
         tasks = list(self._tasks.values())
 
         if status:
-            task_ids = [tid for tid, result in self._results.items() if result.status == status]
+            task_ids = [
+                tid for tid, result in self._results.items() if result.status == status
+            ]
             tasks = [t for t in tasks if t.id in task_ids]
 
         if task_type:
@@ -362,7 +367,9 @@ class DelegationManager:
         provider_counts = {}
         for result in self._results.values():
             if result.provider:
-                provider_counts[result.provider] = provider_counts.get(result.provider, 0) + 1
+                provider_counts[result.provider] = (
+                    provider_counts.get(result.provider, 0) + 1
+                )
 
         total_duration = sum(r.duration_ms for r in self._results.values())
         avg_duration = total_duration / max(len(self._results), 1)
@@ -397,7 +404,9 @@ class DelegationManager:
             attempts = 0
             last_error = None
 
-            while attempts < (self.config.max_retries if self.config.retry_enabled else 1):
+            while attempts < (
+                self.config.max_retries if self.config.retry_enabled else 1
+            ):
                 attempts += 1
                 result.attempts = attempts
 
@@ -416,7 +425,9 @@ class DelegationManager:
                     self._running_tasks[task.id] = exec_task
 
                     # Wait with timeout
-                    execution_result = await asyncio.wait_for(exec_task, timeout=task.timeout)
+                    execution_result = await asyncio.wait_for(
+                        exec_task, timeout=task.timeout
+                    )
 
                     result.result = execution_result
                     result.status = DelegationStatus.COMPLETED
@@ -425,7 +436,9 @@ class DelegationManager:
                         result.completed_at - result.started_at
                     ).total_seconds() * 1000
 
-                    await self._emit_event("task_completed", {"result": result.to_dict()})
+                    await self._emit_event(
+                        "task_completed", {"result": result.to_dict()}
+                    )
                     break
 
                 except TimeoutError:
diff --git a/workspace/src/core/plugins/cloud_agent_delegation/load_balancer.py b/workspace/src/core/plugins/cloud_agent_delegation/load_balancer.py
index c18e68c..02543d2 100644
--- a/workspace/src/core/plugins/cloud_agent_delegation/load_balancer.py
+++ b/workspace/src/core/plugins/cloud_agent_delegation/load_balancer.py
@@ -374,7 +374,8 @@ class LoadBalancer:
                         # Perform health check
                         if hasattr(provider, "health_check"):
                             result = await asyncio.wait_for(
-                                provider.health_check(), timeout=self.config.health_check_timeout
+                                provider.health_check(),
+                                timeout=self.config.health_check_timeout,
                             )
                             healthy = result.get("healthy", True)
                         else:
@@ -388,7 +389,9 @@ class LoadBalancer:
                         self.update_health(name, healthy, latency_ms)
 
                     except TimeoutError:
-                        self.update_health(name, False, self.config.health_check_timeout * 1000)
+                        self.update_health(
+                            name, False, self.config.health_check_timeout * 1000
+                        )
                     except Exception as e:
                         logger.error(f"Health check failed for {name}: {e}")
                         self.update_health(name, False)
diff --git a/workspace/src/core/plugins/cloud_agent_delegation/task_router.py b/workspace/src/core/plugins/cloud_agent_delegation/task_router.py
index 8e6f066..d00e669 100644
--- a/workspace/src/core/plugins/cloud_agent_delegation/task_router.py
+++ b/workspace/src/core/plugins/cloud_agent_delegation/task_router.py
@@ -225,9 +225,9 @@ class TaskRouter:
         for condition_type, condition_value in conditions.items():
             if condition_type == "min_priority":
                 task_priority = context.get("priority", "medium")
-                if self._priority_order.index(task_priority) > self._priority_order.index(
-                    condition_value
-                ):
+                if self._priority_order.index(
+                    task_priority
+                ) > self._priority_order.index(condition_value):
                     return False
 
             elif condition_type == "max_payload_size":
@@ -257,7 +257,9 @@ class TaskRouter:
         rule_counts = {}
 
         for result in self._routing_history:
-            provider_counts[result.provider] = provider_counts.get(result.provider, 0) + 1
+            provider_counts[result.provider] = (
+                provider_counts.get(result.provider, 0) + 1
+            )
             if result.rule_name:
                 rule_counts[result.rule_name] = rule_counts.get(result.rule_name, 0) + 1
 
@@ -300,16 +302,23 @@ class TaskRouter:
 
 # Factory functions
 def create_task_router(
-    default_provider: str = "default", strategy: RoutingStrategy = RoutingStrategy.PATTERN_MATCH
+    default_provider: str = "default",
+    strategy: RoutingStrategy = RoutingStrategy.PATTERN_MATCH,
 ) -> TaskRouter:
     """Create a new TaskRouter instance"""
     return TaskRouter(default_provider, strategy)
 
 
-def create_routing_rule(name: str, pattern: str, preferred_provider: str, **kwargs) -> RoutingRule:
+def create_routing_rule(
+    name: str, pattern: str, preferred_provider: str, **kwargs
+) -> RoutingRule:
     """Create a new RoutingRule"""
     return RoutingRule(
-        id=str(uuid4()), name=name, pattern=pattern, preferred_provider=preferred_provider, **kwargs
+        id=str(uuid4()),
+        name=name,
+        pattern=pattern,
+        preferred_provider=preferred_provider,
+        **kwargs,
     )
 
 
diff --git a/workspace/src/core/plugins/drone_system/autopilot.py b/workspace/src/core/plugins/drone_system/autopilot.py
index 94f325a..cf1c876 100644
--- a/workspace/src/core/plugins/drone_system/autopilot.py
+++ b/workspace/src/core/plugins/drone_system/autopilot.py
@@ -166,7 +166,9 @@ class AutopilotDrone(BaseDrone):
 
     def _run_lint(self, **_kwargs: Any) -> bool:
         """åŸ·è¡Œç¨‹å¼ç¢¼æª¢æŸ¥"""
-        success, _ = self._run_command(["npm", "run", "lint", "--if-present"], "ç¨‹å¼ç¢¼æª¢æŸ¥")
+        success, _ = self._run_command(
+            ["npm", "run", "lint", "--if-present"], "ç¨‹å¼ç¢¼æª¢æŸ¥"
+        )
         return success
 
     def _run_format(self, **_kwargs: Any) -> bool:
@@ -204,7 +206,9 @@ class AutopilotDrone(BaseDrone):
                 checks[tool] = {
                     "installed": result.returncode == 0,
                     "version": (
-                        result.stdout.strip().split("\n")[0] if result.returncode == 0 else None
+                        result.stdout.strip().split("\n")[0]
+                        if result.returncode == 0
+                        else None
                     ),
                 }
             except (FileNotFoundError, subprocess.TimeoutExpired):
diff --git a/workspace/src/core/plugins/drone_system/deployment.py b/workspace/src/core/plugins/drone_system/deployment.py
index 956b156..5d079f1 100644
--- a/workspace/src/core/plugins/drone_system/deployment.py
+++ b/workspace/src/core/plugins/drone_system/deployment.py
@@ -97,7 +97,9 @@ class DeploymentDrone(BaseDrone):
             current = current.parent
         return Path.cwd()
 
-    def _deploy(self, environment: str = "development", **_kwargs: Any) -> dict[str, Any]:
+    def _deploy(
+        self, environment: str = "development", **_kwargs: Any
+    ) -> dict[str, Any]:
         """
         åŸ·è¡Œéƒ¨ç½²
 
@@ -125,7 +127,9 @@ class DeploymentDrone(BaseDrone):
         try:
             # åŸ·è¡Œéƒ¨ç½²è…³æœ¬
             deploy_script = (
-                self._project_root / "deploy.sh" if self._project_root else Path("deploy.sh")
+                self._project_root / "deploy.sh"
+                if self._project_root
+                else Path("deploy.sh")
             )
             if deploy_script.exists():
                 result = subprocess.run(
@@ -187,7 +191,8 @@ class DeploymentDrone(BaseDrone):
         print_info("åŸ·è¡Œéƒ¨ç½²å¥åº·æª¢æŸ¥...")
 
         checks: dict[str, bool] = {
-            "project_root_exists": self._project_root is not None and self._project_root.exists(),
+            "project_root_exists": self._project_root is not None
+            and self._project_root.exists(),
             "deploy_script_exists": self._project_root is not None
             and (self._project_root / "deploy.sh").exists(),
         }
@@ -200,7 +205,9 @@ class DeploymentDrone(BaseDrone):
 
         return {"passed": all_passed, "checks": checks}
 
-    def _pre_deploy_check(self, environment: str = "development", **_kwargs: Any) -> dict[str, Any]:
+    def _pre_deploy_check(
+        self, environment: str = "development", **_kwargs: Any
+    ) -> dict[str, Any]:
         """
         é éƒ¨ç½²æª¢æŸ¥
 
@@ -213,7 +220,8 @@ class DeploymentDrone(BaseDrone):
         print_info(f"åŸ·è¡Œ {environment} ç’°å¢ƒé éƒ¨ç½²æª¢æŸ¥...")
 
         checks: dict[str, bool] = {
-            "environment_valid": environment in ["development", "staging", "production"],
+            "environment_valid": environment
+            in ["development", "staging", "production"],
             "drone_running": self.status == DroneStatus.RUNNING,
         }
 
diff --git a/workspace/src/core/plugins/execution_architecture/agent_orchestration.py b/workspace/src/core/plugins/execution_architecture/agent_orchestration.py
index 7e77b60..d545928 100644
--- a/workspace/src/core/plugins/execution_architecture/agent_orchestration.py
+++ b/workspace/src/core/plugins/execution_architecture/agent_orchestration.py
@@ -77,7 +77,9 @@ class ExecutionPlan:
 
     def get_ready_steps(self) -> list[ExecutionStep]:
         """Get steps that are ready to execute (all dependencies completed)"""
-        completed_ids = {s.step_id for s in self.steps if s.status == StepStatus.COMPLETED}
+        completed_ids = {
+            s.step_id for s in self.steps if s.status == StepStatus.COMPLETED
+        }
         ready = []
         for step in self.steps:
             if step.status == StepStatus.PENDING:
@@ -104,7 +106,12 @@ class ExecutionContext:
         """Set a context variable"""
         self._variables[key] = value
         self._history.append(
-            {"action": "set", "key": key, "value": value, "timestamp": datetime.now().isoformat()}
+            {
+                "action": "set",
+                "key": key,
+                "value": value,
+                "timestamp": datetime.now().isoformat(),
+            }
         )
 
     def get(self, key: str, default: Any = None) -> Any:
@@ -120,7 +127,11 @@ class ExecutionContext:
         if key in self._variables:
             del self._variables[key]
             self._history.append(
-                {"action": "delete", "key": key, "timestamp": datetime.now().isoformat()}
+                {
+                    "action": "delete",
+                    "key": key,
+                    "timestamp": datetime.now().isoformat(),
+                }
             )
 
     def has(self, key: str) -> bool:
@@ -179,7 +190,9 @@ class TaskPlanner:
         self._templates: dict[str, list[dict[str, Any]]] = {}
         self._plans: dict[str, ExecutionPlan] = {}
 
-    def register_template(self, template_name: str, steps: list[dict[str, Any]]) -> None:
+    def register_template(
+        self, template_name: str, steps: list[dict[str, Any]]
+    ) -> None:
         """Register a plan template"""
         self._templates[template_name] = steps
 
@@ -213,7 +226,9 @@ class TaskPlanner:
         self._plans[plan.plan_id] = plan
         return plan
 
-    def decompose_task(self, task_description: str, available_tools: list[str]) -> ExecutionPlan:
+    def decompose_task(
+        self, task_description: str, available_tools: list[str]
+    ) -> ExecutionPlan:
         """
         Decompose a task description into executable steps
         Uses heuristics to break down complex tasks
@@ -280,7 +295,9 @@ class TaskPlanner:
             )
 
         return self.create_plan(
-            name=f"Plan for: {task_description[:50]}...", description=task_description, steps=steps
+            name=f"Plan for: {task_description[:50]}...",
+            description=task_description,
+            steps=steps,
         )
 
     def get_plan(self, plan_id: str) -> ExecutionPlan | None:
@@ -395,8 +412,12 @@ class AgentOrchestrator:
 
                 try:
                     if step.tool_name and tool_executor:
-                        result = await tool_executor.execute(step.tool_name, step.params)
-                        step.result = result.output if hasattr(result, "output") else result
+                        result = await tool_executor.execute(
+                            step.tool_name, step.params
+                        )
+                        step.result = (
+                            result.output if hasattr(result, "output") else result
+                        )
                     else:
                         step.result = f"Executed {step.name} (simulated)"
 
@@ -429,7 +450,10 @@ class AgentOrchestrator:
         }
 
     async def orchestrate_task(
-        self, task_description: str, available_tools: list[str], tool_executor: Any = None
+        self,
+        task_description: str,
+        available_tools: list[str],
+        tool_executor: Any = None,
     ) -> dict[str, Any]:
         """
         High-level task orchestration
diff --git a/workspace/src/core/plugins/execution_architecture/function_calling.py b/workspace/src/core/plugins/execution_architecture/function_calling.py
index 2e0711f..a2491a1 100644
--- a/workspace/src/core/plugins/execution_architecture/function_calling.py
+++ b/workspace/src/core/plugins/execution_architecture/function_calling.py
@@ -78,7 +78,9 @@ class FunctionDefinition:
                 expected_type = properties[key].get("type")
                 if expected_type and expected_type in type_map:
                     if not isinstance(value, type_map[expected_type]):
-                        errors.append(f"Invalid type for {key}: expected {expected_type}")
+                        errors.append(
+                            f"Invalid type for {key}: expected {expected_type}"
+                        )
 
         return errors
 
@@ -215,7 +217,9 @@ class FunctionCallHandler:
         self._call_history.append(result)
         return result
 
-    def parse_openai_tool_call(self, tool_call: dict[str, Any]) -> tuple[str, dict[str, Any]]:
+    def parse_openai_tool_call(
+        self, tool_call: dict[str, Any]
+    ) -> tuple[str, dict[str, Any]]:
         """Parse an OpenAI tool call response"""
         function_name = tool_call.get("function", {}).get("name", "")
         arguments_str = tool_call.get("function", {}).get("arguments", "{}")
@@ -354,7 +358,10 @@ def create_api_function(
             "type": "object",
             "properties": {
                 "url": {"type": "string", "description": "The URL to call"},
-                "method": {"type": "string", "description": "HTTP method (GET, POST, etc.)"},
+                "method": {
+                    "type": "string",
+                    "description": "HTTP method (GET, POST, etc.)",
+                },
                 "body": {"type": "object", "description": "Request body"},
             },
             "required": ["url", "method"],
diff --git a/workspace/src/core/plugins/execution_architecture/langchain_integration.py b/workspace/src/core/plugins/execution_architecture/langchain_integration.py
index 385d81f..5c26d84 100644
--- a/workspace/src/core/plugins/execution_architecture/langchain_integration.py
+++ b/workspace/src/core/plugins/execution_architecture/langchain_integration.py
@@ -174,21 +174,34 @@ class ReActAgentBuilder:
                 # Step 2: Action - Select tool (simplified)
                 if agent["tools"]:
                     selected_tool = agent["tools"][0]
-                    action = {"tool": selected_tool.name, "tool_input": {"query": current_input}}
+                    action = {
+                        "tool": selected_tool.name,
+                        "tool_input": {"query": current_input},
+                    }
                     intermediate_steps.append(
-                        {"type": "action", "content": action, "iteration": iteration + 1}
+                        {
+                            "type": "action",
+                            "content": action,
+                            "iteration": iteration + 1,
+                        }
                     )
 
                     # Step 3: Observation - Execute tool
                     if selected_tool.coroutine:
-                        observation = await selected_tool.coroutine(action["tool_input"])
+                        observation = await selected_tool.coroutine(
+                            action["tool_input"]
+                        )
                     elif selected_tool.func:
                         observation = selected_tool.func(action["tool_input"])
                     else:
                         observation = f"Tool {selected_tool.name} executed (simulated)"
 
                     intermediate_steps.append(
-                        {"type": "observation", "content": observation, "iteration": iteration + 1}
+                        {
+                            "type": "observation",
+                            "content": observation,
+                            "iteration": iteration + 1,
+                        }
                     )
 
                     # Check if task is complete
@@ -278,7 +291,9 @@ class ChainBuilder:
         self._chains[chain_name].append(step)
         return self
 
-    async def run_chain(self, chain_name: str, initial_input: dict[str, Any]) -> dict[str, Any]:
+    async def run_chain(
+        self, chain_name: str, initial_input: dict[str, Any]
+    ) -> dict[str, Any]:
         """Run a chain of tools"""
         if chain_name not in self._chains:
             return {"error": f"Chain not found: {chain_name}"}
@@ -301,17 +316,27 @@ class ChainBuilder:
             # Execute step
             try:
                 if self.tool_executor:
-                    result = await self.tool_executor.execute(step.tool_name, step_input)
+                    result = await self.tool_executor.execute(
+                        step.tool_name, step_input
+                    )
                     step_output = result.output if hasattr(result, "output") else result
                 else:
                     step_output = f"Executed {step.tool_name} (simulated)"
 
                 context[step.output_key] = step_output
-                results.append({"tool": step.tool_name, "output": step_output, "success": True})
+                results.append(
+                    {"tool": step.tool_name, "output": step_output, "success": True}
+                )
             except Exception as e:
                 if not step.continue_on_error:
-                    return {"error": str(e), "failed_at": step.tool_name, "results": results}
-                results.append({"tool": step.tool_name, "error": str(e), "success": False})
+                    return {
+                        "error": str(e),
+                        "failed_at": step.tool_name,
+                        "results": results,
+                    }
+                results.append(
+                    {"tool": step.tool_name, "error": str(e), "success": False}
+                )
 
         return {"success": True, "results": results, "final_context": context}
 
diff --git a/workspace/src/core/plugins/execution_architecture/mcp_integration.py b/workspace/src/core/plugins/execution_architecture/mcp_integration.py
index f5b73ce..bcfde93 100644
--- a/workspace/src/core/plugins/execution_architecture/mcp_integration.py
+++ b/workspace/src/core/plugins/execution_architecture/mcp_integration.py
@@ -121,7 +121,9 @@ class MCPToolProvider:
         count = 0
         for tool in tool_registry.list_all():
             mcp_tool = MCPTool(
-                name=tool.name, description=tool.description, input_schema=tool.input_schema
+                name=tool.name,
+                description=tool.description,
+                input_schema=tool.input_schema,
             )
             self.register_tool(mcp_tool, tool.execute)
             count += 1
@@ -139,13 +141,17 @@ class MCPToolProvider:
         """Handle a tool call request"""
         if call.name not in self._tools:
             return MCPToolResult(
-                call_id=call.call_id, success=False, error=f"Tool not found: {call.name}"
+                call_id=call.call_id,
+                success=False,
+                error=f"Tool not found: {call.name}",
             )
 
         handler = self._handlers.get(call.name)
         if not handler:
             return MCPToolResult(
-                call_id=call.call_id, success=False, error=f"No handler for tool: {call.name}"
+                call_id=call.call_id,
+                success=False,
+                error=f"No handler for tool: {call.name}",
             )
 
         try:
@@ -167,13 +173,21 @@ class MCPToolProvider:
         """Handle an incoming MCP message"""
         msg_type = message.get("type", "")
 
-        if msg_type == MCPMessageType.TOOL_LIST.value or message.get("method") == "tools/list":
+        if (
+            msg_type == MCPMessageType.TOOL_LIST.value
+            or message.get("method") == "tools/list"
+        ):
             return self.handle_list_tools()
 
-        elif msg_type == MCPMessageType.TOOL_CALL.value or message.get("method") == "tools/call":
+        elif (
+            msg_type == MCPMessageType.TOOL_CALL.value
+            or message.get("method") == "tools/call"
+        ):
             call = MCPToolCall(
                 name=message.get("name", message.get("params", {}).get("name", "")),
-                arguments=message.get("arguments", message.get("params", {}).get("arguments", {})),
+                arguments=message.get(
+                    "arguments", message.get("params", {}).get("arguments", {})
+                ),
                 call_id=message.get("id", str(uuid.uuid4())),
             )
             result = await self.handle_tool_call(call)
@@ -263,7 +277,9 @@ class MCPToolConsumer:
 
     def get_all_tools(self) -> dict[str, list[MCPTool]]:
         """Get all tools from all servers"""
-        return {server: list(tools.values()) for server, tools in self._remote_tools.items()}
+        return {
+            server: list(tools.values()) for server, tools in self._remote_tools.items()
+        }
 
     def find_tool(self, tool_name: str) -> tuple[str, MCPTool] | None:
         """Find a tool across all servers"""
@@ -314,7 +330,9 @@ class MCPBridge:
     """
 
     def __init__(
-        self, provider: MCPToolProvider | None = None, consumer: MCPToolConsumer | None = None
+        self,
+        provider: MCPToolProvider | None = None,
+        consumer: MCPToolConsumer | None = None,
     ):
         self.provider = provider or MCPToolProvider()
         self.consumer = consumer or MCPToolConsumer()
@@ -356,12 +374,17 @@ class MCPBridge:
             return await self.consumer.call_tool(server_name, tool_name, arguments)
 
         return MCPToolResult(
-            call_id=str(uuid.uuid4()), success=False, error=f"Tool not found: {tool_name}"
+            call_id=str(uuid.uuid4()),
+            success=False,
+            error=f"Tool not found: {tool_name}",
         )
 
     def get_all_tools(self) -> dict[str, Any]:
         """Get all available tools (local and remote)"""
-        return {"local": self.provider.get_tool_list(), "remote": self.consumer.get_all_tools()}
+        return {
+            "local": self.provider.get_tool_list(),
+            "remote": self.consumer.get_all_tools(),
+        }
 
     def get_provider(self) -> MCPToolProvider:
         """Get the tool provider"""
diff --git a/workspace/src/core/plugins/execution_architecture/tool_system.py b/workspace/src/core/plugins/execution_architecture/tool_system.py
index 704a0e2..4d95f6b 100644
--- a/workspace/src/core/plugins/execution_architecture/tool_system.py
+++ b/workspace/src/core/plugins/execution_architecture/tool_system.py
@@ -143,7 +143,9 @@ class Tool:
             if key in properties:
                 expected_type = properties[key].get("type")
                 if expected_type and not self._check_type(value, expected_type):
-                    raise ValueError(f"Invalid type for {key}: expected {expected_type}")
+                    raise ValueError(
+                        f"Invalid type for {key}: expected {expected_type}"
+                    )
 
     def _check_type(self, value: Any, expected_type: str) -> bool:
         """Check if value matches expected JSON Schema type"""
@@ -188,7 +190,9 @@ class ToolRegistry:
 
     def __init__(self):
         self._tools: dict[str, Tool] = {}
-        self._categories: dict[ToolCategory, list[str]] = {cat: [] for cat in ToolCategory}
+        self._categories: dict[ToolCategory, list[str]] = {
+            cat: [] for cat in ToolCategory
+        }
         self._tags: dict[str, list[str]] = {}
 
     def register(self, tool: Tool) -> None:
@@ -239,7 +243,10 @@ class ToolRegistry:
         query_lower = query.lower()
         results = []
         for tool in self._tools.values():
-            if query_lower in tool.name.lower() or query_lower in tool.description.lower():
+            if (
+                query_lower in tool.name.lower()
+                or query_lower in tool.description.lower()
+            ):
                 results.append(tool)
         return results
 
@@ -265,7 +272,9 @@ class ToolExecutor:
         tool = self.registry.get(tool_name)
         if not tool:
             return ToolResult(
-                tool_name=tool_name, status=ToolStatus.FAILURE, error=f"Tool not found: {tool_name}"
+                tool_name=tool_name,
+                status=ToolStatus.FAILURE,
+                error=f"Tool not found: {tool_name}",
             )
 
         attempts = tool.max_retries if retry_on_failure else 1
@@ -290,7 +299,10 @@ class ToolExecutor:
     ) -> list[ToolResult]:
         """Execute multiple tools"""
         if parallel:
-            tasks = [self.execute(call["tool_name"], call.get("params", {})) for call in tool_calls]
+            tasks = [
+                self.execute(call["tool_name"], call.get("params", {}))
+                for call in tool_calls
+            ]
             return await asyncio.gather(*tasks)
         else:
             results = []
diff --git a/workspace/src/core/plugins/execution_engine/action_executor.py b/workspace/src/core/plugins/execution_engine/action_executor.py
index 581f42f..e678f14 100644
--- a/workspace/src/core/plugins/execution_engine/action_executor.py
+++ b/workspace/src/core/plugins/execution_engine/action_executor.py
@@ -293,12 +293,16 @@ class ActionExecutor:
             # æª¢æŸ¥æ˜¯å¦æœ‰å¤±æ•—
             if plan.stop_on_failure:
                 failed = any(
-                    r.status == StepStatus.FAILED for r in results if isinstance(r, StepResult)
+                    r.status == StepStatus.FAILED
+                    for r in results
+                    if isinstance(r, StepResult)
                 )
                 if failed:
                     break
 
-    def _build_execution_layers(self, steps: list[ActionStep]) -> list[list[ActionStep]]:
+    def _build_execution_layers(
+        self, steps: list[ActionStep]
+    ) -> list[list[ActionStep]]:
         """æ§‹å»ºåŸ·è¡Œå±¤æ¬¡ï¼ˆæŒ‰ä¾è³´é—œä¿‚ï¼‰"""
 
         # è¨ˆç®—æ¯å€‹æ­¥é©Ÿçš„ä¾è³´æ•¸
@@ -350,7 +354,9 @@ class ActionExecutor:
 
         try:
             # ç²å–è™•ç†å™¨
-            handler = step.handler or self._handlers.get(step.name, self._handlers["default"])
+            handler = step.handler or self._handlers.get(
+                step.name, self._handlers["default"]
+            )
 
             # åŸ·è¡Œè™•ç†å™¨
             output = await self._safe_call(handler, step.params, completed_steps)
@@ -377,14 +383,18 @@ class ActionExecutor:
 
         finally:
             step.completed_at = datetime.now()
-            step.duration_ms = int((step.completed_at - step.started_at).total_seconds() * 1000)
+            step.duration_ms = int(
+                (step.completed_at - step.started_at).total_seconds() * 1000
+            )
 
             result.completed_at = step.completed_at
             result.duration_ms = step.duration_ms
 
         return result
 
-    def _check_dependencies(self, step: ActionStep, completed_steps: dict[str, StepResult]) -> bool:
+    def _check_dependencies(
+        self, step: ActionStep, completed_steps: dict[str, StepResult]
+    ) -> bool:
         """æª¢æŸ¥æ­¥é©Ÿä¾è³´æ˜¯å¦æ»¿è¶³"""
 
         for dep_id in step.depends_on:
@@ -460,7 +470,9 @@ class ActionExecutor:
 
         return True
 
-    def create_plan(self, name: str, steps: list[dict[str, Any]], **kwargs) -> ActionPlan:
+    def create_plan(
+        self, name: str, steps: list[dict[str, Any]], **kwargs
+    ) -> ActionPlan:
         """
         å‰µå»ºè¡Œå‹•è¨ˆåŠƒ
 
diff --git a/workspace/src/core/plugins/execution_engine/capability_registry.py b/workspace/src/core/plugins/execution_engine/capability_registry.py
index 2e58d26..4b74694 100644
--- a/workspace/src/core/plugins/execution_engine/capability_registry.py
+++ b/workspace/src/core/plugins/execution_engine/capability_registry.py
@@ -316,7 +316,9 @@ class CapabilityRegistry:
     def get_by_category(self, category: str) -> list[Capability]:
         """æŒ‰é¡åˆ¥ç²å–èƒ½åŠ›"""
         names = self._category_index.get(category, set())
-        return [self._capabilities[name] for name in names if name in self._capabilities]
+        return [
+            self._capabilities[name] for name in names if name in self._capabilities
+        ]
 
     def get_all(self) -> list[Capability]:
         """ç²å–æ‰€æœ‰èƒ½åŠ›"""
@@ -325,7 +327,9 @@ class CapabilityRegistry:
     def get_available(self) -> list[Capability]:
         """ç²å–æ‰€æœ‰å¯ç”¨èƒ½åŠ›"""
         return [
-            cap for cap in self._capabilities.values() if cap.status == CapabilityStatus.AVAILABLE
+            cap
+            for cap in self._capabilities.values()
+            if cap.status == CapabilityStatus.AVAILABLE
         ]
 
     def check_requirements(self, name: str) -> dict[str, Any]:
@@ -447,7 +451,11 @@ class CapabilityRegistry:
 
         total = len(self._capabilities)
         available = len(
-            [c for c in self._capabilities.values() if c.status == CapabilityStatus.AVAILABLE]
+            [
+                c
+                for c in self._capabilities.values()
+                if c.status == CapabilityStatus.AVAILABLE
+            ]
         )
 
         return {
diff --git a/workspace/src/core/plugins/execution_engine/connector_manager.py b/workspace/src/core/plugins/execution_engine/connector_manager.py
index 029d4bb..67e99c7 100644
--- a/workspace/src/core/plugins/execution_engine/connector_manager.py
+++ b/workspace/src/core/plugins/execution_engine/connector_manager.py
@@ -166,7 +166,10 @@ class ConnectorManager:
         self._factories[ConnectorType.MESSAGE_QUEUE] = self._create_mq_connector
 
     async def create(
-        self, name: str, connector_type: ConnectorType, config: ConnectionConfig | None = None
+        self,
+        name: str,
+        connector_type: ConnectorType,
+        config: ConnectionConfig | None = None,
     ) -> Connector:
         """
         å‰µå»ºé€£æ¥å™¨
@@ -307,7 +310,9 @@ class ConnectorManager:
                 return True
 
             # ç­‰å¾…é‡è©¦
-            delay = config.retry_delay_seconds * (config.retry_backoff_multiplier**attempt)
+            delay = config.retry_delay_seconds * (
+                config.retry_backoff_multiplier**attempt
+            )
             await asyncio.sleep(delay)
 
         return False
@@ -338,7 +343,11 @@ class ConnectorManager:
 
     def get_connected(self) -> list[Connector]:
         """ç²å–æ‰€æœ‰å·²é€£æ¥çš„é€£æ¥å™¨"""
-        return [c for c in self._connectors.values() if c.status == ConnectionStatus.CONNECTED]
+        return [
+            c
+            for c in self._connectors.values()
+            if c.status == ConnectionStatus.CONNECTED
+        ]
 
     async def remove(self, name: str) -> bool:
         """
@@ -371,7 +380,9 @@ class ConnectorManager:
 
         return True
 
-    async def execute(self, name: str, operation: str, params: dict[str, Any]) -> dict[str, Any]:
+    async def execute(
+        self, name: str, operation: str, params: dict[str, Any]
+    ) -> dict[str, Any]:
         """
         é€šéé€£æ¥å™¨åŸ·è¡Œæ“ä½œ
 
@@ -414,7 +425,9 @@ class ConnectorManager:
             # æ›´æ–°å¹³å‡å»¶é²
             total = connector.total_requests
             current_avg = connector.average_latency_ms
-            connector.average_latency_ms = (current_avg * (total - 1) + latency_ms) / total
+            connector.average_latency_ms = (
+                current_avg * (total - 1) + latency_ms
+            ) / total
 
             return {
                 "success": True,
@@ -527,23 +540,33 @@ class ConnectorManager:
 
         total = len(self._connectors)
         connected = len(
-            [c for c in self._connectors.values() if c.status == ConnectionStatus.CONNECTED]
+            [
+                c
+                for c in self._connectors.values()
+                if c.status == ConnectionStatus.CONNECTED
+            ]
         )
         healthy = len([c for c in self._connectors.values() if c.is_healthy])
 
         total_requests = sum(c.total_requests for c in self._connectors.values())
-        successful_requests = sum(c.successful_requests for c in self._connectors.values())
+        successful_requests = sum(
+            c.successful_requests for c in self._connectors.values()
+        )
 
         return {
             "total_connectors": total,
             "connected_connectors": connected,
             "healthy_connectors": healthy,
             "disconnected_connectors": total - connected,
-            "connectors_by_type": {t.value: len(names) for t, names in self._type_index.items()},
+            "connectors_by_type": {
+                t.value: len(names) for t, names in self._type_index.items()
+            },
             "total_requests": total_requests,
             "successful_requests": successful_requests,
             "success_rate": (
-                round(successful_requests / total_requests, 4) * 100 if total_requests > 0 else 0
+                round(successful_requests / total_requests, 4) * 100
+                if total_requests > 0
+                else 0
             ),
         }
 
@@ -570,7 +593,9 @@ class ConnectorManager:
 
     # ============ é»˜èªé€£æ¥å·¥å»  ============
 
-    async def _create_database_connector(self, config: ConnectionConfig) -> dict[str, Any]:
+    async def _create_database_connector(
+        self, config: ConnectionConfig
+    ) -> dict[str, Any]:
         """å‰µå»ºæ•¸æ“šåº«é€£æ¥å™¨"""
         return {
             "type": "database",
@@ -587,7 +612,9 @@ class ConnectorManager:
             "timeout": config.read_timeout_seconds,
         }
 
-    async def _create_kubernetes_connector(self, config: ConnectionConfig) -> dict[str, Any]:
+    async def _create_kubernetes_connector(
+        self, config: ConnectionConfig
+    ) -> dict[str, Any]:
         """å‰µå»º Kubernetes é€£æ¥å™¨"""
         return {
             "type": "kubernetes",
@@ -595,14 +622,18 @@ class ConnectorManager:
             "namespace": config.extra.get("namespace", "default"),
         }
 
-    async def _create_docker_connector(self, config: ConnectionConfig) -> dict[str, Any]:
+    async def _create_docker_connector(
+        self, config: ConnectionConfig
+    ) -> dict[str, Any]:
         """å‰µå»º Docker é€£æ¥å™¨"""
         return {
             "type": "docker",
             "socket": config.extra.get("socket", "/var/run/docker.sock"),
         }
 
-    async def _create_filesystem_connector(self, config: ConnectionConfig) -> dict[str, Any]:
+    async def _create_filesystem_connector(
+        self, config: ConnectionConfig
+    ) -> dict[str, Any]:
         """å‰µå»ºæ–‡ä»¶ç³»çµ±é€£æ¥å™¨"""
         return {
             "type": "filesystem",
diff --git a/workspace/src/core/plugins/execution_engine/execution_engine.py b/workspace/src/core/plugins/execution_engine/execution_engine.py
index 3092464..c043187 100644
--- a/workspace/src/core/plugins/execution_engine/execution_engine.py
+++ b/workspace/src/core/plugins/execution_engine/execution_engine.py
@@ -222,11 +222,15 @@ class ExecutionEngine:
 
             # éšæ®µ 2ï¼šåŸ·è¡Œå‰ç½®è™•ç†
             for pre_processor in self._pre_processors:
-                await self._safe_call(pre_processor, action_type, action_params, context)
+                await self._safe_call(
+                    pre_processor, action_type, action_params, context
+                )
 
             # éšæ®µ 3ï¼šæ§‹å»ºåŸ·è¡Œè¨ˆåŠƒ
             result.status = ExecutionStatus.PLANNING
-            execution_plan = await self._build_execution_plan(action_type, action_params, context)
+            execution_plan = await self._build_execution_plan(
+                action_type, action_params, context
+            )
             result.steps_total = len(execution_plan.get("steps", []))
 
             # éšæ®µ 4ï¼šåŸ·è¡Œè¡Œå‹•ï¼ˆæˆ–æ¨¡æ“¬åŸ·è¡Œï¼‰
@@ -234,7 +238,9 @@ class ExecutionEngine:
 
             if context.dry_run:
                 # æ¨¡æ“¬åŸ·è¡Œ
-                output = await self._simulate_execution(action_type, action_params, execution_plan)
+                output = await self._simulate_execution(
+                    action_type, action_params, execution_plan
+                )
             else:
                 # å¯¦éš›åŸ·è¡Œ
                 output = await self._execute_action(
@@ -246,7 +252,9 @@ class ExecutionEngine:
 
             # éšæ®µ 5ï¼šé©—è­‰åŸ·è¡Œçµæœ
             result.status = ExecutionStatus.VERIFYING
-            verification = await self._verify_execution(action_type, action_params, output, context)
+            verification = await self._verify_execution(
+                action_type, action_params, output, context
+            )
             result.verification_passed = verification.get("passed", False)
             result.verification_details = verification
 
@@ -276,12 +284,16 @@ class ExecutionEngine:
             }
 
             # è¨˜éŒ„å­¸ç¿’ç¶“é©—
-            result.lessons_learned.append(f"Execution failed due to: {type(e).__name__}: {str(e)}")
+            result.lessons_learned.append(
+                f"Execution failed due to: {type(e).__name__}: {str(e)}"
+            )
 
         finally:
             # è¨˜éŒ„å®Œæˆæ™‚é–“
             result.completed_at = datetime.now()
-            result.duration_ms = int((result.completed_at - started_at).total_seconds() * 1000)
+            result.duration_ms = int(
+                (result.completed_at - started_at).total_seconds() * 1000
+            )
 
             # æ›´æ–°çµ±è¨ˆ
             self._update_stats(result)
@@ -292,7 +304,10 @@ class ExecutionEngine:
         return result
 
     async def _validate_capability(
-        self, action_type: ActionType, action_params: dict[str, Any], context: ExecutionContext
+        self,
+        action_type: ActionType,
+        action_params: dict[str, Any],
+        context: ExecutionContext,
     ) -> bool:
         """é©—è­‰åŸ·è¡Œèƒ½åŠ› - ç¢ºä¿æˆ‘å€‘çœŸçš„èƒ½åŸ·è¡Œé€™å€‹è¡Œå‹•"""
 
@@ -301,7 +316,9 @@ class ExecutionEngine:
             raise ValueError(f"No executor registered for action type: {action_type}")
 
         # æª¢æŸ¥æ¬Šé™
-        required_permissions = self._get_required_permissions(action_type, action_params)
+        required_permissions = self._get_required_permissions(
+            action_type, action_params
+        )
         for perm in required_permissions:
             if perm not in context.permissions:
                 raise PermissionError(f"Missing required permission: {perm}")
@@ -322,7 +339,10 @@ class ExecutionEngine:
         return True
 
     async def _build_execution_plan(
-        self, action_type: ActionType, action_params: dict[str, Any], context: ExecutionContext
+        self,
+        action_type: ActionType,
+        action_params: dict[str, Any],
+        context: ExecutionContext,
     ) -> dict[str, Any]:
         """æ§‹å»ºåŸ·è¡Œè¨ˆåŠƒ"""
 
@@ -597,7 +617,10 @@ class ExecutionEngine:
         return await executor(action_params, context, execution_plan)
 
     async def _simulate_execution(
-        self, action_type: ActionType, action_params: dict[str, Any], execution_plan: dict[str, Any]
+        self,
+        action_type: ActionType,
+        action_params: dict[str, Any],
+        execution_plan: dict[str, Any],
     ) -> dict[str, Any]:
         """æ¨¡æ“¬åŸ·è¡Œï¼ˆDry Runï¼‰"""
 
@@ -702,7 +725,9 @@ class ExecutionEngine:
 
         return rollback_result
 
-    async def _execute_rollback_step(self, step: dict[str, Any], context: ExecutionContext):
+    async def _execute_rollback_step(
+        self, step: dict[str, Any], context: ExecutionContext
+    ):
         """åŸ·è¡Œå–®å€‹å›æ»¾æ­¥é©Ÿ"""
         # æ¨¡æ“¬å›æ»¾åŸ·è¡Œ
         await asyncio.sleep(0.01)
@@ -891,7 +916,9 @@ class ExecutionEngine:
         """è¨»å†Šé€£æ¥å™¨"""
         self._connectors[name] = connector
 
-    def register_capability_validator(self, action_type: ActionType, validator: Callable):
+    def register_capability_validator(
+        self, action_type: ActionType, validator: Callable
+    ):
         """è¨»å†Šèƒ½åŠ›é©—è­‰å™¨"""
         self._capability_validators[action_type] = validator
 
diff --git a/workspace/src/core/plugins/execution_engine/rollback_manager.py b/workspace/src/core/plugins/execution_engine/rollback_manager.py
index 987b59d..913818f 100644
--- a/workspace/src/core/plugins/execution_engine/rollback_manager.py
+++ b/workspace/src/core/plugins/execution_engine/rollback_manager.py
@@ -221,7 +221,11 @@ class RollbackManager:
         """ç²å–åŸ·è¡Œç›¸é—œçš„æ‰€æœ‰æª¢æŸ¥é»"""
 
         checkpoint_ids = self._execution_checkpoints.get(execution_id, [])
-        return [self._checkpoints[cp_id] for cp_id in checkpoint_ids if cp_id in self._checkpoints]
+        return [
+            self._checkpoints[cp_id]
+            for cp_id in checkpoint_ids
+            if cp_id in self._checkpoints
+        ]
 
     def delete_checkpoint(self, checkpoint_id: str) -> bool:
         """åˆªé™¤æª¢æŸ¥é»"""
@@ -233,13 +237,17 @@ class RollbackManager:
 
         # æ›´æ–°åŸ·è¡Œç´¢å¼•
         if checkpoint.execution_id:
-            exec_checkpoints = self._execution_checkpoints.get(checkpoint.execution_id, [])
+            exec_checkpoints = self._execution_checkpoints.get(
+                checkpoint.execution_id, []
+            )
             if checkpoint_id in exec_checkpoints:
                 exec_checkpoints.remove(checkpoint_id)
 
         return True
 
-    def cleanup_old_checkpoints(self, max_age_hours: int = 24, max_count: int = 1000) -> int:
+    def cleanup_old_checkpoints(
+        self, max_age_hours: int = 24, max_count: int = 1000
+    ) -> int:
         """
         æ¸…ç†èˆŠæª¢æŸ¥é»
 
@@ -255,7 +263,9 @@ class RollbackManager:
         deleted = 0
 
         # æŒ‰æ™‚é–“æ’åº
-        sorted_checkpoints = sorted(self._checkpoints.values(), key=lambda c: c.created_at)
+        sorted_checkpoints = sorted(
+            self._checkpoints.values(), key=lambda c: c.created_at
+        )
 
         for checkpoint in sorted_checkpoints:
             # æª¢æŸ¥å¹´é½¡
@@ -317,7 +327,9 @@ class RollbackManager:
         return plan
 
     async def rollback_execution(
-        self, execution_id: str, strategy: RollbackStrategy = RollbackStrategy.INCREMENTAL
+        self,
+        execution_id: str,
+        strategy: RollbackStrategy = RollbackStrategy.INCREMENTAL,
     ) -> RollbackPlan:
         """
         å›æ»¾æ•´å€‹åŸ·è¡Œ
@@ -349,7 +361,9 @@ class RollbackManager:
         )
 
         # æŒ‰æ™‚é–“é€†åºè™•ç†æª¢æŸ¥é»
-        sorted_checkpoints = sorted(checkpoints, key=lambda c: c.created_at, reverse=True)
+        sorted_checkpoints = sorted(
+            checkpoints, key=lambda c: c.created_at, reverse=True
+        )
 
         # æ§‹å»ºå›æ»¾æ­¥é©Ÿ
         for checkpoint in sorted_checkpoints:
diff --git a/workspace/src/core/plugins/execution_engine/verification_engine.py b/workspace/src/core/plugins/execution_engine/verification_engine.py
index a470288..f457a0d 100644
--- a/workspace/src/core/plugins/execution_engine/verification_engine.py
+++ b/workspace/src/core/plugins/execution_engine/verification_engine.py
@@ -176,7 +176,9 @@ class VerificationEngine:
                 check = VerificationCheck(
                     name=check_def.get("name", "custom_check"),
                     description=check_def.get("description", ""),
-                    strategy=VerificationStrategy(check_def.get("strategy", "exact_match")),
+                    strategy=VerificationStrategy(
+                        check_def.get("strategy", "exact_match")
+                    ),
                     expected=check_def.get("expected"),
                     actual=check_def.get("actual", actual),
                     severity=VerificationSeverity(check_def.get("severity", "error")),
@@ -189,7 +191,11 @@ class VerificationEngine:
         result.total_checks = len(result.checks)
         result.passed_checks = len([c for c in result.checks if c.passed])
         result.failed_checks = len(
-            [c for c in result.checks if not c.passed and c.severity == VerificationSeverity.ERROR]
+            [
+                c
+                for c in result.checks
+                if not c.passed and c.severity == VerificationSeverity.ERROR
+            ]
         )
         result.warning_checks = len(
             [
@@ -355,7 +361,9 @@ class VerificationEngine:
         # æª¢æŸ¥èªç¾©ç›¸ä¼¼æ€§
         # é€™æ˜¯ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›æ‡‰ä½¿ç”¨ NLP
         return (
-            actual_str == expected_str or expected_str in actual_str or actual_str in expected_str
+            actual_str == expected_str
+            or expected_str in actual_str
+            or actual_str in expected_str
         )
 
     def _statistical_match(self, actual: Any, expected: Any) -> bool:
@@ -391,7 +399,9 @@ class VerificationEngine:
 
         return False
 
-    def verify_output(self, output: Any, rules: list[dict[str, Any]]) -> VerificationResult:
+    def verify_output(
+        self, output: Any, rules: list[dict[str, Any]]
+    ) -> VerificationResult:
         """
         ä½¿ç”¨è¦å‰‡åˆ—è¡¨é©—è­‰è¼¸å‡º
 
@@ -495,7 +505,9 @@ class VerificationEngine:
             value = str(value)
 
         passed = bool(re.match(pattern, value))
-        message = f"Pattern check {'passed' if passed else 'failed'}: " f"pattern={pattern}"
+        message = (
+            f"Pattern check {'passed' if passed else 'failed'}: " f"pattern={pattern}"
+        )
         return passed, message
 
     def _validate_contains(self, value: Any, rule: dict[str, Any]) -> tuple:
@@ -510,7 +522,8 @@ class VerificationEngine:
             passed = False
 
         message = (
-            f"Contains check {'passed' if passed else 'failed'}: " f"expected '{expected}' in value"
+            f"Contains check {'passed' if passed else 'failed'}: "
+            f"expected '{expected}' in value"
         )
         return passed, message
 
diff --git a/workspace/src/core/plugins/main_system/automation_pipeline.py b/workspace/src/core/plugins/main_system/automation_pipeline.py
index 4cd1a0f..e45a5bd 100644
--- a/workspace/src/core/plugins/main_system/automation_pipeline.py
+++ b/workspace/src/core/plugins/main_system/automation_pipeline.py
@@ -201,7 +201,9 @@ class AutomationPipeline:
 
         # Check dependencies
         for i, task in enumerate(self._queue):
-            deps_satisfied = all(dep_id in self._completed for dep_id in task.dependencies)
+            deps_satisfied = all(
+                dep_id in self._completed for dep_id in task.dependencies
+            )
             if deps_satisfied:
                 return self._queue.pop(i)
 
@@ -251,7 +253,9 @@ class AutomationPipeline:
 
         return phases
 
-    def execute_task(self, task: PipelineTask, handler: Callable | None = None) -> TaskResult:
+    def execute_task(
+        self, task: PipelineTask, handler: Callable | None = None
+    ) -> TaskResult:
         """
         Execute a task
 
@@ -265,7 +269,9 @@ class AutomationPipeline:
         self.logger.info(f"Executing task: {task.id}")
 
         started_at = datetime.now()
-        result = TaskResult(task_id=task.id, status=TaskStatus.RUNNING, started_at=started_at)
+        result = TaskResult(
+            task_id=task.id, status=TaskStatus.RUNNING, started_at=started_at
+        )
 
         # Track running task
         self._running[task.id] = task
@@ -308,7 +314,10 @@ class AutomationPipeline:
             self.logger.error(f"Task failed: {task.id} - {e}")
 
             # Retry if enabled
-            if self.config.enable_retries and result.retry_count < self.config.max_retries:
+            if (
+                self.config.enable_retries
+                and result.retry_count < self.config.max_retries
+            ):
                 result.retry_count += 1
                 result.status = TaskStatus.RETRYING
                 self.submit_task(task)
@@ -336,7 +345,10 @@ class AutomationPipeline:
 
         for keyword in dangerous_keywords:
             if keyword in task_str:
-                return {"safe": False, "reason": f"Task contains dangerous keyword: {keyword}"}
+                return {
+                    "safe": False,
+                    "reason": f"Task contains dangerous keyword: {keyword}",
+                }
 
         return {"safe": True, "reason": None}
 
@@ -400,7 +412,9 @@ class AutomationPipeline:
             "completed": len(self._completed),
             "queue_capacity": self.config.queue_size,
             "utilization": (
-                len(self._queue) / self.config.queue_size if self.config.queue_size > 0 else 0
+                len(self._queue) / self.config.queue_size
+                if self.config.queue_size > 0
+                else 0
             ),
         }
 
diff --git a/workspace/src/core/plugins/main_system/phase_orchestrator.py b/workspace/src/core/plugins/main_system/phase_orchestrator.py
index 1f70ed2..62ea5e3 100644
--- a/workspace/src/core/plugins/main_system/phase_orchestrator.py
+++ b/workspace/src/core/plugins/main_system/phase_orchestrator.py
@@ -374,12 +374,16 @@ class PhaseOrchestrator:
             if result.state == PhaseState.FAILED:
                 phase = self._phases.get(phase_id)
                 if phase and phase.enabled:
-                    self.logger.error(f"Stopping execution due to phase failure: {phase_id}")
+                    self.logger.error(
+                        f"Stopping execution due to phase failure: {phase_id}"
+                    )
                     break
 
         return results
 
-    def transition(self, from_phase: str, to_phase: str, trigger: str) -> PhaseTransition:
+    def transition(
+        self, from_phase: str, to_phase: str, trigger: str
+    ) -> PhaseTransition:
         """
         Record a phase transition
 
diff --git a/workspace/src/core/plugins/main_system/synergymesh_core.py b/workspace/src/core/plugins/main_system/synergymesh_core.py
index 4ef7ec7..aabb25c 100644
--- a/workspace/src/core/plugins/main_system/synergymesh_core.py
+++ b/workspace/src/core/plugins/main_system/synergymesh_core.py
@@ -142,7 +142,9 @@ class SynergyMeshCore:
         ]
 
         for phase_id, name, description in phase_definitions:
-            self._phases[phase_id] = PhaseInfo(id=phase_id, name=name, description=description)
+            self._phases[phase_id] = PhaseInfo(
+                id=phase_id, name=name, description=description
+            )
 
     def initialize(self) -> bool:
         """
diff --git a/workspace/src/core/plugins/main_system/system_bootstrap.py b/workspace/src/core/plugins/main_system/system_bootstrap.py
index e1faed9..ea347a5 100644
--- a/workspace/src/core/plugins/main_system/system_bootstrap.py
+++ b/workspace/src/core/plugins/main_system/system_bootstrap.py
@@ -275,7 +275,9 @@ class SystemBootstrap:
             for service_name in order:
                 if not self._initialize_service(service_name):
                     if self.config.fail_fast:
-                        self.logger.error(f"Failed to initialize {service_name}, failing fast")
+                        self.logger.error(
+                            f"Failed to initialize {service_name}, failing fast"
+                        )
                         return False
 
             self._initialized = True
@@ -308,7 +310,11 @@ class SystemBootstrap:
             if definition.config:
                 instance = definition.service_class(**definition.config, **deps)
             else:
-                instance = definition.service_class(**deps) if deps else definition.service_class()
+                instance = (
+                    definition.service_class(**deps)
+                    if deps
+                    else definition.service_class()
+                )
 
             # Register instance
             self.registry.set_instance(name, instance)
@@ -392,7 +398,10 @@ class SystemBootstrap:
 
         # Check service states
         for name, service in self.registry.get_all().items():
-            is_healthy = service.lifecycle in [ServiceLifecycle.READY, ServiceLifecycle.RUNNING]
+            is_healthy = service.lifecycle in [
+                ServiceLifecycle.READY,
+                ServiceLifecycle.RUNNING,
+            ]
             results["services"][name] = {
                 "healthy": is_healthy,
                 "lifecycle": service.lifecycle.value,
diff --git a/workspace/src/core/plugins/mcp_servers_enhanced/__init__.py b/workspace/src/core/plugins/mcp_servers_enhanced/__init__.py
index 6197fbb..f5b1022 100644
--- a/workspace/src/core/plugins/mcp_servers_enhanced/__init__.py
+++ b/workspace/src/core/plugins/mcp_servers_enhanced/__init__.py
@@ -12,9 +12,24 @@ Key Components:
 """
 
 from .mcp_server_manager import MCPServer, MCPServerConfig, MCPServerManager
-from .realtime_connector import ConnectionConfig, ConnectionStatus, RealTimeConnector, TransportType
-from .tool_registry import ToolCategory, ToolDefinition, ToolExecutionResult, ToolRegistry
-from .workflow_orchestrator import Workflow, WorkflowOrchestrator, WorkflowResult, WorkflowStep
+from .realtime_connector import (
+    ConnectionConfig,
+    ConnectionStatus,
+    RealTimeConnector,
+    TransportType,
+)
+from .tool_registry import (
+    ToolCategory,
+    ToolDefinition,
+    ToolExecutionResult,
+    ToolRegistry,
+)
+from .workflow_orchestrator import (
+    Workflow,
+    WorkflowOrchestrator,
+    WorkflowResult,
+    WorkflowStep,
+)
 
 __all__ = [
     "MCPServerManager",
diff --git a/workspace/src/core/plugins/mcp_servers_enhanced/mcp_server_manager.py b/workspace/src/core/plugins/mcp_servers_enhanced/mcp_server_manager.py
index c9d72a0..f58fc8b 100644
--- a/workspace/src/core/plugins/mcp_servers_enhanced/mcp_server_manager.py
+++ b/workspace/src/core/plugins/mcp_servers_enhanced/mcp_server_manager.py
@@ -208,7 +208,9 @@ class MCPServerManager:
             return self._servers.get(server_id)
         return None
 
-    async def execute_tool(self, tool_name: str, arguments: dict[str, Any]) -> dict[str, Any]:
+    async def execute_tool(
+        self, tool_name: str, arguments: dict[str, Any]
+    ) -> dict[str, Any]:
         """
         Execute a tool on the appropriate server
 
@@ -250,7 +252,11 @@ class MCPServerManager:
             if server.status == ServerStatus.HEALTHY:
                 for tool in server.tools:
                     tools.append(
-                        {**tool, "server_id": server.id, "server_name": server.config.name}
+                        {
+                            **tool,
+                            "server_id": server.id,
+                            "server_name": server.config.name,
+                        }
                     )
         return tools
 
@@ -359,8 +365,14 @@ class MCPServerManager:
                     "inputSchema": {
                         "type": "object",
                         "properties": {
-                            "code": {"type": "string", "description": "Source code to analyze"},
-                            "language": {"type": "string", "description": "Programming language"},
+                            "code": {
+                                "type": "string",
+                                "description": "Source code to analyze",
+                            },
+                            "language": {
+                                "type": "string",
+                                "description": "Programming language",
+                            },
                             "metrics": {"type": "array", "items": {"type": "string"}},
                         },
                         "required": ["code"],
@@ -373,7 +385,10 @@ class MCPServerManager:
                         "type": "object",
                         "properties": {
                             "code": {"type": "string"},
-                            "pattern_types": {"type": "array", "items": {"type": "string"}},
+                            "pattern_types": {
+                                "type": "array",
+                                "items": {"type": "string"},
+                            },
                         },
                         "required": ["code"],
                     },
@@ -405,7 +420,10 @@ class MCPServerManager:
                                 "type": "string",
                                 "description": "Package manifest file content",
                             },
-                            "ecosystem": {"type": "string", "enum": ["npm", "pip", "maven", "go"]},
+                            "ecosystem": {
+                                "type": "string",
+                                "enum": ["npm", "pip", "maven", "go"],
+                            },
                         },
                         "required": ["manifest"],
                     },
@@ -431,7 +449,10 @@ class MCPServerManager:
                         "type": "object",
                         "properties": {
                             "provenance": {"type": "object"},
-                            "targetLevel": {"type": "string", "enum": ["1", "2", "3", "4"]},
+                            "targetLevel": {
+                                "type": "string",
+                                "enum": ["1", "2", "3", "4"],
+                            },
                         },
                         "required": ["provenance"],
                     },
@@ -449,7 +470,11 @@ class MCPServerManager:
                                 "type": "string",
                                 "enum": ["jest", "pytest", "mocha", "junit"],
                             },
-                            "coverage_target": {"type": "number", "minimum": 0, "maximum": 100},
+                            "coverage_target": {
+                                "type": "number",
+                                "minimum": 0,
+                                "maximum": 100,
+                            },
                         },
                         "required": ["code"],
                     },
diff --git a/workspace/src/core/plugins/mcp_servers_enhanced/realtime_connector.py b/workspace/src/core/plugins/mcp_servers_enhanced/realtime_connector.py
index da53e95..9194fe1 100644
--- a/workspace/src/core/plugins/mcp_servers_enhanced/realtime_connector.py
+++ b/workspace/src/core/plugins/mcp_servers_enhanced/realtime_connector.py
@@ -82,8 +82,12 @@ class Connection:
             "status": self.status.value,
             "host": self.config.host,
             "port": self.config.port,
-            "last_activity": self.last_activity.isoformat() if self.last_activity else None,
-            "connect_time": self.connect_time.isoformat() if self.connect_time else None,
+            "last_activity": (
+                self.last_activity.isoformat() if self.last_activity else None
+            ),
+            "connect_time": (
+                self.connect_time.isoformat() if self.connect_time else None
+            ),
             "reconnect_count": self.reconnect_count,
             "error_count": self.error_count,
             "messages_sent": self.messages_sent,
@@ -207,7 +211,9 @@ class RealTimeConnector:
             Connection instance
         """
         conn_id = str(uuid4())
-        connection = Connection(id=conn_id, config=config, status=ConnectionStatus.CONNECTING)
+        connection = Connection(
+            id=conn_id, config=config, status=ConnectionStatus.CONNECTING
+        )
 
         self._connections[conn_id] = connection
 
@@ -277,7 +283,9 @@ class RealTimeConnector:
                 return conn
         return None
 
-    def list_connections(self, status: ConnectionStatus | None = None) -> list[Connection]:
+    def list_connections(
+        self, status: ConnectionStatus | None = None
+    ) -> list[Connection]:
         """List all connections, optionally filtered by status"""
         connections = list(self._connections.values())
         if status:
@@ -354,7 +362,9 @@ class RealTimeConnector:
         if connection.status != ConnectionStatus.CONNECTED:
             raise ConnectionError(f"Connection not active: {connection.status.value}")
 
-        message = Message(id=str(uuid4()), type="notification", method=method, params=params)
+        message = Message(
+            id=str(uuid4()), type="notification", method=method, params=params
+        )
 
         await self._send_message(connection, message)
         connection.messages_sent += 1
@@ -405,18 +415,24 @@ class RealTimeConnector:
             pass
 
         # Simulate sending
-        logger.debug(f"Sent message to {connection.config.server_name}: {message.method}")
+        logger.debug(
+            f"Sent message to {connection.config.server_name}: {message.method}"
+        )
 
         # Simulate response for requests
         if message.type == "request":
             asyncio.create_task(self._simulate_response(connection, message))
 
-    async def _simulate_response(self, connection: Connection, request: Message) -> None:
+    async def _simulate_response(
+        self, connection: Connection, request: Message
+    ) -> None:
         """Simulate a response for testing"""
         await asyncio.sleep(0.05)  # Simulate latency
 
         response = Message(
-            id=request.id, type="response", result={"status": "success", "method": request.method}
+            id=request.id,
+            type="response",
+            result={"status": "success", "method": request.method},
         )
 
         await self._handle_response(response)
@@ -427,7 +443,9 @@ class RealTimeConnector:
         future = self._pending_requests.get(message.id)
         if future and not future.done():
             if message.error:
-                future.set_exception(Exception(message.error.get("message", "Unknown error")))
+                future.set_exception(
+                    Exception(message.error.get("message", "Unknown error"))
+                )
             else:
                 future.set_result(message.result)
 
@@ -447,7 +465,9 @@ class RealTimeConnector:
                         connection.id, "ping", {"timestamp": datetime.now().isoformat()}
                     )
                 except Exception as e:
-                    logger.warning(f"Heartbeat failed for {connection.config.server_name}: {e}")
+                    logger.warning(
+                        f"Heartbeat failed for {connection.config.server_name}: {e}"
+                    )
                     connection.error_count += 1
 
                     if connection.error_count >= 3:
@@ -463,7 +483,9 @@ class RealTimeConnector:
     def _schedule_reconnect(self, connection: Connection) -> None:
         """Schedule a reconnection attempt"""
         if connection.reconnect_count >= connection.config.max_reconnect_attempts:
-            logger.error(f"Max reconnect attempts reached for {connection.config.server_name}")
+            logger.error(
+                f"Max reconnect attempts reached for {connection.config.server_name}"
+            )
             return
 
         connection.status = ConnectionStatus.RECONNECTING
@@ -483,7 +505,9 @@ class RealTimeConnector:
                 logger.info(f"Reconnected to {connection.config.server_name}")
 
             except Exception as e:
-                logger.error(f"Reconnect failed for {connection.config.server_name}: {e}")
+                logger.error(
+                    f"Reconnect failed for {connection.config.server_name}: {e}"
+                )
                 self._schedule_reconnect(connection)
 
         self._reconnect_tasks[connection.id] = asyncio.create_task(reconnect())
diff --git a/workspace/src/core/plugins/mcp_servers_enhanced/tool_registry.py b/workspace/src/core/plugins/mcp_servers_enhanced/tool_registry.py
index 0b0941d..d352bdf 100644
--- a/workspace/src/core/plugins/mcp_servers_enhanced/tool_registry.py
+++ b/workspace/src/core/plugins/mcp_servers_enhanced/tool_registry.py
@@ -100,7 +100,9 @@ class ToolDefinition:
 
         return {"valid": len(errors) == 0, "errors": errors}
 
-    def _validate_type(self, field_name: str, value: Any, schema: dict[str, Any]) -> str | None:
+    def _validate_type(
+        self, field_name: str, value: Any, schema: dict[str, Any]
+    ) -> str | None:
         """Validate a single field type"""
         expected_type = schema.get("type")
 
@@ -216,7 +218,9 @@ class ToolRegistry:
                 self._server_index[tool.server_name].remove(tool_name)
 
         # Remove aliases
-        aliases_to_remove = [alias for alias, name in self._aliases.items() if name == tool_name]
+        aliases_to_remove = [
+            alias for alias, name in self._aliases.items() if name == tool_name
+        ]
         for alias in aliases_to_remove:
             del self._aliases[alias]
 
@@ -307,12 +311,17 @@ class ToolRegistry:
                 continue
 
             # Search in name and description
-            if query_lower in tool.name.lower() or query_lower in tool.description.lower():
+            if (
+                query_lower in tool.name.lower()
+                or query_lower in tool.description.lower()
+            ):
                 results.append(tool)
 
         return results
 
-    def validate_arguments(self, tool_name: str, arguments: dict[str, Any]) -> dict[str, Any]:
+    def validate_arguments(
+        self, tool_name: str, arguments: dict[str, Any]
+    ) -> dict[str, Any]:
         """
         Validate arguments for a tool
 
@@ -375,7 +384,10 @@ def get_default_tool_definitions() -> list[ToolDefinition]:
                 "type": "object",
                 "properties": {
                     "code": {"type": "string", "description": "Source code to analyze"},
-                    "language": {"type": "string", "description": "Programming language"},
+                    "language": {
+                        "type": "string",
+                        "description": "Programming language",
+                    },
                     "metrics": {
                         "type": "array",
                         "items": {"type": "string"},
@@ -425,7 +437,10 @@ def get_default_tool_definitions() -> list[ToolDefinition]:
                 "type": "object",
                 "properties": {
                     "code": {"type": "string"},
-                    "framework": {"type": "string", "enum": ["jest", "pytest", "mocha", "junit"]},
+                    "framework": {
+                        "type": "string",
+                        "enum": ["jest", "pytest", "mocha", "junit"],
+                    },
                     "coverage_target": {"type": "number", "minimum": 0, "maximum": 100},
                 },
                 "required": ["code"],
diff --git a/workspace/src/core/plugins/mcp_servers_enhanced/workflow_orchestrator.py b/workspace/src/core/plugins/mcp_servers_enhanced/workflow_orchestrator.py
index da5e996..cbe8f9d 100644
--- a/workspace/src/core/plugins/mcp_servers_enhanced/workflow_orchestrator.py
+++ b/workspace/src/core/plugins/mcp_servers_enhanced/workflow_orchestrator.py
@@ -101,7 +101,9 @@ class StepResult:
             "duration_ms": self.duration_ms,
             "attempts": self.attempts,
             "started_at": self.started_at.isoformat() if self.started_at else None,
-            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
+            "completed_at": (
+                self.completed_at.isoformat() if self.completed_at else None
+            ),
         }
 
 
@@ -129,7 +131,9 @@ class WorkflowResult:
             "steps": [s.to_dict() for s in self.steps],
             "total_duration_ms": self.total_duration_ms,
             "started_at": self.started_at.isoformat() if self.started_at else None,
-            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
+            "completed_at": (
+                self.completed_at.isoformat() if self.completed_at else None
+            ),
             "output": self.output,
             "error": self.error,
             "metadata": self.metadata,
@@ -244,7 +248,8 @@ class WorkflowOrchestrator:
             # Check if all steps succeeded
             failed_steps = [s for s in step_results if s.status == StepStatus.FAILED]
             if failed_steps and not all(
-                self._get_step(workflow, s.step_id).continue_on_failure for s in failed_steps
+                self._get_step(workflow, s.step_id).continue_on_failure
+                for s in failed_steps
             ):
                 result.status = WorkflowStatus.FAILED
                 result.error = f"{len(failed_steps)} step(s) failed"
@@ -313,7 +318,9 @@ class WorkflowOrchestrator:
             self._event_handlers[event] = []
         self._event_handlers[event].append(handler)
 
-    async def _execute_steps(self, workflow: Workflow, context: dict[str, Any]) -> list[StepResult]:
+    async def _execute_steps(
+        self, workflow: Workflow, context: dict[str, Any]
+    ) -> list[StepResult]:
         """Execute all steps in a workflow"""
         results: dict[str, StepResult] = {}
         completed: set[str] = set()
@@ -322,7 +329,9 @@ class WorkflowOrchestrator:
         while pending_steps:
             # Find steps that can be executed (all dependencies met)
             ready_steps = [
-                step for step in pending_steps if all(dep in completed for dep in step.dependencies)
+                step
+                for step in pending_steps
+                if all(dep in completed for dep in step.dependencies)
             ]
 
             if not ready_steps:
@@ -339,7 +348,9 @@ class WorkflowOrchestrator:
             # Execute ready steps in parallel (with limit)
             parallel_batch = ready_steps[: workflow.max_parallel]
 
-            batch_tasks = [self._execute_step(step, context, results) for step in parallel_batch]
+            batch_tasks = [
+                self._execute_step(step, context, results) for step in parallel_batch
+            ]
 
             batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
 
@@ -365,7 +376,10 @@ class WorkflowOrchestrator:
         return list(results.values())
 
     async def _execute_step(
-        self, step: WorkflowStep, context: dict[str, Any], previous_results: dict[str, StepResult]
+        self,
+        step: WorkflowStep,
+        context: dict[str, Any],
+        previous_results: dict[str, StepResult],
     ) -> StepResult:
         """Execute a single workflow step"""
         result = StepResult(
@@ -393,7 +407,8 @@ class WorkflowOrchestrator:
             try:
                 start_time = datetime.now()
                 tool_result = await asyncio.wait_for(
-                    self._tool_executor(step.tool, arguments), timeout=step.timeout / 1000.0
+                    self._tool_executor(step.tool, arguments),
+                    timeout=step.timeout / 1000.0,
                 )
                 end_time = datetime.now()
 
@@ -473,7 +488,9 @@ class WorkflowOrchestrator:
                 condition = condition.replace(f"${{{key}}}", repr(value))
             # Basic safety check - only allow simple comparisons
             allowed_chars = set("0123456789.!=<>andornotTrueFalse\"' ")
-            if not all(c in allowed_chars or c.isalnum() or c == "_" for c in condition):
+            if not all(
+                c in allowed_chars or c.isalnum() or c == "_" for c in condition
+            ):
                 logger.warning(f"Unsafe condition blocked: {condition}")
                 return True
             # For framework demonstration, return True
@@ -489,7 +506,11 @@ class WorkflowOrchestrator:
         """Substitute context values into arguments"""
         result = {}
         for key, value in arguments.items():
-            if isinstance(value, str) and value.startswith("${") and value.endswith("}"):
+            if (
+                isinstance(value, str)
+                and value.startswith("${")
+                and value.endswith("}")
+            ):
                 # Context reference
                 ref = value[2:-1]
                 result[key] = context.get(ref, value)
@@ -532,7 +553,9 @@ class WorkflowOrchestrator:
         except Exception as e:
             logger.error(f"Callback error: {e}")
 
-    async def _default_executor(self, tool_name: str, arguments: dict[str, Any]) -> dict[str, Any]:
+    async def _default_executor(
+        self, tool_name: str, arguments: dict[str, Any]
+    ) -> dict[str, Any]:
         """Default tool executor (for testing)"""
         return {
             "success": True,
@@ -543,7 +566,9 @@ class WorkflowOrchestrator:
 
 
 # Factory functions
-def create_workflow_orchestrator(tool_executor: Callable = None) -> WorkflowOrchestrator:
+def create_workflow_orchestrator(
+    tool_executor: Callable = None,
+) -> WorkflowOrchestrator:
     """Create a new WorkflowOrchestrator instance"""
     return WorkflowOrchestrator(tool_executor)
 
@@ -553,10 +578,16 @@ def create_workflow(name: str, steps: list[WorkflowStep], **kwargs) -> Workflow:
     return Workflow(id=str(uuid4()), name=name, steps=steps, **kwargs)
 
 
-def create_step(name: str, tool: str, arguments: dict[str, Any], **kwargs) -> WorkflowStep:
+def create_step(
+    name: str, tool: str, arguments: dict[str, Any], **kwargs
+) -> WorkflowStep:
     """Create a new WorkflowStep instance"""
     return WorkflowStep(
-        id=kwargs.pop("id", str(uuid4())), name=name, tool=tool, arguments=arguments, **kwargs
+        id=kwargs.pop("id", str(uuid4())),
+        name=name,
+        tool=tool,
+        arguments=arguments,
+        **kwargs,
     )
 
 
diff --git a/workspace/src/core/plugins/mind_matrix/executive_auto.py b/workspace/src/core/plugins/mind_matrix/executive_auto.py
index c1ce8b7..b77a98d 100644
--- a/workspace/src/core/plugins/mind_matrix/executive_auto.py
+++ b/workspace/src/core/plugins/mind_matrix/executive_auto.py
@@ -92,7 +92,9 @@ class ExecutiveAutoController:
             # location
             possible_paths = [
                 Path("config/topology-mind-matrix.yaml"),
-                Path(__file__).parent.parent.parent / "config" / "topology-mind-matrix.yaml",
+                Path(__file__).parent.parent.parent
+                / "config"
+                / "topology-mind-matrix.yaml",
             ]
             for path in possible_paths:
                 if path.exists():
@@ -263,10 +265,14 @@ class ExecutiveAutoController:
             raise AssertionError(f"æ²»ç†åŸå‰‡æœªè¦†è“‹: {missing}")
 
         # Filter to only allowed actions
-        filtered_decisions = [d for d in plan["decisions"] if d["action"] in self.ALLOWED_ACTIONS]
+        filtered_decisions = [
+            d for d in plan["decisions"] if d["action"] in self.ALLOWED_ACTIONS
+        ]
 
         # Log any blocked actions
-        blocked = [d for d in plan["decisions"] if d["action"] not in self.ALLOWED_ACTIONS]
+        blocked = [
+            d for d in plan["decisions"] if d["action"] not in self.ALLOWED_ACTIONS
+        ]
         if blocked:
             self._evidence("policy_blocked", {"blocked_actions": blocked})
 
@@ -520,7 +526,9 @@ class ExecutiveAutoController:
                 "error_rate": s.get("error_rate", 0),
                 "cpu_utilization": s.get("cpu_utilization", 0),
                 "decisions_made": len(g["decisions"]),
-                "executions_success": sum(1 for r in e["results"] if r.get("status") == "success"),
+                "executions_success": sum(
+                    1 for r in e["results"] if r.get("status") == "success"
+                ),
             }
         )
 
diff --git a/workspace/src/core/plugins/mind_matrix/main.py b/workspace/src/core/plugins/mind_matrix/main.py
index d04cd0d..d275099 100644
--- a/workspace/src/core/plugins/mind_matrix/main.py
+++ b/workspace/src/core/plugins/mind_matrix/main.py
@@ -194,7 +194,9 @@ class MindMatrix:
         """
         return self.model.executive_layer.roles
 
-    def get_ceo_mission(self, ceo_id: str = "machinenativenops.ceo") -> list[str] | None:
+    def get_ceo_mission(
+        self, ceo_id: str = "machinenativenops.ceo"
+    ) -> list[str] | None:
         """
         å–å¾—ç‰¹å®šåŸ·è¡Œé•·çš„ä½¿å‘½ (Get mission for a specific executive).
 
@@ -299,7 +301,9 @@ class MindMatrix:
             # location
             possible_paths = [
                 Path("config/topology-mind-matrix.yaml"),
-                Path(__file__).parent.parent.parent / "config" / "topology-mind-matrix.yaml",
+                Path(__file__).parent.parent.parent
+                / "config"
+                / "topology-mind-matrix.yaml",
             ]
             for path in possible_paths:
                 if path.exists():
@@ -317,8 +321,12 @@ class MindMatrix:
         tool_stages = mm.get_tool_pipeline_stages()
         yaml_stages = mm.get_yaml_validation_stages()
 
-        assert len(tool_stages) == 8, f"å·¥å…·ç®¡ç·šå¿…é ˆç‚ºå…«éšæ®µï¼Œç›®å‰æœ‰ {len(tool_stages)} éšæ®µ"
-        assert len(yaml_stages) == 7, f"YAML é©—è­‰ç®¡ç·šå¿…é ˆç‚ºä¸ƒéšæ®µï¼Œç›®å‰æœ‰ {len(yaml_stages)} éšæ®µ"
+        assert (
+            len(tool_stages) == 8
+        ), f"å·¥å…·ç®¡ç·šå¿…é ˆç‚ºå…«éšæ®µï¼Œç›®å‰æœ‰ {len(tool_stages)} éšæ®µ"
+        assert (
+            len(yaml_stages) == 7
+        ), f"YAML é©—è­‰ç®¡ç·šå¿…é ˆç‚ºä¸ƒéšæ®µï¼Œç›®å‰æœ‰ {len(yaml_stages)} éšæ®µ"
 
         print("âœ… MindMatrix å•Ÿå‹•è‡ªæª¢é€šéï¼šå…«éšæ®µå·¥å…·ç®¡ç·šã€ä¸ƒéšæ®µ YAML é©—è­‰")
 
@@ -345,7 +353,9 @@ if __name__ == "__main__":
 
         controller = ExecutiveAutoController()
         report = controller.run_once()
-        print(f"ğŸš€ Autonomous Executive å®Œæˆä¸€æ¬¡é–‰ç’°ï¼Œå¯©è¨ˆäº‹ä»¶æ•¸ï¼š{len(report['audit'])}")
+        print(
+            f"ğŸš€ Autonomous Executive å®Œæˆä¸€æ¬¡é–‰ç’°ï¼Œå¯©è¨ˆäº‹ä»¶æ•¸ï¼š{len(report['audit'])}"
+        )
     except ImportError as ex:
         print(f"[WARN] è‡ªå‹•åŸ·è¡Œé•·æ¨¡çµ„æœªè¼‰å…¥ï¼š{ex}")
     except Exception as ex:
diff --git a/workspace/src/core/plugins/monitoring_system/auto_diagnosis.py b/workspace/src/core/plugins/monitoring_system/auto_diagnosis.py
index 8db29cb..61f56cb 100644
--- a/workspace/src/core/plugins/monitoring_system/auto_diagnosis.py
+++ b/workspace/src/core/plugins/monitoring_system/auto_diagnosis.py
@@ -108,7 +108,9 @@ class AutoDiagnosisEngine:
     """
 
     def __init__(self):
-        self._diagnosis_rules: dict[str, Callable[[DiagnosisContext], list[RootCause]]] = {}
+        self._diagnosis_rules: dict[
+            str, Callable[[DiagnosisContext], list[RootCause]]
+        ] = {}
         self._component_dependencies: dict[str, list[str]] = {}
         self._history: list[DiagnosisResult] = []
 
@@ -118,14 +120,23 @@ class AutoDiagnosisEngine:
         """Register a diagnosis rule"""
         self._diagnosis_rules[name] = rule
 
-    def set_component_dependencies(self, component: str, dependencies: list[str]) -> None:
+    def set_component_dependencies(
+        self, component: str, dependencies: list[str]
+    ) -> None:
         """Set dependencies for a component"""
         self._component_dependencies[component] = dependencies
 
     def _analyze_logs(self, logs: list[str]) -> list[str]:
         """Analyze logs for evidence"""
         evidence = []
-        error_keywords = ["error", "exception", "failed", "timeout", "refused", "unavailable"]
+        error_keywords = [
+            "error",
+            "exception",
+            "failed",
+            "timeout",
+            "refused",
+            "unavailable",
+        ]
 
         for log in logs:
             log_lower = log.lower()
@@ -160,7 +171,9 @@ class AutoDiagnosisEngine:
 
         return causes
 
-    def _analyze_dependencies(self, component: str, context: DiagnosisContext) -> list[RootCause]:
+    def _analyze_dependencies(
+        self, component: str, context: DiagnosisContext
+    ) -> list[RootCause]:
         """Analyze component dependencies"""
         causes = []
         dependencies = self._component_dependencies.get(component, [])
@@ -193,7 +206,9 @@ class AutoDiagnosisEngine:
         start_time = time.time()
 
         result = DiagnosisResult(
-            anomaly_id=context.anomaly_id, status=DiagnosisStatus.IN_PROGRESS, context=context
+            anomaly_id=context.anomaly_id,
+            status=DiagnosisStatus.IN_PROGRESS,
+            context=context,
         )
 
         try:
@@ -227,7 +242,9 @@ class AutoDiagnosisEngine:
 
             # Analyze dependencies
             component = (
-                context.metric_name.split(".")[0] if "." in context.metric_name else "unknown"
+                context.metric_name.split(".")[0]
+                if "." in context.metric_name
+                else "unknown"
             )
             dep_causes = self._analyze_dependencies(component, context)
             root_causes.extend(dep_causes)
@@ -249,7 +266,9 @@ class AutoDiagnosisEngine:
                 top_cause = root_causes[0]
                 result.summary = f"Most likely cause: {top_cause.description} (confidence: {top_cause.confidence.value})"
             else:
-                result.summary = "No root cause identified. Further investigation needed."
+                result.summary = (
+                    "No root cause identified. Further investigation needed."
+                )
 
             # Generate recommendations
             result.recommendations = RecommendationGenerator().generate(result)
@@ -302,7 +321,11 @@ class RecommendationGenerator:
                 "Check database connections",
                 "Optimize database indexes",
             ],
-            "default": ["Review system logs", "Check recent changes", "Monitor the situation"],
+            "default": [
+                "Review system logs",
+                "Check recent changes",
+                "Monitor the situation",
+            ],
         }
 
     def generate(self, diagnosis: DiagnosisResult) -> list[str]:
diff --git a/workspace/src/core/plugins/monitoring_system/auto_remediation.py b/workspace/src/core/plugins/monitoring_system/auto_remediation.py
index cc87e21..f912e37 100644
--- a/workspace/src/core/plugins/monitoring_system/auto_remediation.py
+++ b/workspace/src/core/plugins/monitoring_system/auto_remediation.py
@@ -183,7 +183,9 @@ class RemediationExecutor:
 
         try:
             # Execute with timeout
-            result = await asyncio.wait_for(handler(action), timeout=action.timeout_seconds)
+            result = await asyncio.wait_for(
+                handler(action), timeout=action.timeout_seconds
+            )
 
             if result:
                 # Check post-conditions
@@ -235,7 +237,10 @@ class AutoRemediationEngine:
             if playbook.is_in_cooldown():
                 continue
             for condition in playbook.trigger_conditions:
-                if condition.lower() in trigger.lower() or trigger.lower() in condition.lower():
+                if (
+                    condition.lower() in trigger.lower()
+                    or trigger.lower() in condition.lower()
+                ):
                     matching.append(playbook)
                     break
 
@@ -308,7 +313,9 @@ class AutoRemediationEngine:
 
         return result
 
-    async def auto_remediate(self, trigger: str, anomaly_id: str = "") -> RemediationResult | None:
+    async def auto_remediate(
+        self, trigger: str, anomaly_id: str = ""
+    ) -> RemediationResult | None:
         """
         Automatically find and execute matching playbook
 
diff --git a/workspace/src/core/plugins/monitoring_system/intelligent_monitoring.py b/workspace/src/core/plugins/monitoring_system/intelligent_monitoring.py
index 7696a81..d055de8 100644
--- a/workspace/src/core/plugins/monitoring_system/intelligent_monitoring.py
+++ b/workspace/src/core/plugins/monitoring_system/intelligent_monitoring.py
@@ -118,10 +118,13 @@ class MetricsCollector:
         if name not in self._metrics:
             self._metrics[name] = []
 
-    def collect(self, name: str, value: float, labels: dict[str, str] | None = None) -> Metric:
+    def collect(
+        self, name: str, value: float, labels: dict[str, str] | None = None
+    ) -> Metric:
         """Manually collect a metric value"""
         config = self._collectors.get(
-            name, {"type": MetricType.GAUGE, "labels": {}, "unit": "", "description": ""}
+            name,
+            {"type": MetricType.GAUGE, "labels": {}, "unit": "", "description": ""},
         )
 
         metric = Metric(
@@ -316,9 +319,15 @@ class IntelligentMonitoringSystem:
     def get_health_status(self) -> dict[str, Any]:
         """Get overall system health status"""
         active_alerts = self.get_active_alerts()
-        critical_count = len([a for a in active_alerts if a.severity == AlertSeverity.CRITICAL])
-        error_count = len([a for a in active_alerts if a.severity == AlertSeverity.ERROR])
-        warning_count = len([a for a in active_alerts if a.severity == AlertSeverity.WARNING])
+        critical_count = len(
+            [a for a in active_alerts if a.severity == AlertSeverity.CRITICAL]
+        )
+        error_count = len(
+            [a for a in active_alerts if a.severity == AlertSeverity.ERROR]
+        )
+        warning_count = len(
+            [a for a in active_alerts if a.severity == AlertSeverity.WARNING]
+        )
 
         if critical_count > 0:
             status = "CRITICAL"
@@ -338,7 +347,9 @@ class IntelligentMonitoringSystem:
             "timestamp": datetime.now().isoformat(),
         }
 
-    async def start(self, collection_interval: float = 10.0, check_interval: float = 30.0) -> None:
+    async def start(
+        self, collection_interval: float = 10.0, check_interval: float = 30.0
+    ) -> None:
         """Start the monitoring system"""
         self._running = True
 
diff --git a/workspace/src/core/plugins/monitoring_system/observability_platform.py b/workspace/src/core/plugins/monitoring_system/observability_platform.py
index 6867ad8..f3de830 100644
--- a/workspace/src/core/plugins/monitoring_system/observability_platform.py
+++ b/workspace/src/core/plugins/monitoring_system/observability_platform.py
@@ -101,7 +101,11 @@ class TraceSpan:
     def add_event(self, name: str, attributes: dict[str, Any] | None = None) -> None:
         """Add an event to the span"""
         self.events.append(
-            {"name": name, "timestamp": datetime.now().isoformat(), "attributes": attributes or {}}
+            {
+                "name": name,
+                "timestamp": datetime.now().isoformat(),
+                "attributes": attributes or {},
+            }
         )
 
     def to_dict(self) -> dict[str, Any]:
@@ -174,7 +178,9 @@ class CorrelationEngine:
     ) -> CorrelatedEvent:
         """Correlate events by time proximity"""
         event = CorrelatedEvent(
-            event_type=EventType.INCIDENT, title="Time-correlated event", timestamp=reference_time
+            event_type=EventType.INCIDENT,
+            title="Time-correlated event",
+            timestamp=reference_time,
         )
 
         # Find logs within time window
diff --git a/workspace/src/core/plugins/monitoring_system/self_learning.py b/workspace/src/core/plugins/monitoring_system/self_learning.py
index dc1860a..ce49e24 100644
--- a/workspace/src/core/plugins/monitoring_system/self_learning.py
+++ b/workspace/src/core/plugins/monitoring_system/self_learning.py
@@ -148,14 +148,19 @@ class PatternLearner:
 
         return intersection / union if union > 0 else 0.0
 
-    def find_similar_pattern(self, conditions: list[dict[str, Any]]) -> IncidentPattern | None:
+    def find_similar_pattern(
+        self, conditions: list[dict[str, Any]]
+    ) -> IncidentPattern | None:
         """Find a similar existing pattern"""
         best_match = None
         best_similarity = 0.0
 
         for pattern in self._patterns.values():
             similarity = self._calculate_similarity(conditions, pattern.conditions)
-            if similarity > best_similarity and similarity >= self._similarity_threshold:
+            if (
+                similarity > best_similarity
+                and similarity >= self._similarity_threshold
+            ):
                 best_similarity = similarity
                 best_match = pattern
 
@@ -306,7 +311,10 @@ class SelfLearningEngine:
         return self._effectiveness_tracker
 
     def learn_from_incident(
-        self, conditions: list[dict[str, Any]], description: str = "", tags: list[str] | None = None
+        self,
+        conditions: list[dict[str, Any]],
+        description: str = "",
+        tags: list[str] | None = None,
     ) -> IncidentPattern:
         """Learn from an incident"""
         return self._pattern_learner.learn(
@@ -348,7 +356,8 @@ class SelfLearningEngine:
     def analyze_and_learn(self) -> LearningOutcome:
         """Analyze data and generate learning outcomes"""
         outcome = LearningOutcome(
-            source=LearningSource.MONITORING, description="Periodic analysis of monitoring data"
+            source=LearningSource.MONITORING,
+            description="Periodic analysis of monitoring data",
         )
 
         # Count patterns
diff --git a/workspace/src/core/plugins/monitoring_system/smart_anomaly_detector.py b/workspace/src/core/plugins/monitoring_system/smart_anomaly_detector.py
index 666078c..798d3a6 100644
--- a/workspace/src/core/plugins/monitoring_system/smart_anomaly_detector.py
+++ b/workspace/src/core/plugins/monitoring_system/smart_anomaly_detector.py
@@ -180,7 +180,9 @@ class SmartAnomalyDetector:
         else:
             return AnomalyCategory.UNKNOWN
 
-    def _calculate_severity(self, deviation: float, confidence: float) -> AnomalySeverity:
+    def _calculate_severity(
+        self, deviation: float, confidence: float
+    ) -> AnomalySeverity:
         """Calculate severity based on deviation and confidence"""
         score = deviation * confidence
 
@@ -193,7 +195,9 @@ class SmartAnomalyDetector:
         else:
             return AnomalySeverity.LOW
 
-    def detect_statistical(self, metric_name: str, value: float) -> DetectedAnomaly | None:
+    def detect_statistical(
+        self, metric_name: str, value: float
+    ) -> DetectedAnomaly | None:
         """Detect anomaly using statistical method (Z-score)"""
         baseline = self._baselines.get(metric_name)
         if not baseline or baseline["stdev"] == 0:
@@ -286,7 +290,10 @@ class SmartAnomalyDetector:
         return None
 
     def detect(
-        self, metric_name: str, value: float, strategy: AnomalyDetectionStrategy | None = None
+        self,
+        metric_name: str,
+        value: float,
+        strategy: AnomalyDetectionStrategy | None = None,
     ) -> DetectedAnomaly | None:
         """
         Detect anomaly using specified or default strategy
diff --git a/workspace/src/core/plugins/tech_stack/architecture_config.py b/workspace/src/core/plugins/tech_stack/architecture_config.py
index f2c6675..1ae8a58 100644
--- a/workspace/src/core/plugins/tech_stack/architecture_config.py
+++ b/workspace/src/core/plugins/tech_stack/architecture_config.py
@@ -146,16 +146,22 @@ class TechStackConfig:
     primary_pattern: str = "microservices"
     communication_pattern: str = "event-driven"
 
-    def get_frameworks_for_layer(self, layer: ArchitectureLayer) -> list[FrameworkConfig]:
+    def get_frameworks_for_layer(
+        self, layer: ArchitectureLayer
+    ) -> list[FrameworkConfig]:
         """Get all frameworks recommended for a specific layer"""
         if layer.value not in self.layers:
             return []
         layer_config = self.layers[layer.value]
         return [
-            self.frameworks[fw_id] for fw_id in layer_config.frameworks if fw_id in self.frameworks
+            self.frameworks[fw_id]
+            for fw_id in layer_config.frameworks
+            if fw_id in self.frameworks
         ]
 
-    def get_frameworks_by_category(self, category: FrameworkCategory) -> list[FrameworkConfig]:
+    def get_frameworks_by_category(
+        self, category: FrameworkCategory
+    ) -> list[FrameworkConfig]:
         """Get all frameworks in a specific category"""
         return [fw for fw in self.frameworks.values() if fw.category == category]
 
@@ -174,7 +180,9 @@ class TechStackConfig:
         if ArchitectureLayer.AI_CORE.value in self.layers:
             ai_layer = self.layers[ArchitectureLayer.AI_CORE.value]
             if ai_layer.primary_language != LanguageType.PYTHON:
-                warnings.append("AI core layer should use Python (80% of AI agents use Python)")
+                warnings.append(
+                    "AI core layer should use Python (80% of AI agents use Python)"
+                )
 
         return {"valid": len(issues) == 0, "issues": issues, "warnings": warnings}
 
@@ -237,7 +245,11 @@ def get_recommended_stack() -> TechStackConfig:
                 "Strong tooling",
                 "Modern language features",
             ],
-            weaknesses=["Compilation step required", "Complex type system", "Smaller AI ecosystem"],
+            weaknesses=[
+                "Compilation step required",
+                "Complex type system",
+                "Smaller AI ecosystem",
+            ],
             adoption_rate=30.0,
             ecosystem_maturity="mature",
         ),
@@ -261,7 +273,12 @@ def get_recommended_stack() -> TechStackConfig:
                 "Memory management",
                 "Prompt templates",
             ],
-            use_cases=["Conversational AI", "Document Q&A", "Code generation", "Task automation"],
+            use_cases=[
+                "Conversational AI",
+                "Document Q&A",
+                "Code generation",
+                "Task automation",
+            ],
             dependencies=["openai", "tiktoken", "pydantic"],
             integration_complexity="medium",
             documentation_url="https://python.langchain.com/docs/",
@@ -377,7 +394,12 @@ def get_recommended_stack() -> TechStackConfig:
                 "Inference optimization",
                 "Pipeline API",
             ],
-            use_cases=["NLP tasks", "Text generation", "Embeddings", "Sentiment analysis"],
+            use_cases=[
+                "NLP tasks",
+                "Text generation",
+                "Embeddings",
+                "Sentiment analysis",
+            ],
             dependencies=["pytorch", "tokenizers"],
             integration_complexity="low",
             documentation_url="https://huggingface.co/docs/transformers/",
@@ -398,7 +420,12 @@ def get_recommended_stack() -> TechStackConfig:
                 "Dependency injection",
                 "WebSocket support",
             ],
-            use_cases=["REST APIs", "ML model serving", "Microservices", "Real-time apps"],
+            use_cases=[
+                "REST APIs",
+                "ML model serving",
+                "Microservices",
+                "Real-time apps",
+            ],
             dependencies=["starlette", "pydantic"],
             integration_complexity="low",
             documentation_url="https://fastapi.tiangolo.com/",
@@ -418,7 +445,12 @@ def get_recommended_stack() -> TechStackConfig:
                 "Static files",
                 "Error handling",
             ],
-            use_cases=["REST APIs", "Web applications", "Microservices", "Real-time apps"],
+            use_cases=[
+                "REST APIs",
+                "Web applications",
+                "Microservices",
+                "Real-time apps",
+            ],
             dependencies=["node"],
             integration_complexity="low",
             documentation_url="https://expressjs.com/",
@@ -432,7 +464,14 @@ def get_recommended_stack() -> TechStackConfig:
             layer=ArchitectureLayer.AI_CORE,
             primary_language=LanguageType.PYTHON,
             secondary_languages=[],
-            frameworks=["langchain", "crewai", "autogen", "langgraph", "pytorch", "transformers"],
+            frameworks=[
+                "langchain",
+                "crewai",
+                "autogen",
+                "langgraph",
+                "pytorch",
+                "transformers",
+            ],
             responsibilities=[
                 "AI agent implementation",
                 "ML model training and inference",
@@ -505,7 +544,10 @@ def get_stack_summary() -> dict[str, Any]:
         "name": stack.name,
         "version": stack.version,
         "architecture_type": stack.architecture_type,
-        "primary_languages": {"ai_core": "Python 3.11+", "orchestration": "TypeScript 5.0+"},
+        "primary_languages": {
+            "ai_core": "Python 3.11+",
+            "orchestration": "TypeScript 5.0+",
+        },
         "key_frameworks": {
             "ai_agents": ["LangChain", "CrewAI", "AutoGen", "LangGraph"],
             "ml_libraries": ["PyTorch", "Transformers"],
diff --git a/workspace/src/core/plugins/tech_stack/framework_integrations.py b/workspace/src/core/plugins/tech_stack/framework_integrations.py
index aea8c78..ccf039f 100644
--- a/workspace/src/core/plugins/tech_stack/framework_integrations.py
+++ b/workspace/src/core/plugins/tech_stack/framework_integrations.py
@@ -219,12 +219,19 @@ class LangChainIntegration(FrameworkIntegration):
         self.chains[chain_id] = chain_config
         return chain_id
 
-    async def register_tool(self, tool_id: str, name: str, description: str, func: Callable) -> str:
+    async def register_tool(
+        self, tool_id: str, name: str, description: str, func: Callable
+    ) -> str:
         """Register a tool for agents to use
 
         è¨»å†Šå·¥å…·ä¾›ä»£ç†ä½¿ç”¨
         """
-        tool_config = {"id": tool_id, "name": name, "description": description, "func": func}
+        tool_config = {
+            "id": tool_id,
+            "name": name,
+            "description": description,
+            "func": func,
+        }
         self.tools[tool_id] = tool_config
         return tool_id
 
@@ -257,10 +264,16 @@ class LangChainIntegration(FrameworkIntegration):
                 success=True,
                 result=result,
                 execution_time=execution_time,
-                metadata={"agent_id": agent_id, "framework": "langchain", "context": context},
+                metadata={
+                    "agent_id": agent_id,
+                    "framework": "langchain",
+                    "context": context,
+                },
             )
         except Exception as e:
-            return TaskResult(task_id=str(uuid.uuid4()), success=False, result=None, error=str(e))
+            return TaskResult(
+                task_id=str(uuid.uuid4()), success=False, result=None, error=str(e)
+            )
 
     async def shutdown(self) -> bool:
         """Shutdown LangChain connection"""
@@ -374,7 +387,10 @@ class CrewAIIntegration(FrameworkIntegration):
 
         if crew_id not in self.crews:
             return TaskResult(
-                task_id=crew_id, success=False, result=None, error=f"Crew {crew_id} not found"
+                task_id=crew_id,
+                success=False,
+                result=None,
+                error=f"Crew {crew_id} not found",
             )
 
         try:
@@ -388,7 +404,11 @@ class CrewAIIntegration(FrameworkIntegration):
                 success=True,
                 result=f"Crew {crew_id} completed {len(task_ids)} tasks",
                 execution_time=execution_time,
-                metadata={"crew_id": crew_id, "task_ids": task_ids, "framework": "crewai"},
+                metadata={
+                    "crew_id": crew_id,
+                    "task_ids": task_ids,
+                    "framework": "crewai",
+                },
             )
         except Exception as e:
             return TaskResult(task_id=crew_id, success=False, result=None, error=str(e))
@@ -486,7 +506,9 @@ class AutoGenIntegration(FrameworkIntegration):
         self.group_chats[chat_id] = chat_config
         return chat_id
 
-    async def initiate_chat(self, initiator_id: str, recipient_id: str, message: str) -> TaskResult:
+    async def initiate_chat(
+        self, initiator_id: str, recipient_id: str, message: str
+    ) -> TaskResult:
         """Initiate a two-agent chat
 
         ç™¼èµ·é›™ä»£ç†å°è©±
@@ -495,7 +517,11 @@ class AutoGenIntegration(FrameworkIntegration):
 
         conversation_id = f"conv_{uuid.uuid4()}"
         self.conversations[conversation_id] = [
-            {"sender": initiator_id, "content": message, "timestamp": datetime.now().isoformat()}
+            {
+                "sender": initiator_id,
+                "content": message,
+                "timestamp": datetime.now().isoformat(),
+            }
         ]
 
         try:
@@ -527,7 +553,9 @@ class AutoGenIntegration(FrameworkIntegration):
                 },
             )
         except Exception as e:
-            return TaskResult(task_id=conversation_id, success=False, result=None, error=str(e))
+            return TaskResult(
+                task_id=conversation_id, success=False, result=None, error=str(e)
+            )
 
     async def execute_task(
         self, agent_id: str, task: str, context: dict | None = None
@@ -536,7 +564,11 @@ class AutoGenIntegration(FrameworkIntegration):
         # Create a temporary assistant for task execution
         assistant_id = f"assistant_{uuid.uuid4()}"
         await self.create_agent(
-            AgentConfig(id=assistant_id, name="AssistantAgent", agent_type=AgentType.TASK_ORIENTED)
+            AgentConfig(
+                id=assistant_id,
+                name="AssistantAgent",
+                agent_type=AgentType.TASK_ORIENTED,
+            )
         )
 
         return await self.initiate_chat(agent_id, assistant_id, task)
@@ -624,7 +656,11 @@ class LangGraphIntegration(FrameworkIntegration):
         return graph_id
 
     async def add_conditional_edge(
-        self, graph_id: str, source: str, condition_func: Callable, destinations: dict[str, str]
+        self,
+        graph_id: str,
+        source: str,
+        condition_func: Callable,
+        destinations: dict[str, str],
     ) -> bool:
         """Add a conditional edge to a graph
 
@@ -643,7 +679,9 @@ class LangGraphIntegration(FrameworkIntegration):
         )
         return True
 
-    async def execute_graph(self, graph_id: str, initial_state: dict[str, Any]) -> TaskResult:
+    async def execute_graph(
+        self, graph_id: str, initial_state: dict[str, Any]
+    ) -> TaskResult:
         """Execute a graph with initial state
 
         åŸ·è¡Œåœ–ä¸¦è¿”å›æœ€çµ‚ç‹€æ…‹
@@ -652,7 +690,10 @@ class LangGraphIntegration(FrameworkIntegration):
 
         if graph_id not in self.graphs:
             return TaskResult(
-                task_id=graph_id, success=False, result=None, error=f"Graph {graph_id} not found"
+                task_id=graph_id,
+                success=False,
+                result=None,
+                error=f"Graph {graph_id} not found",
             )
 
         try:
@@ -677,7 +718,9 @@ class LangGraphIntegration(FrameworkIntegration):
                 metadata={"graph_id": graph_id, "framework": "langgraph"},
             )
         except Exception as e:
-            return TaskResult(task_id=graph_id, success=False, result=None, error=str(e))
+            return TaskResult(
+                task_id=graph_id, success=False, result=None, error=str(e)
+            )
 
     async def execute_task(
         self, agent_id: str, task: str, context: dict | None = None
@@ -686,7 +729,10 @@ class LangGraphIntegration(FrameworkIntegration):
         # Create a simple single-node graph
         graph_id = f"task_graph_{uuid.uuid4()}"
         await self.create_graph(
-            graph_id, nodes=[{"id": agent_id, "type": "agent"}], edges=[], entry_point=agent_id
+            graph_id,
+            nodes=[{"id": agent_id, "type": "agent"}],
+            edges=[],
+            entry_point=agent_id,
         )
 
         return await self.execute_graph(graph_id, {"task": task, "context": context})
@@ -726,7 +772,9 @@ class FrameworkOrchestrator:
             self.default_framework = framework.name.lower()
         return framework.id
 
-    async def initialize_all(self, credentials: dict[str, FrameworkCredentials]) -> dict[str, bool]:
+    async def initialize_all(
+        self, credentials: dict[str, FrameworkCredentials]
+    ) -> dict[str, bool]:
         """Initialize all registered frameworks
 
         åˆå§‹åŒ–æ‰€æœ‰è¨»å†Šçš„æ¡†æ¶
@@ -790,4 +838,6 @@ class FrameworkOrchestrator:
 
         ç²å–æ‰€æœ‰æ¡†æ¶çš„ç‹€æ…‹
         """
-        return {name: framework.get_status() for name, framework in self.frameworks.items()}
+        return {
+            name: framework.get_status() for name, framework in self.frameworks.items()
+        }
diff --git a/workspace/src/core/plugins/tech_stack/multi_agent_coordinator.py b/workspace/src/core/plugins/tech_stack/multi_agent_coordinator.py
index 35166b7..8e374cc 100644
--- a/workspace/src/core/plugins/tech_stack/multi_agent_coordinator.py
+++ b/workspace/src/core/plugins/tech_stack/multi_agent_coordinator.py
@@ -236,7 +236,9 @@ class AgentCommunicationBus:
         message.message_type = MessageType.BROADCAST
         await self.publish("broadcast", message)
 
-    async def respond_to(self, original_message_id: str, response: AgentMessage) -> None:
+    async def respond_to(
+        self, original_message_id: str, response: AgentMessage
+    ) -> None:
         """Respond to a message
 
         å›è¦†æ¶ˆæ¯
@@ -249,7 +251,9 @@ class AgentCommunicationBus:
         """Process messages from the queue"""
         while self._running:
             try:
-                topic, message = await asyncio.wait_for(self.message_queue.get(), timeout=1.0)
+                topic, message = await asyncio.wait_for(
+                    self.message_queue.get(), timeout=1.0
+                )
 
                 for callback in self.subscribers.get(topic, []):
                     try:
@@ -318,7 +322,9 @@ class TaskRouter:
         )
         self.routing_rules.sort(key=lambda x: x["priority"])
 
-    def find_suitable_agents(self, task: TeamTask, max_agents: int = 1) -> list[AgentDefinition]:
+    def find_suitable_agents(
+        self, task: TeamTask, max_agents: int = 1
+    ) -> list[AgentDefinition]:
         """Find agents suitable for a task
 
         æ‰¾åˆ°é©åˆä»»å‹™çš„ä»£ç†
@@ -378,7 +384,8 @@ class TaskRouter:
                 "current_load": self.agent_load[agent_id],
                 "max_load": self.agents[agent_id].max_concurrent_tasks,
                 "utilization": (
-                    self.agent_load[agent_id] / self.agents[agent_id].max_concurrent_tasks
+                    self.agent_load[agent_id]
+                    / self.agents[agent_id].max_concurrent_tasks
                     if self.agents[agent_id].max_concurrent_tasks > 0
                     else 0
                 ),
@@ -424,7 +431,9 @@ class AgentTeam:
         """Get all agents with a specific role"""
         return [a for a in self.agents.values() if a.role == role]
 
-    def get_agents_with_capability(self, capability: AgentCapability) -> list[AgentDefinition]:
+    def get_agents_with_capability(
+        self, capability: AgentCapability
+    ) -> list[AgentDefinition]:
         """Get all agents with a specific capability"""
         return [a for a in self.agents.values() if a.has_capability(capability)]
 
@@ -633,9 +642,15 @@ class MultiAgentCoordinator:
             "teams_count": len(self.teams),
             "tasks": {
                 "total": len(self.tasks),
-                "pending": len([t for t in self.tasks.values() if t.status == "pending"]),
-                "running": len([t for t in self.tasks.values() if t.status == "running"]),
-                "completed": len([t for t in self.tasks.values() if t.status == "completed"]),
+                "pending": len(
+                    [t for t in self.tasks.values() if t.status == "pending"]
+                ),
+                "running": len(
+                    [t for t in self.tasks.values() if t.status == "running"]
+                ),
+                "completed": len(
+                    [t for t in self.tasks.values() if t.status == "completed"]
+                ),
                 "failed": len([t for t in self.tasks.values() if t.status == "failed"]),
             },
             "agent_load": self.task_router.get_load_status(),
diff --git a/workspace/src/core/plugins/tech_stack/python_bridge.py b/workspace/src/core/plugins/tech_stack/python_bridge.py
index 5250e2c..3b12c1f 100644
--- a/workspace/src/core/plugins/tech_stack/python_bridge.py
+++ b/workspace/src/core/plugins/tech_stack/python_bridge.py
@@ -275,7 +275,10 @@ class PackageManager:
             PythonPackage("langchain-openai", "0.0.5"),
             PythonPackage("crewai", "0.28.0"),
             PythonPackage(
-                "autogen", "0.2.0", source="git", git_url="https://github.com/microsoft/autogen"
+                "autogen",
+                "0.2.0",
+                source="git",
+                git_url="https://github.com/microsoft/autogen",
             ),
             PythonPackage("langgraph", "0.0.1"),
         ],
@@ -526,15 +529,19 @@ class PythonBridge:
         self.default_environment: PythonEnvironment | None = None
         self._initialized = False
 
-    async def initialize(self, setup_ai_env: bool = True, include_ml: bool = True) -> bool:
+    async def initialize(
+        self, setup_ai_env: bool = True, include_ml: bool = True
+    ) -> bool:
         """Initialize the Python bridge
 
         åˆå§‹åŒ– Python æ©‹æ¥å™¨
         """
         try:
             if setup_ai_env:
-                self.default_environment = await self.package_manager.setup_ai_environment(
-                    include_ml=include_ml
+                self.default_environment = (
+                    await self.package_manager.setup_ai_environment(
+                        include_ml=include_ml
+                    )
                 )
                 self.executors["default"] = PythonExecutor(self.default_environment)
 
@@ -555,7 +562,9 @@ class PythonBridge:
         self.executors[name] = executor
         return executor
 
-    async def execute_ai_code(self, code: str, executor_name: str = "default") -> ExecutionResult:
+    async def execute_ai_code(
+        self, code: str, executor_name: str = "default"
+    ) -> ExecutionResult:
         """Execute AI-related Python code
 
         åŸ·è¡Œ AI ç›¸é—œçš„ Python ä»£ç¢¼
@@ -566,12 +575,16 @@ class PythonBridge:
 
         if not executor:
             return ExecutionResult(
-                success=False, error_type="RuntimeError", error_message="No executor available"
+                success=False,
+                error_type="RuntimeError",
+                error_message="No executor available",
             )
 
         return await executor.execute_code(code)
 
-    async def run_langchain_agent(self, agent_config: dict[str, Any], task: str) -> ExecutionResult:
+    async def run_langchain_agent(
+        self, agent_config: dict[str, Any], task: str
+    ) -> ExecutionResult:
         """Run a LangChain agent
 
         é‹è¡Œ LangChain ä»£ç†
@@ -624,7 +637,9 @@ print(f"CrewAI crew executed with {{len(config.get('agents', []))}} agents")
         return {
             "initialized": self._initialized,
             "default_environment": (
-                self.default_environment.get_status() if self.default_environment else None
+                self.default_environment.get_status()
+                if self.default_environment
+                else None
             ),
             "executors_count": len(self.executors),
             "environments_count": len(self.package_manager.environments),
diff --git a/workspace/src/core/plugins/training_system/example_library.py b/workspace/src/core/plugins/training_system/example_library.py
index f05f284..ffb1102 100644
--- a/workspace/src/core/plugins/training_system/example_library.py
+++ b/workspace/src/core/plugins/training_system/example_library.py
@@ -850,9 +850,9 @@ async def get_products_optimized(cursor: str, limit: int = 20):
 
         results["code_examples"] = [
             e
-            for e, _ in sorted(results["code_examples"], key=lambda x: x[1], reverse=True)[
-                :max_results
-            ]
+            for e, _ in sorted(
+                results["code_examples"], key=lambda x: x[1], reverse=True
+            )[:max_results]
         ]
 
         # Search scenario examples
@@ -868,9 +868,9 @@ async def get_products_optimized(cursor: str, limit: int = 20):
 
         results["scenario_examples"] = [
             e
-            for e, _ in sorted(results["scenario_examples"], key=lambda x: x[1], reverse=True)[
-                :max_results
-            ]
+            for e, _ in sorted(
+                results["scenario_examples"], key=lambda x: x[1], reverse=True
+            )[:max_results]
         ]
 
         # Search decision examples
@@ -886,9 +886,9 @@ async def get_products_optimized(cursor: str, limit: int = 20):
 
         results["decision_examples"] = [
             e
-            for e, _ in sorted(results["decision_examples"], key=lambda x: x[1], reverse=True)[
-                :max_results
-            ]
+            for e, _ in sorted(
+                results["decision_examples"], key=lambda x: x[1], reverse=True
+            )[:max_results]
         ]
 
         return results
@@ -910,10 +910,14 @@ async def get_products_optimized(cursor: str, limit: int = 20):
 
         return score
 
-    def get_examples_for_category(self, category: ExampleCategory) -> dict[str, list[Any]]:
+    def get_examples_for_category(
+        self, category: ExampleCategory
+    ) -> dict[str, list[Any]]:
         """Get all examples for a category."""
         return {
-            "code_examples": [e for e in self.code_examples.values() if e.category == category],
+            "code_examples": [
+                e for e in self.code_examples.values() if e.category == category
+            ],
             "scenario_examples": [
                 e for e in self.scenario_examples.values() if e.category == category
             ],
diff --git a/workspace/src/core/plugins/training_system/knowledge_base.py b/workspace/src/core/plugins/training_system/knowledge_base.py
index 84512af..63724b4 100644
--- a/workspace/src/core/plugins/training_system/knowledge_base.py
+++ b/workspace/src/core/plugins/training_system/knowledge_base.py
@@ -559,21 +559,33 @@ user = db.users.find_first(where={'email': email})
         """Get a specific best practice by ID."""
         return self.best_practices.get(practice_id)
 
-    def get_best_practices_for_category(self, category: KnowledgeCategory) -> list[BestPractice]:
+    def get_best_practices_for_category(
+        self, category: KnowledgeCategory
+    ) -> list[BestPractice]:
         """Get all best practices for a category."""
         return [
-            practice for practice in self.best_practices.values() if practice.category == category
+            practice
+            for practice in self.best_practices.values()
+            if practice.category == category
         ]
 
     def get_anti_pattern(self, pattern_id: str) -> AntiPattern | None:
         """Get a specific anti-pattern by ID."""
         return self.anti_patterns.get(pattern_id)
 
-    def get_anti_patterns_for_category(self, category: KnowledgeCategory) -> list[AntiPattern]:
+    def get_anti_patterns_for_category(
+        self, category: KnowledgeCategory
+    ) -> list[AntiPattern]:
         """Get all anti-patterns for a category."""
-        return [pattern for pattern in self.anti_patterns.values() if pattern.category == category]
+        return [
+            pattern
+            for pattern in self.anti_patterns.values()
+            if pattern.category == category
+        ]
 
-    def get_domain_knowledge(self, category: KnowledgeCategory) -> DomainKnowledge | None:
+    def get_domain_knowledge(
+        self, category: KnowledgeCategory
+    ) -> DomainKnowledge | None:
         """Get complete domain knowledge."""
         return self.domains.get(category)
 
@@ -605,7 +617,9 @@ user = db.users.find_first(where={'email': email})
         if pattern.category in self.domains:
             self.domains[pattern.category].anti_patterns[pattern.id] = pattern
 
-    def get_relevant_knowledge(self, context: str, max_results: int = 5) -> dict[str, Any]:
+    def get_relevant_knowledge(
+        self, context: str, max_results: int = 5
+    ) -> dict[str, Any]:
         """
         Get relevant knowledge based on context.
 
@@ -630,7 +644,9 @@ user = db.users.find_first(where={'email': email})
 
         relevant["concepts"] = [
             c
-            for c, _ in sorted(relevant["concepts"], key=lambda x: x[1], reverse=True)[:max_results]
+            for c, _ in sorted(relevant["concepts"], key=lambda x: x[1], reverse=True)[
+                :max_results
+            ]
         ]
 
         # Find relevant best practices
@@ -643,9 +659,9 @@ user = db.users.find_first(where={'email': email})
 
         relevant["best_practices"] = [
             p
-            for p, _ in sorted(relevant["best_practices"], key=lambda x: x[1], reverse=True)[
-                :max_results
-            ]
+            for p, _ in sorted(
+                relevant["best_practices"], key=lambda x: x[1], reverse=True
+            )[:max_results]
         ]
 
         # Find relevant anti-patterns
@@ -658,9 +674,9 @@ user = db.users.find_first(where={'email': email})
 
         relevant["anti_patterns"] = [
             p
-            for p, _ in sorted(relevant["anti_patterns"], key=lambda x: x[1], reverse=True)[
-                :max_results
-            ]
+            for p, _ in sorted(
+                relevant["anti_patterns"], key=lambda x: x[1], reverse=True
+            )[:max_results]
         ]
 
         # Collect tips from relevant domains
diff --git a/workspace/src/core/plugins/training_system/skills_training.py b/workspace/src/core/plugins/training_system/skills_training.py
index e0e2072..c293da7 100644
--- a/workspace/src/core/plugins/training_system/skills_training.py
+++ b/workspace/src/core/plugins/training_system/skills_training.py
@@ -809,7 +809,11 @@ def login(email, password):
         for result in session.exercise_results:
             total_score += result["result"]["score"]
 
-        avg_score = total_score / len(session.exercise_results) if session.exercise_results else 0.0
+        avg_score = (
+            total_score / len(session.exercise_results)
+            if session.exercise_results
+            else 0.0
+        )
         session.assessment_score = avg_score
 
         # Determine if passed
@@ -831,7 +835,9 @@ def login(email, password):
             agent_id=session.agent_id,
             skill_id=module.skill_id,
             assessed_level=(
-                module.target_level if session.status == "completed" else SkillLevel.NOVICE
+                module.target_level
+                if session.status == "completed"
+                else SkillLevel.NOVICE
             ),
             score=avg_score,
             confidence=0.8 if len(session.exercise_results) >= 3 else 0.5,
@@ -862,7 +868,9 @@ def login(email, password):
             return self.agent_skills[agent_id].get(skill_id, SkillLevel.NOVICE)
         return SkillLevel.NOVICE
 
-    def get_recommended_modules(self, agent_id: str, skill_id: str) -> list[TrainingModule]:
+    def get_recommended_modules(
+        self, agent_id: str, skill_id: str
+    ) -> list[TrainingModule]:
         """Get recommended training modules for an agent."""
         current_level = self.get_agent_skill_level(agent_id, skill_id)
 
@@ -892,7 +900,9 @@ def login(email, password):
             if self._has_completed_module(agent_id, module_id):
                 completed_modules.append(module_id)
 
-        progress = len(completed_modules) / len(path.modules) * 100 if path.modules else 0
+        progress = (
+            len(completed_modules) / len(path.modules) * 100 if path.modules else 0
+        )
 
         return {
             "path_id": path_id,
diff --git a/workspace/src/core/plugins/virtual_experts/expert_team.py b/workspace/src/core/plugins/virtual_experts/expert_team.py
index be5b9d4..25180dc 100644
--- a/workspace/src/core/plugins/virtual_experts/expert_team.py
+++ b/workspace/src/core/plugins/virtual_experts/expert_team.py
@@ -229,10 +229,41 @@ class VirtualExpertTeam:
         combined_text = (query + " " + (code or "")).lower()
 
         domain_keywords = {
-            "security": ["password", "authentication", "injection", "xss", "csrf", "å¯†ç¢¼", "å®‰å…¨"],
-            "database": ["sql", "query", "index", "transaction", "æ•¸æ“šåº«", "ç´¢å¼•", "æŸ¥è©¢"],
-            "performance": ["optimize", "performance", "slow", "cache", "æ€§èƒ½", "å„ªåŒ–", "ç·©å­˜"],
-            "architecture": ["design", "pattern", "microservice", "æ¶æ§‹", "è¨­è¨ˆ", "æ¨¡å¼"],
+            "security": [
+                "password",
+                "authentication",
+                "injection",
+                "xss",
+                "csrf",
+                "å¯†ç¢¼",
+                "å®‰å…¨",
+            ],
+            "database": [
+                "sql",
+                "query",
+                "index",
+                "transaction",
+                "æ•¸æ“šåº«",
+                "ç´¢å¼•",
+                "æŸ¥è©¢",
+            ],
+            "performance": [
+                "optimize",
+                "performance",
+                "slow",
+                "cache",
+                "æ€§èƒ½",
+                "å„ªåŒ–",
+                "ç·©å­˜",
+            ],
+            "architecture": [
+                "design",
+                "pattern",
+                "microservice",
+                "æ¶æ§‹",
+                "è¨­è¨ˆ",
+                "æ¨¡å¼",
+            ],
             "ai": ["model", "prediction", "machine learning", "ml", "æ¨¡å‹", "é æ¸¬"],
             "deployment": ["deploy", "ci/cd", "docker", "kubernetes", "éƒ¨ç½²", "å®¹å™¨"],
             "nlp": ["intent", "language", "text", "æ„åœ–", "èªè¨€", "æ–‡æœ¬"],
@@ -284,7 +315,11 @@ class VirtualExpertTeam:
 
         # Synthesize results
         result = self._synthesize_results(
-            consultation, expert_responses, all_issues, all_suggestions, all_recommendations
+            consultation,
+            expert_responses,
+            all_issues,
+            all_suggestions,
+            all_recommendations,
         )
 
         # Update consultation status
@@ -305,7 +340,9 @@ class VirtualExpertTeam:
         }
 
         if consultation.type == ConsultationType.CODE_REVIEW and consultation.code:
-            review = expert.review_code(consultation.code, consultation.language or "python")
+            review = expert.review_code(
+                consultation.code, consultation.language or "python"
+            )
             response.update(review)
 
         elif consultation.type in [
@@ -344,22 +381,30 @@ class VirtualExpertTeam:
 
         # Sort issues by severity
         severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
-        unique_issues.sort(key=lambda x: severity_order.get(x.get("severity", "low"), 4))
+        unique_issues.sort(
+            key=lambda x: severity_order.get(x.get("severity", "low"), 4)
+        )
 
         # Deduplicate recommendations
         unique_recommendations = list(dict.fromkeys(all_recommendations))
 
         # Calculate quality score
         quality_scores = [
-            r.get("quality_score", 0.8) for r in expert_responses if "quality_score" in r
+            r.get("quality_score", 0.8)
+            for r in expert_responses
+            if "quality_score" in r
         ]
-        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0.8
+        avg_quality = (
+            sum(quality_scores) / len(quality_scores) if quality_scores else 0.8
+        )
 
         # Generate summary
         summary = self._generate_summary(consultation, expert_responses, unique_issues)
 
         # Generate action items
-        action_items = self._generate_action_items(unique_issues, unique_recommendations)
+        action_items = self._generate_action_items(
+            unique_issues, unique_recommendations
+        )
 
         return ConsultationResult(
             consultation_id=consultation.id,
diff --git a/workspace/src/core/plugins/yaml_module_system/audit_trail.py b/workspace/src/core/plugins/yaml_module_system/audit_trail.py
index 6bdda8f..6e2b27c 100644
--- a/workspace/src/core/plugins/yaml_module_system/audit_trail.py
+++ b/workspace/src/core/plugins/yaml_module_system/audit_trail.py
@@ -283,9 +283,13 @@ class AuditLogger:
 
         return entries[:limit]
 
-    def get_resource_history(self, resource_type: str, resource_id: str) -> list[AuditEntry]:
+    def get_resource_history(
+        self, resource_type: str, resource_id: str
+    ) -> list[AuditEntry]:
         """ç²å–è³‡æºçš„å®Œæ•´æ­·å²"""
-        return self.get_entries(resource_type=resource_type, resource_id=resource_id, limit=1000)
+        return self.get_entries(
+            resource_type=resource_type, resource_id=resource_id, limit=1000
+        )
 
     def export(self, format: str = "json") -> str:
         """å°å‡ºå¯©è¨ˆæ—¥èªŒ"""
diff --git a/workspace/src/core/plugins/yaml_module_system/ci_verification_pipeline.py b/workspace/src/core/plugins/yaml_module_system/ci_verification_pipeline.py
index 927b0e6..8003016 100644
--- a/workspace/src/core/plugins/yaml_module_system/ci_verification_pipeline.py
+++ b/workspace/src/core/plugins/yaml_module_system/ci_verification_pipeline.py
@@ -62,7 +62,9 @@ class StageResult:
             "stage_type": self.stage_type.value,
             "status": self.status.value,
             "started_at": self.started_at.isoformat(),
-            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
+            "completed_at": (
+                self.completed_at.isoformat() if self.completed_at else None
+            ),
             "duration_ms": self.duration_ms,
             "outputs": self.outputs,
             "errors": self.errors,
@@ -132,10 +134,19 @@ class Evidence:
 
     @classmethod
     def create(
-        cls, type: str, name: str, description: str, data: Any, source: str | None = None
+        cls,
+        type: str,
+        name: str,
+        description: str,
+        data: Any,
+        source: str | None = None,
     ) -> "Evidence":
         """å‰µå»ºè­‰æ“š"""
-        data_str = json.dumps(data, sort_keys=True) if isinstance(data, (dict, list)) else str(data)
+        data_str = (
+            json.dumps(data, sort_keys=True)
+            if isinstance(data, (dict, list))
+            else str(data)
+        )
         data_hash = hashlib.sha256(data_str.encode()).hexdigest()
 
         return cls(
@@ -173,7 +184,12 @@ class EvidenceCollector:
         self._evidence: list[Evidence] = []
 
     def collect(
-        self, type: str, name: str, description: str, data: Any, source: str | None = None
+        self,
+        type: str,
+        name: str,
+        description: str,
+        data: Any,
+        source: str | None = None,
     ) -> Evidence:
         """æ”¶é›†è­‰æ“š"""
         evidence = Evidence.create(type, name, description, data, source)
@@ -223,7 +239,9 @@ class VerificationReport:
     def passed(self) -> bool:
         """æ˜¯å¦å…¨éƒ¨é€šé"""
         return all(
-            s.status == StageStatus.PASSED for s in self.stages if s.status != StageStatus.SKIPPED
+            s.status == StageStatus.PASSED
+            for s in self.stages
+            if s.status != StageStatus.SKIPPED
         )
 
     @property
@@ -243,7 +261,9 @@ class VerificationReport:
             "stages": [s.to_dict() for s in self.stages],
             "evidence": [e.to_dict() for e in self.evidence],
             "started_at": self.started_at.isoformat(),
-            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
+            "completed_at": (
+                self.completed_at.isoformat() if self.completed_at else None
+            ),
             "total_duration_ms": self.total_duration_ms,
             "failed_stages": [s.stage_id for s in self.failed_stages],
         }
@@ -256,7 +276,11 @@ class VerificationReport:
             f"- **Pipeline ID**: {self.pipeline_id}",
             f"- **Module**: {self.module_id} v{self.module_version}",
             f"- **Status**: {'âœ… PASSED' if self.passed else 'âŒ FAILED'}",
-            f"- **Duration**: {self.total_duration_ms}ms" if self.total_duration_ms else "",
+            (
+                f"- **Duration**: {self.total_duration_ms}ms"
+                if self.total_duration_ms
+                else ""
+            ),
             "",
             "## Stages",
             "",
@@ -272,7 +296,9 @@ class VerificationReport:
                 StageStatus.CANCELLED: "ğŸš«",
             }.get(stage.status, "â“")
 
-            lines.append(f"- {status_icon} **{stage.stage_type.value}**: {stage.status.value}")
+            lines.append(
+                f"- {status_icon} **{stage.stage_type.value}**: {stage.status.value}"
+            )
 
             if stage.errors:
                 for error in stage.errors:
@@ -325,7 +351,11 @@ class CIVerificationPipeline:
         return None
 
     def run(
-        self, data: Any, module_id: str, module_version: str, context: dict[str, Any] | None = None
+        self,
+        data: Any,
+        module_id: str,
+        module_version: str,
+        context: dict[str, Any] | None = None,
     ) -> VerificationReport:
         """
         åŸ·è¡Œé©—è­‰ç®¡é“
@@ -352,7 +382,8 @@ class CIVerificationPipeline:
         for stage in self._stages:
             # æª¢æŸ¥ä¾è³´
             dependencies_met = all(
-                dep in completed_stages and completed_stages[dep].status == StageStatus.PASSED
+                dep in completed_stages
+                and completed_stages[dep].status == StageStatus.PASSED
                 for dep in stage.depends_on
             )
 
diff --git a/workspace/src/core/plugins/yaml_module_system/policy_gate.py b/workspace/src/core/plugins/yaml_module_system/policy_gate.py
index c562352..051e7dc 100644
--- a/workspace/src/core/plugins/yaml_module_system/policy_gate.py
+++ b/workspace/src/core/plugins/yaml_module_system/policy_gate.py
@@ -104,7 +104,9 @@ class PolicyRule:
     remediation: str | None = None
     documentation_url: str | None = None
 
-    def evaluate(self, data: Any, context: dict[str, Any] | None = None) -> PolicyViolation | None:
+    def evaluate(
+        self, data: Any, context: dict[str, Any] | None = None
+    ) -> PolicyViolation | None:
         """
         è©•ä¼°æ•¸æ“šæ˜¯å¦ç¬¦åˆç­–ç•¥
 
@@ -140,7 +142,9 @@ class PolicyRule:
 
         return None
 
-    def _evaluate_condition(self, data: Any, context: dict[str, Any] | None = None) -> bool:
+    def _evaluate_condition(
+        self, data: Any, context: dict[str, Any] | None = None
+    ) -> bool:
         """è©•ä¼°æ¢ä»¶è¡¨é”å¼"""
         # ç°¡å–®çš„æ¢ä»¶è©•ä¼°
         # æ”¯æŒ: exists, equals, contains, matches, etc.
@@ -222,7 +226,9 @@ class PolicyEvaluationResult:
     @property
     def critical_count(self) -> int:
         """åš´é‡é•è¦æ•¸é‡"""
-        return len([v for v in self.violations if v.severity == PolicySeverity.CRITICAL])
+        return len(
+            [v for v in self.violations if v.severity == PolicySeverity.CRITICAL]
+        )
 
     @property
     def high_count(self) -> int:
@@ -288,7 +294,9 @@ class PolicyGate:
             return True
         return False
 
-    def add_exception(self, rule_id: str, module_id: str, reason: str, approved_by: str) -> bool:
+    def add_exception(
+        self, rule_id: str, module_id: str, reason: str, approved_by: str
+    ) -> bool:
         """æ·»åŠ ä¾‹å¤–"""
         if rule_id not in self._rules:
             return False
@@ -304,7 +312,10 @@ class PolicyGate:
         return module_id in self._exceptions.get(rule_id, [])
 
     def evaluate(
-        self, data: Any, module_id: str | None = None, context: dict[str, Any] | None = None
+        self,
+        data: Any,
+        module_id: str | None = None,
+        context: dict[str, Any] | None = None,
     ) -> PolicyEvaluationResult:
         """
         è©•ä¼°æ•¸æ“šæ˜¯å¦ç¬¦åˆæ‰€æœ‰ç­–ç•¥
@@ -374,7 +385,9 @@ class PolicyGate:
         return result
 
     def get_rules(
-        self, category: PolicyCategory | None = None, severity: PolicySeverity | None = None
+        self,
+        category: PolicyCategory | None = None,
+        severity: PolicySeverity | None = None,
     ) -> list[PolicyRule]:
         """ç²å–ç­–ç•¥è¦å‰‡åˆ—è¡¨"""
         rules = list(self._rules.values())
diff --git a/workspace/src/core/plugins/yaml_module_system/slsa_compliance.py b/workspace/src/core/plugins/yaml_module_system/slsa_compliance.py
index 12aa595..f0ae14f 100644
--- a/workspace/src/core/plugins/yaml_module_system/slsa_compliance.py
+++ b/workspace/src/core/plugins/yaml_module_system/slsa_compliance.py
@@ -121,7 +121,9 @@ class SLSAProvenance:
             "subject": [s.to_dict() for s in self.subjects],
             "predicateType": self.predicate_type,
             "predicate": {
-                "buildDefinition": self.build_definition.to_dict() if self.build_definition else {},
+                "buildDefinition": (
+                    self.build_definition.to_dict() if self.build_definition else {}
+                ),
                 "runDetails": self.run_details.to_dict() if self.run_details else {},
             },
             "metadata": {
@@ -259,7 +261,9 @@ class ArtifactSigner:
     å°è£½å“é€²è¡Œæ•¸å­—ç°½åä»¥ç¢ºä¿å®Œæ•´æ€§ã€‚
     """
 
-    def __init__(self, key_id: str, algorithm: SignatureAlgorithm = SignatureAlgorithm.ECDSA_P256):
+    def __init__(
+        self, key_id: str, algorithm: SignatureAlgorithm = SignatureAlgorithm.ECDSA_P256
+    ):
         self.key_id = key_id
         self.algorithm = algorithm
 
@@ -285,7 +289,9 @@ class ArtifactSigner:
         # ç”Ÿæˆç°½åï¼ˆæ¨¡æ“¬ï¼‰
         # åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒä½¿ç”¨çœŸæ­£çš„å¯†ç¢¼å­¸ç°½å
         signature_data = f"{digest}:{self.key_id}:{self.algorithm.value}"
-        signature = base64.b64encode(hashlib.sha256(signature_data.encode()).digest()).decode()
+        signature = base64.b64encode(
+            hashlib.sha256(signature_data.encode()).digest()
+        ).decode()
 
         return SignedArtifact(
             artifact_name=artifact_name,
diff --git a/workspace/src/core/plugins/yaml_module_system/yaml_module_definition.py b/workspace/src/core/plugins/yaml_module_system/yaml_module_definition.py
index 0b552e6..f1a5632 100644
--- a/workspace/src/core/plugins/yaml_module_system/yaml_module_definition.py
+++ b/workspace/src/core/plugins/yaml_module_system/yaml_module_definition.py
@@ -235,7 +235,9 @@ class YAMLModuleDefinition:
             "lifecycle": {
                 "state": self.lifecycle.state.value,
                 "approved_at": (
-                    self.lifecycle.approved_at.isoformat() if self.lifecycle.approved_at else None
+                    self.lifecycle.approved_at.isoformat()
+                    if self.lifecycle.approved_at
+                    else None
                 ),
                 "approved_by": self.lifecycle.approved_by,
             },
diff --git a/workspace/src/core/plugins/yaml_module_system/yaml_schema_validator.py b/workspace/src/core/plugins/yaml_module_system/yaml_schema_validator.py
index c020548..48c1804 100644
--- a/workspace/src/core/plugins/yaml_module_system/yaml_schema_validator.py
+++ b/workspace/src/core/plugins/yaml_module_system/yaml_schema_validator.py
@@ -91,7 +91,9 @@ class SchemaRegistry:
         self._schemas: dict[str, dict[str, Any]] = {}
         self._schema_versions: dict[str, list[str]] = {}
 
-    def register(self, schema_id: str, schema: dict[str, Any], version: str = "1.0.0") -> None:
+    def register(
+        self, schema_id: str, schema: dict[str, Any], version: str = "1.0.0"
+    ) -> None:
         """è¨»å†Š Schema"""
         full_id = f"{schema_id}@{version}"
         self._schemas[full_id] = schema
@@ -159,7 +161,9 @@ class YAMLSchemaValidator:
         """è¨»å†Šè‡ªå®šç¾©é©—è­‰å™¨"""
         self._custom_validators[name] = validator
 
-    def validate(self, data: Any, schema: dict[str, Any], path: str = "$") -> ValidationResult:
+    def validate(
+        self, data: Any, schema: dict[str, Any], path: str = "$"
+    ) -> ValidationResult:
         """
         é©—è­‰æ•¸æ“šæ˜¯å¦ç¬¦åˆ Schema
 
@@ -438,7 +442,9 @@ class YAMLSchemaValidator:
             seen = []
             for item in data:
                 item_json = (
-                    json.dumps(item, sort_keys=True) if isinstance(item, (dict, list)) else item
+                    json.dumps(item, sort_keys=True)
+                    if isinstance(item, (dict, list))
+                    else item
                 )
                 if item_json in seen:
                     result.add_error(
diff --git a/workspace/src/core/project_factory/cli.py b/workspace/src/core/project_factory/cli.py
index 4a3c5c8..c1a8d43 100644
--- a/workspace/src/core/project_factory/cli.py
+++ b/workspace/src/core/project_factory/cli.py
@@ -155,7 +155,9 @@ def load_spec_from_yaml(spec_file: Path) -> ProjectSpec:
             spec.deliverables.tests.unit = tests.get("unit", True)
             spec.deliverables.tests.integration = tests.get("integration", True)
             spec.deliverables.tests.e2e = tests.get("e2e", False)
-            spec.deliverables.tests.coverage_threshold = tests.get("coverage_threshold", 80)
+            spec.deliverables.tests.coverage_threshold = tests.get(
+                "coverage_threshold", 80
+            )
 
         if "ci_cd" in deliv:
             cicd = deliv["ci_cd"]
@@ -275,14 +277,20 @@ Examples:
 
     # Generate command
     gen_parser = subparsers.add_parser("generate", help="Generate project artifacts")
-    gen_subparsers = gen_parser.add_subparsers(dest="generate_type", help="What to generate")
+    gen_subparsers = gen_parser.add_subparsers(
+        dest="generate_type", help="What to generate"
+    )
 
     # Generate project
-    project_parser = gen_subparsers.add_parser("project", help="Generate complete project")
+    project_parser = gen_subparsers.add_parser(
+        "project", help="Generate complete project"
+    )
 
     # Specification source (mutually exclusive)
     spec_group = project_parser.add_mutually_exclusive_group(required=True)
-    spec_group.add_argument("--spec-file", type=str, help="Load specification from YAML file")
+    spec_group.add_argument(
+        "--spec-file", type=str, help="Load specification from YAML file"
+    )
     spec_group.add_argument("--name", type=str, help="Project name")
 
     # Basic project options
@@ -302,7 +310,9 @@ Examples:
         "--framework", type=str, help="Framework (e.g., fastapi, nestjs, gin)"
     )
     project_parser.add_argument("--description", type=str, help="Project description")
-    project_parser.add_argument("--version", type=str, default="1.0.0", help="Project version")
+    project_parser.add_argument(
+        "--version", type=str, default="1.0.0", help="Project version"
+    )
 
     # Architecture
     project_parser.add_argument(
@@ -316,11 +326,15 @@ Examples:
     project_parser.add_argument(
         "--database", type=str, help="Database type (postgresql, mysql, mongodb, etc.)"
     )
-    project_parser.add_argument("--orm", type=str, help="ORM framework (sqlalchemy, typeorm, etc.)")
+    project_parser.add_argument(
+        "--orm", type=str, help="ORM framework (sqlalchemy, typeorm, etc.)"
+    )
     project_parser.add_argument(
         "--migrations", type=str, help="Migration tool (alembic, flyway, etc.)"
     )
-    project_parser.add_argument("--cache", type=str, help="Cache type (redis, memcached, etc.)")
+    project_parser.add_argument(
+        "--cache", type=str, help="Cache type (redis, memcached, etc.)"
+    )
     project_parser.add_argument(
         "--messaging", type=str, help="Messaging system (kafka, rabbitmq, etc.)"
     )
@@ -329,17 +343,26 @@ Examples:
     )
 
     # Tests
-    project_parser.add_argument("--tests-unit", type=bool, default=True, help="Generate unit tests")
     project_parser.add_argument(
-        "--tests-integration", type=bool, default=True, help="Generate integration tests"
+        "--tests-unit", type=bool, default=True, help="Generate unit tests"
+    )
+    project_parser.add_argument(
+        "--tests-integration",
+        type=bool,
+        default=True,
+        help="Generate integration tests",
+    )
+    project_parser.add_argument(
+        "--tests-e2e", type=bool, default=False, help="Generate E2E tests"
     )
-    project_parser.add_argument("--tests-e2e", type=bool, default=False, help="Generate E2E tests")
     project_parser.add_argument(
         "--coverage-threshold", type=int, default=80, help="Test coverage threshold"
     )
 
     # Infrastructure
-    project_parser.add_argument("--docker", type=bool, default=True, help="Generate Dockerfile")
+    project_parser.add_argument(
+        "--docker", type=bool, default=True, help="Generate Dockerfile"
+    )
     project_parser.add_argument(
         "--kubernetes", type=bool, default=True, help="Generate Kubernetes manifests"
     )
@@ -352,9 +375,14 @@ Examples:
         "--compliance", type=str, help="Comma-separated compliance standards"
     )
     project_parser.add_argument(
-        "--security-level", type=str, default="high", choices=["low", "medium", "high", "critical"]
+        "--security-level",
+        type=str,
+        default="high",
+        choices=["low", "medium", "high", "critical"],
+    )
+    project_parser.add_argument(
+        "--license", type=str, default="MIT", help="License type"
     )
-    project_parser.add_argument("--license", type=str, default="MIT", help="License type")
 
     # Output
     project_parser.add_argument("--output", type=str, help="Output directory")
@@ -367,7 +395,9 @@ Examples:
     # List templates command
     list_parser = subparsers.add_parser("list", help="List available resources")
     list_subparsers = list_parser.add_subparsers(dest="list_type", help="What to list")
-    templates_parser = list_subparsers.add_parser("templates", help="List available templates")
+    templates_parser = list_subparsers.add_parser(
+        "templates", help="List available templates"
+    )
     templates_parser.set_defaults(func=cmd_list_templates)
 
     # Parse arguments
diff --git a/workspace/src/core/project_factory/factory.py b/workspace/src/core/project_factory/factory.py
index cfb7d35..1707ce8 100644
--- a/workspace/src/core/project_factory/factory.py
+++ b/workspace/src/core/project_factory/factory.py
@@ -33,7 +33,11 @@ class GeneratedProject:
     """
 
     def __init__(
-        self, spec: ProjectSpec, root_path: Path, files: Dict[str, str], metadata: Dict[str, Any]
+        self,
+        spec: ProjectSpec,
+        root_path: Path,
+        files: Dict[str, str],
+        metadata: Dict[str, Any],
     ):
         self.spec = spec
         self.root_path = root_path
@@ -171,7 +175,9 @@ class ProjectFactory:
     """
 
     def __init__(
-        self, template_dir: Optional[Path] = None, governance_config: Optional[Path] = None
+        self,
+        template_dir: Optional[Path] = None,
+        governance_config: Optional[Path] = None,
     ):
         """
         Initialize Project Factory.
@@ -183,7 +189,9 @@ class ProjectFactory:
             governance_config: Path to governance configuration
         """
         self.template_dir = template_dir or self._get_default_template_dir()
-        self.governance_config = governance_config or self._get_default_governance_config()
+        self.governance_config = (
+            governance_config or self._get_default_governance_config()
+        )
 
         self.template_engine = TemplateEngine(self.template_dir)
         self.generator = ProjectGenerator(self.template_engine)
@@ -200,7 +208,10 @@ class ProjectFactory:
         return Path(__file__).parents[2] / "governance" / "governance.yaml"
 
     def generate(
-        self, spec: ProjectSpec, output_path: Optional[Path] = None, validate: bool = True
+        self,
+        spec: ProjectSpec,
+        output_path: Optional[Path] = None,
+        validate: bool = True,
     ) -> GeneratedProject:
         """
         Generate complete project from specification.
@@ -315,7 +326,9 @@ class ProjectFactory:
             "generator_version": "1.0.0",
         }
 
-    def _create_metadata(self, spec: ProjectSpec, context: Dict[str, Any]) -> Dict[str, Any]:
+    def _create_metadata(
+        self, spec: ProjectSpec, context: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """
         Create generation metadata.
 
diff --git a/workspace/src/core/project_factory/generator.py b/workspace/src/core/project_factory/generator.py
index d1e7eca..d6cdba5 100644
--- a/workspace/src/core/project_factory/generator.py
+++ b/workspace/src/core/project_factory/generator.py
@@ -121,7 +121,9 @@ class ProjectGenerator:
 
         return files
 
-    def _generate_source_code(self, spec: ProjectSpec, context: Dict[str, Any]) -> Dict[str, str]:
+    def _generate_source_code(
+        self, spec: ProjectSpec, context: Dict[str, Any]
+    ) -> Dict[str, str]:
         """Generate source code based on architecture pattern."""
         files = {}
 
@@ -171,13 +173,17 @@ class ProjectGenerator:
 
             # Infrastructure layer
             if spec.features.database:
-                files[f"src/{pkg}/infrastructure/database.py"] = self.template_engine.render(
-                    f"{template_base}/infrastructure/database.j2", context
+                files[f"src/{pkg}/infrastructure/database.py"] = (
+                    self.template_engine.render(
+                        f"{template_base}/infrastructure/database.j2", context
+                    )
                 )
 
             if spec.features.cache:
-                files[f"src/{pkg}/infrastructure/cache.py"] = self.template_engine.render(
-                    f"{template_base}/infrastructure/cache.j2", context
+                files[f"src/{pkg}/infrastructure/cache.py"] = (
+                    self.template_engine.render(
+                        f"{template_base}/infrastructure/cache.j2", context
+                    )
                 )
 
             # Main entry point
@@ -220,14 +226,18 @@ class ProjectGenerator:
 
         return files
 
-    def _generate_tests(self, spec: ProjectSpec, context: Dict[str, Any]) -> Dict[str, str]:
+    def _generate_tests(
+        self, spec: ProjectSpec, context: Dict[str, Any]
+    ) -> Dict[str, str]:
         """Generate test suites."""
         files = {}
         pkg = context["package_name"]
 
         if spec.language == Language.PYTHON:
             # pytest configuration
-            files["pytest.ini"] = self.template_engine.render("python/pytest.ini.j2", context)
+            files["pytest.ini"] = self.template_engine.render(
+                "python/pytest.ini.j2", context
+            )
 
             # Unit tests
             if spec.deliverables.tests.unit:
@@ -251,7 +261,9 @@ class ProjectGenerator:
 
         return files
 
-    def _generate_docker(self, spec: ProjectSpec, context: Dict[str, Any]) -> Dict[str, str]:
+    def _generate_docker(
+        self, spec: ProjectSpec, context: Dict[str, Any]
+    ) -> Dict[str, str]:
         """Generate Docker configuration."""
         files = {}
 
@@ -259,7 +271,9 @@ class ProjectGenerator:
             f"docker/{spec.language.value}/Dockerfile.j2", context
         )
 
-        files[".dockerignore"] = self.template_engine.render("docker/.dockerignore.j2", context)
+        files[".dockerignore"] = self.template_engine.render(
+            "docker/.dockerignore.j2", context
+        )
 
         files["docker-compose.yml"] = self.template_engine.render(
             "docker/docker-compose.yml.j2", context
@@ -267,7 +281,9 @@ class ProjectGenerator:
 
         return files
 
-    def _generate_kubernetes(self, spec: ProjectSpec, context: Dict[str, Any]) -> Dict[str, str]:
+    def _generate_kubernetes(
+        self, spec: ProjectSpec, context: Dict[str, Any]
+    ) -> Dict[str, str]:
         """Generate Kubernetes manifests."""
         files = {}
 
@@ -277,13 +293,19 @@ class ProjectGenerator:
             )
 
         if spec.deliverables.kubernetes.service:
-            files["k8s/service.yaml"] = self.template_engine.render("k8s/service.yaml.j2", context)
+            files["k8s/service.yaml"] = self.template_engine.render(
+                "k8s/service.yaml.j2", context
+            )
 
         if spec.deliverables.kubernetes.ingress:
-            files["k8s/ingress.yaml"] = self.template_engine.render("k8s/ingress.yaml.j2", context)
+            files["k8s/ingress.yaml"] = self.template_engine.render(
+                "k8s/ingress.yaml.j2", context
+            )
 
         if spec.deliverables.kubernetes.hpa:
-            files["k8s/hpa.yaml"] = self.template_engine.render("k8s/hpa.yaml.j2", context)
+            files["k8s/hpa.yaml"] = self.template_engine.render(
+                "k8s/hpa.yaml.j2", context
+            )
 
         if spec.deliverables.kubernetes.network_policy:
             files["k8s/network-policy.yaml"] = self.template_engine.render(
@@ -292,7 +314,9 @@ class ProjectGenerator:
 
         return files
 
-    def _generate_cicd(self, spec: ProjectSpec, context: Dict[str, Any]) -> Dict[str, str]:
+    def _generate_cicd(
+        self, spec: ProjectSpec, context: Dict[str, Any]
+    ) -> Dict[str, str]:
         """Generate CI/CD pipeline configuration."""
         files = {}
 
@@ -312,11 +336,15 @@ class ProjectGenerator:
             )
 
         elif platform == "drone":
-            files[".drone.yml"] = self.template_engine.render("cicd/drone/drone.yml.j2", context)
+            files[".drone.yml"] = self.template_engine.render(
+                "cicd/drone/drone.yml.j2", context
+            )
 
         return files
 
-    def _generate_documentation(self, spec: ProjectSpec, context: Dict[str, Any]) -> Dict[str, str]:
+    def _generate_documentation(
+        self, spec: ProjectSpec, context: Dict[str, Any]
+    ) -> Dict[str, str]:
         """Generate project documentation."""
         files = {}
 
@@ -357,6 +385,8 @@ class ProjectGenerator:
         )
 
         # Security policy
-        files["SECURITY.md"] = self.template_engine.render("common/SECURITY.md.j2", context)
+        files["SECURITY.md"] = self.template_engine.render(
+            "common/SECURITY.md.j2", context
+        )
 
         return files
diff --git a/workspace/src/core/project_factory/spec.py b/workspace/src/core/project_factory/spec.py
index 5f8aa71..d03dc2c 100644
--- a/workspace/src/core/project_factory/spec.py
+++ b/workspace/src/core/project_factory/spec.py
@@ -193,7 +193,12 @@ class ArchitectureSpec:
 
     pattern: ArchitecturePattern = ArchitecturePattern.CLEAN_ARCHITECTURE
     layers: List[str] = field(
-        default_factory=lambda: ["presentation", "application", "domain", "infrastructure"]
+        default_factory=lambda: [
+            "presentation",
+            "application",
+            "domain",
+            "infrastructure",
+        ]
     )
     bounded_contexts: List[str] = field(default_factory=list)
 
@@ -316,7 +321,9 @@ class ProjectSpec:
             "django",
             "starlette",
         ]:
-            errors.append(f"Unsupported framework {self.framework} for {self.language.value}")
+            errors.append(
+                f"Unsupported framework {self.framework} for {self.language.value}"
+            )
 
         # Validate coverage threshold
         if not 0 <= self.deliverables.tests.coverage_threshold <= 100:
diff --git a/workspace/src/core/project_factory/templates.py b/workspace/src/core/project_factory/templates.py
index a19d379..c885613 100644
--- a/workspace/src/core/project_factory/templates.py
+++ b/workspace/src/core/project_factory/templates.py
@@ -117,7 +117,9 @@ class TemplateEngine:
         template = Template(template_string)
         return template.render(**context)
 
-    def _get_fallback_template(self, template_path: str, context: Dict[str, Any]) -> str:
+    def _get_fallback_template(
+        self, template_path: str, context: Dict[str, Any]
+    ) -> str:
         """
         Get fallback content when template is missing.
 
@@ -151,7 +153,9 @@ class TemplateEngine:
 
         for template_file in self.template_dir.rglob("*.j2"):
             relative_path = template_file.relative_to(self.template_dir)
-            category = str(relative_path.parts[0]) if relative_path.parts else "uncategorized"
+            category = (
+                str(relative_path.parts[0]) if relative_path.parts else "uncategorized"
+            )
 
             if category not in templates:
                 templates[category] = []
diff --git a/workspace/src/core/project_factory/validator.py b/workspace/src/core/project_factory/validator.py
index abd70c2..078a406 100644
--- a/workspace/src/core/project_factory/validator.py
+++ b/workspace/src/core/project_factory/validator.py
@@ -29,7 +29,9 @@ class ValidationResult:
         self.checks: Dict[str, Dict[str, Any]] = {}
         self.overall_status: str = "PENDING"
 
-    def add_check(self, check_name: str, status: str, details: str, **extra_data) -> None:
+    def add_check(
+        self, check_name: str, status: str, details: str, **extra_data
+    ) -> None:
         """Add validation check result."""
         self.checks[check_name] = {"status": status, "details": details, **extra_data}
 
@@ -142,7 +144,9 @@ class GovernanceValidator:
         logger.info(f"Validation complete: {result.overall_status}")
         return result.to_dict()
 
-    def _check_language_policy(self, project: "GeneratedProject", result: ValidationResult) -> None:
+    def _check_language_policy(
+        self, project: "GeneratedProject", result: ValidationResult
+    ) -> None:
         """Check language policy compliance."""
         spec = project.spec
 
@@ -166,7 +170,9 @@ class GovernanceValidator:
 
         required_version = version_requirements.get(spec.language.value)
         if required_version:
-            details = f"Language {spec.language.value} requires version {required_version}"
+            details = (
+                f"Language {spec.language.value} requires version {required_version}"
+            )
         else:
             details = "All language constraints satisfied"
 
@@ -201,7 +207,9 @@ class GovernanceValidator:
                 issues.append("Dockerfile runs as root (security risk)")
 
         if issues:
-            result.add_check("security", "WARNING", f"Security issues found: {', '.join(issues)}")
+            result.add_check(
+                "security", "WARNING", f"Security issues found: {', '.join(issues)}"
+            )
         else:
             result.add_check("security", "PASSED", "No security issues found")
 
@@ -213,13 +221,20 @@ class GovernanceValidator:
 
         # Check if architecture pattern is correctly implemented
         if spec.architecture.pattern.value == "clean-architecture":
-            expected_layers = {"presentation", "application", "domain", "infrastructure"}
+            expected_layers = {
+                "presentation",
+                "application",
+                "domain",
+                "infrastructure",
+            }
             actual_layers = set(spec.architecture.layers)
 
             if not expected_layers.issubset(actual_layers):
                 missing = expected_layers - actual_layers
                 result.add_check(
-                    "architecture", "WARNING", f"Clean architecture missing layers: {missing}"
+                    "architecture",
+                    "WARNING",
+                    f"Clean architecture missing layers: {missing}",
                 )
             else:
                 result.add_check(
@@ -229,10 +244,14 @@ class GovernanceValidator:
                 )
         else:
             result.add_check(
-                "architecture", "PASSED", f"Architecture pattern: {spec.architecture.pattern.value}"
+                "architecture",
+                "PASSED",
+                f"Architecture pattern: {spec.architecture.pattern.value}",
             )
 
-    def _check_cicd_standards(self, project: "GeneratedProject", result: ValidationResult) -> None:
+    def _check_cicd_standards(
+        self, project: "GeneratedProject", result: ValidationResult
+    ) -> None:
         """Check CI/CD standards compliance."""
         spec = project.spec
         files = project.files
@@ -257,7 +276,9 @@ class GovernanceValidator:
                 )
             else:
                 result.add_check(
-                    "ci_cd", "WARNING", "CI/CD configured but pipeline file not generated"
+                    "ci_cd",
+                    "WARNING",
+                    "CI/CD configured but pipeline file not generated",
                 )
 
     def _check_compliance_requirements(
@@ -290,4 +311,6 @@ class GovernanceValidator:
                 artifacts=compliance_artifacts,
             )
         else:
-            result.add_check("compliance", "WARNING", "Missing compliance documentation")
+            result.add_check(
+                "compliance", "WARNING", "Missing compliance documentation"
+            )
diff --git a/workspace/src/core/run-debug/adapters/python_adapter.py b/workspace/src/core/run-debug/adapters/python_adapter.py
index 1df26c6..674bfa5 100644
--- a/workspace/src/core/run-debug/adapters/python_adapter.py
+++ b/workspace/src/core/run-debug/adapters/python_adapter.py
@@ -5,16 +5,23 @@ Python Debug Adapter
 å¯¦ä½œ Python èªè¨€çš„åµéŒ¯åŠŸèƒ½ï¼Œæ”¯æ´ debugpy å”è­°ã€‚
 """
 
-import os
 import asyncio
 import json
+import os
 import socket
 import subprocess
 import sys
 from pathlib import Path
 from typing import Any, Dict, List, Optional
 
-from ..engine import BreakpointType, DebugAdapter, DebugSession, DebugState, StackFrame, Variable
+from ..engine import (
+    BreakpointType,
+    DebugAdapter,
+    DebugSession,
+    DebugState,
+    StackFrame,
+    Variable,
+)
 
 
 class PythonDebugAdapter(DebugAdapter):
@@ -31,7 +38,9 @@ class PythonDebugAdapter(DebugAdapter):
 
     async def initialize(self, session: DebugSession):
         """åˆå§‹åŒ– Python åµéŒ¯å™¨"""
-        self.logger.info(f"Initializing Python debug adapter for session {session.session_id}")
+        self.logger.info(
+            f"Initializing Python debug adapter for session {session.session_id}"
+        )
 
         # æª¢æŸ¥ debugpy æ˜¯å¦å·²å®‰è£
         try:
@@ -41,7 +50,9 @@ class PythonDebugAdapter(DebugAdapter):
         except ImportError:
             self.logger.warning("debugpy not installed, installing...")
             subprocess.run(
-                [sys.executable, "-m", "pip", "install", "debugpy"], check=True, capture_output=True
+                [sys.executable, "-m", "pip", "install", "debugpy"],
+                check=True,
+                capture_output=True,
             )
 
         session.state = DebugState.INITIALIZING
@@ -125,7 +136,9 @@ class PythonDebugAdapter(DebugAdapter):
                 else:
                     raise
 
-    async def _send_request(self, command: str, arguments: Optional[Dict] = None) -> Dict:
+    async def _send_request(
+        self, command: str, arguments: Optional[Dict] = None
+    ) -> Dict:
         """ç™¼é€ DAP è«‹æ±‚"""
         self.seq += 1
         request = {
@@ -212,7 +225,9 @@ class PythonDebugAdapter(DebugAdapter):
                 if message.get("success"):
                     future.set_result(message.get("body", {}))
                 else:
-                    future.set_exception(Exception(message.get("message", "Request failed")))
+                    future.set_exception(
+                        Exception(message.get("message", "Request failed"))
+                    )
 
         elif msg_type == "event":
             # äº‹ä»¶è¨Šæ¯
@@ -266,7 +281,11 @@ class PythonDebugAdapter(DebugAdapter):
             if bp.file not in breakpoints_by_file:
                 breakpoints_by_file[bp.file] = []
             breakpoints_by_file[bp.file].append(
-                {"line": bp.line, "condition": bp.condition, "logMessage": bp.log_message}
+                {
+                    "line": bp.line,
+                    "condition": bp.condition,
+                    "logMessage": bp.log_message,
+                }
             )
 
         # ç‚ºæ¯å€‹æª”æ¡ˆè¨­å®šæ–·é»
@@ -286,7 +305,9 @@ class PythonDebugAdapter(DebugAdapter):
 
         async def read_stream(stream, prefix):
             while True:
-                line = await asyncio.get_event_loop().run_in_executor(None, stream.readline)
+                line = await asyncio.get_event_loop().run_in_executor(
+                    None, stream.readline
+                )
                 if not line:
                     break
                 self.logger.info(f"{prefix}: {line.decode('utf-8').strip()}")
@@ -324,14 +345,18 @@ class PythonDebugAdapter(DebugAdapter):
         """å–®æ­¥åŸ·è¡Œï¼ˆè·³å‡ºï¼‰"""
         await self._send_request("stepOut", {"threadId": 1})
 
-    async def evaluate(self, session: DebugSession, expression: str) -> Optional[Variable]:
+    async def evaluate(
+        self, session: DebugSession, expression: str
+    ) -> Optional[Variable]:
         """è©•ä¼°è¡¨é”å¼"""
         try:
             response = await self._send_request(
                 "evaluate",
                 {
                     "expression": expression,
-                    "frameId": session.stack_frames[0].id if session.stack_frames else 0,
+                    "frameId": (
+                        session.stack_frames[0].id if session.stack_frames else 0
+                    ),
                     "context": "repl",
                 },
             )
@@ -370,7 +395,9 @@ class PythonDebugAdapter(DebugAdapter):
             self.logger.error(f"Failed to get stack trace: {e}")
             return []
 
-    async def get_variables(self, session: DebugSession, scope: str = "local") -> List[Variable]:
+    async def get_variables(
+        self, session: DebugSession, scope: str = "local"
+    ) -> List[Variable]:
         """å–å¾—è®Šæ•¸"""
         try:
             if not session.stack_frames:
@@ -387,7 +414,8 @@ class PythonDebugAdapter(DebugAdapter):
                 if scope == "all" or scope in scope_name:
                     # å–å¾—è©²ä½œç”¨åŸŸçš„è®Šæ•¸
                     vars_response = await self._send_request(
-                        "variables", {"variablesReference": scope_data.get("variablesReference", 0)}
+                        "variables",
+                        {"variablesReference": scope_data.get("variablesReference", 0)},
                     )
 
                     for var_data in vars_response.get("variables", []):
diff --git a/workspace/src/core/run-debug/chat_interface.py b/workspace/src/core/run-debug/chat_interface.py
index 4a4a3a0..177a767 100644
--- a/workspace/src/core/run-debug/chat_interface.py
+++ b/workspace/src/core/run-debug/chat_interface.py
@@ -163,10 +163,15 @@ class NaturalLanguageProcessor:
                             entities["expression"] = match.group(1).strip()
 
                     return Intent(
-                        type=intent_type, confidence=0.9, entities=entities, original_text=text
+                        type=intent_type,
+                        confidence=0.9,
+                        entities=entities,
+                        original_text=text,
                     )
 
-        return Intent(type=IntentType.UNKNOWN, confidence=0.0, entities={}, original_text=text)
+        return Intent(
+            type=IntentType.UNKNOWN, confidence=0.0, entities={}, original_text=text
+        )
 
 
 class ErrorAnalyzer:
@@ -275,7 +280,11 @@ class ErrorAnalyzer:
             analysis["suggested_fixes"] = error_info["fixes"]
         else:
             analysis["explanation"] = f"ç™¼ç”Ÿäº† {error_type} éŒ¯èª¤ã€‚"
-            analysis["suggested_fixes"] = ["æª¢æŸ¥éŒ¯èª¤è¨Šæ¯", "æŸ¥çœ‹å †ç–Šè¿½è¹¤", "æª¢æŸ¥ç›¸é—œç¨‹å¼ç¢¼"]
+            analysis["suggested_fixes"] = [
+                "æª¢æŸ¥éŒ¯èª¤è¨Šæ¯",
+                "æŸ¥çœ‹å †ç–Šè¿½è¹¤",
+                "æª¢æŸ¥ç›¸é—œç¨‹å¼ç¢¼",
+            ]
 
         return analysis
 
@@ -411,14 +420,14 @@ class ChatDebugInterface:
             config_name = configs[0].name
         else:
             # åˆ—å‡ºå¯ç”¨é…ç½®
-            config_list = "\n".join([f"  {i+1}. {c.name}" for i, c in enumerate(configs)])
+            config_list = "\n".join(
+                [f"  {i+1}. {c.name}" for i, c in enumerate(configs)]
+            )
             return f"è«‹é¸æ“‡è¦ä½¿ç”¨çš„é…ç½®ï¼š\n{config_list}\n\nè«‹èªªã€Œä½¿ç”¨é…ç½® 1ã€æˆ–ç›´æ¥èªªé…ç½®åç¨±ã€‚"
 
         success = await self.cli.start_debug(config_name)
         if success:
-            return (
-                f"âœ… å·²å•Ÿå‹•åµéŒ¯æœƒè©±ï¼š{config_name}\n\næ‚¨å¯ä»¥ï¼š\n- è¨­å®šæ–·é»\n- é–‹å§‹åŸ·è¡Œ\n- æª¢è¦–è®Šæ•¸"
-            )
+            return f"âœ… å·²å•Ÿå‹•åµéŒ¯æœƒè©±ï¼š{config_name}\n\næ‚¨å¯ä»¥ï¼š\n- è¨­å®šæ–·é»\n- é–‹å§‹åŸ·è¡Œ\n- æª¢è¦–è®Šæ•¸"
         else:
             return "âŒ å•Ÿå‹•åµéŒ¯æœƒè©±å¤±æ•—ã€‚è«‹æª¢æŸ¥é…ç½®æ˜¯å¦æ­£ç¢ºã€‚"
 
@@ -472,9 +481,7 @@ class ChatDebugInterface:
             frames = await self.cli.engine.get_stack_trace(self.cli.current_session_id)
             if frames:
                 frame = frames[0]
-                return (
-                    f"â­ï¸ å·²åŸ·è¡Œåˆ°ä¸‹ä¸€è¡Œ\n\nğŸ“ ç•¶å‰ä½ç½®ï¼š{frame.file}:{frame.line}\n   {frame.name}"
-                )
+                return f"â­ï¸ å·²åŸ·è¡Œåˆ°ä¸‹ä¸€è¡Œ\n\nğŸ“ ç•¶å‰ä½ç½®ï¼š{frame.file}:{frame.line}\n   {frame.name}"
             return "â­ï¸ å·²åŸ·è¡Œåˆ°ä¸‹ä¸€è¡Œ"
         else:
             return "âŒ ç„¡æ³•åŸ·è¡Œå–®æ­¥æ“ä½œ"
@@ -527,7 +534,9 @@ class ChatDebugInterface:
         if not expression:
             return "è«‹æŒ‡å®šè¦è©•ä¼°çš„è¡¨é”å¼"
 
-        result = await self.cli.engine.evaluate_expression(self.cli.current_session_id, expression)
+        result = await self.cli.engine.evaluate_expression(
+            self.cli.current_session_id, expression
+        )
 
         if result:
             return f"ğŸ’¡ {result.name} = {result.value}\n   é¡å‹ï¼š{result.type}"
diff --git a/workspace/src/core/run-debug/cli.py b/workspace/src/core/run-debug/cli.py
index f57da22..489f9f4 100644
--- a/workspace/src/core/run-debug/cli.py
+++ b/workspace/src/core/run-debug/cli.py
@@ -249,7 +249,9 @@ class DebugCLI:
             click.echo("âŒ No active debug session", err=True)
             return
 
-        result = await self.engine.evaluate_expression(self.current_session_id, expression)
+        result = await self.engine.evaluate_expression(
+            self.current_session_id, expression
+        )
         if result:
             click.echo(f"ğŸ’¡ {result.name} = {result.value} ({result.type})")
         else:
diff --git a/workspace/src/core/run-debug/engine.py b/workspace/src/core/run-debug/engine.py
index 4a7fa20..5de8a06 100644
--- a/workspace/src/core/run-debug/engine.py
+++ b/workspace/src/core/run-debug/engine.py
@@ -135,7 +135,9 @@ class DebugSession:
         """ç§»é™¤æ–·é»"""
         if breakpoint_id in self.breakpoints:
             bp = self.breakpoints.pop(breakpoint_id)
-            self.logger.info(f"Breakpoint {breakpoint_id} removed from {bp.file}:{bp.line}")
+            self.logger.info(
+                f"Breakpoint {breakpoint_id} removed from {bp.file}:{bp.line}"
+            )
             self._emit_event("breakpoint_removed", bp)
             return True
         return False
@@ -280,7 +282,9 @@ class DebugEngine:
             return True
         return False
 
-    async def evaluate_expression(self, session_id: str, expression: str) -> Optional[Variable]:
+    async def evaluate_expression(
+        self, session_id: str, expression: str
+    ) -> Optional[Variable]:
         """è©•ä¼°è¡¨é”å¼"""
         session = self.sessions.get(session_id)
         if not session or session.state != DebugState.PAUSED:
@@ -302,7 +306,9 @@ class DebugEngine:
             return await adapter.get_stack_trace(session)
         return []
 
-    async def get_variables(self, session_id: str, scope: str = "local") -> List[Variable]:
+    async def get_variables(
+        self, session_id: str, scope: str = "local"
+    ) -> List[Variable]:
         """å–å¾—è®Šæ•¸"""
         session = self.sessions.get(session_id)
         if not session or session.state != DebugState.PAUSED:
@@ -375,7 +381,9 @@ class DebugAdapter:
         """å–®æ­¥åŸ·è¡Œï¼ˆè·³å‡ºï¼‰"""
         raise NotImplementedError
 
-    async def evaluate(self, session: DebugSession, expression: str) -> Optional[Variable]:
+    async def evaluate(
+        self, session: DebugSession, expression: str
+    ) -> Optional[Variable]:
         """è©•ä¼°è¡¨é”å¼"""
         raise NotImplementedError
 
diff --git a/workspace/src/core/safety/anomaly_detector.py b/workspace/src/core/safety/anomaly_detector.py
index be4f5d6..b2f852d 100644
--- a/workspace/src/core/safety/anomaly_detector.py
+++ b/workspace/src/core/safety/anomaly_detector.py
@@ -161,7 +161,9 @@ class AnomalyDetector:
         }
 
     def add_handler(
-        self, handler: Callable[[AnomalyAlert], None], anomaly_type: Optional[AnomalyType] = None
+        self,
+        handler: Callable[[AnomalyAlert], None],
+        anomaly_type: Optional[AnomalyType] = None,
     ) -> None:
         """
         Add a handler for anomaly alerts
@@ -257,7 +259,9 @@ class AnomalyDetector:
                     z_score = abs(value - mean) / std_dev
                     if z_score > factor:
                         is_anomaly = True
-                        description = f"Value {value} is {z_score:.2f} std devs from mean"
+                        description = (
+                            f"Value {value} is {z_score:.2f} std devs from mean"
+                        )
                         details["z_score"] = z_score
                         details["mean"] = mean
                         details["std_dev"] = std_dev
@@ -270,9 +274,7 @@ class AnomalyDetector:
             if len(recent) > count:
                 is_anomaly = True
                 anomaly_type = AnomalyType.RATE_ANOMALY
-                description = (
-                    f"Rate limit exceeded: {len(recent)} events in {seconds}s (limit: {count})"
-                )
+                description = f"Rate limit exceeded: {len(recent)} events in {seconds}s (limit: {count})"
                 details["rate_count"] = len(recent)
                 details["rate_limit"] = count
                 details["rate_window"] = seconds
@@ -325,7 +327,9 @@ class AnomalyDetector:
 
         return AnomalySeverity.LOW
 
-    def _get_recommended_action(self, anomaly_type: AnomalyType, severity: AnomalySeverity) -> str:
+    def _get_recommended_action(
+        self, anomaly_type: AnomalyType, severity: AnomalySeverity
+    ) -> str:
         """Get recommended action based on anomaly type and severity"""
         actions = {
             (
@@ -333,14 +337,23 @@ class AnomalyDetector:
                 AnomalySeverity.CRITICAL,
             ): "Immediately throttle or stop operations",
             (AnomalyType.RATE_ANOMALY, AnomalySeverity.HIGH): "Enable rate limiting",
-            (AnomalyType.VALUE_ANOMALY, AnomalySeverity.CRITICAL): "Trigger circuit breaker",
+            (
+                AnomalyType.VALUE_ANOMALY,
+                AnomalySeverity.CRITICAL,
+            ): "Trigger circuit breaker",
             (AnomalyType.VALUE_ANOMALY, AnomalySeverity.HIGH): "Alert on-call team",
             (
                 AnomalyType.SECURITY_ANOMALY,
                 AnomalySeverity.CRITICAL,
             ): "Emergency stop all operations",
-            (AnomalyType.SECURITY_ANOMALY, AnomalySeverity.HIGH): "Isolate affected components",
-            (AnomalyType.RESOURCE_ANOMALY, AnomalySeverity.CRITICAL): "Scale resources immediately",
+            (
+                AnomalyType.SECURITY_ANOMALY,
+                AnomalySeverity.HIGH,
+            ): "Isolate affected components",
+            (
+                AnomalyType.RESOURCE_ANOMALY,
+                AnomalySeverity.CRITICAL,
+            ): "Scale resources immediately",
         }
 
         return actions.get((anomaly_type, severity), "Monitor and investigate")
diff --git a/workspace/src/core/safety/autonomous_trust_engine.py b/workspace/src/core/safety/autonomous_trust_engine.py
index 56c432e..84e4230 100644
--- a/workspace/src/core/safety/autonomous_trust_engine.py
+++ b/workspace/src/core/safety/autonomous_trust_engine.py
@@ -218,7 +218,10 @@ class AutonomousTrustEngine:
         default_nets = [
             SafetyNet(
                 name="cascade_failure_prevention",
-                trigger_conditions=["multiple_failures_in_succession", "error_rate_spike"],
+                trigger_conditions=[
+                    "multiple_failures_in_succession",
+                    "error_rate_spike",
+                ],
                 action_on_trigger="pause_all_operations",
                 auto_rollback=True,
             ),
@@ -236,7 +239,10 @@ class AutonomousTrustEngine:
             ),
             SafetyNet(
                 name="security_boundary",
-                trigger_conditions=["privilege_escalation_attempt", "unauthorized_access"],
+                trigger_conditions=[
+                    "privilege_escalation_attempt",
+                    "unauthorized_access",
+                ],
                 action_on_trigger="lockdown",
                 auto_rollback=True,
             ),
@@ -267,7 +273,9 @@ class AutonomousTrustEngine:
 
         return RiskLevel.CRITICAL if trust >= 95 else RiskLevel.MINIMAL
 
-    async def make_autonomous_decision(self, action: ProposedAction) -> AutonomousDecision:
+    async def make_autonomous_decision(
+        self, action: ProposedAction
+    ) -> AutonomousDecision:
         """
         Make fully autonomous decision without human approval
 
@@ -289,7 +297,9 @@ class AutonomousTrustEngine:
         risk_assessment = self._assess_risk(action)
 
         # Get domain-specific trust
-        domain_trust = self.trust_score.domains.get(action.domain, self.trust_score.overall)
+        domain_trust = self.trust_score.domains.get(
+            action.domain, self.trust_score.overall
+        )
 
         # Calculate combined trust score
         combined_trust = (self.trust_score.overall * 0.6) + (domain_trust * 0.4)
@@ -308,7 +318,9 @@ class AutonomousTrustEngine:
             self.stats["auto_rejected"] += 1
         elif can_auto_approve:
             outcome = DecisionOutcome.APPROVED_AUTO
-            reasoning = self._generate_approval_reasoning(action, risk_assessment, combined_trust)
+            reasoning = self._generate_approval_reasoning(
+                action, risk_assessment, combined_trust
+            )
             confidence = min(combined_trust / 100, 0.99)
             self.stats["auto_approved"] += 1
         else:
@@ -408,7 +420,9 @@ class AutonomousTrustEngine:
             return "consider_alternatives"
         return "high_risk_action"
 
-    def _suggest_mitigations(self, action: ProposedAction, composite_risk: float) -> List[str]:
+    def _suggest_mitigations(
+        self, action: ProposedAction, composite_risk: float
+    ) -> List[str]:
         """Suggest risk mitigations"""
         mitigations = []
 
@@ -458,13 +472,17 @@ class AutonomousTrustEngine:
 
         if condition == "privilege_escalation_attempt":
             return (
-                action.domain == TrustDomain.SECURITY and "escalate" in action.action_type.lower()
+                action.domain == TrustDomain.SECURITY
+                and "escalate" in action.action_type.lower()
             )
 
         return False
 
     def _generate_approval_reasoning(
-        self, action: ProposedAction, risk_assessment: Dict[str, Any], trust_score: float
+        self,
+        action: ProposedAction,
+        risk_assessment: Dict[str, Any],
+        trust_score: float,
     ) -> str:
         """Generate human-readable reasoning for approval"""
         parts = [
@@ -481,7 +499,9 @@ class AutonomousTrustEngine:
 
         return " ".join(parts)
 
-    async def execute_decision(self, decision: AutonomousDecision) -> AutonomousDecision:
+    async def execute_decision(
+        self, decision: AutonomousDecision
+    ) -> AutonomousDecision:
         """
         Execute an approved decision
 
@@ -497,7 +517,9 @@ class AutonomousTrustEngine:
             DecisionOutcome.APPROVED_AUTO,
             DecisionOutcome.APPROVED_ESCALATED,
         ]:
-            logger.warning(f"Cannot execute non-approved decision: {decision.decision_id}")
+            logger.warning(
+                f"Cannot execute non-approved decision: {decision.decision_id}"
+            )
             return decision
 
         self.stats["executions"] += 1
@@ -581,7 +603,9 @@ class AutonomousTrustEngine:
         adjustment = self.TRUST_ADJUSTMENTS.get(event_type, 0)
 
         # Update overall trust
-        self.trust_score.overall = max(0, min(100, self.trust_score.overall + adjustment))
+        self.trust_score.overall = max(
+            0, min(100, self.trust_score.overall + adjustment)
+        )
 
         # Update domain-specific trust
         if domain in self.trust_score.domains:
@@ -620,7 +644,8 @@ class AutonomousTrustEngine:
         return {
             "overall_trust": round(self.trust_score.overall, 2),
             "domain_trust": {
-                domain.value: round(score, 2) for domain, score in self.trust_score.domains.items()
+                domain.value: round(score, 2)
+                for domain, score in self.trust_score.domains.items()
             },
             "autonomy_level": self.get_current_autonomy_level().value,
             "acceptable_risk": self.get_acceptable_risk_level().name,
@@ -630,20 +655,27 @@ class AutonomousTrustEngine:
 
     def get_statistics(self) -> Dict[str, Any]:
         """Get engine statistics"""
-        success_rate = self.stats["successful_executions"] / max(self.stats["executions"], 1) * 100
+        success_rate = (
+            self.stats["successful_executions"] / max(self.stats["executions"], 1) * 100
+        )
 
         return {
             "total_decisions": self.stats["total_decisions"],
             "auto_approved": self.stats["auto_approved"],
             "auto_rejected": self.stats["auto_rejected"],
             "approval_rate": round(
-                self.stats["auto_approved"] / max(self.stats["total_decisions"], 1) * 100, 2
+                self.stats["auto_approved"]
+                / max(self.stats["total_decisions"], 1)
+                * 100,
+                2,
             ),
             "executions": self.stats["executions"],
             "successful_executions": self.stats["successful_executions"],
             "success_rate": round(success_rate, 2),
             "rollbacks": self.stats["rollbacks"],
-            "safety_nets_active": len([net for net in self.safety_nets.values() if net.enabled]),
+            "safety_nets_active": len(
+                [net for net in self.safety_nets.values() if net.enabled]
+            ),
         }
 
     def get_decision_history(
diff --git a/workspace/src/core/safety/checkpoint_manager.py b/workspace/src/core/safety/checkpoint_manager.py
index e72d204..54fdfb5 100644
--- a/workspace/src/core/safety/checkpoint_manager.py
+++ b/workspace/src/core/safety/checkpoint_manager.py
@@ -99,7 +99,9 @@ class CheckpointManager:
             compression_enabled,
         )
 
-    def create_checkpoint(self, execution_id: str, phase_id: str, state: dict[str, Any]) -> str:
+    def create_checkpoint(
+        self, execution_id: str, phase_id: str, state: dict[str, Any]
+    ) -> str:
         """
         Create a checkpoint for the current state.
 
@@ -191,7 +193,9 @@ class CheckpointManager:
 
         # Verify checksum
         if not self._verify_checksum(checkpoint):
-            raise ValueError(f"Checksum verification failed for checkpoint: {checkpoint_id}")
+            raise ValueError(
+                f"Checksum verification failed for checkpoint: {checkpoint_id}"
+            )
 
         # Update status
         checkpoint.status = CheckpointStatus.RESTORED
@@ -319,7 +323,9 @@ class CheckpointManager:
             }
 
         total_size = sum(cp.original_size for cp in checkpoints)
-        compressed_size = sum(cp.compressed_size or 0 for cp in checkpoints if cp.compressed)
+        compressed_size = sum(
+            cp.compressed_size or 0 for cp in checkpoints if cp.compressed
+        )
         compressed_count = sum(1 for cp in checkpoints if cp.compressed)
 
         return {
@@ -328,7 +334,9 @@ class CheckpointManager:
             "compressed_checkpoints": compressed_count,
             "total_size": total_size,
             "compressed_size": compressed_size,
-            "compression_ratio": (1 - compressed_size / total_size) * 100 if total_size > 0 else 0,
+            "compression_ratio": (
+                (1 - compressed_size / total_size) * 100 if total_size > 0 else 0
+            ),
             "oldest_checkpoint": min(cp.timestamp for cp in checkpoints),
             "newest_checkpoint": max(cp.timestamp for cp in checkpoints),
         }
@@ -425,7 +433,9 @@ class CheckpointManager:
                 del self._checkpoints[execution_id]
 
         logger.info(
-            "Cleaned up %d expired checkpoints (older than %d days)", removed_count, max_age_days
+            "Cleaned up %d expired checkpoints (older than %d days)",
+            removed_count,
+            max_age_days,
         )
 
         return removed_count
diff --git a/workspace/src/core/safety/circuit_breaker.py b/workspace/src/core/safety/circuit_breaker.py
index ca4ef38..cac1ba6 100644
--- a/workspace/src/core/safety/circuit_breaker.py
+++ b/workspace/src/core/safety/circuit_breaker.py
@@ -79,7 +79,9 @@ class CircuitBreaker(Generic[T]):
         self._last_failure_time: Optional[float] = None
         self._last_state_change_time = time.time()
         self._metrics = CircuitBreakerMetrics()
-        self._listeners: List[Callable[[CircuitBreakerState, CircuitBreakerState], None]] = []
+        self._listeners: List[
+            Callable[[CircuitBreakerState, CircuitBreakerState], None]
+        ] = []
         self._lock = asyncio.Lock()
 
     @property
@@ -209,7 +211,9 @@ class CircuitBreaker(Generic[T]):
                 self._metrics.rejected_calls += 1
                 if fallback:
                     return fallback()
-                raise CircuitBreakerOpenError(f"Circuit breaker '{self.config.name}' is OPEN")
+                raise CircuitBreakerOpenError(
+                    f"Circuit breaker '{self.config.name}' is OPEN"
+                )
 
             # Execute the operation
             start_time = time.time()
@@ -277,7 +281,9 @@ class CircuitBreakerRegistry:
     def __init__(self):
         self._breakers: Dict[str, CircuitBreaker] = {}
 
-    def register(self, name: str, config: Optional[CircuitBreakerConfig] = None) -> CircuitBreaker:
+    def register(
+        self, name: str, config: Optional[CircuitBreakerConfig] = None
+    ) -> CircuitBreaker:
         """Register a new circuit breaker"""
         if config is None:
             config = CircuitBreakerConfig(name=name)
@@ -301,7 +307,10 @@ class CircuitBreakerRegistry:
         return self._breakers[name]
 
     async def execute(
-        self, name: str, operation: Callable[[], T], fallback: Optional[Callable[[], T]] = None
+        self,
+        name: str,
+        operation: Callable[[], T],
+        fallback: Optional[Callable[[], T]] = None,
     ) -> T:
         """Execute operation through named circuit breaker"""
         breaker = self.get_or_create(name)
diff --git a/workspace/src/core/safety/escalation_ladder.py b/workspace/src/core/safety/escalation_ladder.py
index bbf61bb..2f3490f 100644
--- a/workspace/src/core/safety/escalation_ladder.py
+++ b/workspace/src/core/safety/escalation_ladder.py
@@ -181,7 +181,9 @@ class EscalationLadder:
 
         return len(self._last_escalation_times) < self.config.max_escalation_rate
 
-    async def escalate(self, reason: str, triggered_by: str, levels: int = 1) -> EscalationEvent:
+    async def escalate(
+        self, reason: str, triggered_by: str, levels: int = 1
+    ) -> EscalationEvent:
         """
         Escalate to a higher level
 
@@ -201,7 +203,9 @@ class EscalationLadder:
             )
 
         old_level = self._current_level
-        new_level_value = min(old_level.value + levels, EscalationLevel.LEVEL_5_DISASTER.value)
+        new_level_value = min(
+            old_level.value + levels, EscalationLevel.LEVEL_5_DISASTER.value
+        )
         new_level = EscalationLevel(new_level_value)
 
         if new_level == old_level:
@@ -237,7 +241,9 @@ class EscalationLadder:
 
         return event
 
-    async def de_escalate(self, reason: str, triggered_by: str, levels: int = 1) -> EscalationEvent:
+    async def de_escalate(
+        self, reason: str, triggered_by: str, levels: int = 1
+    ) -> EscalationEvent:
         """
         De-escalate to a lower level
 
@@ -250,7 +256,9 @@ class EscalationLadder:
             EscalationEvent record
         """
         old_level = self._current_level
-        new_level_value = max(old_level.value - levels, EscalationLevel.LEVEL_0_NORMAL.value)
+        new_level_value = max(
+            old_level.value - levels, EscalationLevel.LEVEL_0_NORMAL.value
+        )
         new_level = EscalationLevel(new_level_value)
 
         if new_level == old_level:
@@ -311,7 +319,9 @@ class EscalationLadder:
 
         return event
 
-    async def acknowledge(self, event_timestamp: datetime, acknowledged_by: str) -> bool:
+    async def acknowledge(
+        self, event_timestamp: datetime, acknowledged_by: str
+    ) -> bool:
         """
         Acknowledge an escalation event
 
diff --git a/workspace/src/core/safety/hallucination_detector.py b/workspace/src/core/safety/hallucination_detector.py
index 415ff81..c3f6244 100644
--- a/workspace/src/core/safety/hallucination_detector.py
+++ b/workspace/src/core/safety/hallucination_detector.py
@@ -119,7 +119,9 @@ class HallucinationDetector:
 
     def __init__(self) -> None:
         self._detection_history: list[HallucinationDetection] = []
-        self._custom_validators: list[Callable[[str], list[HallucinationDetection]]] = []
+        self._custom_validators: list[Callable[[str], list[HallucinationDetection]]] = (
+            []
+        )
         self._false_positive_hashes: set[str] = set()
         self._detection_count = 0
 
@@ -262,7 +264,9 @@ class HallucinationDetector:
 
         return detections
 
-    def _detect_logic_errors(self, code: str, language: str) -> list[HallucinationDetection]:
+    def _detect_logic_errors(
+        self, code: str, language: str
+    ) -> list[HallucinationDetection]:
         """Detect logic errors (æª¢æ¸¬é‚è¼¯éŒ¯èª¤)"""
         detections: list[HallucinationDetection] = []
 
@@ -330,7 +334,9 @@ class HallucinationDetector:
 
         return detections
 
-    def _detect_incomplete_implementation(self, code: str) -> list[HallucinationDetection]:
+    def _detect_incomplete_implementation(
+        self, code: str
+    ) -> list[HallucinationDetection]:
         """Detect incomplete implementations (æª¢æ¸¬ä¸å®Œæ•´å¯¦ç¾)"""
         detections: list[HallucinationDetection] = []
 
@@ -456,7 +462,9 @@ class HallucinationDetector:
 
         return max(0.0, 1.0 - min(total_penalty, 1.0))
 
-    def _generate_suggestions(self, detections: list[HallucinationDetection]) -> list[str]:
+    def _generate_suggestions(
+        self, detections: list[HallucinationDetection]
+    ) -> list[str]:
         """Generate improvement suggestions (ç”Ÿæˆæ”¹é€²å»ºè­°)"""
         suggestions = []
 
@@ -465,22 +473,32 @@ class HallucinationDetector:
         high = [d for d in detections if d.severity == SeverityLevel.HIGH]
 
         if critical:
-            suggestions.append(f"âš ï¸ {len(critical)} critical issues require immediate attention")
+            suggestions.append(
+                f"âš ï¸ {len(critical)} critical issues require immediate attention"
+            )
         if high:
-            suggestions.append(f"ğŸ”´ {len(high)} high-priority issues should be addressed soon")
+            suggestions.append(
+                f"ğŸ”´ {len(high)} high-priority issues should be addressed soon"
+            )
 
         # æŒ‰é¡å‹æä¾›å»ºè­°
         security_issues = [
-            d for d in detections if d.hallucination_type == HallucinationType.SECURITY_FLAW
+            d
+            for d in detections
+            if d.hallucination_type == HallucinationType.SECURITY_FLAW
         ]
         if security_issues:
             suggestions.append("ğŸ”’ Security review recommended before deployment")
 
         incomplete_issues = [
-            d for d in detections if d.hallucination_type == HallucinationType.INCOMPLETE
+            d
+            for d in detections
+            if d.hallucination_type == HallucinationType.INCOMPLETE
         ]
         if incomplete_issues:
-            suggestions.append("ğŸ“ Complete all TODO items and placeholder implementations")
+            suggestions.append(
+                "ğŸ“ Complete all TODO items and placeholder implementations"
+            )
 
         return suggestions
 
@@ -491,7 +509,9 @@ class HallucinationDetector:
 
         for d in detections:
             type_key = d.hallucination_type.value
-            self._stats["by_type"][type_key] = self._stats["by_type"].get(type_key, 0) + 1
+            self._stats["by_type"][type_key] = (
+                self._stats["by_type"].get(type_key, 0) + 1
+            )
 
             severity_key = d.severity.value
             self._stats["by_severity"][severity_key] = (
diff --git a/workspace/src/core/safety/partial_rollback.py b/workspace/src/core/safety/partial_rollback.py
index cc6bc6b..fd1b9df 100644
--- a/workspace/src/core/safety/partial_rollback.py
+++ b/workspace/src/core/safety/partial_rollback.py
@@ -95,7 +95,9 @@ class PartialRollbackManager:
         self._execution_graph: dict[str, set[str]] = {}
         self._reverse_graph: dict[str, set[str]] = {}
 
-        logger.info("PartialRollbackManager initialized with retention=%d", checkpoint_retention)
+        logger.info(
+            "PartialRollbackManager initialized with retention=%d", checkpoint_retention
+        )
 
     def evaluate_rollback_trigger(self, condition: str, scope: str) -> RollbackAction:
         """
@@ -174,7 +176,10 @@ class PartialRollbackManager:
             )
 
         logger.info(
-            "Executing rollback: scope=%s, target=%s, execution_id=%s", scope, target, execution_id
+            "Executing rollback: scope=%s, target=%s, execution_id=%s",
+            scope,
+            target,
+            execution_id,
         )
 
         # Find dependencies that need to be rolled back
@@ -201,7 +206,9 @@ class PartialRollbackManager:
             rolled_back_items=rolled_back,
         )
 
-    def create_checkpoint(self, execution_id: str, phase_id: str, state: dict[str, Any]) -> str:
+    def create_checkpoint(
+        self, execution_id: str, phase_id: str, state: dict[str, Any]
+    ) -> str:
         """
         Create a checkpoint for rollback.
 
@@ -213,7 +220,9 @@ class PartialRollbackManager:
         Returns:
             Checkpoint ID
         """
-        checkpoint_id = f"cp_{execution_id}_{phase_id}_{int(datetime.utcnow().timestamp())}"
+        checkpoint_id = (
+            f"cp_{execution_id}_{phase_id}_{int(datetime.utcnow().timestamp())}"
+        )
 
         checkpoint = Checkpoint(
             checkpoint_id=checkpoint_id,
@@ -319,7 +328,9 @@ class PartialRollbackManager:
 
         return dependents
 
-    def _find_checkpoint_for_target(self, execution_id: str, target: str) -> Checkpoint | None:
+    def _find_checkpoint_for_target(
+        self, execution_id: str, target: str
+    ) -> Checkpoint | None:
         """
         Find the most recent checkpoint for a target.
 
@@ -400,6 +411,8 @@ class PartialRollbackManager:
         to_remove = current_count - keep_count
         self._checkpoints[execution_id] = self._checkpoints[execution_id][to_remove:]
 
-        logger.info("Cleaned up %d old checkpoints for execution=%s", to_remove, execution_id)
+        logger.info(
+            "Cleaned up %d old checkpoints for execution=%s", to_remove, execution_id
+        )
 
         return to_remove
diff --git a/workspace/src/core/safety/retry_policies.py b/workspace/src/core/safety/retry_policies.py
index 5175b22..01d6706 100644
--- a/workspace/src/core/safety/retry_policies.py
+++ b/workspace/src/core/safety/retry_policies.py
@@ -127,7 +127,10 @@ class RetryPolicy:
             delay = self._apply_jitter(delay)
 
         # Apply risk factor if risk-adaptive is enabled
-        if self.config.risk_adaptive and self.config.strategy != RetryStrategy.RISK_ADAPTIVE:
+        if (
+            self.config.risk_adaptive
+            and self.config.strategy != RetryStrategy.RISK_ADAPTIVE
+        ):
             delay = self._apply_risk_factor(delay, risk_score)
 
         # Cap at maximum delay
@@ -169,7 +172,10 @@ class RetryPolicy:
                     attempts=attempts + 1,
                     total_delay_ms=total_delay_ms,
                     success=True,
-                    metadata={"result": result, "elapsed_ms": self._elapsed_ms(start_time)},
+                    metadata={
+                        "result": result,
+                        "elapsed_ms": self._elapsed_ms(start_time),
+                    },
                 )
 
             except Exception as e:
@@ -177,7 +183,10 @@ class RetryPolicy:
                 attempts += 1
 
                 logger.warning(
-                    "Attempt %d/%d failed: %s", attempts, self.config.max_attempts, last_error
+                    "Attempt %d/%d failed: %s",
+                    attempts,
+                    self.config.max_attempts,
+                    last_error,
                 )
 
                 # Check if we should retry
@@ -224,7 +233,9 @@ class RetryPolicy:
 
     def _exponential_delay(self, attempt: int) -> int:
         """Calculate exponential backoff delay."""
-        return int(self.config.base_delay_ms * (self.config.backoff_multiplier**attempt))
+        return int(
+            self.config.base_delay_ms * (self.config.backoff_multiplier**attempt)
+        )
 
     def _linear_delay(self, attempt: int) -> int:
         """Calculate linear backoff delay."""
diff --git a/workspace/src/core/safety/rollback_system.py b/workspace/src/core/safety/rollback_system.py
index 837b6cf..27ea79d 100644
--- a/workspace/src/core/safety/rollback_system.py
+++ b/workspace/src/core/safety/rollback_system.py
@@ -130,7 +130,10 @@ class RollbackSystem:
             compensate_handler: Optional function for compensating transactions
         """
         self._component_handlers[name] = ComponentHandler(
-            name=name, save=save_handler, restore=restore_handler, compensate=compensate_handler
+            name=name,
+            save=save_handler,
+            restore=restore_handler,
+            compensate=compensate_handler,
         )
 
     def add_listener(self, listener: Callable[[RollbackResult], None]) -> None:
@@ -300,7 +303,9 @@ class RollbackSystem:
         self._current_state = copy.deepcopy(snapshot.data)
         return restored, errors
 
-    async def _rollback_incremental(self, target_snapshot_id: str, components: set) -> tuple:
+    async def _rollback_incremental(
+        self, target_snapshot_id: str, components: set
+    ) -> tuple:
         """Incremental rollback - reverse changes one by one"""
         restored = []
         errors = []
@@ -321,7 +326,9 @@ class RollbackSystem:
                     try:
                         # Get previous state
                         if snapshot.parent_id and snapshot.parent_id in self._snapshots:
-                            prev_state = self._snapshots[snapshot.parent_id].data.get(name)
+                            prev_state = self._snapshots[snapshot.parent_id].data.get(
+                                name
+                            )
                         else:
                             prev_state = snapshot.data.get(name)
 
@@ -340,7 +347,9 @@ class RollbackSystem:
         """Selective rollback - restore specific components"""
         return await self._rollback_full(snapshot, components)
 
-    async def _rollback_compensating(self, snapshot: Snapshot, components: set) -> tuple:
+    async def _rollback_compensating(
+        self, snapshot: Snapshot, components: set
+    ) -> tuple:
         """Compensating rollback - execute compensating transactions"""
         restored = []
         errors = []
diff --git a/workspace/src/core/safety/safety_net.py b/workspace/src/core/safety/safety_net.py
index 9ef0e5b..2e4eff6 100644
--- a/workspace/src/core/safety/safety_net.py
+++ b/workspace/src/core/safety/safety_net.py
@@ -92,7 +92,9 @@ class SafetyNet:
 
     def __init__(self, config: Optional[SafetyNetConfig] = None):
         self.config = config or SafetyNetConfig()
-        self._checks: Dict[SafetyLayer, List[SafetyCheck]] = {layer: [] for layer in SafetyLayer}
+        self._checks: Dict[SafetyLayer, List[SafetyCheck]] = {
+            layer: [] for layer in SafetyLayer
+        }
         self._results_history: List[List[SafetyCheckResult]] = []
         self._blocked_count = 0
         self._passed_count = 0
@@ -189,7 +191,9 @@ class SafetyNet:
             # Check for blocking failures
             if self.config.fail_fast:
                 blocking_failures = [
-                    r for r in layer_results if not r.passed and self._is_blocking(r.check_name)
+                    r
+                    for r in layer_results
+                    if not r.passed and self._is_blocking(r.check_name)
                 ]
                 if blocking_failures:
                     break
@@ -206,7 +210,9 @@ class SafetyNet:
 
         return results
 
-    async def _run_layer_checks(self, layer: SafetyLayer, data: Any) -> List[SafetyCheckResult]:
+    async def _run_layer_checks(
+        self, layer: SafetyLayer, data: Any
+    ) -> List[SafetyCheckResult]:
         """Run all checks for a specific layer"""
         results: List[SafetyCheckResult] = []
 
@@ -220,7 +226,10 @@ class SafetyNet:
                     passed = await passed
 
                 result = SafetyCheckResult(
-                    check_name=check.name, layer=layer, passed=passed, timestamp=datetime.now()
+                    check_name=check.name,
+                    layer=layer,
+                    passed=passed,
+                    timestamp=datetime.now(),
                 )
 
                 if not passed and check.on_failure:
@@ -275,7 +284,9 @@ class SafetyNet:
         results = await self.validate(data)
 
         # Check for failures
-        failures = [r for r in results if not r.passed and self._is_blocking(r.check_name)]
+        failures = [
+            r for r in results if not r.passed and self._is_blocking(r.check_name)
+        ]
 
         if failures:
             raise SafetyCheckError(
@@ -322,7 +333,9 @@ class SafetyNet:
                 "passed": len([r for r in results if r.passed]),
                 "failed": len([r for r in results if not r.passed]),
                 "failures": [
-                    {"check": r.check_name, "layer": r.layer.name} for r in results if not r.passed
+                    {"check": r.check_name, "layer": r.layer.name}
+                    for r in results
+                    if not r.passed
                 ],
             }
             for results in recent
diff --git a/workspace/src/core/slsa_provenance/__init__.py b/workspace/src/core/slsa_provenance/__init__.py
index c70aec4..4fc4c59 100644
--- a/workspace/src/core/slsa_provenance/__init__.py
+++ b/workspace/src/core/slsa_provenance/__init__.py
@@ -17,7 +17,12 @@ Key Components:
 
 from .artifact_verifier import ArtifactMetadata, ArtifactVerifier, VerificationResult
 from .attestation_manager import Attestation, AttestationManager, AttestationType
-from .provenance_generator import BuildDefinition, Provenance, ProvenanceGenerator, SLSALevel
+from .provenance_generator import (
+    BuildDefinition,
+    Provenance,
+    ProvenanceGenerator,
+    SLSALevel,
+)
 from .signature_verifier import (
     SignatureResult,
     SignatureType,
diff --git a/workspace/src/core/slsa_provenance/artifact_verifier.py b/workspace/src/core/slsa_provenance/artifact_verifier.py
index bd2466e..a3f78ab 100644
--- a/workspace/src/core/slsa_provenance/artifact_verifier.py
+++ b/workspace/src/core/slsa_provenance/artifact_verifier.py
@@ -183,11 +183,15 @@ class ArtifactVerifier:
         if artifact_path:
             metadata = self._get_file_metadata(artifact_path)
         elif artifact_content:
-            metadata = self._get_content_metadata(artifact_content, artifact_name or "unknown")
+            metadata = self._get_content_metadata(
+                artifact_content, artifact_name or "unknown"
+            )
         elif expected_digest and artifact_name:
             metadata = ArtifactMetadata(name=artifact_name, digest=expected_digest)
         else:
-            raise ValueError("Must provide artifact_path, artifact_content, or expected_digest")
+            raise ValueError(
+                "Must provide artifact_path, artifact_content, or expected_digest"
+            )
 
         result = VerificationResult(
             artifact=metadata,
@@ -196,7 +200,9 @@ class ArtifactVerifier:
         )
 
         # Step 1: Verify integrity
-        integrity_result = self._verify_integrity(metadata, expected_digest, active_policy)
+        integrity_result = self._verify_integrity(
+            metadata, expected_digest, active_policy
+        )
         result.integrity_status = integrity_result["status"]
         result.checks.extend(integrity_result["checks"])
 
@@ -205,7 +211,9 @@ class ArtifactVerifier:
 
         # Step 2: Verify provenance
         if provenance:
-            provenance_result = self._verify_provenance(metadata, provenance, active_policy)
+            provenance_result = self._verify_provenance(
+                metadata, provenance, active_policy
+            )
             result.provenance_status = provenance_result["status"]
             result.slsa_level = provenance_result.get("slsa_level", 0)
             result.checks.extend(provenance_result["checks"])
@@ -226,11 +234,15 @@ class ArtifactVerifier:
         cache_key = self._get_cache_key(metadata)
         self._verification_cache[cache_key] = result
 
-        logger.info(f"Verified artifact: {metadata.name} - {result.integrity_status.value}")
+        logger.info(
+            f"Verified artifact: {metadata.name} - {result.integrity_status.value}"
+        )
         return result
 
     def verify_artifact_batch(
-        self, artifacts: List[Dict[str, Any]], policy: Optional[VerificationPolicy] = None
+        self,
+        artifacts: List[Dict[str, Any]],
+        policy: Optional[VerificationPolicy] = None,
     ) -> List[VerificationResult]:
         """
         Verify multiple artifacts
@@ -256,7 +268,9 @@ class ArtifactVerifier:
         return results
 
     def verify_provenance_chain(
-        self, artifact_metadata: ArtifactMetadata, provenance_chain: List[Dict[str, Any]]
+        self,
+        artifact_metadata: ArtifactMetadata,
+        provenance_chain: List[Dict[str, Any]],
     ) -> Dict[str, Any]:
         """
         Verify a chain of provenance
@@ -290,7 +304,9 @@ class ArtifactVerifier:
                     break
 
             if not found and i == 0:
-                result["errors"].append(f"Artifact not found in provenance at position {i}")
+                result["errors"].append(
+                    f"Artifact not found in provenance at position {i}"
+                )
                 result["valid"] = False
                 continue
 
@@ -319,7 +335,9 @@ class ArtifactVerifier:
             if deps:
                 # Use first dependency's digest as next current
                 first_dep = deps[0]
-                current_digest = first_dep.get("digest", {}).get("sha256", current_digest)
+                current_digest = first_dep.get("digest", {}).get(
+                    "sha256", current_digest
+                )
 
         return result
 
@@ -336,7 +354,9 @@ class ArtifactVerifier:
         self._verification_cache.clear()
 
     def create_verification_summary(
-        self, results: List[VerificationResult], policy: Optional[VerificationPolicy] = None
+        self,
+        results: List[VerificationResult],
+        policy: Optional[VerificationPolicy] = None,
     ) -> Dict[str, Any]:
         """
         Create a verification summary for multiple results
@@ -416,7 +436,11 @@ class ArtifactVerifier:
         if not metadata.digest:
             result["status"] = IntegrityStatus.UNVERIFIED
             result["checks"].append(
-                {"name": "digest_presence", "passed": False, "error": "No digest available"}
+                {
+                    "name": "digest_presence",
+                    "passed": False,
+                    "error": "No digest available",
+                }
             )
             return result
 
@@ -439,7 +463,9 @@ class ArtifactVerifier:
                         f"Digest mismatch: expected {expected_hash}, got {actual_hash}"
                     )
                 else:
-                    result["checks"].append({"name": f"digest_match_{alg}", "passed": True})
+                    result["checks"].append(
+                        {"name": f"digest_match_{alg}", "passed": True}
+                    )
 
         # Check required algorithms
         for alg in policy.digest_algorithms:
@@ -455,7 +481,10 @@ class ArtifactVerifier:
         return result
 
     def _verify_provenance(
-        self, metadata: ArtifactMetadata, provenance: Dict[str, Any], policy: VerificationPolicy
+        self,
+        metadata: ArtifactMetadata,
+        provenance: Dict[str, Any],
+        policy: VerificationPolicy,
     ) -> Dict[str, Any]:
         """Verify provenance data"""
         result = {
@@ -503,13 +532,17 @@ class ArtifactVerifier:
         if policy.allowed_builders and builder_id not in policy.allowed_builders:
             result["warnings"].append(f"Builder {builder_id} not in allowed list")
 
-        result["checks"].append({"name": "builder_check", "passed": True, "builder": builder_id})
+        result["checks"].append(
+            {"name": "builder_check", "passed": True, "builder": builder_id}
+        )
 
         # Check source (from external parameters)
         source = build_def.get("externalParameters", {}).get("source", {})
         source_uri = source.get("uri", "")
         if policy.allowed_sources and source_uri:
-            source_allowed = any(allowed in source_uri for allowed in policy.allowed_sources)
+            source_allowed = any(
+                allowed in source_uri for allowed in policy.allowed_sources
+            )
             if not source_allowed:
                 result["warnings"].append(f"Source {source_uri} not in allowed list")
 
@@ -517,7 +550,10 @@ class ArtifactVerifier:
         return result
 
     def _determine_slsa_level(
-        self, build_def: Dict[str, Any], run_details: Dict[str, Any], policy: VerificationPolicy
+        self,
+        build_def: Dict[str, Any],
+        run_details: Dict[str, Any],
+        policy: VerificationPolicy,
     ) -> int:
         """Determine SLSA level achieved"""
         level = 0
@@ -568,7 +604,11 @@ class ArtifactVerifier:
         if result.integrity_status != IntegrityStatus.VERIFIED:
             compliance["compliant"] = False
             compliance["checks"].append(
-                {"name": "integrity", "passed": False, "status": result.integrity_status.value}
+                {
+                    "name": "integrity",
+                    "passed": False,
+                    "status": result.integrity_status.value,
+                }
             )
         else:
             compliance["checks"].append({"name": "integrity", "passed": True})
@@ -582,7 +622,9 @@ class ArtifactVerifier:
 
 
 # Factory functions
-def create_artifact_verifier(policy: Optional[VerificationPolicy] = None) -> ArtifactVerifier:
+def create_artifact_verifier(
+    policy: Optional[VerificationPolicy] = None,
+) -> ArtifactVerifier:
     """Create a new ArtifactVerifier instance"""
     return ArtifactVerifier(policy)
 
diff --git a/workspace/src/core/slsa_provenance/attestation_manager.py b/workspace/src/core/slsa_provenance/attestation_manager.py
index 77ad930..e4d1884 100644
--- a/workspace/src/core/slsa_provenance/attestation_manager.py
+++ b/workspace/src/core/slsa_provenance/attestation_manager.py
@@ -133,7 +133,9 @@ class AttestationManager:
     - Verify attestation chains
     """
 
-    def __init__(self, storage_backend: Optional[Any] = None, signer: Optional[Callable] = None):
+    def __init__(
+        self, storage_backend: Optional[Any] = None, signer: Optional[Callable] = None
+    ):
         """
         Initialize the manager
 
@@ -216,7 +218,9 @@ class AttestationManager:
             raise ValueError(f"Attestation not found: {attestation_id}")
 
         if attestation.status != AttestationStatus.DRAFT:
-            raise ValueError(f"Attestation is not in draft status: {attestation.status}")
+            raise ValueError(
+                f"Attestation is not in draft status: {attestation.status}"
+            )
 
         # Compute attestation digest
         digest = attestation.compute_digest()
@@ -251,7 +255,11 @@ class AttestationManager:
         """
         key = f"{algorithm}:{digest}"
         attestation_ids = self._subject_index.get(key, [])
-        return [self._attestations[aid] for aid in attestation_ids if aid in self._attestations]
+        return [
+            self._attestations[aid]
+            for aid in attestation_ids
+            if aid in self._attestations
+        ]
 
     def list_attestations(
         self,
@@ -279,7 +287,9 @@ class AttestationManager:
         return attestations
 
     def verify_attestation(
-        self, attestation_id: str, expected_subjects: Optional[List[Dict[str, Any]]] = None
+        self,
+        attestation_id: str,
+        expected_subjects: Optional[List[Dict[str, Any]]] = None,
     ) -> Dict[str, Any]:
         """
         Verify an attestation
@@ -298,26 +308,42 @@ class AttestationManager:
         result = {"valid": True, "attestation_id": attestation_id, "checks": []}
 
         # Check signature
-        if attestation.status not in (AttestationStatus.SIGNED, AttestationStatus.VERIFIED):
+        if attestation.status not in (
+            AttestationStatus.SIGNED,
+            AttestationStatus.VERIFIED,
+        ):
             result["valid"] = False
             result["checks"].append(
-                {"name": "signature", "passed": False, "error": "Attestation is not signed"}
+                {
+                    "name": "signature",
+                    "passed": False,
+                    "error": "Attestation is not signed",
+                }
             )
         else:
             result["checks"].append({"name": "signature", "passed": True})
 
         # Check expiration
-        if attestation.expires_at and datetime.now(timezone.utc) > attestation.expires_at:
+        if (
+            attestation.expires_at
+            and datetime.now(timezone.utc) > attestation.expires_at
+        ):
             result["valid"] = False
             result["checks"].append(
-                {"name": "expiration", "passed": False, "error": "Attestation has expired"}
+                {
+                    "name": "expiration",
+                    "passed": False,
+                    "error": "Attestation has expired",
+                }
             )
         else:
             result["checks"].append({"name": "expiration", "passed": True})
 
         # Check subjects match
         if expected_subjects:
-            subjects_match = self._verify_subjects(attestation.subjects, expected_subjects)
+            subjects_match = self._verify_subjects(
+                attestation.subjects, expected_subjects
+            )
             result["checks"].append(
                 {
                     "name": "subjects",
@@ -356,14 +382,20 @@ class AttestationManager:
         }
 
         if attestation.signature:
-            dsse_envelope["signatures"].append({"keyid": "", "sig": attestation.signature})
+            dsse_envelope["signatures"].append(
+                {"keyid": "", "sig": attestation.signature}
+            )
 
         # Create verification material
         verification_material = {}
         if attestation.certificate:
             verification_material["x509CertificateChain"] = {
                 "certificates": [
-                    {"rawBytes": base64.b64encode(attestation.certificate.encode()).decode()}
+                    {
+                        "rawBytes": base64.b64encode(
+                            attestation.certificate.encode()
+                        ).decode()
+                    }
                 ]
             }
 
@@ -421,7 +453,9 @@ class AttestationManager:
         logger.info(f"Deleted attestation: {attestation_id}")
         return True
 
-    def export_attestations(self, attestation_ids: Optional[List[str]] = None) -> Dict[str, Any]:
+    def export_attestations(
+        self, attestation_ids: Optional[List[str]] = None
+    ) -> Dict[str, Any]:
         """
         Export attestations
 
@@ -433,7 +467,9 @@ class AttestationManager:
         """
         if attestation_ids:
             attestations = [
-                self._attestations[aid] for aid in attestation_ids if aid in self._attestations
+                self._attestations[aid]
+                for aid in attestation_ids
+                if aid in self._attestations
             ]
         else:
             attestations = list(self._attestations.values())
@@ -463,7 +499,9 @@ class AttestationManager:
 
         return True
 
-    async def _default_signer(self, digest: str, identity_token: Optional[str]) -> Dict[str, Any]:
+    async def _default_signer(
+        self, digest: str, identity_token: Optional[str]
+    ) -> Dict[str, Any]:
         """Default signing function (for testing)"""
         # Simulate Sigstore signing
         signature_data = f"sig:{digest}"
@@ -508,8 +546,12 @@ def create_provenance_attestation(
             "builder": {"id": builder_id, "version": kwargs.get("builder_version", {})},
             "metadata": {
                 "invocationId": kwargs.get("invocation_id", str(uuid4())),
-                "startedOn": kwargs.get("started_on", datetime.now(timezone.utc).isoformat()),
-                "finishedOn": kwargs.get("finished_on", datetime.now(timezone.utc).isoformat()),
+                "startedOn": kwargs.get(
+                    "started_on", datetime.now(timezone.utc).isoformat()
+                ),
+                "finishedOn": kwargs.get(
+                    "finished_on", datetime.now(timezone.utc).isoformat()
+                ),
             },
             "byproducts": kwargs.get("byproducts", []),
         },
diff --git a/workspace/src/core/slsa_provenance/provenance_generator.py b/workspace/src/core/slsa_provenance/provenance_generator.py
index 6adcaba..840e42b 100644
--- a/workspace/src/core/slsa_provenance/provenance_generator.py
+++ b/workspace/src/core/slsa_provenance/provenance_generator.py
@@ -80,7 +80,9 @@ class Builder:
         if self.version:
             result["version"] = self.version
         if self.builder_dependencies:
-            result["builderDependencies"] = [d.to_dict() for d in self.builder_dependencies]
+            result["builderDependencies"] = [
+                d.to_dict() for d in self.builder_dependencies
+            ]
         return result
 
 
@@ -94,7 +96,10 @@ class BuildMetadata:
 
     def to_dict(self) -> Dict[str, Any]:
         """Convert to dictionary"""
-        result = {"invocationId": self.invocation_id, "startedOn": self.started_on.isoformat()}
+        result = {
+            "invocationId": self.invocation_id,
+            "startedOn": self.started_on.isoformat(),
+        }
         if self.finished_on:
             result["finishedOn"] = self.finished_on.isoformat()
         return result
@@ -110,7 +115,10 @@ class RunDetails:
 
     def to_dict(self) -> Dict[str, Any]:
         """Convert to dictionary"""
-        result = {"builder": self.builder.to_dict(), "metadata": self.metadata.to_dict()}
+        result = {
+            "builder": self.builder.to_dict(),
+            "metadata": self.metadata.to_dict(),
+        }
         if self.byproducts:
             result["byproducts"] = [b.to_dict() for b in self.byproducts]
         return result
@@ -127,11 +135,16 @@ class BuildDefinition:
 
     def to_dict(self) -> Dict[str, Any]:
         """Convert to dictionary"""
-        result = {"buildType": self.build_type, "externalParameters": self.external_parameters}
+        result = {
+            "buildType": self.build_type,
+            "externalParameters": self.external_parameters,
+        }
         if self.internal_parameters:
             result["internalParameters"] = self.internal_parameters
         if self.resolved_dependencies:
-            result["resolvedDependencies"] = [d.to_dict() for d in self.resolved_dependencies]
+            result["resolvedDependencies"] = [
+                d.to_dict() for d in self.resolved_dependencies
+            ]
         return result
 
 
@@ -303,7 +316,11 @@ class ProvenanceGenerator:
         # Create builder
         builder = Builder(
             id=self.builder_id,
-            version={"machinenativenops": self.builder_version} if self.builder_version else None,
+            version=(
+                {"machinenativenops": self.builder_version}
+                if self.builder_version
+                else None
+            ),
         )
 
         # Create build metadata
@@ -314,7 +331,9 @@ class ProvenanceGenerator:
         )
 
         # Create run details
-        run_details = RunDetails(builder=builder, metadata=metadata, byproducts=build["byproducts"])
+        run_details = RunDetails(
+            builder=builder, metadata=metadata, byproducts=build["byproducts"]
+        )
 
         # Create build definition
         build_definition = BuildDefinition(
@@ -326,7 +345,9 @@ class ProvenanceGenerator:
 
         # Create provenance
         provenance = Provenance(
-            subjects=build["subjects"], build_definition=build_definition, run_details=run_details
+            subjects=build["subjects"],
+            build_definition=build_definition,
+            run_details=run_details,
         )
 
         self._current_build = None
@@ -365,7 +386,9 @@ class ProvenanceGenerator:
         if dependencies:
             for dep in dependencies:
                 self.add_dependency(
-                    uri=dep.get("uri", ""), digest=dep.get("digest", {}), name=dep.get("name")
+                    uri=dep.get("uri", ""),
+                    digest=dep.get("digest", {}),
+                    name=dep.get("name"),
                 )
 
         # Add subjects
@@ -488,7 +511,11 @@ class ProvenanceGenerator:
         }
 
         keywords = level_keywords.get(level, [])
-        return [issue for issue in issues if any(kw.lower() in issue.lower() for kw in keywords)]
+        return [
+            issue
+            for issue in issues
+            if any(kw.lower() in issue.lower() for kw in keywords)
+        ]
 
 
 # Factory functions
@@ -499,7 +526,9 @@ def create_provenance_generator(
     return ProvenanceGenerator(builder_id, builder_version)
 
 
-def compute_digest(content: bytes, algorithm: DigestAlgorithm = DigestAlgorithm.SHA256) -> str:
+def compute_digest(
+    content: bytes, algorithm: DigestAlgorithm = DigestAlgorithm.SHA256
+) -> str:
     """Compute digest of content"""
     hasher = hashlib.new(algorithm.value)
     hasher.update(content)
diff --git a/workspace/src/core/slsa_provenance/signature_verifier.py b/workspace/src/core/slsa_provenance/signature_verifier.py
index 27ac640..28d3a8a 100644
--- a/workspace/src/core/slsa_provenance/signature_verifier.py
+++ b/workspace/src/core/slsa_provenance/signature_verifier.py
@@ -104,7 +104,9 @@ class SignatureResult:
     verified_claims: Dict[str, Any] = field(default_factory=dict)
     errors: List[str] = field(default_factory=list)
     warnings: List[str] = field(default_factory=list)
-    verification_time: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
+    verification_time: datetime = field(
+        default_factory=lambda: datetime.now(timezone.utc)
+    )
     metadata: Dict[str, Any] = field(default_factory=dict)
 
     def to_dict(self) -> Dict[str, Any]:
@@ -262,7 +264,9 @@ class SignatureVerifier:
                 result.verified_claims = verify_result.get("claims", {})
             else:
                 result.status = VerificationStatus.INVALID
-                result.errors.append(verify_result.get("error", "Signature verification failed"))
+                result.errors.append(
+                    verify_result.get("error", "Signature verification failed")
+                )
 
         except Exception as e:
             result.status = VerificationStatus.INVALID
@@ -347,7 +351,9 @@ class SignatureVerifier:
                     log_index=entry.get("logIndex", 0),
                     log_id=entry.get("logId", {}).get("keyId", ""),
                     integrated_time=datetime.fromisoformat(
-                        entry.get("integratedTime", datetime.now(timezone.utc).isoformat())
+                        entry.get(
+                            "integratedTime", datetime.now(timezone.utc).isoformat()
+                        )
                     ),
                     body=entry.get("canonicalizedBody", ""),
                     inclusion_proof=entry.get("inclusionProof"),
@@ -437,7 +443,9 @@ class SignatureVerifier:
         # Extract from SAN or subject
         return cert.subject
 
-    def _verify_policy(self, result: SignatureResult, policy: VerificationPolicy) -> Dict[str, Any]:
+    def _verify_policy(
+        self, result: SignatureResult, policy: VerificationPolicy
+    ) -> Dict[str, Any]:
         """Verify against policy requirements"""
         errors = []
 
@@ -486,7 +494,9 @@ class SignatureVerifier:
             log_index=12345,
             log_id="rekor.sigstore.dev",
             integrated_time=datetime.now(timezone.utc),
-            body=base64.b64encode(f"{artifact_digest}:{signature[:20]}".encode()).decode(),
+            body=base64.b64encode(
+                f"{artifact_digest}:{signature[:20]}".encode()
+            ).decode(),
         )
 
     def _cryptographic_verify(
@@ -525,7 +535,8 @@ class SignatureVerifier:
 
 # Factory functions
 def create_signature_verifier(
-    rekor_url: str = "https://rekor.sigstore.dev", fulcio_url: str = "https://fulcio.sigstore.dev"
+    rekor_url: str = "https://rekor.sigstore.dev",
+    fulcio_url: str = "https://fulcio.sigstore.dev",
 ) -> SignatureVerifier:
     """Create a new SignatureVerifier instance"""
     return SignatureVerifier(rekor_url, fulcio_url)
diff --git a/workspace/src/core/tech_stack/architecture_config.py b/workspace/src/core/tech_stack/architecture_config.py
index 02e4f62..b7654b9 100644
--- a/workspace/src/core/tech_stack/architecture_config.py
+++ b/workspace/src/core/tech_stack/architecture_config.py
@@ -146,16 +146,22 @@ class TechStackConfig:
     primary_pattern: str = "microservices"
     communication_pattern: str = "event-driven"
 
-    def get_frameworks_for_layer(self, layer: ArchitectureLayer) -> List[FrameworkConfig]:
+    def get_frameworks_for_layer(
+        self, layer: ArchitectureLayer
+    ) -> List[FrameworkConfig]:
         """Get all frameworks recommended for a specific layer"""
         if layer.value not in self.layers:
             return []
         layer_config = self.layers[layer.value]
         return [
-            self.frameworks[fw_id] for fw_id in layer_config.frameworks if fw_id in self.frameworks
+            self.frameworks[fw_id]
+            for fw_id in layer_config.frameworks
+            if fw_id in self.frameworks
         ]
 
-    def get_frameworks_by_category(self, category: FrameworkCategory) -> List[FrameworkConfig]:
+    def get_frameworks_by_category(
+        self, category: FrameworkCategory
+    ) -> List[FrameworkConfig]:
         """Get all frameworks in a specific category"""
         return [fw for fw in self.frameworks.values() if fw.category == category]
 
@@ -174,7 +180,9 @@ class TechStackConfig:
         if ArchitectureLayer.AI_CORE.value in self.layers:
             ai_layer = self.layers[ArchitectureLayer.AI_CORE.value]
             if ai_layer.primary_language != LanguageType.PYTHON:
-                warnings.append("AI core layer should use Python (80% of AI agents use Python)")
+                warnings.append(
+                    "AI core layer should use Python (80% of AI agents use Python)"
+                )
 
         return {"valid": len(issues) == 0, "issues": issues, "warnings": warnings}
 
@@ -237,7 +245,11 @@ def get_recommended_stack() -> TechStackConfig:
                 "Strong tooling",
                 "Modern language features",
             ],
-            weaknesses=["Compilation step required", "Complex type system", "Smaller AI ecosystem"],
+            weaknesses=[
+                "Compilation step required",
+                "Complex type system",
+                "Smaller AI ecosystem",
+            ],
             adoption_rate=30.0,
             ecosystem_maturity="mature",
         ),
@@ -261,7 +273,12 @@ def get_recommended_stack() -> TechStackConfig:
                 "Memory management",
                 "Prompt templates",
             ],
-            use_cases=["Conversational AI", "Document Q&A", "Code generation", "Task automation"],
+            use_cases=[
+                "Conversational AI",
+                "Document Q&A",
+                "Code generation",
+                "Task automation",
+            ],
             dependencies=["openai", "tiktoken", "pydantic"],
             integration_complexity="medium",
             documentation_url="https://python.langchain.com/docs/",
@@ -377,7 +394,12 @@ def get_recommended_stack() -> TechStackConfig:
                 "Inference optimization",
                 "Pipeline API",
             ],
-            use_cases=["NLP tasks", "Text generation", "Embeddings", "Sentiment analysis"],
+            use_cases=[
+                "NLP tasks",
+                "Text generation",
+                "Embeddings",
+                "Sentiment analysis",
+            ],
             dependencies=["pytorch", "tokenizers"],
             integration_complexity="low",
             documentation_url="https://huggingface.co/docs/transformers/",
@@ -398,7 +420,12 @@ def get_recommended_stack() -> TechStackConfig:
                 "Dependency injection",
                 "WebSocket support",
             ],
-            use_cases=["REST APIs", "ML model serving", "Microservices", "Real-time apps"],
+            use_cases=[
+                "REST APIs",
+                "ML model serving",
+                "Microservices",
+                "Real-time apps",
+            ],
             dependencies=["starlette", "pydantic"],
             integration_complexity="low",
             documentation_url="https://fastapi.tiangolo.com/",
@@ -418,7 +445,12 @@ def get_recommended_stack() -> TechStackConfig:
                 "Static files",
                 "Error handling",
             ],
-            use_cases=["REST APIs", "Web applications", "Microservices", "Real-time apps"],
+            use_cases=[
+                "REST APIs",
+                "Web applications",
+                "Microservices",
+                "Real-time apps",
+            ],
             dependencies=["node"],
             integration_complexity="low",
             documentation_url="https://expressjs.com/",
@@ -432,7 +464,14 @@ def get_recommended_stack() -> TechStackConfig:
             layer=ArchitectureLayer.AI_CORE,
             primary_language=LanguageType.PYTHON,
             secondary_languages=[],
-            frameworks=["langchain", "crewai", "autogen", "langgraph", "pytorch", "transformers"],
+            frameworks=[
+                "langchain",
+                "crewai",
+                "autogen",
+                "langgraph",
+                "pytorch",
+                "transformers",
+            ],
             responsibilities=[
                 "AI agent implementation",
                 "ML model training and inference",
@@ -505,7 +544,10 @@ def get_stack_summary() -> Dict[str, Any]:
         "name": stack.name,
         "version": stack.version,
         "architecture_type": stack.architecture_type,
-        "primary_languages": {"ai_core": "Python 3.11+", "orchestration": "TypeScript 5.0+"},
+        "primary_languages": {
+            "ai_core": "Python 3.11+",
+            "orchestration": "TypeScript 5.0+",
+        },
         "key_frameworks": {
             "ai_agents": ["LangChain", "CrewAI", "AutoGen", "LangGraph"],
             "ml_libraries": ["PyTorch", "Transformers"],
diff --git a/workspace/src/core/tech_stack/framework_integrations.py b/workspace/src/core/tech_stack/framework_integrations.py
index 86659f7..474775e 100644
--- a/workspace/src/core/tech_stack/framework_integrations.py
+++ b/workspace/src/core/tech_stack/framework_integrations.py
@@ -218,12 +218,19 @@ class LangChainIntegration(FrameworkIntegration):
         self.chains[chain_id] = chain_config
         return chain_id
 
-    async def register_tool(self, tool_id: str, name: str, description: str, func: Callable) -> str:
+    async def register_tool(
+        self, tool_id: str, name: str, description: str, func: Callable
+    ) -> str:
         """Register a tool for agents to use
 
         è¨»å†Šå·¥å…·ä¾›ä»£ç†ä½¿ç”¨
         """
-        tool_config = {"id": tool_id, "name": name, "description": description, "func": func}
+        tool_config = {
+            "id": tool_id,
+            "name": name,
+            "description": description,
+            "func": func,
+        }
         self.tools[tool_id] = tool_config
         return tool_id
 
@@ -256,10 +263,16 @@ class LangChainIntegration(FrameworkIntegration):
                 success=True,
                 result=result,
                 execution_time=execution_time,
-                metadata={"agent_id": agent_id, "framework": "langchain", "context": context},
+                metadata={
+                    "agent_id": agent_id,
+                    "framework": "langchain",
+                    "context": context,
+                },
             )
         except Exception as e:
-            return TaskResult(task_id=str(uuid.uuid4()), success=False, result=None, error=str(e))
+            return TaskResult(
+                task_id=str(uuid.uuid4()), success=False, result=None, error=str(e)
+            )
 
     async def shutdown(self) -> bool:
         """Shutdown LangChain connection"""
@@ -373,7 +386,10 @@ class CrewAIIntegration(FrameworkIntegration):
 
         if crew_id not in self.crews:
             return TaskResult(
-                task_id=crew_id, success=False, result=None, error=f"Crew {crew_id} not found"
+                task_id=crew_id,
+                success=False,
+                result=None,
+                error=f"Crew {crew_id} not found",
             )
 
         try:
@@ -387,7 +403,11 @@ class CrewAIIntegration(FrameworkIntegration):
                 success=True,
                 result=f"Crew {crew_id} completed {len(task_ids)} tasks",
                 execution_time=execution_time,
-                metadata={"crew_id": crew_id, "task_ids": task_ids, "framework": "crewai"},
+                metadata={
+                    "crew_id": crew_id,
+                    "task_ids": task_ids,
+                    "framework": "crewai",
+                },
             )
         except Exception as e:
             return TaskResult(task_id=crew_id, success=False, result=None, error=str(e))
@@ -485,7 +505,9 @@ class AutoGenIntegration(FrameworkIntegration):
         self.group_chats[chat_id] = chat_config
         return chat_id
 
-    async def initiate_chat(self, initiator_id: str, recipient_id: str, message: str) -> TaskResult:
+    async def initiate_chat(
+        self, initiator_id: str, recipient_id: str, message: str
+    ) -> TaskResult:
         """Initiate a two-agent chat
 
         ç™¼èµ·é›™ä»£ç†å°è©±
@@ -494,7 +516,11 @@ class AutoGenIntegration(FrameworkIntegration):
 
         conversation_id = f"conv_{uuid.uuid4()}"
         self.conversations[conversation_id] = [
-            {"sender": initiator_id, "content": message, "timestamp": datetime.now().isoformat()}
+            {
+                "sender": initiator_id,
+                "content": message,
+                "timestamp": datetime.now().isoformat(),
+            }
         ]
 
         try:
@@ -526,7 +552,9 @@ class AutoGenIntegration(FrameworkIntegration):
                 },
             )
         except Exception as e:
-            return TaskResult(task_id=conversation_id, success=False, result=None, error=str(e))
+            return TaskResult(
+                task_id=conversation_id, success=False, result=None, error=str(e)
+            )
 
     async def execute_task(
         self, agent_id: str, task: str, context: Optional[Dict] = None
@@ -535,7 +563,11 @@ class AutoGenIntegration(FrameworkIntegration):
         # Create a temporary assistant for task execution
         assistant_id = f"assistant_{uuid.uuid4()}"
         await self.create_agent(
-            AgentConfig(id=assistant_id, name="AssistantAgent", agent_type=AgentType.TASK_ORIENTED)
+            AgentConfig(
+                id=assistant_id,
+                name="AssistantAgent",
+                agent_type=AgentType.TASK_ORIENTED,
+            )
         )
 
         return await self.initiate_chat(agent_id, assistant_id, task)
@@ -623,7 +655,11 @@ class LangGraphIntegration(FrameworkIntegration):
         return graph_id
 
     async def add_conditional_edge(
-        self, graph_id: str, source: str, condition_func: Callable, destinations: Dict[str, str]
+        self,
+        graph_id: str,
+        source: str,
+        condition_func: Callable,
+        destinations: Dict[str, str],
     ) -> bool:
         """Add a conditional edge to a graph
 
@@ -642,7 +678,9 @@ class LangGraphIntegration(FrameworkIntegration):
         )
         return True
 
-    async def execute_graph(self, graph_id: str, initial_state: Dict[str, Any]) -> TaskResult:
+    async def execute_graph(
+        self, graph_id: str, initial_state: Dict[str, Any]
+    ) -> TaskResult:
         """Execute a graph with initial state
 
         åŸ·è¡Œåœ–ä¸¦è¿”å›æœ€çµ‚ç‹€æ…‹
@@ -651,7 +689,10 @@ class LangGraphIntegration(FrameworkIntegration):
 
         if graph_id not in self.graphs:
             return TaskResult(
-                task_id=graph_id, success=False, result=None, error=f"Graph {graph_id} not found"
+                task_id=graph_id,
+                success=False,
+                result=None,
+                error=f"Graph {graph_id} not found",
             )
 
         try:
@@ -676,7 +717,9 @@ class LangGraphIntegration(FrameworkIntegration):
                 metadata={"graph_id": graph_id, "framework": "langgraph"},
             )
         except Exception as e:
-            return TaskResult(task_id=graph_id, success=False, result=None, error=str(e))
+            return TaskResult(
+                task_id=graph_id, success=False, result=None, error=str(e)
+            )
 
     async def execute_task(
         self, agent_id: str, task: str, context: Optional[Dict] = None
@@ -685,7 +728,10 @@ class LangGraphIntegration(FrameworkIntegration):
         # Create a simple single-node graph
         graph_id = f"task_graph_{uuid.uuid4()}"
         await self.create_graph(
-            graph_id, nodes=[{"id": agent_id, "type": "agent"}], edges=[], entry_point=agent_id
+            graph_id,
+            nodes=[{"id": agent_id, "type": "agent"}],
+            edges=[],
+            entry_point=agent_id,
         )
 
         return await self.execute_graph(graph_id, {"task": task, "context": context})
@@ -725,7 +771,9 @@ class FrameworkOrchestrator:
             self.default_framework = framework.name.lower()
         return framework.id
 
-    async def initialize_all(self, credentials: Dict[str, FrameworkCredentials]) -> Dict[str, bool]:
+    async def initialize_all(
+        self, credentials: Dict[str, FrameworkCredentials]
+    ) -> Dict[str, bool]:
         """Initialize all registered frameworks
 
         åˆå§‹åŒ–æ‰€æœ‰è¨»å†Šçš„æ¡†æ¶
@@ -738,7 +786,9 @@ class FrameworkOrchestrator:
                 results[name] = False
         return results
 
-    def get_framework(self, name: Optional[str] = None) -> Optional[FrameworkIntegration]:
+    def get_framework(
+        self, name: Optional[str] = None
+    ) -> Optional[FrameworkIntegration]:
         """Get a framework by name or default"""
         if name is None:
             name = self.default_framework
@@ -789,4 +839,6 @@ class FrameworkOrchestrator:
 
         ç²å–æ‰€æœ‰æ¡†æ¶çš„ç‹€æ…‹
         """
-        return {name: framework.get_status() for name, framework in self.frameworks.items()}
+        return {
+            name: framework.get_status() for name, framework in self.frameworks.items()
+        }
diff --git a/workspace/src/core/tech_stack/multi_agent_coordinator.py b/workspace/src/core/tech_stack/multi_agent_coordinator.py
index 5ce2096..f14da03 100644
--- a/workspace/src/core/tech_stack/multi_agent_coordinator.py
+++ b/workspace/src/core/tech_stack/multi_agent_coordinator.py
@@ -238,7 +238,9 @@ class AgentCommunicationBus:
         message.message_type = MessageType.BROADCAST
         await self.publish("broadcast", message)
 
-    async def respond_to(self, original_message_id: str, response: AgentMessage) -> None:
+    async def respond_to(
+        self, original_message_id: str, response: AgentMessage
+    ) -> None:
         """Respond to a message
 
         å›è¦†æ¶ˆæ¯
@@ -251,7 +253,9 @@ class AgentCommunicationBus:
         """Process messages from the queue"""
         while self._running:
             try:
-                topic, message = await asyncio.wait_for(self.message_queue.get(), timeout=1.0)
+                topic, message = await asyncio.wait_for(
+                    self.message_queue.get(), timeout=1.0
+                )
 
                 for callback in self.subscribers.get(topic, []):
                     try:
@@ -260,7 +264,9 @@ class AgentCommunicationBus:
                         else:
                             callback(message)
                     except Exception as e:
-                        logger.error(f"Error in message callback for topic {topic}: {e}")
+                        logger.error(
+                            f"Error in message callback for topic {topic}: {e}"
+                        )
 
             except asyncio.TimeoutError:
                 continue
@@ -321,7 +327,9 @@ class TaskRouter:
         )
         self.routing_rules.sort(key=lambda x: x["priority"])
 
-    def find_suitable_agents(self, task: TeamTask, max_agents: int = 1) -> List[AgentDefinition]:
+    def find_suitable_agents(
+        self, task: TeamTask, max_agents: int = 1
+    ) -> List[AgentDefinition]:
         """Find agents suitable for a task
 
         æ‰¾åˆ°é©åˆä»»å‹™çš„ä»£ç†
@@ -381,7 +389,8 @@ class TaskRouter:
                 "current_load": self.agent_load[agent_id],
                 "max_load": self.agents[agent_id].max_concurrent_tasks,
                 "utilization": (
-                    self.agent_load[agent_id] / self.agents[agent_id].max_concurrent_tasks
+                    self.agent_load[agent_id]
+                    / self.agents[agent_id].max_concurrent_tasks
                     if self.agents[agent_id].max_concurrent_tasks > 0
                     else 0
                 ),
@@ -427,7 +436,9 @@ class AgentTeam:
         """Get all agents with a specific role"""
         return [a for a in self.agents.values() if a.role == role]
 
-    def get_agents_with_capability(self, capability: AgentCapability) -> List[AgentDefinition]:
+    def get_agents_with_capability(
+        self, capability: AgentCapability
+    ) -> List[AgentDefinition]:
         """Get all agents with a specific capability"""
         return [a for a in self.agents.values() if a.has_capability(capability)]
 
@@ -636,9 +647,15 @@ class MultiAgentCoordinator:
             "teams_count": len(self.teams),
             "tasks": {
                 "total": len(self.tasks),
-                "pending": len([t for t in self.tasks.values() if t.status == "pending"]),
-                "running": len([t for t in self.tasks.values() if t.status == "running"]),
-                "completed": len([t for t in self.tasks.values() if t.status == "completed"]),
+                "pending": len(
+                    [t for t in self.tasks.values() if t.status == "pending"]
+                ),
+                "running": len(
+                    [t for t in self.tasks.values() if t.status == "running"]
+                ),
+                "completed": len(
+                    [t for t in self.tasks.values() if t.status == "completed"]
+                ),
                 "failed": len([t for t in self.tasks.values() if t.status == "failed"]),
             },
             "agent_load": self.task_router.get_load_status(),
diff --git a/workspace/src/core/tech_stack/python_bridge.py b/workspace/src/core/tech_stack/python_bridge.py
index 994f606..b46db80 100644
--- a/workspace/src/core/tech_stack/python_bridge.py
+++ b/workspace/src/core/tech_stack/python_bridge.py
@@ -230,7 +230,9 @@ class PythonEnvironment:
             await asyncio.sleep(0.1)
             return True
         except Exception as e:
-            logger.error(f"Failed to install requirements from {requirements_path}: {e}")
+            logger.error(
+                f"Failed to install requirements from {requirements_path}: {e}"
+            )
             return False
 
     async def destroy(self) -> bool:
@@ -283,7 +285,10 @@ class PackageManager:
             PythonPackage("langchain-openai", "0.0.5"),
             PythonPackage("crewai", "0.28.0"),
             PythonPackage(
-                "autogen", "0.2.0", source="git", git_url="https://github.com/microsoft/autogen"
+                "autogen",
+                "0.2.0",
+                source="git",
+                git_url="https://github.com/microsoft/autogen",
             ),
             PythonPackage("langgraph", "0.0.1"),
         ],
@@ -534,15 +539,19 @@ class PythonBridge:
         self.default_environment: Optional[PythonEnvironment] = None
         self._initialized = False
 
-    async def initialize(self, setup_ai_env: bool = True, include_ml: bool = True) -> bool:
+    async def initialize(
+        self, setup_ai_env: bool = True, include_ml: bool = True
+    ) -> bool:
         """Initialize the Python bridge
 
         åˆå§‹åŒ– Python æ©‹æ¥å™¨
         """
         try:
             if setup_ai_env:
-                self.default_environment = await self.package_manager.setup_ai_environment(
-                    include_ml=include_ml
+                self.default_environment = (
+                    await self.package_manager.setup_ai_environment(
+                        include_ml=include_ml
+                    )
                 )
                 self.executors["default"] = PythonExecutor(self.default_environment)
 
@@ -564,7 +573,9 @@ class PythonBridge:
         self.executors[name] = executor
         return executor
 
-    async def execute_ai_code(self, code: str, executor_name: str = "default") -> ExecutionResult:
+    async def execute_ai_code(
+        self, code: str, executor_name: str = "default"
+    ) -> ExecutionResult:
         """Execute AI-related Python code
 
         åŸ·è¡Œ AI ç›¸é—œçš„ Python ä»£ç¢¼
@@ -575,12 +586,16 @@ class PythonBridge:
 
         if not executor:
             return ExecutionResult(
-                success=False, error_type="RuntimeError", error_message="No executor available"
+                success=False,
+                error_type="RuntimeError",
+                error_message="No executor available",
             )
 
         return await executor.execute_code(code)
 
-    async def run_langchain_agent(self, agent_config: Dict[str, Any], task: str) -> ExecutionResult:
+    async def run_langchain_agent(
+        self, agent_config: Dict[str, Any], task: str
+    ) -> ExecutionResult:
         """Run a LangChain agent
 
         é‹è¡Œ LangChain ä»£ç†
@@ -633,7 +648,9 @@ print(f"CrewAI crew executed with {{len(config.get('agents', []))}} agents")
         return {
             "initialized": self._initialized,
             "default_environment": (
-                self.default_environment.get_status() if self.default_environment else None
+                self.default_environment.get_status()
+                if self.default_environment
+                else None
             ),
             "executors_count": len(self.executors),
             "environments_count": len(self.package_manager.environments),
diff --git a/workspace/src/core/training_system/example_library.py b/workspace/src/core/training_system/example_library.py
index 78ac289..98f1f6c 100644
--- a/workspace/src/core/training_system/example_library.py
+++ b/workspace/src/core/training_system/example_library.py
@@ -825,7 +825,10 @@ async def get_products_optimized(cursor: str, limit: int = 20):
         return self.decision_examples.get(example_id)
 
     def search_examples(
-        self, query: str, category: Optional[ExampleCategory] = None, max_results: int = 5
+        self,
+        query: str,
+        category: Optional[ExampleCategory] = None,
+        max_results: int = 5,
     ) -> Dict[str, List[Any]]:
         """
         Search for relevant examples.
@@ -852,9 +855,9 @@ async def get_products_optimized(cursor: str, limit: int = 20):
 
         results["code_examples"] = [
             e
-            for e, _ in sorted(results["code_examples"], key=lambda x: x[1], reverse=True)[
-                :max_results
-            ]
+            for e, _ in sorted(
+                results["code_examples"], key=lambda x: x[1], reverse=True
+            )[:max_results]
         ]
 
         # Search scenario examples
@@ -870,9 +873,9 @@ async def get_products_optimized(cursor: str, limit: int = 20):
 
         results["scenario_examples"] = [
             e
-            for e, _ in sorted(results["scenario_examples"], key=lambda x: x[1], reverse=True)[
-                :max_results
-            ]
+            for e, _ in sorted(
+                results["scenario_examples"], key=lambda x: x[1], reverse=True
+            )[:max_results]
         ]
 
         # Search decision examples
@@ -888,9 +891,9 @@ async def get_products_optimized(cursor: str, limit: int = 20):
 
         results["decision_examples"] = [
             e
-            for e, _ in sorted(results["decision_examples"], key=lambda x: x[1], reverse=True)[
-                :max_results
-            ]
+            for e, _ in sorted(
+                results["decision_examples"], key=lambda x: x[1], reverse=True
+            )[:max_results]
         ]
 
         return results
@@ -912,10 +915,14 @@ async def get_products_optimized(cursor: str, limit: int = 20):
 
         return score
 
-    def get_examples_for_category(self, category: ExampleCategory) -> Dict[str, List[Any]]:
+    def get_examples_for_category(
+        self, category: ExampleCategory
+    ) -> Dict[str, List[Any]]:
         """Get all examples for a category."""
         return {
-            "code_examples": [e for e in self.code_examples.values() if e.category == category],
+            "code_examples": [
+                e for e in self.code_examples.values() if e.category == category
+            ],
             "scenario_examples": [
                 e for e in self.scenario_examples.values() if e.category == category
             ],
diff --git a/workspace/src/core/training_system/knowledge_base.py b/workspace/src/core/training_system/knowledge_base.py
index 68cb37e..9ba21fd 100644
--- a/workspace/src/core/training_system/knowledge_base.py
+++ b/workspace/src/core/training_system/knowledge_base.py
@@ -560,21 +560,33 @@ user = db.users.find_first(where={'email': email})
         """Get a specific best practice by ID."""
         return self.best_practices.get(practice_id)
 
-    def get_best_practices_for_category(self, category: KnowledgeCategory) -> List[BestPractice]:
+    def get_best_practices_for_category(
+        self, category: KnowledgeCategory
+    ) -> List[BestPractice]:
         """Get all best practices for a category."""
         return [
-            practice for practice in self.best_practices.values() if practice.category == category
+            practice
+            for practice in self.best_practices.values()
+            if practice.category == category
         ]
 
     def get_anti_pattern(self, pattern_id: str) -> Optional[AntiPattern]:
         """Get a specific anti-pattern by ID."""
         return self.anti_patterns.get(pattern_id)
 
-    def get_anti_patterns_for_category(self, category: KnowledgeCategory) -> List[AntiPattern]:
+    def get_anti_patterns_for_category(
+        self, category: KnowledgeCategory
+    ) -> List[AntiPattern]:
         """Get all anti-patterns for a category."""
-        return [pattern for pattern in self.anti_patterns.values() if pattern.category == category]
+        return [
+            pattern
+            for pattern in self.anti_patterns.values()
+            if pattern.category == category
+        ]
 
-    def get_domain_knowledge(self, category: KnowledgeCategory) -> Optional[DomainKnowledge]:
+    def get_domain_knowledge(
+        self, category: KnowledgeCategory
+    ) -> Optional[DomainKnowledge]:
         """Get complete domain knowledge."""
         return self.domains.get(category)
 
@@ -606,7 +618,9 @@ user = db.users.find_first(where={'email': email})
         if pattern.category in self.domains:
             self.domains[pattern.category].anti_patterns[pattern.id] = pattern
 
-    def get_relevant_knowledge(self, context: str, max_results: int = 5) -> Dict[str, Any]:
+    def get_relevant_knowledge(
+        self, context: str, max_results: int = 5
+    ) -> Dict[str, Any]:
         """
         Get relevant knowledge based on context.
 
@@ -631,7 +645,9 @@ user = db.users.find_first(where={'email': email})
 
         relevant["concepts"] = [
             c
-            for c, _ in sorted(relevant["concepts"], key=lambda x: x[1], reverse=True)[:max_results]
+            for c, _ in sorted(relevant["concepts"], key=lambda x: x[1], reverse=True)[
+                :max_results
+            ]
         ]
 
         # Find relevant best practices
@@ -644,9 +660,9 @@ user = db.users.find_first(where={'email': email})
 
         relevant["best_practices"] = [
             p
-            for p, _ in sorted(relevant["best_practices"], key=lambda x: x[1], reverse=True)[
-                :max_results
-            ]
+            for p, _ in sorted(
+                relevant["best_practices"], key=lambda x: x[1], reverse=True
+            )[:max_results]
         ]
 
         # Find relevant anti-patterns
@@ -659,9 +675,9 @@ user = db.users.find_first(where={'email': email})
 
         relevant["anti_patterns"] = [
             p
-            for p, _ in sorted(relevant["anti_patterns"], key=lambda x: x[1], reverse=True)[
-                :max_results
-            ]
+            for p, _ in sorted(
+                relevant["anti_patterns"], key=lambda x: x[1], reverse=True
+            )[:max_results]
         ]
 
         # Collect tips from relevant domains
diff --git a/workspace/src/core/training_system/skills_training.py b/workspace/src/core/training_system/skills_training.py
index e11407d..5afdd42 100644
--- a/workspace/src/core/training_system/skills_training.py
+++ b/workspace/src/core/training_system/skills_training.py
@@ -809,7 +809,11 @@ def login(email, password):
         for result in session.exercise_results:
             total_score += result["result"]["score"]
 
-        avg_score = total_score / len(session.exercise_results) if session.exercise_results else 0.0
+        avg_score = (
+            total_score / len(session.exercise_results)
+            if session.exercise_results
+            else 0.0
+        )
         session.assessment_score = avg_score
 
         # Determine if passed
@@ -831,7 +835,9 @@ def login(email, password):
             agent_id=session.agent_id,
             skill_id=module.skill_id,
             assessed_level=(
-                module.target_level if session.status == "completed" else SkillLevel.NOVICE
+                module.target_level
+                if session.status == "completed"
+                else SkillLevel.NOVICE
             ),
             score=avg_score,
             confidence=0.8 if len(session.exercise_results) >= 3 else 0.5,
@@ -862,7 +868,9 @@ def login(email, password):
             return self.agent_skills[agent_id].get(skill_id, SkillLevel.NOVICE)
         return SkillLevel.NOVICE
 
-    def get_recommended_modules(self, agent_id: str, skill_id: str) -> List[TrainingModule]:
+    def get_recommended_modules(
+        self, agent_id: str, skill_id: str
+    ) -> List[TrainingModule]:
         """Get recommended training modules for an agent."""
         current_level = self.get_agent_skill_level(agent_id, skill_id)
 
@@ -892,7 +900,9 @@ def login(email, password):
             if self._has_completed_module(agent_id, module_id):
                 completed_modules.append(module_id)
 
-        progress = len(completed_modules) / len(path.modules) * 100 if path.modules else 0
+        progress = (
+            len(completed_modules) / len(path.modules) * 100 if path.modules else 0
+        )
 
         return {
             "path_id": path_id,
diff --git a/workspace/src/core/validators/multi_layer_validator.py b/workspace/src/core/validators/multi_layer_validator.py
index 1b97590..7edfcb9 100644
--- a/workspace/src/core/validators/multi_layer_validator.py
+++ b/workspace/src/core/validators/multi_layer_validator.py
@@ -42,7 +42,9 @@ class MultiLayerValidator:
                 logger.error(f"Validation error: {e}")
                 results.append(
                     ValidationResult(
-                        layer=validator.__class__.__name__, is_valid=False, errors=[str(e)]
+                        layer=validator.__class__.__name__,
+                        is_valid=False,
+                        errors=[str(e)],
                     )
                 )
         return results
diff --git a/workspace/src/core/validators/security_validator.py b/workspace/src/core/validators/security_validator.py
index 4f30e7c..a72b3cc 100644
--- a/workspace/src/core/validators/security_validator.py
+++ b/workspace/src/core/validators/security_validator.py
@@ -42,7 +42,11 @@ class SecurityValidator:
     def _load_security_patterns(self) -> List[Tuple[str, str, str]]:
         """Load security patterns"""
         return [
-            ("hardcoded_secrets", r"(password|api_key|secret)\s*=\s*['\"]\w+", "critical"),
+            (
+                "hardcoded_secrets",
+                r"(password|api_key|secret)\s*=\s*['\"]\w+",
+                "critical",
+            ),
             ("sql_injection", r"execute\(.*\+.*\)", "critical"),
             ("xss", r"innerHTML\s*=\s*", "high"),
         ]
diff --git a/workspace/src/core/virtual_experts/expert_team.py b/workspace/src/core/virtual_experts/expert_team.py
index 5009a7e..07374e0 100644
--- a/workspace/src/core/virtual_experts/expert_team.py
+++ b/workspace/src/core/virtual_experts/expert_team.py
@@ -241,10 +241,41 @@ class VirtualExpertTeam:
         combined_text = (query + " " + (code or "")).lower()
 
         domain_keywords = {
-            "security": ["password", "authentication", "injection", "xss", "csrf", "å¯†ç¢¼", "å®‰å…¨"],
-            "database": ["sql", "query", "index", "transaction", "æ•¸æ“šåº«", "ç´¢å¼•", "æŸ¥è©¢"],
-            "performance": ["optimize", "performance", "slow", "cache", "æ€§èƒ½", "å„ªåŒ–", "ç·©å­˜"],
-            "architecture": ["design", "pattern", "microservice", "æ¶æ§‹", "è¨­è¨ˆ", "æ¨¡å¼"],
+            "security": [
+                "password",
+                "authentication",
+                "injection",
+                "xss",
+                "csrf",
+                "å¯†ç¢¼",
+                "å®‰å…¨",
+            ],
+            "database": [
+                "sql",
+                "query",
+                "index",
+                "transaction",
+                "æ•¸æ“šåº«",
+                "ç´¢å¼•",
+                "æŸ¥è©¢",
+            ],
+            "performance": [
+                "optimize",
+                "performance",
+                "slow",
+                "cache",
+                "æ€§èƒ½",
+                "å„ªåŒ–",
+                "ç·©å­˜",
+            ],
+            "architecture": [
+                "design",
+                "pattern",
+                "microservice",
+                "æ¶æ§‹",
+                "è¨­è¨ˆ",
+                "æ¨¡å¼",
+            ],
             "ai": ["model", "prediction", "machine learning", "ml", "æ¨¡å‹", "é æ¸¬"],
             "deployment": ["deploy", "ci/cd", "docker", "kubernetes", "éƒ¨ç½²", "å®¹å™¨"],
             "nlp": ["intent", "language", "text", "æ„åœ–", "èªè¨€", "æ–‡æœ¬"],
@@ -296,7 +327,11 @@ class VirtualExpertTeam:
 
         # Synthesize results
         result = self._synthesize_results(
-            consultation, expert_responses, all_issues, all_suggestions, all_recommendations
+            consultation,
+            expert_responses,
+            all_issues,
+            all_suggestions,
+            all_recommendations,
         )
 
         # Update consultation status
@@ -317,7 +352,9 @@ class VirtualExpertTeam:
         }
 
         if consultation.type == ConsultationType.CODE_REVIEW and consultation.code:
-            review = expert.review_code(consultation.code, consultation.language or "python")
+            review = expert.review_code(
+                consultation.code, consultation.language or "python"
+            )
             response.update(review)
 
         elif consultation.type in [
@@ -356,22 +393,30 @@ class VirtualExpertTeam:
 
         # Sort issues by severity
         severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
-        unique_issues.sort(key=lambda x: severity_order.get(x.get("severity", "low"), 4))
+        unique_issues.sort(
+            key=lambda x: severity_order.get(x.get("severity", "low"), 4)
+        )
 
         # Deduplicate recommendations
         unique_recommendations = list(dict.fromkeys(all_recommendations))
 
         # Calculate quality score
         quality_scores = [
-            r.get("quality_score", 0.8) for r in expert_responses if "quality_score" in r
+            r.get("quality_score", 0.8)
+            for r in expert_responses
+            if "quality_score" in r
         ]
-        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0.8
+        avg_quality = (
+            sum(quality_scores) / len(quality_scores) if quality_scores else 0.8
+        )
 
         # Generate summary
         summary = self._generate_summary(consultation, expert_responses, unique_issues)
 
         # Generate action items
-        action_items = self._generate_action_items(unique_issues, unique_recommendations)
+        action_items = self._generate_action_items(
+            unique_issues, unique_recommendations
+        )
 
         return ConsultationResult(
             consultation_id=consultation.id,
diff --git a/workspace/src/core/yaml_module_system/audit_trail.py b/workspace/src/core/yaml_module_system/audit_trail.py
index 66f9024..a0eb12f 100644
--- a/workspace/src/core/yaml_module_system/audit_trail.py
+++ b/workspace/src/core/yaml_module_system/audit_trail.py
@@ -283,9 +283,13 @@ class AuditLogger:
 
         return entries[:limit]
 
-    def get_resource_history(self, resource_type: str, resource_id: str) -> List[AuditEntry]:
+    def get_resource_history(
+        self, resource_type: str, resource_id: str
+    ) -> List[AuditEntry]:
         """ç²å–è³‡æºçš„å®Œæ•´æ­·å²"""
-        return self.get_entries(resource_type=resource_type, resource_id=resource_id, limit=1000)
+        return self.get_entries(
+            resource_type=resource_type, resource_id=resource_id, limit=1000
+        )
 
     def export(self, format: str = "json") -> str:
         """å°å‡ºå¯©è¨ˆæ—¥èªŒ"""
diff --git a/workspace/src/core/yaml_module_system/ci_verification_pipeline.py b/workspace/src/core/yaml_module_system/ci_verification_pipeline.py
index 8497203..d298b74 100644
--- a/workspace/src/core/yaml_module_system/ci_verification_pipeline.py
+++ b/workspace/src/core/yaml_module_system/ci_verification_pipeline.py
@@ -61,7 +61,9 @@ class StageResult:
             "stage_type": self.stage_type.value,
             "status": self.status.value,
             "started_at": self.started_at.isoformat(),
-            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
+            "completed_at": (
+                self.completed_at.isoformat() if self.completed_at else None
+            ),
             "duration_ms": self.duration_ms,
             "outputs": self.outputs,
             "errors": self.errors,
@@ -131,10 +133,19 @@ class Evidence:
 
     @classmethod
     def create(
-        cls, type: str, name: str, description: str, data: Any, source: Optional[str] = None
+        cls,
+        type: str,
+        name: str,
+        description: str,
+        data: Any,
+        source: Optional[str] = None,
     ) -> "Evidence":
         """å‰µå»ºè­‰æ“š"""
-        data_str = json.dumps(data, sort_keys=True) if isinstance(data, (dict, list)) else str(data)
+        data_str = (
+            json.dumps(data, sort_keys=True)
+            if isinstance(data, (dict, list))
+            else str(data)
+        )
         data_hash = hashlib.sha256(data_str.encode()).hexdigest()
 
         return cls(
@@ -172,7 +183,12 @@ class EvidenceCollector:
         self._evidence: List[Evidence] = []
 
     def collect(
-        self, type: str, name: str, description: str, data: Any, source: Optional[str] = None
+        self,
+        type: str,
+        name: str,
+        description: str,
+        data: Any,
+        source: Optional[str] = None,
     ) -> Evidence:
         """æ”¶é›†è­‰æ“š"""
         evidence = Evidence.create(type, name, description, data, source)
@@ -222,7 +238,9 @@ class VerificationReport:
     def passed(self) -> bool:
         """æ˜¯å¦å…¨éƒ¨é€šé"""
         return all(
-            s.status == StageStatus.PASSED for s in self.stages if s.status != StageStatus.SKIPPED
+            s.status == StageStatus.PASSED
+            for s in self.stages
+            if s.status != StageStatus.SKIPPED
         )
 
     @property
@@ -242,7 +260,9 @@ class VerificationReport:
             "stages": [s.to_dict() for s in self.stages],
             "evidence": [e.to_dict() for e in self.evidence],
             "started_at": self.started_at.isoformat(),
-            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
+            "completed_at": (
+                self.completed_at.isoformat() if self.completed_at else None
+            ),
             "total_duration_ms": self.total_duration_ms,
             "failed_stages": [s.stage_id for s in self.failed_stages],
         }
@@ -255,7 +275,11 @@ class VerificationReport:
             f"- **Pipeline ID**: {self.pipeline_id}",
             f"- **Module**: {self.module_id} v{self.module_version}",
             f"- **Status**: {'âœ… PASSED' if self.passed else 'âŒ FAILED'}",
-            f"- **Duration**: {self.total_duration_ms}ms" if self.total_duration_ms else "",
+            (
+                f"- **Duration**: {self.total_duration_ms}ms"
+                if self.total_duration_ms
+                else ""
+            ),
             f"",
             f"## Stages",
             f"",
@@ -271,7 +295,9 @@ class VerificationReport:
                 StageStatus.CANCELLED: "ğŸš«",
             }.get(stage.status, "â“")
 
-            lines.append(f"- {status_icon} **{stage.stage_type.value}**: {stage.status.value}")
+            lines.append(
+                f"- {status_icon} **{stage.stage_type.value}**: {stage.status.value}"
+            )
 
             if stage.errors:
                 for error in stage.errors:
@@ -355,7 +381,8 @@ class CIVerificationPipeline:
         for stage in self._stages:
             # æª¢æŸ¥ä¾è³´
             dependencies_met = all(
-                dep in completed_stages and completed_stages[dep].status == StageStatus.PASSED
+                dep in completed_stages
+                and completed_stages[dep].status == StageStatus.PASSED
                 for dep in stage.depends_on
             )
 
diff --git a/workspace/src/core/yaml_module_system/policy_gate.py b/workspace/src/core/yaml_module_system/policy_gate.py
index 172236a..dfbb348 100644
--- a/workspace/src/core/yaml_module_system/policy_gate.py
+++ b/workspace/src/core/yaml_module_system/policy_gate.py
@@ -141,7 +141,9 @@ class PolicyRule:
 
         return None
 
-    def _evaluate_condition(self, data: Any, context: Optional[Dict[str, Any]] = None) -> bool:
+    def _evaluate_condition(
+        self, data: Any, context: Optional[Dict[str, Any]] = None
+    ) -> bool:
         """è©•ä¼°æ¢ä»¶è¡¨é”å¼"""
         # ç°¡å–®çš„æ¢ä»¶è©•ä¼°
         # æ”¯æŒ: exists, equals, contains, matches, etc.
@@ -223,7 +225,9 @@ class PolicyEvaluationResult:
     @property
     def critical_count(self) -> int:
         """åš´é‡é•è¦æ•¸é‡"""
-        return len([v for v in self.violations if v.severity == PolicySeverity.CRITICAL])
+        return len(
+            [v for v in self.violations if v.severity == PolicySeverity.CRITICAL]
+        )
 
     @property
     def high_count(self) -> int:
@@ -289,7 +293,9 @@ class PolicyGate:
             return True
         return False
 
-    def add_exception(self, rule_id: str, module_id: str, reason: str, approved_by: str) -> bool:
+    def add_exception(
+        self, rule_id: str, module_id: str, reason: str, approved_by: str
+    ) -> bool:
         """æ·»åŠ ä¾‹å¤–"""
         if rule_id not in self._rules:
             return False
@@ -305,7 +311,10 @@ class PolicyGate:
         return module_id in self._exceptions.get(rule_id, [])
 
     def evaluate(
-        self, data: Any, module_id: Optional[str] = None, context: Optional[Dict[str, Any]] = None
+        self,
+        data: Any,
+        module_id: Optional[str] = None,
+        context: Optional[Dict[str, Any]] = None,
     ) -> PolicyEvaluationResult:
         """
         è©•ä¼°æ•¸æ“šæ˜¯å¦ç¬¦åˆæ‰€æœ‰ç­–ç•¥
@@ -375,7 +384,9 @@ class PolicyGate:
         return result
 
     def get_rules(
-        self, category: Optional[PolicyCategory] = None, severity: Optional[PolicySeverity] = None
+        self,
+        category: Optional[PolicyCategory] = None,
+        severity: Optional[PolicySeverity] = None,
     ) -> List[PolicyRule]:
         """ç²å–ç­–ç•¥è¦å‰‡åˆ—è¡¨"""
         rules = list(self._rules.values())
diff --git a/workspace/src/core/yaml_module_system/slsa_compliance.py b/workspace/src/core/yaml_module_system/slsa_compliance.py
index 4e5af9f..bf151d1 100644
--- a/workspace/src/core/yaml_module_system/slsa_compliance.py
+++ b/workspace/src/core/yaml_module_system/slsa_compliance.py
@@ -121,7 +121,9 @@ class SLSAProvenance:
             "subject": [s.to_dict() for s in self.subjects],
             "predicateType": self.predicate_type,
             "predicate": {
-                "buildDefinition": self.build_definition.to_dict() if self.build_definition else {},
+                "buildDefinition": (
+                    self.build_definition.to_dict() if self.build_definition else {}
+                ),
                 "runDetails": self.run_details.to_dict() if self.run_details else {},
             },
             "metadata": {
@@ -259,7 +261,9 @@ class ArtifactSigner:
     å°è£½å“é€²è¡Œæ•¸å­—ç°½åä»¥ç¢ºä¿å®Œæ•´æ€§ã€‚
     """
 
-    def __init__(self, key_id: str, algorithm: SignatureAlgorithm = SignatureAlgorithm.ECDSA_P256):
+    def __init__(
+        self, key_id: str, algorithm: SignatureAlgorithm = SignatureAlgorithm.ECDSA_P256
+    ):
         self.key_id = key_id
         self.algorithm = algorithm
 
@@ -285,7 +289,9 @@ class ArtifactSigner:
         # ç”Ÿæˆç°½åï¼ˆæ¨¡æ“¬ï¼‰
         # åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒä½¿ç”¨çœŸæ­£çš„å¯†ç¢¼å­¸ç°½å
         signature_data = f"{digest}:{self.key_id}:{self.algorithm.value}"
-        signature = base64.b64encode(hashlib.sha256(signature_data.encode()).digest()).decode()
+        signature = base64.b64encode(
+            hashlib.sha256(signature_data.encode()).digest()
+        ).decode()
 
         return SignedArtifact(
             artifact_name=artifact_name,
@@ -381,7 +387,10 @@ class SBOMGenerator:
         self.author = author
 
     def generate(
-        self, name: str, version: str, dependencies: Optional[List[Dict[str, Any]]] = None
+        self,
+        name: str,
+        version: str,
+        dependencies: Optional[List[Dict[str, Any]]] = None,
     ) -> SBOM:
         """
         ç”Ÿæˆ SBOM
diff --git a/workspace/src/core/yaml_module_system/yaml_module_definition.py b/workspace/src/core/yaml_module_system/yaml_module_definition.py
index 0670766..14c8983 100644
--- a/workspace/src/core/yaml_module_system/yaml_module_definition.py
+++ b/workspace/src/core/yaml_module_system/yaml_module_definition.py
@@ -235,7 +235,9 @@ class YAMLModuleDefinition:
             "lifecycle": {
                 "state": self.lifecycle.state.value,
                 "approved_at": (
-                    self.lifecycle.approved_at.isoformat() if self.lifecycle.approved_at else None
+                    self.lifecycle.approved_at.isoformat()
+                    if self.lifecycle.approved_at
+                    else None
                 ),
                 "approved_by": self.lifecycle.approved_by,
             },
diff --git a/workspace/src/core/yaml_module_system/yaml_schema_validator.py b/workspace/src/core/yaml_module_system/yaml_schema_validator.py
index b6c3c83..ed9ca1e 100644
--- a/workspace/src/core/yaml_module_system/yaml_schema_validator.py
+++ b/workspace/src/core/yaml_module_system/yaml_schema_validator.py
@@ -91,7 +91,9 @@ class SchemaRegistry:
         self._schemas: Dict[str, Dict[str, Any]] = {}
         self._schema_versions: Dict[str, List[str]] = {}
 
-    def register(self, schema_id: str, schema: Dict[str, Any], version: str = "1.0.0") -> None:
+    def register(
+        self, schema_id: str, schema: Dict[str, Any], version: str = "1.0.0"
+    ) -> None:
         """è¨»å†Š Schema"""
         full_id = f"{schema_id}@{version}"
         self._schemas[full_id] = schema
@@ -100,7 +102,9 @@ class SchemaRegistry:
             self._schema_versions[schema_id] = []
         self._schema_versions[schema_id].append(version)
 
-    def get(self, schema_id: str, version: Optional[str] = None) -> Optional[Dict[str, Any]]:
+    def get(
+        self, schema_id: str, version: Optional[str] = None
+    ) -> Optional[Dict[str, Any]]:
         """ç²å– Schema"""
         if version:
             full_id = f"{schema_id}@{version}"
@@ -159,7 +163,9 @@ class YAMLSchemaValidator:
         """è¨»å†Šè‡ªå®šç¾©é©—è­‰å™¨"""
         self._custom_validators[name] = validator
 
-    def validate(self, data: Any, schema: Dict[str, Any], path: str = "$") -> ValidationResult:
+    def validate(
+        self, data: Any, schema: Dict[str, Any], path: str = "$"
+    ) -> ValidationResult:
         """
         é©—è­‰æ•¸æ“šæ˜¯å¦ç¬¦åˆ Schema
 
@@ -441,7 +447,9 @@ class YAMLSchemaValidator:
             seen = []
             for item in data:
                 item_json = (
-                    json.dumps(item, sort_keys=True) if isinstance(item, (dict, list)) else item
+                    json.dumps(item, sort_keys=True)
+                    if isinstance(item, (dict, list))
+                    else item
                 )
                 if item_json in seen:
                     result.add_error(
diff --git a/workspace/src/demo_core.py b/workspace/src/demo_core.py
index 3a83040..8adc499 100644
--- a/workspace/src/demo_core.py
+++ b/workspace/src/demo_core.py
@@ -3,18 +3,21 @@ MachineNativeOps Core Demo
 æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤º
 """
 
-from core.new import core
-import logging
 import asyncio
+import logging
 import os
 import sys
 
+from core.new import core
+
 # æ·»åŠ è·¯å¾‘ä»¥ä¾¿å°å…¥
 sys.path.append(os.path.dirname(__file__))
 
 
 # è¨­ç½®æ—¥èªŒ
-logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
+logging.basicConfig(
+    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
+)
 logger = logging.getLogger(__name__)
 
 
@@ -42,7 +45,9 @@ async def demo_basic_functionality():
         logger.info(f"ğŸ“‹ åŸ·è¡Œä»»å‹™: {message}")
         return f"ä»»å‹™å®Œæˆ: {message}"
 
-    task_id = await core.submit_task("demo_task", demo_task, {"message": "Hello MachineNativeOps!"})
+    task_id = await core.submit_task(
+        "demo_task", demo_task, {"message": "Hello MachineNativeOps!"}
+    )
     logger.info(f"âœ… ä»»å‹™å·²æäº¤: {task_id}")
 
     # 4. å·¥ä½œæµå‰µå»ºæ¼”ç¤º
diff --git a/workspace/src/demo_instant_generation.py b/workspace/src/demo_instant_generation.py
index d37d247..c84dad8 100644
--- a/workspace/src/demo_instant_generation.py
+++ b/workspace/src/demo_instant_generation.py
@@ -5,13 +5,17 @@ Instant Generation Demo
 å±•ç¤ºé©å‘½æ€§æ¶æ§‹çš„å®Œæ•´åŠŸèƒ½
 """
 
-from core.machinenativenops.instant_generation.main import InstantGenerationSystem, quick_generate
 import asyncio
 import json
 import logging
 import time
 from datetime import datetime
 
+from core.machinenativenops.instant_generation.main import (
+    InstantGenerationSystem,
+    quick_generate,
+)
+
 # é…ç½®æ—¥èªŒ
 logging.basicConfig(
     level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
@@ -131,7 +135,13 @@ async def demo_performance_analysis():
     # å¤šæ¬¡ç”Ÿæˆä»¥æ”¶é›†æ€§èƒ½æ•¸æ“š
     print("ğŸ”„ åŸ·è¡Œå¤šæ¬¡ç”Ÿæˆæ¸¬è©¦...")
 
-    test_inputs = ["ç°¡å–®çš„åšå®¢ç¶²ç«™", "é›»å•†ç³»çµ±", "ç¤¾äº¤åª’é«”æ‡‰ç”¨", "åœ¨ç·šæ•™è‚²å¹³å°", "é‡‘èç®¡ç†ç³»çµ±"]
+    test_inputs = [
+        "ç°¡å–®çš„åšå®¢ç¶²ç«™",
+        "é›»å•†ç³»çµ±",
+        "ç¤¾äº¤åª’é«”æ‡‰ç”¨",
+        "åœ¨ç·šæ•™è‚²å¹³å°",
+        "é‡‘èç®¡ç†ç³»çµ±",
+    ]
 
     results = []
     for i, user_input in enumerate(test_inputs, 1):
@@ -161,17 +171,25 @@ async def demo_performance_analysis():
     successful_results = [r for r in results if r["success"]]
 
     if successful_results:
-        avg_time = sum(r["execution_time"] for r in successful_results) / len(successful_results)
+        avg_time = sum(r["execution_time"] for r in successful_results) / len(
+            successful_results
+        )
         success_rate = len(successful_results) / len(results) * 100
         target_met_rate = (
-            sum(1 for r in successful_results if r["target_met"]) / len(successful_results) * 100
+            sum(1 for r in successful_results if r["target_met"])
+            / len(successful_results)
+            * 100
         )
 
         print(f"æˆåŠŸç‡: {success_rate:.1f}%")
         print(f"å¹³å‡åŸ·è¡Œæ™‚é–“: {avg_time:.2f}ç§’")
         print(f"ç›®æ¨™é”æˆç‡: {target_met_rate:.1f}%")
-        print(f"æœ€å¿«åŸ·è¡Œæ™‚é–“: {min(r['execution_time'] for r in successful_results):.2f}ç§’")
-        print(f"æœ€æ…¢åŸ·è¡Œæ™‚é–“: {max(r['execution_time'] for r in successful_results):.2f}ç§’")
+        print(
+            f"æœ€å¿«åŸ·è¡Œæ™‚é–“: {min(r['execution_time'] for r in successful_results):.2f}ç§’"
+        )
+        print(
+            f"æœ€æ…¢åŸ·è¡Œæ™‚é–“: {max(r['execution_time'] for r in successful_results):.2f}ç§’"
+        )
 
     # ç²å–ç³»çµ±çµ±è¨ˆ
     print(f"\nğŸ“ˆ ç³»çµ±çµ±è¨ˆ:")
diff --git a/workspace/src/developer-tools/automated-test-generator/test_generator.py b/workspace/src/developer-tools/automated-test-generator/test_generator.py
index 1ca3964..0a61971 100644
--- a/workspace/src/developer-tools/automated-test-generator/test_generator.py
+++ b/workspace/src/developer-tools/automated-test-generator/test_generator.py
@@ -226,7 +226,11 @@ class AutomatedTestGenerator:
         for arg in node.args.args:
             param_info = {
                 "name": arg.arg,
-                "type": self._get_annotation_string(arg.annotation) if arg.annotation else None,
+                "type": (
+                    self._get_annotation_string(arg.annotation)
+                    if arg.annotation
+                    else None
+                ),
                 "default": None,
                 "kind": "positional",
             }
@@ -245,7 +249,11 @@ class AutomatedTestGenerator:
         for kwarg in node.args.kwonlyargs:
             param_info = {
                 "name": kwarg.arg,
-                "type": self._get_annotation_string(kwarg.annotation) if kwarg.annotation else None,
+                "type": (
+                    self._get_annotation_string(kwarg.annotation)
+                    if kwarg.annotation
+                    else None
+                ),
                 "default": None,
                 "kind": "keyword_only",
             }
@@ -254,7 +262,12 @@ class AutomatedTestGenerator:
         # **kwargs
         if node.args.kwarg:
             parameters.append(
-                {"name": node.args.kwarg.arg, "type": None, "default": None, "kind": "kwargs"}
+                {
+                    "name": node.args.kwarg.arg,
+                    "type": None,
+                    "default": None,
+                    "kind": "kwargs",
+                }
             )
 
         return parameters
@@ -308,7 +321,9 @@ class AutomatedTestGenerator:
 
         return complexity
 
-    def _analyze_dependencies(self, node: ast.FunctionDef, module: astroid.Module) -> List[str]:
+    def _analyze_dependencies(
+        self, node: ast.FunctionDef, module: astroid.Module
+    ) -> List[str]:
         """åˆ†æå‡½æ•¸ä¾è³´"""
         dependencies = set()
 
@@ -322,7 +337,9 @@ class AutomatedTestGenerator:
 
         return list(dependencies)
 
-    def generate_test_cases(self, function_analysis: FunctionAnalysis) -> List[TestCase]:
+    def generate_test_cases(
+        self, function_analysis: FunctionAnalysis
+    ) -> List[TestCase]:
         """ç”Ÿæˆæ¸¬è©¦ç”¨ä¾‹"""
         test_cases = []
 
@@ -521,14 +538,18 @@ def test_{analysis.name}_{scenario}():
     def _has_nullable_parameters(self, parameters: List[Dict[str, Any]]) -> bool:
         """æª¢æŸ¥æ˜¯å¦æœ‰å¯ç©ºåƒæ•¸"""
         for param in parameters:
-            if param.get("type") and ("Optional" in param["type"] or "Union" in param["type"]):
+            if param.get("type") and (
+                "Optional" in param["type"] or "Union" in param["type"]
+            ):
                 return True
         return False
 
     def _has_numeric_parameters(self, parameters: List[Dict[str, Any]]) -> bool:
         """æª¢æŸ¥æ˜¯å¦æœ‰æ•¸å­—åƒæ•¸"""
         for param in parameters:
-            if param.get("type") and any(t in param["type"].lower() for t in ["int", "float"]):
+            if param.get("type") and any(
+                t in param["type"].lower() for t in ["int", "float"]
+            ):
                 return True
         return False
 
@@ -661,7 +682,9 @@ def test_{analysis.name}_dependency_error():
         for test_case in test_cases:
             if "import" in test_case.setup_code:
                 for line in test_case.setup_code.split("\n"):
-                    if line.strip().startswith("import") or line.strip().startswith("from"):
+                    if line.strip().startswith("import") or line.strip().startswith(
+                        "from"
+                    ):
                         imports.add(line.strip())
 
         content.extend(sorted(imports))
@@ -687,7 +710,9 @@ def test_{analysis.name}_dependency_error():
                 test_lines = test_case.test_code.strip().split("\n")
                 for line in test_lines:
                     if line.strip():
-                        if line.strip().startswith("def ") or line.strip().startswith("async def "):
+                        if line.strip().startswith("def ") or line.strip().startswith(
+                            "async def "
+                        ):
                             content.append(f"    {line}\n")
                         else:
                             content.append(f"        {line}\n")
@@ -704,7 +729,9 @@ def test_{analysis.name}_dependency_error():
         except Exception:
             return file_content
 
-    def save_test_files(self, functions_analysis: List[FunctionAnalysis], output_dir: str):
+    def save_test_files(
+        self, functions_analysis: List[FunctionAnalysis], output_dir: str
+    ):
         """ä¿å­˜æ¸¬è©¦æ–‡ä»¶"""
         output_path = Path(output_dir)
         output_path.mkdir(parents=True, exist_ok=True)
@@ -735,10 +762,14 @@ def test_{analysis.name}_dependency_error():
 
             print(f"ç”Ÿæˆæ¸¬è©¦æ–‡ä»¶: {test_file_path}")
 
-    def generate_report(self, functions_analysis: List[FunctionAnalysis]) -> Dict[str, Any]:
+    def generate_report(
+        self, functions_analysis: List[FunctionAnalysis]
+    ) -> Dict[str, Any]:
         """ç”Ÿæˆåˆ†æå ±å‘Š"""
         total_functions = len(functions_analysis)
-        testable_functions = len([f for f in functions_analysis if not f.is_test_function])
+        testable_functions = len(
+            [f for f in functions_analysis if not f.is_test_function]
+        )
 
         complexity_stats = {
             "low": 0,  # 1-5
diff --git a/workspace/src/developer-tools/ci-monitor-dashboard/app.py b/workspace/src/developer-tools/ci-monitor-dashboard/app.py
index a94bbc9..dea1c36 100644
--- a/workspace/src/developer-tools/ci-monitor-dashboard/app.py
+++ b/workspace/src/developer-tools/ci-monitor-dashboard/app.py
@@ -73,7 +73,9 @@ class CIMonitorDashboard:
             return {
                 "github": {
                     "token": os.getenv("GITHUB_TOKEN"),
-                    "repo": os.getenv("GITHUB_REPO", "MachineNativeOps/MachineNativeOps"),
+                    "repo": os.getenv(
+                        "GITHUB_REPO", "MachineNativeOps/MachineNativeOps"
+                    ),
                 },
                 "redis": {
                     "host": os.getenv("REDIS_HOST", "localhost"),
@@ -113,13 +115,18 @@ class CIMonitorDashboard:
             __name__,
             external_stylesheets=[dbc.themes.BOOTSTRAP, dbc.icons.BOOTSTRAP],
             title=self.config["dashboard"]["title"],
-            meta_tags=[{"name": "viewport", "content": "width=device-width, initial-scale=1"}],
+            meta_tags=[
+                {"name": "viewport", "content": "width=device-width, initial-scale=1"}
+            ],
         )
 
         # è¨­ç½®æ‡‰ç”¨é…ç½®
         app.config.suppress_callback_exceptions = True
         app.config.update(
-            {"requests_pathname_prefix": "/ci-monitor/", "routes_pathname_prefix": "/ci-monitor/"}
+            {
+                "requests_pathname_prefix": "/ci-monitor/",
+                "routes_pathname_prefix": "/ci-monitor/",
+            }
         )
 
         return app
@@ -232,7 +239,9 @@ class CIMonitorDashboard:
                     "test_passed": int(cached_data.get("test_passed", 0)),
                     "coverage_percent": float(cached_data.get("coverage_percent", 0.0)),
                     "security_issues": int(cached_data.get("security_issues", 0)),
-                    "code_quality_score": float(cached_data.get("code_quality_score", 0.0)),
+                    "code_quality_score": float(
+                        cached_data.get("code_quality_score", 0.0)
+                    ),
                 }
         except Exception as e:
             print(f"å¾ç·©å­˜ç²å–æŒ‡æ¨™å¤±æ•—: {e}")
@@ -264,7 +273,10 @@ class CIMonitorDashboard:
                     ]
                 ),
                 # ç¸½è¦½å¡ç‰‡
-                dbc.Row([dbc.Col([self._create_overview_cards()], width=12)], className="mb-4"),
+                dbc.Row(
+                    [dbc.Col([self._create_overview_cards()], width=12)],
+                    className="mb-4",
+                ),
                 # åœ–è¡¨å€åŸŸ
                 dbc.Row(
                     [
@@ -272,7 +284,8 @@ class CIMonitorDashboard:
                         dbc.Col(
                             [
                                 dcc.Graph(
-                                    id="status-distribution-chart", config={"displayModeBar": False}
+                                    id="status-distribution-chart",
+                                    config={"displayModeBar": False},
                                 )
                             ],
                             width=4,
@@ -281,7 +294,8 @@ class CIMonitorDashboard:
                         dbc.Col(
                             [
                                 dcc.Graph(
-                                    id="duration-trend-chart", config={"displayModeBar": False}
+                                    id="duration-trend-chart",
+                                    config={"displayModeBar": False},
                                 )
                             ],
                             width=8,
@@ -296,21 +310,30 @@ class CIMonitorDashboard:
                         dbc.Col(
                             [
                                 dcc.Graph(
-                                    id="coverage-trend-chart", config={"displayModeBar": False}
+                                    id="coverage-trend-chart",
+                                    config={"displayModeBar": False},
                                 )
                             ],
                             width=6,
                         ),
                         # ä»£ç¢¼å“è³ªè©•åˆ†
                         dbc.Col(
-                            [dcc.Graph(id="quality-score-chart", config={"displayModeBar": False})],
+                            [
+                                dcc.Graph(
+                                    id="quality-score-chart",
+                                    config={"displayModeBar": False},
+                                )
+                            ],
                             width=6,
                         ),
                     ],
                     className="mb-4",
                 ),
                 # æµæ°´ç·šè©³ç´°è¡¨æ ¼
-                dbc.Row([dbc.Col([self._create_pipeline_table()], width=12)], className="mb-4"),
+                dbc.Row(
+                    [dbc.Col([self._create_pipeline_table()], width=12)],
+                    className="mb-4",
+                ),
                 # è‡ªå‹•åˆ·æ–°é–“éš”
                 dcc.Interval(
                     id="interval-component",
@@ -339,12 +362,15 @@ class CIMonitorDashboard:
                                                 html.I(
                                                     className="bi bi-check-circle me-2 text-success"
                                                 ),
-                                                html.Span("æˆåŠŸç‡", id="success-rate-value"),
+                                                html.Span(
+                                                    "æˆåŠŸç‡", id="success-rate-value"
+                                                ),
                                             ],
                                             className="card-title",
                                         ),
                                         html.P(
-                                            "éå»7å¤©æµæ°´ç·šæˆåŠŸç‡", className="card-text text-muted"
+                                            "éå»7å¤©æµæ°´ç·šæˆåŠŸç‡",
+                                            className="card-text text-muted",
                                         ),
                                     ]
                                 )
@@ -363,12 +389,19 @@ class CIMonitorDashboard:
                                     [
                                         html.H4(
                                             [
-                                                html.I(className="bi bi-clock me-2 text-info"),
-                                                html.Span("0åˆ†é˜", id="avg-duration-value"),
+                                                html.I(
+                                                    className="bi bi-clock me-2 text-info"
+                                                ),
+                                                html.Span(
+                                                    "0åˆ†é˜", id="avg-duration-value"
+                                                ),
                                             ],
                                             className="card-title",
                                         ),
-                                        html.P("å¹³å‡åŸ·è¡Œæ™‚é–“", className="card-text text-muted"),
+                                        html.P(
+                                            "å¹³å‡åŸ·è¡Œæ™‚é–“",
+                                            className="card-text text-muted",
+                                        ),
                                     ]
                                 )
                             ],
@@ -389,12 +422,15 @@ class CIMonitorDashboard:
                                                 html.I(
                                                     className="bi bi-lightning me-2 text-warning"
                                                 ),
-                                                html.Span("0", id="active-pipelines-value"),
+                                                html.Span(
+                                                    "0", id="active-pipelines-value"
+                                                ),
                                             ],
                                             className="card-title",
                                         ),
                                         html.P(
-                                            "æ­£åœ¨é‹è¡Œçš„æµæ°´ç·š", className="card-text text-muted"
+                                            "æ­£åœ¨é‹è¡Œçš„æµæ°´ç·š",
+                                            className="card-text text-muted",
                                         ),
                                     ]
                                 )
@@ -416,12 +452,15 @@ class CIMonitorDashboard:
                                                 html.I(
                                                     className="bi bi-shield-exclamation me-2 text-danger"
                                                 ),
-                                                html.Span("0", id="security-issues-value"),
+                                                html.Span(
+                                                    "0", id="security-issues-value"
+                                                ),
                                             ],
                                             className="card-title",
                                         ),
                                         html.P(
-                                            "å¾…è§£æ±ºçš„å®‰å…¨å•é¡Œ", className="card-text text-muted"
+                                            "å¾…è§£æ±ºçš„å®‰å…¨å•é¡Œ",
+                                            className="card-text text-muted",
                                         ),
                                     ]
                                 )
@@ -474,8 +513,12 @@ class CIMonitorDashboard:
                 seven_days_ago = datetime.now() - timedelta(days=7)
                 recent_metrics = [m for m in metrics if m.timestamp > seven_days_ago]
 
-                success_count = sum(1 for m in recent_metrics if m.status == PipelineStatus.SUCCESS)
-                success_rate = (success_count / len(recent_metrics) * 100) if recent_metrics else 0
+                success_count = sum(
+                    1 for m in recent_metrics if m.status == PipelineStatus.SUCCESS
+                )
+                success_rate = (
+                    (success_count / len(recent_metrics) * 100) if recent_metrics else 0
+                )
 
                 # è¨ˆç®—å¹³å‡åŸ·è¡Œæ™‚é–“
                 completed_metrics = [m for m in metrics if m.duration > 0]
@@ -486,7 +529,9 @@ class CIMonitorDashboard:
                 )
 
                 # è¨ˆç®—æ´»èºæµæ°´ç·šæ•¸
-                active_count = sum(1 for m in metrics if m.status == PipelineStatus.RUNNING)
+                active_count = sum(
+                    1 for m in metrics if m.status == PipelineStatus.RUNNING
+                )
 
                 # è¨ˆç®—å®‰å…¨å•é¡Œç¸½æ•¸
                 security_issues = sum(m.security_issues for m in metrics)
@@ -502,7 +547,8 @@ class CIMonitorDashboard:
                 return [[], "0%", "0åˆ†é˜", "0", "0"]
 
         @self.app.callback(
-            Output("status-distribution-chart", "figure"), [Input("pipeline-data-store", "data")]
+            Output("status-distribution-chart", "figure"),
+            [Input("pipeline-data-store", "data")],
         )
         def update_status_distribution(data):
             """æ›´æ–°ç‹€æ…‹åˆ†ä½ˆåœ–"""
@@ -522,7 +568,13 @@ class CIMonitorDashboard:
                         labels=list(status_counts.keys()),
                         values=list(status_counts.values()),
                         hole=0.3,
-                        marker_colors=["#28a745", "#dc3545", "#ffc107", "#17a2b8", "#6c757d"],
+                        marker_colors=[
+                            "#28a745",
+                            "#dc3545",
+                            "#ffc107",
+                            "#17a2b8",
+                            "#6c757d",
+                        ],
                     )
                 ]
             )
@@ -534,7 +586,8 @@ class CIMonitorDashboard:
             return fig
 
         @self.app.callback(
-            Output("duration-trend-chart", "figure"), [Input("pipeline-data-store", "data")]
+            Output("duration-trend-chart", "figure"),
+            [Input("pipeline-data-store", "data")],
         )
         def update_duration_trend(data):
             """æ›´æ–°åŸ·è¡Œæ™‚é–“è¶¨å‹¢åœ–"""
@@ -583,7 +636,8 @@ class CIMonitorDashboard:
             return fig
 
         @self.app.callback(
-            Output("coverage-trend-chart", "figure"), [Input("pipeline-data-store", "data")]
+            Output("coverage-trend-chart", "figure"),
+            [Input("pipeline-data-store", "data")],
         )
         def update_coverage_trend(data):
             """æ›´æ–°æ¸¬è©¦è¦†è“‹ç‡è¶¨å‹¢"""
@@ -621,7 +675,9 @@ class CIMonitorDashboard:
             )
 
             # æ·»åŠ ç›®æ¨™ç·š
-            fig.add_hline(y=80, line_dash="dash", line_color="red", annotation_text="ç›®æ¨™: 80%")
+            fig.add_hline(
+                y=80, line_dash="dash", line_color="red", annotation_text="ç›®æ¨™: 80%"
+            )
 
             fig.update_layout(
                 title="æ¸¬è©¦è¦†è“‹ç‡è¶¨å‹¢",
@@ -636,7 +692,8 @@ class CIMonitorDashboard:
             return fig
 
         @self.app.callback(
-            Output("quality-score-chart", "figure"), [Input("pipeline-data-store", "data")]
+            Output("quality-score-chart", "figure"),
+            [Input("pipeline-data-store", "data")],
         )
         def update_quality_score(data):
             """æ›´æ–°ä»£ç¢¼å“è³ªè©•åˆ†åœ–"""
@@ -659,7 +716,8 @@ class CIMonitorDashboard:
 
             # è¨ˆç®—å¹³å‡å€¼
             avg_scores = {
-                name: sum(scores) / len(scores) for name, scores in pipeline_scores.items()
+                name: sum(scores) / len(scores)
+                for name, scores in pipeline_scores.items()
             }
 
             names = list(avg_scores.keys())
@@ -694,7 +752,8 @@ class CIMonitorDashboard:
             return fig
 
         @self.app.callback(
-            Output("pipeline-table-container", "children"), [Input("pipeline-data-store", "data")]
+            Output("pipeline-table-container", "children"),
+            [Input("pipeline-data-store", "data")],
         )
         def update_pipeline_table(data):
             """æ›´æ–°æµæ°´ç·šè¡¨æ ¼"""
@@ -702,7 +761,9 @@ class CIMonitorDashboard:
                 return html.P("æš«ç„¡æ•¸æ“š", className="text-center text-muted")
 
             # æŒ‰æ™‚é–“å€’åºæ’åˆ—
-            sorted_data = sorted(data, key=lambda x: x["timestamp"], reverse=True)[:10]  # æœ€è¿‘10æ¢
+            sorted_data = sorted(data, key=lambda x: x["timestamp"], reverse=True)[
+                :10
+            ]  # æœ€è¿‘10æ¢
 
             # å‰µå»ºè¡¨æ ¼æ•¸æ“š
             table_data = []
@@ -721,7 +782,9 @@ class CIMonitorDashboard:
                             else "-"
                         ),
                         html.Td(
-                            metric["security_issues"] if metric["security_issues"] > 0 else "-"
+                            metric["security_issues"]
+                            if metric["security_issues"] > 0
+                            else "-"
                         ),
                         html.Td(
                             datetime.fromisoformat(
@@ -814,7 +877,9 @@ def main():
     parser.add_argument("--host", default="0.0.0.0", help="ä¸»æ©Ÿåœ°å€")
     parser.add_argument("--port", type=int, default=8050, help="ç«¯å£è™Ÿ")
     parser.add_argument("--debug", action="store_true", help="èª¿è©¦æ¨¡å¼")
-    parser.add_argument("--config", default="config/ci-monitor-config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾‘")
+    parser.add_argument(
+        "--config", default="config/ci-monitor-config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾‘"
+    )
 
     args = parser.parse_args()
 
diff --git a/workspace/src/developer-tools/code-complexity-analyzer/complexity_analyzer.py b/workspace/src/developer-tools/code-complexity-analyzer/complexity_analyzer.py
index 2c599d5..b80ae16 100644
--- a/workspace/src/developer-tools/code-complexity-analyzer/complexity_analyzer.py
+++ b/workspace/src/developer-tools/code-complexity-analyzer/complexity_analyzer.py
@@ -113,9 +113,24 @@ class CodeComplexityAnalyzer:
             # é»˜èªé…ç½®
             return {
                 "thresholds": {
-                    "cyclomatic": {"low": 5, "moderate": 10, "high": 15, "very_high": 20},
-                    "cognitive": {"low": 8, "moderate": 15, "high": 25, "very_high": 40},
-                    "maintainability": {"excellent": 85, "good": 70, "moderate": 50, "poor": 30},
+                    "cyclomatic": {
+                        "low": 5,
+                        "moderate": 10,
+                        "high": 15,
+                        "very_high": 20,
+                    },
+                    "cognitive": {
+                        "low": 8,
+                        "moderate": 15,
+                        "high": 25,
+                        "very_high": 40,
+                    },
+                    "maintainability": {
+                        "excellent": 85,
+                        "good": 70,
+                        "moderate": 50,
+                        "poor": 30,
+                    },
                 },
                 "exclude_patterns": [
                     "test_*.py",
@@ -193,7 +208,9 @@ class CodeComplexityAnalyzer:
 
         return python_files
 
-    def _should_exclude_file(self, file_path: Path, exclude_patterns: List[str]) -> bool:
+    def _should_exclude_file(
+        self, file_path: Path, exclude_patterns: List[str]
+    ) -> bool:
         """åˆ¤æ–·æ–‡ä»¶æ˜¯å¦æ‡‰è©²è¢«æ’é™¤"""
         file_str = str(file_path)
 
@@ -222,20 +239,28 @@ class CodeComplexityAnalyzer:
         # åˆ†æå‡½æ•¸
         functions = []
         for func in cc_results:
-            function_complexity = self._analyze_function(func, file_path, content, halstead_results)
+            function_complexity = self._analyze_function(
+                func, file_path, content, halstead_results
+            )
             functions.append(function_complexity)
 
         # è¨ˆç®—æ–‡ä»¶ç´šåˆ¥æŒ‡æ¨™
         total_lines = len(content.splitlines())
         code_lines = lizard_result.nloc
-        comment_lines = len([line for line in content.splitlines() if line.strip().startswith("#")])
+        comment_lines = len(
+            [line for line in content.splitlines() if line.strip().startswith("#")]
+        )
         blank_lines = total_lines - code_lines - comment_lines
 
         # è¨ˆç®—å¹³å‡è¤‡é›œåº¦
-        avg_complexity = np.mean([f.cyclomatic_complexity for f in functions]) if functions else 0
+        avg_complexity = (
+            np.mean([f.cyclomatic_complexity for f in functions]) if functions else 0
+        )
 
         # ç²å–å¯ç¶­è­·æ€§æŒ‡æ•¸
-        maintainability_index = mi_results if isinstance(mi_results, (int, float)) else 70.0
+        maintainability_index = (
+            mi_results if isinstance(mi_results, (int, float)) else 70.0
+        )
 
         # è¨ˆç®—é¢¨éšªç­‰ç´š
         risk_level = self._calculate_file_risk_level(functions)
@@ -268,7 +293,9 @@ class CodeComplexityAnalyzer:
         halstead_metrics = self._get_halstead_metrics(func, halstead_results)
 
         # å¯ç¶­è­·æ€§æŒ‡æ•¸
-        maintainability = self._calculate_function_maintainability(func, halstead_metrics)
+        maintainability = self._calculate_function_maintainability(
+            func, halstead_metrics
+        )
 
         # ä»£ç¢¼è¡Œæ•¸
         lines_of_code = func.endlineno - func.lineno + 1
@@ -348,7 +375,9 @@ class CodeComplexityAnalyzer:
         # ç°¡åŒ–å¯¦ç¾
         return min(5, func.complexity // 3)
 
-    def _calculate_function_risk_level(self, cyclomatic: int, cognitive: int) -> RiskLevel:
+    def _calculate_function_risk_level(
+        self, cyclomatic: int, cognitive: int
+    ) -> RiskLevel:
         """è¨ˆç®—å‡½æ•¸é¢¨éšªç­‰ç´š"""
         thresholds = self.config["thresholds"]["cyclomatic"]
 
@@ -394,7 +423,9 @@ class CodeComplexityAnalyzer:
 
         return recommendations
 
-    def _calculate_file_risk_level(self, functions: List[FunctionComplexity]) -> RiskLevel:
+    def _calculate_file_risk_level(
+        self, functions: List[FunctionComplexity]
+    ) -> RiskLevel:
         """è¨ˆç®—æ–‡ä»¶é¢¨éšªç­‰ç´š"""
         if not functions:
             return RiskLevel.LOW
@@ -440,7 +471,9 @@ class CodeComplexityAnalyzer:
 
         # å¹³å‡è¤‡é›œåº¦
         avg_complexity = (
-            np.mean([f.cyclomatic_complexity for f in total_functions]) if total_functions else 0
+            np.mean([f.cyclomatic_complexity for f in total_functions])
+            if total_functions
+            else 0
         )
 
         # è¤‡é›œåº¦åˆ†ä½ˆ
@@ -454,7 +487,9 @@ class CodeComplexityAnalyzer:
         # æŠ€è¡“å‚µå‹™ç¸½çµ
         tech_debt_summary = {
             "total_hours": sum(f.technical_debt for f in file_complexities),
-            "files_with_debt": len([f for f in file_complexities if f.technical_debt > 0]),
+            "files_with_debt": len(
+                [f for f in file_complexities if f.technical_debt > 0]
+            ),
             "functions_requiring_refactor": len(
                 [
                     f
@@ -465,7 +500,9 @@ class CodeComplexityAnalyzer:
         }
 
         # é …ç›®å»ºè­°
-        recommendations = self._generate_project_recommendations(file_complexities, total_functions)
+        recommendations = self._generate_project_recommendations(
+            file_complexities, total_functions
+        )
 
         return ProjectComplexity(
             project_name=project_name,
@@ -492,23 +529,31 @@ class CodeComplexityAnalyzer:
         return distribution
 
     def _generate_project_recommendations(
-        self, file_complexities: List[FileComplexity], total_functions: List[FunctionComplexity]
+        self,
+        file_complexities: List[FileComplexity],
+        total_functions: List[FunctionComplexity],
     ) -> List[str]:
         """ç”Ÿæˆé …ç›®ç´šåˆ¥å»ºè­°"""
         recommendations = []
 
         # çµ±è¨ˆé«˜è¤‡é›œåº¦å‡½æ•¸
         high_complexity_funcs = [
-            f for f in total_functions if f.risk_level in [RiskLevel.HIGH, RiskLevel.VERY_HIGH]
+            f
+            for f in total_functions
+            if f.risk_level in [RiskLevel.HIGH, RiskLevel.VERY_HIGH]
         ]
 
-        if len(high_complexity_funcs) > len(total_functions) * 0.2:  # è¶…é20%çš„å‡½æ•¸æ˜¯é«˜è¤‡é›œåº¦
+        if (
+            len(high_complexity_funcs) > len(total_functions) * 0.2
+        ):  # è¶…é20%çš„å‡½æ•¸æ˜¯é«˜è¤‡é›œåº¦
             recommendations.append("é …ç›®ä¸­æœ‰å¤ªå¤šé«˜è¤‡é›œåº¦å‡½æ•¸ï¼Œå»ºè­°åˆ¶å®šé‡æ§‹è¨ˆåŠƒ")
 
         # çµ±è¨ˆæŠ€è¡“å‚µå‹™
         total_debt = sum(f.technical_debt for f in file_complexities)
         if total_debt > 40:  # è¶…é40å°æ™‚
-            recommendations.append(f"æŠ€è¡“å‚µå‹™éé«˜ï¼ˆ{total_debt:.1f}å°æ™‚ï¼‰ï¼Œéœ€è¦å„ªå…ˆè™•ç†")
+            recommendations.append(
+                f"æŠ€è¡“å‚µå‹™éé«˜ï¼ˆ{total_debt:.1f}å°æ™‚ï¼‰ï¼Œéœ€è¦å„ªå…ˆè™•ç†"
+            )
 
         # çµ±è¨ˆæ–‡ä»¶å¤§å°
         large_files = [f for f in file_complexities if f.total_lines > 500]
@@ -526,7 +571,8 @@ class CodeComplexityAnalyzer:
     def _save_historical_data(self, project_complexity: ProjectComplexity):
         """ä¿å­˜æ­·å²æ•¸æ“š"""
         historical_file = (
-            Path(self.config.get("output_directory", "reports/complexity")) / "historical_data.json"
+            Path(self.config.get("output_directory", "reports/complexity"))
+            / "historical_data.json"
         )
         historical_file.parent.mkdir(parents=True, exist_ok=True)
 
@@ -544,7 +590,9 @@ class CodeComplexityAnalyzer:
             "total_functions": project_complexity.total_functions,
             "average_complexity": project_complexity.average_complexity,
             "total_lines": project_complexity.total_lines,
-            "technical_debt_hours": project_complexity.technical_debt_summary["total_hours"],
+            "technical_debt_hours": project_complexity.technical_debt_summary[
+                "total_hours"
+            ],
         }
 
         historical_data.append(data_point)
@@ -559,7 +607,8 @@ class CodeComplexityAnalyzer:
     def _analyze_trends(self) -> List[Dict[str, Any]]:
         """åˆ†æè¶¨å‹¢"""
         historical_file = (
-            Path(self.config.get("output_directory", "reports/complexity")) / "historical_data.json"
+            Path(self.config.get("output_directory", "reports/complexity"))
+            / "historical_data.json"
         )
 
         if not historical_file.exists():
@@ -574,10 +623,17 @@ class CodeComplexityAnalyzer:
         trends = []
 
         # è¨ˆç®—å„é …æŒ‡æ¨™çš„è¶¨å‹¢
-        metrics = ["total_functions", "average_complexity", "total_lines", "technical_debt_hours"]
+        metrics = [
+            "total_functions",
+            "average_complexity",
+            "total_lines",
+            "technical_debt_hours",
+        ]
 
         for metric in metrics:
-            values = [point[metric] for point in historical_data[-10:]]  # æœ€è¿‘10å€‹æ•¸æ“šé»
+            values = [
+                point[metric] for point in historical_data[-10:]
+            ]  # æœ€è¿‘10å€‹æ•¸æ“šé»
 
             if len(values) >= 2:
                 # è¨ˆç®—è¶¨å‹¢ï¼ˆç°¡å–®ç·šæ€§å›æ­¸ï¼‰
@@ -606,13 +662,16 @@ class CodeComplexityAnalyzer:
     ) -> str:
         """ç”Ÿæˆè¤‡é›œåº¦åˆ†æå ±å‘Š"""
         # å‰µå»ºè¼¸å‡ºç›®éŒ„
-        output_dir = Path(output_path or self.config.get("output_directory", "reports/complexity"))
+        output_dir = Path(
+            output_path or self.config.get("output_directory", "reports/complexity")
+        )
         output_dir.mkdir(parents=True, exist_ok=True)
 
         # ç”Ÿæˆ HTML å ±å‘Š
         html_report = self._generate_html_report(project_complexity)
         html_file = (
-            output_dir / f"complexity_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
+            output_dir
+            / f"complexity_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
         )
 
         with open(html_file, "w", encoding="utf-8") as f:
@@ -620,14 +679,18 @@ class CodeComplexityAnalyzer:
 
         # ç”Ÿæˆ JSON å ±å‘Š
         json_report = asdict(project_complexity)
-        json_file = output_dir / f"complexity_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
+        json_file = (
+            output_dir
+            / f"complexity_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
+        )
 
         with open(json_file, "w", encoding="utf-8") as f:
             json.dump(json_report, f, indent=2, ensure_ascii=False, default=str)
 
         # ç”Ÿæˆ CSV å ±å‘Š
         csv_file = (
-            output_dir / f"complexity_functions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
+            output_dir
+            / f"complexity_functions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
         )
         self._generate_csv_report(project_complexity, csv_file)
 
@@ -829,7 +892,9 @@ class CodeComplexityAnalyzer:
             most_complex_files_rows=most_complex_files_rows,
         )
 
-    def _generate_csv_report(self, project_complexity: ProjectComplexity, csv_file: Path):
+    def _generate_csv_report(
+        self, project_complexity: ProjectComplexity, csv_file: Path
+    ):
         """ç”Ÿæˆ CSV æ ¼å¼çš„å ±å‘Š"""
         # é€™è£¡éœ€è¦æ”¶é›†æ‰€æœ‰å‡½æ•¸æ•¸æ“šä¸¦ç”Ÿæˆ CSV
         # ç°¡åŒ–å¯¦ç¾
@@ -865,7 +930,9 @@ def main():
     print(f"ç¸½æ–‡ä»¶: {project_complexity.total_files}")
     print(f"ç¸½å‡½æ•¸: {project_complexity.total_functions}")
     print(f"å¹³å‡è¤‡é›œåº¦: {project_complexity.average_complexity:.2f}")
-    print(f"æŠ€è¡“å‚µå‹™: {project_complexity.technical_debt_summary['total_hours']:.1f} å°æ™‚")
+    print(
+        f"æŠ€è¡“å‚µå‹™: {project_complexity.technical_debt_summary['total_hours']:.1f} å°æ™‚"
+    )
     print(f"å ±å‘Š: {report_path}")
 
 
diff --git a/workspace/src/developer-tools/deployment-risk-assessor/risk_assessor.py b/workspace/src/developer-tools/deployment-risk-assessor/risk_assessor.py
index 4903460..92ac528 100644
--- a/workspace/src/developer-tools/deployment-risk-assessor/risk_assessor.py
+++ b/workspace/src/developer-tools/deployment-risk-assessor/risk_assessor.py
@@ -107,9 +107,16 @@ class DeploymentRiskAssessor:
             return {
                 "github": {
                     "token": os.getenv("GITHUB_TOKEN"),
-                    "repo": os.getenv("GITHUB_REPO", "MachineNativeOps/MachineNativeOps"),
+                    "repo": os.getenv(
+                        "GITHUB_REPO", "MachineNativeOps/MachineNativeOps"
+                    ),
+                },
+                "risk_thresholds": {
+                    "low": 30,
+                    "medium": 60,
+                    "high": 80,
+                    "critical": 90,
                 },
-                "risk_thresholds": {"low": 30, "medium": 60, "high": 80, "critical": 90},
                 "risk_factors": {
                     "code_change_impact": 0.25,
                     "test_coverage": 0.20,
@@ -144,7 +151,9 @@ class DeploymentRiskAssessor:
 
         if not logger.handlers:
             handler = logging.StreamHandler()
-            formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
+            formatter = logging.Formatter(
+                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+            )
             handler.setFormatter(formatter)
             logger.addHandler(handler)
 
@@ -220,7 +229,9 @@ class DeploymentRiskAssessor:
         rollback_time = self._estimate_rollback_time(deployment_type, change_impact)
 
         # åˆ†æéƒ¨ç½²å½±éŸ¿
-        deployment_impact = self._analyze_deployment_impact(change_impact, deployment_type)
+        deployment_impact = self._analyze_deployment_impact(
+            change_impact, deployment_type
+        )
 
         # ç¢ºå®šæ˜¯å¦éœ€è¦å¯©æ‰¹
         approval_required = self._requires_approval(risk_level, overall_risk_score)
@@ -317,7 +328,10 @@ class DeploymentRiskAssessor:
 
                 # æª¢æŸ¥é…ç½®è®Šæ›´
                 for item in commit.stats.files:
-                    if any(ext in item.lower() for ext in [".yaml", ".yml", ".json", ".env"]):
+                    if any(
+                        ext in item.lower()
+                        for ext in [".yaml", ".yml", ".json", ".env"]
+                    ):
                         config_changes += 1
 
             # è©•ä¼°æ¸¬è©¦è¦†è“‹ç‡å½±éŸ¿ï¼ˆç°¡åŒ–å¯¦ç¾ï¼‰
@@ -405,7 +419,11 @@ class DeploymentRiskAssessor:
 
         recommendations = []
         if coverage_score < 60:
-            recommendations = ["å¢åŠ å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡", "æ·»åŠ é›†æˆæ¸¬è©¦", "ç¢ºä¿é—œéµè·¯å¾‘éƒ½æœ‰æ¸¬è©¦è¦†è“‹"]
+            recommendations = [
+                "å¢åŠ å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡",
+                "æ·»åŠ é›†æˆæ¸¬è©¦",
+                "ç¢ºä¿é—œéµè·¯å¾‘éƒ½æœ‰æ¸¬è©¦è¦†è“‹",
+            ]
         elif coverage_score < 80:
             recommendations = ["æé«˜é‚Šç•Œæ¢ä»¶æ¸¬è©¦è¦†è“‹", "æ·»åŠ ç•°å¸¸è™•ç†æ¸¬è©¦"]
 
@@ -431,7 +449,11 @@ class DeploymentRiskAssessor:
 
         recommendations = []
         if security_issues > 0:
-            recommendations = ["ä¿®å¾©å·²ç™¼ç¾çš„å®‰å…¨æ¼æ´", "é‹è¡Œå®Œæ•´çš„å®‰å…¨æƒæ", "å¯©æ¬Šé™å’Œèªè­‰é‚è¼¯"]
+            recommendations = [
+                "ä¿®å¾©å·²ç™¼ç¾çš„å®‰å…¨æ¼æ´",
+                "é‹è¡Œå®Œæ•´çš„å®‰å…¨æƒæ",
+                "å¯©æ¬Šé™å’Œèªè­‰é‚è¼¯",
+            ]
 
         impact_desc = "é«˜" if risk_value > 70 else "ä¸­" if risk_value > 40 else "ä½"
 
@@ -455,7 +477,11 @@ class DeploymentRiskAssessor:
 
         recommendations = []
         if performance_impact_score > 50:
-            recommendations = ["åŸ·è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦", "ç›£æ§é—œéµæ€§èƒ½æŒ‡æ¨™", "æº–å‚™æ€§èƒ½å›æ»¾æ–¹æ¡ˆ"]
+            recommendations = [
+                "åŸ·è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦",
+                "ç›£æ§é—œéµæ€§èƒ½æŒ‡æ¨™",
+                "æº–å‚™æ€§èƒ½å›æ»¾æ–¹æ¡ˆ",
+            ]
 
         impact_desc = "é«˜" if risk_value > 70 else "ä¸­" if risk_value > 40 else "ä½"
 
@@ -468,7 +494,9 @@ class DeploymentRiskAssessor:
             recommendations=recommendations,
         )
 
-    def _assess_deployment_complexity_risk(self, deployment_type: DeploymentType) -> RiskFactor:
+    def _assess_deployment_complexity_risk(
+        self, deployment_type: DeploymentType
+    ) -> RiskFactor:
         """è©•ä¼°éƒ¨ç½²è¤‡é›œåº¦é¢¨éšª"""
         weight = self.config["risk_factors"]["deployment_complexity"]
 
@@ -516,7 +544,11 @@ class DeploymentRiskAssessor:
 
         recommendations = []
         if environment.lower().startswith("production"):
-            recommendations = ["ç¢ºä¿å®Œæ•´çš„ç›£æ§è¦†è“‹", "æº–å‚™ç·Šæ€¥å›æ»¾ç¨‹åº", "å®‰æ’å€¼ç­äººå“¡ç›£æ§"]
+            recommendations = [
+                "ç¢ºä¿å®Œæ•´çš„ç›£æ§è¦†è“‹",
+                "æº–å‚™ç·Šæ€¥å›æ»¾ç¨‹åº",
+                "å®‰æ’å€¼ç­äººå“¡ç›£æ§",
+            ]
 
         impact_desc = "é«˜" if risk_value > 70 else "ä¸­" if risk_value > 40 else "ä½"
 
@@ -550,7 +582,9 @@ class DeploymentRiskAssessor:
         else:
             return RiskLevel.LOW
 
-    def _generate_mitigation_strategies(self, risk_factors: List[RiskFactor]) -> List[str]:
+    def _generate_mitigation_strategies(
+        self, risk_factors: List[RiskFactor]
+    ) -> List[str]:
         """ç”Ÿæˆç·©è§£ç­–ç•¥"""
         strategies = []
 
@@ -569,7 +603,9 @@ class DeploymentRiskAssessor:
         # å»é‡
         return list(set(strategies))
 
-    def _estimate_rollback_time(self, deployment_type: DeploymentType, impact: ChangeImpact) -> int:
+    def _estimate_rollback_time(
+        self, deployment_type: DeploymentType, impact: ChangeImpact
+    ) -> int:
         """ä¼°ç®—å›æ»¾æ™‚é–“ï¼ˆåˆ†é˜ï¼‰"""
         base_times = {
             DeploymentType.ROLLING: 15,
@@ -602,7 +638,9 @@ class DeploymentRiskAssessor:
                 DeploymentType.CANARY: 0,
                 DeploymentType.RECREATE: 5,
             }.get(deployment_type, 0),
-            "user_impact": "minimal" if deployment_type != DeploymentType.RECREATE else "full",
+            "user_impact": (
+                "minimal" if deployment_type != DeploymentType.RECREATE else "full"
+            ),
             "affected_services": impact.files_changed,  # ç°¡åŒ–
             "estimated_risk_users": "low" if impact.breaking_changes == 0 else "high",
         }
@@ -620,10 +658,13 @@ class DeploymentRiskAssessor:
     def _update_metrics(self, assessment: RiskAssessment):
         """æ›´æ–° Prometheus æŒ‡æ¨™"""
         self.risk_score_gauge.labels(
-            environment=assessment.environment, deployment_type=assessment.deployment_type.value
+            environment=assessment.environment,
+            deployment_type=assessment.deployment_type.value,
         ).set(assessment.risk_score)
 
-        self.assessment_counter.labels(risk_level=assessment.overall_risk_level.value).inc()
+        self.assessment_counter.labels(
+            risk_level=assessment.overall_risk_level.value
+        ).inc()
 
     def generate_risk_report(self, assessment: RiskAssessment) -> str:
         """ç”Ÿæˆé¢¨éšªè©•ä¼°å ±å‘Š"""
diff --git a/workspace/src/developer-tools/team-collaboration-platform/collaboration_hub.py b/workspace/src/developer-tools/team-collaboration-platform/collaboration_hub.py
index 0a8a490..9fb7206 100644
--- a/workspace/src/developer-tools/team-collaboration-platform/collaboration_hub.py
+++ b/workspace/src/developer-tools/team-collaboration-platform/collaboration_hub.py
@@ -147,7 +147,9 @@ class CollaborationHub:
                 },
                 "github": {
                     "token": os.getenv("GITHUB_TOKEN"),
-                    "repo": os.getenv("GITHUB_REPO", "MachineNativeOps/MachineNativeOps"),
+                    "repo": os.getenv(
+                        "GITHUB_REPO", "MachineNativeOps/MachineNativeOps"
+                    ),
                 },
                 "notifications": {
                     "email_enabled": False,
@@ -169,7 +171,9 @@ class CollaborationHub:
 
         if not logger.handlers:
             handler = logging.StreamHandler()
-            formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
+            formatter = logging.Formatter(
+                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+            )
             handler.setFormatter(formatter)
             logger.addHandler(handler)
 
@@ -495,7 +499,11 @@ class CollaborationHub:
 
     async def _broadcast_user_status(self, user_id: str, status: UserStatus):
         """å»£æ’­ç”¨æˆ¶ç‹€æ…‹è®Šæ›´"""
-        status_data = {"type": "user_status", "user_id": user_id, "status": status.value}
+        status_data = {
+            "type": "user_status",
+            "user_id": user_id,
+            "status": status.value,
+        }
 
         await self._broadcast_to_all(status_data)
 
@@ -529,7 +537,10 @@ class CollaborationHub:
             if self.redis_client:
                 self.redis_client.hset(
                     f"user:{user_id}",
-                    mapping={"status": status.value, "last_seen": datetime.now().isoformat()},
+                    mapping={
+                        "status": status.value,
+                        "last_seen": datetime.now().isoformat(),
+                    },
                 )
 
             await self._broadcast_user_status(user_id, status)
@@ -540,7 +551,10 @@ class CollaborationHub:
         websocket = self.connected_websockets.get(notification.user_id)
         if websocket:
             try:
-                notification_data = {"type": "notification", "notification": asdict(notification)}
+                notification_data = {
+                    "type": "notification",
+                    "notification": asdict(notification),
+                }
                 await websocket.send_text(json.dumps(notification_data))
             except Exception as e:
                 self.logger.error(f"ç™¼é€é€šçŸ¥å¤±æ•—: {e}")
@@ -560,7 +574,9 @@ class CollaborationHub:
         if teams_webhook:
             await self._send_teams_notification(notification, teams_webhook)
 
-    async def _send_slack_notification(self, notification: Notification, webhook_url: str):
+    async def _send_slack_notification(
+        self, notification: Notification, webhook_url: str
+    ):
         """ç™¼é€ Slack é€šçŸ¥"""
         async with aiohttp.ClientSession() as session:
             payload = {
@@ -580,7 +596,9 @@ class CollaborationHub:
             except Exception as e:
                 self.logger.error(f"Slack é€šçŸ¥ç™¼é€ç•°å¸¸: {e}")
 
-    async def _send_teams_notification(self, notification: Notification, webhook_url: str):
+    async def _send_teams_notification(
+        self, notification: Notification, webhook_url: str
+    ):
         """ç™¼é€ Teams é€šçŸ¥"""
         async with aiohttp.ClientSession() as session:
             payload = {
diff --git a/workspace/src/enterprise/data/audit.py b/workspace/src/enterprise/data/audit.py
index edecff4..8bd598a 100644
--- a/workspace/src/enterprise/data/audit.py
+++ b/workspace/src/enterprise/data/audit.py
@@ -588,7 +588,9 @@ class AuditLogger:
             key_lower = key.lower()
 
             # Check if field is sensitive
-            is_sensitive = any(pattern in key_lower for pattern in self.sensitive_fields)
+            is_sensitive = any(
+                pattern in key_lower for pattern in self.sensitive_fields
+            )
 
             if is_sensitive:
                 if isinstance(value, str):
diff --git a/workspace/src/enterprise/iam/sso.py b/workspace/src/enterprise/iam/sso.py
index 5d8849a..7c25ae1 100644
--- a/workspace/src/enterprise/iam/sso.py
+++ b/workspace/src/enterprise/iam/sso.py
@@ -16,14 +16,13 @@ from urllib.parse import urlencode, urlparse
 from uuid import UUID
 
 import jwt as pyjwt
-from jwt import PyJWKClient
-
 from enterprise.iam.models import (
     Membership,
     Role,
     SSOConfig,
     User,
 )
+from jwt import PyJWKClient
 
 logger = logging.getLogger(__name__)
 
diff --git a/workspace/src/frontend/ui/services/models.py b/workspace/src/frontend/ui/services/models.py
index fa13b21..e68706e 100644
--- a/workspace/src/frontend/ui/services/models.py
+++ b/workspace/src/frontend/ui/services/models.py
@@ -8,18 +8,16 @@
 ============================================================================
 """
 
-from sqlalchemy.orm import Session, sessionmaker
-from sqlalchemy import create_engine
-from contextlib import contextmanager
 import enum
+from contextlib import contextmanager
 from datetime import datetime
 from typing import Any, Dict, List, Optional
 
 from sqlalchemy import JSON, Column, DateTime
 from sqlalchemy import Enum as SQLEnum
-from sqlalchemy import Float, ForeignKey, Index, Integer, String, Text
+from sqlalchemy import Float, ForeignKey, Index, Integer, String, Text, create_engine
 from sqlalchemy.ext.declarative import declarative_base
-from sqlalchemy.orm import relationship
+from sqlalchemy.orm import Session, relationship, sessionmaker
 
 Base = declarative_base()
 
diff --git a/workspace/src/frontend/ui/tests/test_code_analyzer.py b/workspace/src/frontend/ui/tests/test_code_analyzer.py
index 4ba6a91..60b0ba7 100644
--- a/workspace/src/frontend/ui/tests/test_code_analyzer.py
+++ b/workspace/src/frontend/ui/tests/test_code_analyzer.py
@@ -10,6 +10,11 @@ Version: 2.0.0
 ============================================================================
 """
 
+import sys
+from datetime import datetime
+from pathlib import Path
+
+import pytest
 from services.code_analyzer import (
     AnalysisResult,
     AnalysisStrategy,
@@ -22,11 +27,6 @@ from services.code_analyzer import (
     SeverityLevel,
     StaticAnalyzer,
 )
-import sys
-from datetime import datetime
-from pathlib import Path
-
-import pytest
 
 # Add parent directory to path for imports
 sys.path.insert(0, str(Path(__file__).parent.parent))
diff --git a/workspace/src/governance/01-architecture/automation_engine.py b/workspace/src/governance/01-architecture/automation_engine.py
index 1f35c58..2e6875e 100644
--- a/workspace/src/governance/01-architecture/automation_engine.py
+++ b/workspace/src/governance/01-architecture/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/02-decision/automation_engine.py b/workspace/src/governance/02-decision/automation_engine.py
index 1e0bd86..7ef8b43 100644
--- a/workspace/src/governance/02-decision/automation_engine.py
+++ b/workspace/src/governance/02-decision/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/03-change/automation_engine.py b/workspace/src/governance/03-change/automation_engine.py
index 8cc6422..d434cbf 100644
--- a/workspace/src/governance/03-change/automation_engine.py
+++ b/workspace/src/governance/03-change/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/04-risk/automation_engine.py b/workspace/src/governance/04-risk/automation_engine.py
index 88a3191..7db296e 100644
--- a/workspace/src/governance/04-risk/automation_engine.py
+++ b/workspace/src/governance/04-risk/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/05-compliance/automation_engine.py b/workspace/src/governance/05-compliance/automation_engine.py
index 8ff3f56..5689b7b 100644
--- a/workspace/src/governance/05-compliance/automation_engine.py
+++ b/workspace/src/governance/05-compliance/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/06-security/automation_engine.py b/workspace/src/governance/06-security/automation_engine.py
index c84f7c1..9f5e9da 100644
--- a/workspace/src/governance/06-security/automation_engine.py
+++ b/workspace/src/governance/06-security/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/07-audit/automation_engine.py b/workspace/src/governance/07-audit/automation_engine.py
index 644b149..aa25d70 100644
--- a/workspace/src/governance/07-audit/automation_engine.py
+++ b/workspace/src/governance/07-audit/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/08-process/automation_engine.py b/workspace/src/governance/08-process/automation_engine.py
index 4631348..6871e5f 100644
--- a/workspace/src/governance/08-process/automation_engine.py
+++ b/workspace/src/governance/08-process/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/09-performance/automation_engine.py b/workspace/src/governance/09-performance/automation_engine.py
index bfb3e20..8297daf 100644
--- a/workspace/src/governance/09-performance/automation_engine.py
+++ b/workspace/src/governance/09-performance/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/11-tools-systems/automation_engine.py b/workspace/src/governance/11-tools-systems/automation_engine.py
index 2dab900..a6b512f 100644
--- a/workspace/src/governance/11-tools-systems/automation_engine.py
+++ b/workspace/src/governance/11-tools-systems/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/12-culture-capability/automation_engine.py b/workspace/src/governance/12-culture-capability/automation_engine.py
index 5c49efa..998a085 100644
--- a/workspace/src/governance/12-culture-capability/automation_engine.py
+++ b/workspace/src/governance/12-culture-capability/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/13-metrics-reporting/automation_engine.py b/workspace/src/governance/13-metrics-reporting/automation_engine.py
index 8e66585..80edfd5 100644
--- a/workspace/src/governance/13-metrics-reporting/automation_engine.py
+++ b/workspace/src/governance/13-metrics-reporting/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/14-improvement/automation_engine.py b/workspace/src/governance/14-improvement/automation_engine.py
index e5c99cb..017becc 100644
--- a/workspace/src/governance/14-improvement/automation_engine.py
+++ b/workspace/src/governance/14-improvement/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/governance/dimensions/82-stakeholder/automation_engine.py b/workspace/src/governance/dimensions/82-stakeholder/automation_engine.py
index 719356c..2ed6af2 100644
--- a/workspace/src/governance/dimensions/82-stakeholder/automation_engine.py
+++ b/workspace/src/governance/dimensions/82-stakeholder/automation_engine.py
@@ -9,15 +9,16 @@
 governance automation launcher.
 """
 
+import sys
+from pathlib import Path
+from typing import Any, Dict
+
 from engines import (
     DimensionAutomationEngine,
     DimensionTask,
     TaskType,
     create_dimension_engine,
 )
-import sys
-from pathlib import Path
-from typing import Any, Dict
 
 # Add parent to path for imports
 automation_dir = Path(__file__).parent.parent
diff --git a/workspace/src/quantum/repositories/workflow_repository.py b/workspace/src/quantum/repositories/workflow_repository.py
index 490d7fe..173f176 100644
--- a/workspace/src/quantum/repositories/workflow_repository.py
+++ b/workspace/src/quantum/repositories/workflow_repository.py
@@ -10,7 +10,13 @@ from pathlib import Path
 from typing import List, Optional
 
 from backend.python.config import get_settings
-from backend.python.core.entities import Task, TaskStatus, TaskType, Workflow, WorkflowStatus
+from backend.python.core.entities import (
+    Task,
+    TaskStatus,
+    TaskType,
+    Workflow,
+    WorkflowStatus,
+)
 from backend.python.core.exceptions import DatabaseError
 from backend.python.core.logging_config import get_logger
 
diff --git a/workspace/src/quantum/use_cases/workflow_use_cases.py b/workspace/src/quantum/use_cases/workflow_use_cases.py
index 9293153..9a36536 100644
--- a/workspace/src/quantum/use_cases/workflow_use_cases.py
+++ b/workspace/src/quantum/use_cases/workflow_use_cases.py
@@ -6,8 +6,18 @@ Implements application-specific business logic.
 from datetime import datetime
 from typing import List, Optional
 
-from backend.python.core.entities import Task, TaskStatus, TaskType, Workflow, WorkflowStatus
-from backend.python.core.exceptions import TaskExecutionError, ValidationError, WorkflowError
+from backend.python.core.entities import (
+    Task,
+    TaskStatus,
+    TaskType,
+    Workflow,
+    WorkflowStatus,
+)
+from backend.python.core.exceptions import (
+    TaskExecutionError,
+    ValidationError,
+    WorkflowError,
+)
 from backend.python.core.logging_config import get_logger
 
 logger = get_logger(__name__)
diff --git a/workspace/src/services/agents/dependency-manager/src/crossplatform/__init__.py b/workspace/src/services/agents/dependency-manager/src/crossplatform/__init__.py
index 2066e5b..bd1da89 100644
--- a/workspace/src/services/agents/dependency-manager/src/crossplatform/__init__.py
+++ b/workspace/src/services/agents/dependency-manager/src/crossplatform/__init__.py
@@ -5,12 +5,27 @@ Cross-platform Integration Module
 Phase 9: Web3ã€IoTã€AR/VR æ•´åˆä»¥åŠé¢¨éšªç®¡æ§ç³»çµ±
 """
 
-from .arvr_integration import ARVRIntegration, ImmersiveExperience, MetaversePlatform, MixedReality
+from .arvr_integration import (
+    ARVRIntegration,
+    ImmersiveExperience,
+    MetaversePlatform,
+    MixedReality,
+)
 from .emergency_response import EmergencyResponse, PlanType, TriggerCondition
-from .iot_integration import DeviceInterconnection, EdgeComputing, Industry40, IoTIntegration
+from .iot_integration import (
+    DeviceInterconnection,
+    EdgeComputing,
+    Industry40,
+    IoTIntegration,
+)
 from .risk_assessment import MitigationStrategy, RiskAssessment, RiskCategory
 from .tech_stack_matrix import StackRecommendation, TechStackMatrix
-from .web3_integration import DAppAssessment, NFTStrategy, SmartContractDev, Web3Integration
+from .web3_integration import (
+    DAppAssessment,
+    NFTStrategy,
+    SmartContractDev,
+    Web3Integration,
+)
 
 __all__ = [
     "Web3Integration",
diff --git a/workspace/src/services/agents/dependency-manager/src/strategy/__init__.py b/workspace/src/services/agents/dependency-manager/src/strategy/__init__.py
index 77758f8..df07281 100644
--- a/workspace/src/services/agents/dependency-manager/src/strategy/__init__.py
+++ b/workspace/src/services/agents/dependency-manager/src/strategy/__init__.py
@@ -12,7 +12,12 @@ MIT License
 """
 
 from .case_study_engine import CaseStudy, CaseStudyEngine, EvolutionPhase, LessonLearned
-from .evolution_tracker import EvolutionTracker, MaturityLevel, PhaseTransition, ProjectMaturity
+from .evolution_tracker import (
+    EvolutionTracker,
+    MaturityLevel,
+    PhaseTransition,
+    ProjectMaturity,
+)
 from .resource_optimizer import (
     BudgetAllocation,
     OptimizationResult,
diff --git a/workspace/src/services/agents/dependency-manager/tests/test_models.py b/workspace/src/services/agents/dependency-manager/tests/test_models.py
index 91de417..d8a4d21 100644
--- a/workspace/src/services/agents/dependency-manager/tests/test_models.py
+++ b/workspace/src/services/agents/dependency-manager/tests/test_models.py
@@ -3,13 +3,13 @@
 Tests for Dependency Manager Agent
 """
 
-from models.vulnerability import Vulnerability, VulnerabilitySeverity
-from models.update import Update, UpdateResult, UpdateStatus, UpdateType
-from models.dependency import Dependency, DependencyAnalysis, DependencyType, Ecosystem
 import sys
 from pathlib import Path
 
 import pytest
+from models.dependency import Dependency, DependencyAnalysis, DependencyType, Ecosystem
+from models.update import Update, UpdateResult, UpdateStatus, UpdateType
+from models.vulnerability import Vulnerability, VulnerabilitySeverity
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
diff --git a/workspace/src/services/agents/dependency-manager/tests/test_phase10.py b/workspace/src/services/agents/dependency-manager/tests/test_phase10.py
index a483c2e..5e471dd 100644
--- a/workspace/src/services/agents/dependency-manager/tests/test_phase10.py
+++ b/workspace/src/services/agents/dependency-manager/tests/test_phase10.py
@@ -310,7 +310,11 @@ class TestActionGuide(unittest.TestCase):
 
     def test_recommendation_creation(self):
         """æ¸¬è©¦å»ºè­°å‰µå»º"""
-        from implementation.action_guide import ActionPriority, Recommendation, RecommendationType
+        from implementation.action_guide import (
+            ActionPriority,
+            Recommendation,
+            RecommendationType,
+        )
 
         rec = Recommendation(
             id="rec_1",
diff --git a/workspace/src/services/agents/dependency-manager/tests/test_phase2.py b/workspace/src/services/agents/dependency-manager/tests/test_phase2.py
index 9a893e6..f87856c 100644
--- a/workspace/src/services/agents/dependency-manager/tests/test_phase2.py
+++ b/workspace/src/services/agents/dependency-manager/tests/test_phase2.py
@@ -3,17 +3,17 @@
 Phase 2 Tests - Analyzers and Utils
 """
 
-from utils.dependency_tree import DependencyTree, RiskLevel
-from utils.audit_logger import AuditEventType, AuditLogger, AuditSeverity
-from models.dependency import Dependency, DependencyType, Ecosystem
-from analyzers.pip_analyzer import PipAnalyzer
-from analyzers.go_analyzer import GoAnalyzer
 import os
 import sys
 import tempfile
 from pathlib import Path
 
 import pytest
+from analyzers.go_analyzer import GoAnalyzer
+from analyzers.pip_analyzer import PipAnalyzer
+from models.dependency import Dependency, DependencyType, Ecosystem
+from utils.audit_logger import AuditEventType, AuditLogger, AuditSeverity
+from utils.dependency_tree import DependencyTree, RiskLevel
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
diff --git a/workspace/src/services/agents/dependency-manager/tests/test_phase3.py b/workspace/src/services/agents/dependency-manager/tests/test_phase3.py
index 6696a83..fc0ef90 100644
--- a/workspace/src/services/agents/dependency-manager/tests/test_phase3.py
+++ b/workspace/src/services/agents/dependency-manager/tests/test_phase3.py
@@ -3,12 +3,12 @@
 Phase 3 Tests - Policy Simulator and Language Boundary
 """
 
-from utils.policy_simulator import (
-    PolicySimulator,
-    SimulationMode,
-    SimulationResult,
-    SimulationScenario,
-)
+import sys
+from pathlib import Path
+
+import pytest
+from models.dependency import Dependency, DependencyAnalysis, DependencyType, Ecosystem
+from models.update import UpdatePolicy
 from utils.language_boundary import (
     LanguageBoundary,
     LanguageRegistry,
@@ -17,12 +17,12 @@ from utils.language_boundary import (
     msg,
     t,
 )
-from models.update import UpdatePolicy
-from models.dependency import Dependency, DependencyAnalysis, DependencyType, Ecosystem
-import sys
-from pathlib import Path
-
-import pytest
+from utils.policy_simulator import (
+    PolicySimulator,
+    SimulationMode,
+    SimulationResult,
+    SimulationScenario,
+)
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
diff --git a/workspace/src/services/agents/dependency-manager/tests/test_phase4.py b/workspace/src/services/agents/dependency-manager/tests/test_phase4.py
index 2c49e48..76440e4 100644
--- a/workspace/src/services/agents/dependency-manager/tests/test_phase4.py
+++ b/workspace/src/services/agents/dependency-manager/tests/test_phase4.py
@@ -8,17 +8,15 @@ Phase 4 ä¼æ¥­ç´šåŠŸèƒ½å–®å…ƒæ¸¬è©¦
 - ä¸‹ä¸–ä»£å®‰å…¨æ¨¡çµ„
 """
 
-from enterprise.security import (
-    ComplianceFramework,
-    NextGenSecurity,
-    SBOMFormat,
-    SupplyChainRisk,
-    TrustLevel,
-)
-from enterprise.recommendation import (
-    IntelligentRecommendation,
-    RecommendationType,
-    RiskLevel,
+import os
+import sys
+import unittest
+
+from enterprise.analytics import (
+    CommercialAnalytics,
+    CostCategory,
+    TechDebtItem,
+    TechDebtType,
 )
 from enterprise.integration import (
     AuthMethod,
@@ -27,15 +25,18 @@ from enterprise.integration import (
     IntegrationType,
     WebhookEvent,
 )
-from enterprise.analytics import (
-    CommercialAnalytics,
-    CostCategory,
-    TechDebtItem,
-    TechDebtType,
+from enterprise.recommendation import (
+    IntelligentRecommendation,
+    RecommendationType,
+    RiskLevel,
+)
+from enterprise.security import (
+    ComplianceFramework,
+    NextGenSecurity,
+    SBOMFormat,
+    SupplyChainRisk,
+    TrustLevel,
 )
-import os
-import sys
-import unittest
 
 # æ·»åŠ è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
diff --git a/workspace/src/services/agents/dependency-manager/tests/test_phase5.py b/workspace/src/services/agents/dependency-manager/tests/test_phase5.py
index 0cc0cad..0aadb8c 100644
--- a/workspace/src/services/agents/dependency-manager/tests/test_phase5.py
+++ b/workspace/src/services/agents/dependency-manager/tests/test_phase5.py
@@ -11,22 +11,19 @@ Copyright (c) 2024 SynergyMesh
 MIT License
 """
 
-from strategy.strategy_advisor import (
-    CapabilityLevel,
-    MarketMaturity,
-    MarketTimingAnalysis,
-    StrategicPriority,
-    StrategyAdvisor,
-    StrategyRecommendation,
-    TechCapability,
-    TechCapabilityAssessment,
-)
-from strategy.resource_optimizer import (
-    AllocationStrategy,
-    BudgetAllocation,
-    OptimizationResult,
-    ResourceOptimizer,
-    TeamAllocation,
+import os
+
+# æ¨¡æ“¬å°å…¥ï¼ˆæ¸¬è©¦æ™‚éœ€è¦ç¢ºä¿è·¯å¾‘æ­£ç¢ºï¼‰
+import sys
+import unittest
+from datetime import datetime
+
+from strategy.case_study_engine import (
+    CaseStudy,
+    CaseStudyEngine,
+    DevelopmentStrategy,
+    EvolutionPhase,
+    PhaseType,
 )
 from strategy.evolution_tracker import (
     DevelopmentPhase,
@@ -36,19 +33,23 @@ from strategy.evolution_tracker import (
     PhaseTransition,
     ProjectMaturity,
 )
-from strategy.case_study_engine import (
-    CaseStudy,
-    CaseStudyEngine,
-    DevelopmentStrategy,
-    EvolutionPhase,
-    PhaseType,
+from strategy.resource_optimizer import (
+    AllocationStrategy,
+    BudgetAllocation,
+    OptimizationResult,
+    ResourceOptimizer,
+    TeamAllocation,
+)
+from strategy.strategy_advisor import (
+    CapabilityLevel,
+    MarketMaturity,
+    MarketTimingAnalysis,
+    StrategicPriority,
+    StrategyAdvisor,
+    StrategyRecommendation,
+    TechCapability,
+    TechCapabilityAssessment,
 )
-import os
-
-# æ¨¡æ“¬å°å…¥ï¼ˆæ¸¬è©¦æ™‚éœ€è¦ç¢ºä¿è·¯å¾‘æ­£ç¢ºï¼‰
-import sys
-import unittest
-from datetime import datetime
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
diff --git a/workspace/src/services/agents/dependency-manager/tests/test_phase7.py b/workspace/src/services/agents/dependency-manager/tests/test_phase7.py
index 668197b..d619b03 100644
--- a/workspace/src/services/agents/dependency-manager/tests/test_phase7.py
+++ b/workspace/src/services/agents/dependency-manager/tests/test_phase7.py
@@ -4,7 +4,11 @@ Phase 7 æ¸¬è©¦ - SMART-V è©•ä¼°æ¡†æ¶
 æ¸¬è©¦ SMART-V é‡åŒ–è©•ä¼°ç³»çµ±çš„å„é …åŠŸèƒ½ã€‚
 """
 
-from evaluation.weight_config import CompanyStage, WeightConfigManager
+import os
+import sys
+import unittest
+
+from evaluation.evaluation_report import EvaluationReportGenerator
 from evaluation.smartv_framework import (
     AchievabilityEvaluator,
     EvaluationDimension,
@@ -15,10 +19,7 @@ from evaluation.smartv_framework import (
     TechnologyMaturityEvaluator,
     ValueCreationEvaluator,
 )
-from evaluation.evaluation_report import EvaluationReportGenerator
-import os
-import sys
-import unittest
+from evaluation.weight_config import CompanyStage, WeightConfigManager
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
diff --git a/workspace/src/services/agents/dependency-manager/tests/test_phase8.py b/workspace/src/services/agents/dependency-manager/tests/test_phase8.py
index 2ab81a3..7c66c93 100644
--- a/workspace/src/services/agents/dependency-manager/tests/test_phase8.py
+++ b/workspace/src/services/agents/dependency-manager/tests/test_phase8.py
@@ -3,25 +3,26 @@ Phase 8 å–®å…ƒæ¸¬è©¦
 Tests for Advanced Prompt Combination Strategy Modules
 """
 
-from combination.quarterly_review import (
-    QuarterlyReviewEngine,
-    ReviewCategory,
-    ReviewStatus,
+import sys
+import unittest
+from pathlib import Path
+
+from combination.combination_templates import (
+    CombinationTemplateManager,
+    CompanyStage,
+)
+from combination.core_satellite import (
+    CoreSatelliteArchitecture,
 )
 from combination.dynamic_adjuster import (
     AdjustmentTrigger,
     DynamicAdjuster,
 )
-from combination.core_satellite import (
-    CoreSatelliteArchitecture,
-)
-from combination.combination_templates import (
-    CombinationTemplateManager,
-    CompanyStage,
+from combination.quarterly_review import (
+    QuarterlyReviewEngine,
+    ReviewCategory,
+    ReviewStatus,
 )
-import sys
-import unittest
-from pathlib import Path
 
 sys.path.insert(0, str(Path(__file__).resolve().parents[1] / "src"))
 
diff --git a/workspace/src/services/agents/dependency-manager/tests/test_phase9.py b/workspace/src/services/agents/dependency-manager/tests/test_phase9.py
index 62ee387..0ab6faa 100644
--- a/workspace/src/services/agents/dependency-manager/tests/test_phase9.py
+++ b/workspace/src/services/agents/dependency-manager/tests/test_phase9.py
@@ -3,23 +3,24 @@ Phase 9 å–®å…ƒæ¸¬è©¦
 Cross-platform Integration & Risk Management Tests
 """
 
-from crossplatform.web3_integration import (
-    BlockchainType,
-    ConsensusType,
-    DAppAssessment,
-    NFTAssetType,
-    NFTStrategy,
-    SmartContractDev,
-    Web3Integration,
+import os
+import sys
+import unittest
+
+from crossplatform.arvr_integration import (
+    ARVRIntegration,
+    HardwareRequirement,
+    ImmersiveExperience,
+    InteractionMode,
+    MetaversePlatform,
+    MixedReality,
+    XRType,
 )
-from crossplatform.tech_stack_matrix import (
-    BackendArch,
-    DataProcessing,
-    DeploymentStrategy,
-    FrontendTech,
-    TechStackMatrix,
+from crossplatform.emergency_response import (
+    EmergencyResponse,
+    PlanType,
+    TriggerCategory,
 )
-from crossplatform.risk_assessment import RiskAssessment, RiskCategory, RiskType
 from crossplatform.iot_integration import (
     DeviceInterconnection,
     EdgeComputing,
@@ -29,23 +30,23 @@ from crossplatform.iot_integration import (
     IoTIntegration,
     IoTProtocol,
 )
-from crossplatform.emergency_response import (
-    EmergencyResponse,
-    PlanType,
-    TriggerCategory,
+from crossplatform.risk_assessment import RiskAssessment, RiskCategory, RiskType
+from crossplatform.tech_stack_matrix import (
+    BackendArch,
+    DataProcessing,
+    DeploymentStrategy,
+    FrontendTech,
+    TechStackMatrix,
 )
-from crossplatform.arvr_integration import (
-    ARVRIntegration,
-    HardwareRequirement,
-    ImmersiveExperience,
-    InteractionMode,
-    MetaversePlatform,
-    MixedReality,
-    XRType,
+from crossplatform.web3_integration import (
+    BlockchainType,
+    ConsensusType,
+    DAppAssessment,
+    NFTAssetType,
+    NFTStrategy,
+    SmartContractDev,
+    Web3Integration,
 )
-import os
-import sys
-import unittest
 
 # æ·»åŠ è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
diff --git a/workspace/src/shared/__init__.py b/workspace/src/shared/__init__.py
index 2d37cb7..31f55a1 100644
--- a/workspace/src/shared/__init__.py
+++ b/workspace/src/shared/__init__.py
@@ -8,7 +8,13 @@ __version__ = "1.0.0"
 __author__ = "SynergyMesh Team"
 
 from .config import BaseConfig
-from .constants import BRIDGE_PROTOCOLS, ISLAND_TYPES, SUPPORTED_MODES, SYSTEM_NAME, VERSION
+from .constants import (
+    BRIDGE_PROTOCOLS,
+    ISLAND_TYPES,
+    SUPPORTED_MODES,
+    SYSTEM_NAME,
+    VERSION,
+)
 from .utils import (
     Colors,
     get_project_root,
diff --git a/workspace/src/tests/automation/test_self_awareness_security.py b/workspace/src/tests/automation/test_self_awareness_security.py
index d9fd48a..a2bd304 100644
--- a/workspace/src/tests/automation/test_self_awareness_security.py
+++ b/workspace/src/tests/automation/test_self_awareness_security.py
@@ -1,17 +1,17 @@
 #!/usr/bin/env python3
 """Security tests for self_awareness_report.py command injection prevention."""
 
+import os
+import sys
+from pathlib import Path
+
+import pytest
 from self_awareness_report import (
     COMMAND_TIMEOUT,
     AutomationResult,
     _run_command_summary,
     _validate_command,
 )
-import os
-import sys
-from pathlib import Path
-
-import pytest
 
 # Add automation directory to path for imports
 sys.path.insert(0, str(Path(__file__).parent.parent.parent / "automation"))
diff --git a/workspace/src/tests/integration/test_recovery_system.py b/workspace/src/tests/integration/test_recovery_system.py
index 6d6a252..9e8c7e2 100644
--- a/workspace/src/tests/integration/test_recovery_system.py
+++ b/workspace/src/tests/integration/test_recovery_system.py
@@ -22,7 +22,10 @@ class TestRecoverySystemIntegration(unittest.TestCase):
     def test_phoenix_agent_import(self):
         """Test that Phoenix Agent can be imported"""
         try:
-            from services.agents.recovery.phoenix_agent import OperatingMode, PhoenixAgent
+            from services.agents.recovery.phoenix_agent import (
+                OperatingMode,
+                PhoenixAgent,
+            )
 
             self.assertTrue(True)
         except ImportError as e:
@@ -50,7 +53,10 @@ class TestRecoverySystemIntegration(unittest.TestCase):
     def test_phoenix_agent_creation(self):
         """Test creating Phoenix Agent instance"""
         try:
-            from services.agents.recovery.phoenix_agent import OperatingMode, PhoenixAgent
+            from services.agents.recovery.phoenix_agent import (
+                OperatingMode,
+                PhoenixAgent,
+            )
 
             agent = PhoenixAgent(mode=OperatingMode.MANUAL)
             self.assertIsNotNone(agent)
@@ -98,7 +104,10 @@ class TestRecoverySystemIntegration(unittest.TestCase):
     def test_phoenix_agent_status(self):
         """Test getting Phoenix Agent status"""
         try:
-            from services.agents.recovery.phoenix_agent import OperatingMode, PhoenixAgent
+            from services.agents.recovery.phoenix_agent import (
+                OperatingMode,
+                PhoenixAgent,
+            )
 
             agent = PhoenixAgent(mode=OperatingMode.MANUAL)
             status = agent.get_status()
@@ -128,7 +137,10 @@ class TestRecoverySystemAsync(unittest.IsolatedAsyncioTestCase):
     async def test_phoenix_start_stop(self):
         """Test starting and stopping Phoenix Agent"""
         try:
-            from services.agents.recovery.phoenix_agent import OperatingMode, PhoenixAgent
+            from services.agents.recovery.phoenix_agent import (
+                OperatingMode,
+                PhoenixAgent,
+            )
 
             agent = PhoenixAgent(mode=OperatingMode.MANUAL)
 
diff --git a/workspace/src/tests/integration/test_workflow_system.py b/workspace/src/tests/integration/test_workflow_system.py
index ff5c5bf..e11af74 100644
--- a/workspace/src/tests/integration/test_workflow_system.py
+++ b/workspace/src/tests/integration/test_workflow_system.py
@@ -1,7 +1,6 @@
 #!/usr/bin/env python3
 """Integration tests for workflow system"""
 import pytest
-
 from core.contract_engine import ContractEngine
 
 
diff --git a/workspace/src/tests/unit/phases/test_phase19_mcp_servers.py b/workspace/src/tests/unit/phases/test_phase19_mcp_servers.py
index b02c021..f459a36 100644
--- a/workspace/src/tests/unit/phases/test_phase19_mcp_servers.py
+++ b/workspace/src/tests/unit/phases/test_phase19_mcp_servers.py
@@ -2,6 +2,11 @@
 Tests for Phase 19: MCP Servers Enhanced Integration
 """
 
+import asyncio
+import os
+import sys
+
+import pytest
 from mcp_servers_enhanced import (
     ConnectionConfig,
     MCPServerConfig,
@@ -15,11 +20,6 @@ from mcp_servers_enhanced import (
     WorkflowOrchestrator,
     WorkflowStep,
 )
-import asyncio
-import os
-import sys
-
-import pytest
 
 # Add core to path
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "..", "core"))
diff --git a/workspace/src/tests/unit/phases/test_phase20_slsa_provenance.py b/workspace/src/tests/unit/phases/test_phase20_slsa_provenance.py
index 065af65..1810155 100644
--- a/workspace/src/tests/unit/phases/test_phase20_slsa_provenance.py
+++ b/workspace/src/tests/unit/phases/test_phase20_slsa_provenance.py
@@ -2,7 +2,11 @@
 Tests for Phase 20: SLSA L3 Provenance System
 """
 
-from slsa_provenance.provenance_generator import SLSALevel, Subject
+import asyncio
+import os
+import sys
+
+import pytest
 from slsa_provenance import (
     ArtifactVerifier,
     AttestationManager,
@@ -15,11 +19,7 @@ from slsa_provenance import (
     VerificationPolicy,
     VerificationResult,
 )
-import asyncio
-import os
-import sys
-
-import pytest
+from slsa_provenance.provenance_generator import SLSALevel, Subject
 
 # Add core to path
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "..", "core"))
diff --git a/workspace/src/tests/unit/phases/test_phase21_cloud_delegation.py b/workspace/src/tests/unit/phases/test_phase21_cloud_delegation.py
index c0fd05a..c23f655 100644
--- a/workspace/src/tests/unit/phases/test_phase21_cloud_delegation.py
+++ b/workspace/src/tests/unit/phases/test_phase21_cloud_delegation.py
@@ -2,7 +2,11 @@
 Tests for Phase 21: Cloud Agent Delegation System
 """
 
-from cloud_agent_delegation.delegation_manager import DelegationStatus, Task, TaskPriority
+import asyncio
+import os
+import sys
+
+import pytest
 from cloud_agent_delegation import (
     BalancingStrategy,
     CloudProviderAdapter,
@@ -17,11 +21,11 @@ from cloud_agent_delegation import (
     RoutingStrategy,
     TaskRouter,
 )
-import asyncio
-import os
-import sys
-
-import pytest
+from cloud_agent_delegation.delegation_manager import (
+    DelegationStatus,
+    Task,
+    TaskPriority,
+)
 
 # Add core to path
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "..", "core"))
diff --git a/workspace/src/tests/unit/phases/test_phase22_unified_integration.py b/workspace/src/tests/unit/phases/test_phase22_unified_integration.py
index 93760bf..6079dd5 100644
--- a/workspace/src/tests/unit/phases/test_phase22_unified_integration.py
+++ b/workspace/src/tests/unit/phases/test_phase22_unified_integration.py
@@ -5,23 +5,11 @@ Comprehensive tests for the unified integration layer that connects
 all SynergyMesh phases into a cohesive system.
 """
 
-from unified_integration.unified_controller import (
-    PhaseCategory,
-    PhaseDefinition,
-    SystemState,
-)
-from unified_integration.system_orchestrator import (
-    TaskType,
-    WorkflowState,
-)
-from unified_integration.integration_hub import (
-    MessagePriority,
-    MessageType,
-)
-from unified_integration.configuration_manager import (
-    Environment,
-    PhaseConfig,
-)
+import asyncio
+import sys
+from datetime import datetime, timezone
+
+import pytest
 from unified_integration import (
     ConfigurationManager,
     IntegrationConfig,
@@ -31,11 +19,23 @@ from unified_integration import (
     SystemOrchestrator,
     UnifiedSystemController,
 )
-import asyncio
-import sys
-from datetime import datetime, timezone
-
-import pytest
+from unified_integration.configuration_manager import (
+    Environment,
+    PhaseConfig,
+)
+from unified_integration.integration_hub import (
+    MessagePriority,
+    MessageType,
+)
+from unified_integration.system_orchestrator import (
+    TaskType,
+    WorkflowState,
+)
+from unified_integration.unified_controller import (
+    PhaseCategory,
+    PhaseDefinition,
+    SystemState,
+)
 
 sys.path.insert(0, str(__file__).rsplit("/tests", 1)[0] + "/core")
 
diff --git a/workspace/src/tests/unit/phases/test_phase24_mind_matrix.py b/workspace/src/tests/unit/phases/test_phase24_mind_matrix.py
index 0bab347..e7d1239 100644
--- a/workspace/src/tests/unit/phases/test_phase24_mind_matrix.py
+++ b/workspace/src/tests/unit/phases/test_phase24_mind_matrix.py
@@ -9,17 +9,17 @@ Tests for Phase 24: Mind Matrix System Integration.
 Minimal test vectors ensuring compatibility and no overlap.
 """
 
-from runtime.mind_matrix.main import (
-    ExecutiveRole,
-    MindMatrix,
-    MindMatrixModel,
-)
 import sys
 from pathlib import Path
 
 import pytest
 import yaml
 from pydantic import ValidationError
+from runtime.mind_matrix.main import (
+    ExecutiveRole,
+    MindMatrix,
+    MindMatrixModel,
+)
 
 # Add runtime to path for imports
 sys.path.insert(0, str(Path(__file__).parent.parent.parent))
diff --git a/workspace/src/tests/unit/test_ai_decision_engine.py b/workspace/src/tests/unit/test_ai_decision_engine.py
index b2b1f12..21c8130 100644
--- a/workspace/src/tests/unit/test_ai_decision_engine.py
+++ b/workspace/src/tests/unit/test_ai_decision_engine.py
@@ -8,7 +8,6 @@ Tests for verifying the AI Decision Engine core functionality.
 from __future__ import annotations
 
 import pytest  # type: ignore[import-not-found]
-
 from core.ai_decision_engine import (
     AIDecisionEngine,
     ConfidenceLevel,
diff --git a/workspace/src/tests/unit/test_contract_engine.py b/workspace/src/tests/unit/test_contract_engine.py
index 0609ba0..15d2aef 100644
--- a/workspace/src/tests/unit/test_contract_engine.py
+++ b/workspace/src/tests/unit/test_contract_engine.py
@@ -1,7 +1,6 @@
 #!/usr/bin/env python3
 """Unit tests for contract engine"""
 import pytest
-
 from core.contract_engine import ContractDefinition, ContractRegistry
 
 
diff --git a/workspace/src/tests/unit/test_deep_execution_system.py b/workspace/src/tests/unit/test_deep_execution_system.py
index fd500d6..0240af9 100644
--- a/workspace/src/tests/unit/test_deep_execution_system.py
+++ b/workspace/src/tests/unit/test_deep_execution_system.py
@@ -6,7 +6,6 @@ Test suite for Deep Execution System
 import asyncio
 
 import pytest
-
 from core.unified_integration.deep_execution_system import (
     AuditLogger,
     DeepExecutionConfig,
diff --git a/workspace/src/tests/unit/test_enhanced_integration.py b/workspace/src/tests/unit/test_enhanced_integration.py
index db620cb..328c878 100644
--- a/workspace/src/tests/unit/test_enhanced_integration.py
+++ b/workspace/src/tests/unit/test_enhanced_integration.py
@@ -7,7 +7,6 @@ import asyncio
 from datetime import datetime, timezone
 
 import pytest
-
 from core.unified_integration import (  # Service Registry; Cognitive Processor; Configuration Optimizer
     CognitiveLayer,
     CognitiveSignal,
diff --git a/workspace/src/tests/unit/test_executive_auto.py b/workspace/src/tests/unit/test_executive_auto.py
index 57d16ec..17ba7e2 100644
--- a/workspace/src/tests/unit/test_executive_auto.py
+++ b/workspace/src/tests/unit/test_executive_auto.py
@@ -9,11 +9,11 @@ Tests the complete autonomous executive loop:
 perceive â†’ reason â†’ policy_gate â†’ execute â†’ prove â†’ heal â†’ evolve
 """
 
-from runtime.mind_matrix.executive_auto import ExecutiveAutoController
 import sys
 from pathlib import Path
 
 import pytest
+from runtime.mind_matrix.executive_auto import ExecutiveAutoController
 
 # Add runtime to path for imports
 sys.path.insert(0, str(Path(__file__).parent.parent))
diff --git a/workspace/src/tests/unit/test_partial_rollback.py b/workspace/src/tests/unit/test_partial_rollback.py
index ba6fe35..44f6c72 100644
--- a/workspace/src/tests/unit/test_partial_rollback.py
+++ b/workspace/src/tests/unit/test_partial_rollback.py
@@ -11,7 +11,6 @@ from datetime import datetime
 from typing import Any
 
 import pytest
-
 from core.safety_mechanisms.partial_rollback import (
     PartialRollbackManager,
     RollbackAction,
diff --git a/workspace/src/tests/unit/test_validators.py b/workspace/src/tests/unit/test_validators.py
index 2c3ff54..06044d5 100644
--- a/workspace/src/tests/unit/test_validators.py
+++ b/workspace/src/tests/unit/test_validators.py
@@ -1,7 +1,6 @@
 #!/usr/bin/env python3
 """Unit tests for validators"""
 import pytest
-
 from core.validators import SecurityValidator, SyntaxValidator
 
 
diff --git a/workspace/teams/default-team/orchestrator/main.py b/workspace/teams/default-team/orchestrator/main.py
index d9a8f79..db8f368 100644
--- a/workspace/teams/default-team/orchestrator/main.py
+++ b/workspace/teams/default-team/orchestrator/main.py
@@ -35,9 +35,6 @@ from models.messages import (
     MessageType,
     Urgency,
 )
-
-# Local imports
-from config import settings
 from services.agent_client import AgentClient, AgentRegistry
 from services.audit_trail import AuditAction, AuditTrail
 from services.consensus import ConsensusManager
@@ -52,6 +49,9 @@ from utils.structured_logging import (
     set_trace_context,
 )
 
+# Local imports
+from config import settings
+
 # Initialize logger
 logger = get_logger(
     name="super-agent",
diff --git a/workspace/teams/default-team/orchestrator/tests/conftest.py b/workspace/teams/default-team/orchestrator/tests/conftest.py
index 0c495bc..c7e86a7 100644
--- a/workspace/teams/default-team/orchestrator/tests/conftest.py
+++ b/workspace/teams/default-team/orchestrator/tests/conftest.py
@@ -3,7 +3,6 @@
 Pytest Configuration and Fixtures for SuperAgent Tests.
 """
 
-from main import app, superagent_core
 import asyncio
 import os
 import sys
@@ -12,6 +11,7 @@ from typing import AsyncGenerator, Generator
 import pytest
 import pytest_asyncio
 from httpx import AsyncClient
+from main import app, superagent_core
 
 # Add parent directory to path for imports
 sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
diff --git a/workspace/teams/default-team/orchestrator/tests/test_models.py b/workspace/teams/default-team/orchestrator/tests/test_models.py
index d739cbc..29c43de 100644
--- a/workspace/teams/default-team/orchestrator/tests/test_models.py
+++ b/workspace/teams/default-team/orchestrator/tests/test_models.py
@@ -8,21 +8,12 @@ Tests cover:
 - Consensus voting models
 """
 
-from models.messages import (
-    MessageContext,
-    MessageEnvelope,
-    MessageMetadata,
-    MessageResponse,
-    MessageType,
-    Urgency,
-)
-from models.incidents import (
-    VALID_TRANSITIONS,
-    Incident,
-    IncidentHistory,
-    IncidentState,
-    IncidentTransition,
-)
+import os
+import sys
+from datetime import datetime
+from uuid import uuid4
+
+import pytest
 from models.consensus import (
     DEFAULT_AGENT_WEIGHTS,
     AgentWeight,
@@ -32,12 +23,21 @@ from models.consensus import (
     Vote,
     VoteType,
 )
-import os
-import sys
-from datetime import datetime
-from uuid import uuid4
-
-import pytest
+from models.incidents import (
+    VALID_TRANSITIONS,
+    Incident,
+    IncidentHistory,
+    IncidentState,
+    IncidentTransition,
+)
+from models.messages import (
+    MessageContext,
+    MessageEnvelope,
+    MessageMetadata,
+    MessageResponse,
+    MessageType,
+    Urgency,
+)
 
 sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
 
diff --git a/workspace/teams/default-team/orchestrator/tests/test_services.py b/workspace/teams/default-team/orchestrator/tests/test_services.py
index d70c550..4a37cf4 100644
--- a/workspace/teams/default-team/orchestrator/tests/test_services.py
+++ b/workspace/teams/default-team/orchestrator/tests/test_services.py
@@ -10,13 +10,6 @@ Tests cover:
 - Agent client communication
 """
 
-from services.state_machine import IncidentStateMachine
-from services.event_store import EventStore, StoredEvent
-from services.consensus import ConsensusManager
-from services.audit_trail import AuditAction, AuditEntry, AuditTrail
-from services.agent_client import AgentClient, AgentRegistry
-from models.incidents import Incident, IncidentState
-from models.consensus import ConsensusState, VoteType
 import asyncio
 import os
 import sys
@@ -24,6 +17,13 @@ from datetime import datetime
 from unittest.mock import AsyncMock, MagicMock, patch
 
 import pytest
+from models.consensus import ConsensusState, VoteType
+from models.incidents import Incident, IncidentState
+from services.agent_client import AgentClient, AgentRegistry
+from services.audit_trail import AuditAction, AuditEntry, AuditTrail
+from services.consensus import ConsensusManager
+from services.event_store import EventStore, StoredEvent
+from services.state_machine import IncidentStateMachine
 
 sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
 
diff --git a/workspace/teams/default-team/orchestrator/tests/test_utils.py b/workspace/teams/default-team/orchestrator/tests/test_utils.py
index 35db1c4..c75eb66 100644
--- a/workspace/teams/default-team/orchestrator/tests/test_utils.py
+++ b/workspace/teams/default-team/orchestrator/tests/test_utils.py
@@ -9,6 +9,19 @@ Tests cover:
 - Rate limiting and backpressure
 """
 
+import asyncio
+import os
+import sys
+import time
+
+import pytest
+from utils.circuit_breaker import (
+    CircuitBreaker,
+    CircuitBreakerRegistry,
+    CircuitOpenError,
+    CircuitState,
+)
+from utils.metrics import Counter, Gauge, Histogram, MetricsCollector
 from utils.retry import (
     BackpressureController,
     RateLimiter,
@@ -16,19 +29,6 @@ from utils.retry import (
     RetryExhaustedError,
     retry_async,
 )
-from utils.metrics import Counter, Gauge, Histogram, MetricsCollector
-from utils.circuit_breaker import (
-    CircuitBreaker,
-    CircuitBreakerRegistry,
-    CircuitOpenError,
-    CircuitState,
-)
-import asyncio
-import os
-import sys
-import time
-
-import pytest
 
 sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
 
diff --git a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/crossplatform/__init__.py b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/crossplatform/__init__.py
index 2066e5b..bd1da89 100644
--- a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/crossplatform/__init__.py
+++ b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/crossplatform/__init__.py
@@ -5,12 +5,27 @@ Cross-platform Integration Module
 Phase 9: Web3ã€IoTã€AR/VR æ•´åˆä»¥åŠé¢¨éšªç®¡æ§ç³»çµ±
 """
 
-from .arvr_integration import ARVRIntegration, ImmersiveExperience, MetaversePlatform, MixedReality
+from .arvr_integration import (
+    ARVRIntegration,
+    ImmersiveExperience,
+    MetaversePlatform,
+    MixedReality,
+)
 from .emergency_response import EmergencyResponse, PlanType, TriggerCondition
-from .iot_integration import DeviceInterconnection, EdgeComputing, Industry40, IoTIntegration
+from .iot_integration import (
+    DeviceInterconnection,
+    EdgeComputing,
+    Industry40,
+    IoTIntegration,
+)
 from .risk_assessment import MitigationStrategy, RiskAssessment, RiskCategory
 from .tech_stack_matrix import StackRecommendation, TechStackMatrix
-from .web3_integration import DAppAssessment, NFTStrategy, SmartContractDev, Web3Integration
+from .web3_integration import (
+    DAppAssessment,
+    NFTStrategy,
+    SmartContractDev,
+    Web3Integration,
+)
 
 __all__ = [
     "Web3Integration",
diff --git a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/strategy/__init__.py b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/strategy/__init__.py
index 275cf74..0415045 100644
--- a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/strategy/__init__.py
+++ b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/src/strategy/__init__.py
@@ -13,7 +13,12 @@ MIT License
 """
 
 from .case_study_engine import CaseStudy, CaseStudyEngine, EvolutionPhase, LessonLearned
-from .evolution_tracker import EvolutionTracker, MaturityLevel, PhaseTransition, ProjectMaturity
+from .evolution_tracker import (
+    EvolutionTracker,
+    MaturityLevel,
+    PhaseTransition,
+    ProjectMaturity,
+)
 from .resource_optimizer import (
     BudgetAllocation,
     OptimizationResult,
diff --git a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_models.py b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_models.py
index 376cf5d..eff9368 100644
--- a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_models.py
+++ b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_models.py
@@ -3,8 +3,10 @@
 Tests for Dependency Manager Agent
 """
 
-from models.vulnerability import Vulnerability, VulnerabilitySeverity, VulnerabilitySource
-from models.update import Update, UpdatePolicy, UpdateResult, UpdateStatus, UpdateType
+import sys
+from pathlib import Path
+
+import pytest
 from models.dependency import (
     Dependency,
     DependencyAnalysis,
@@ -12,10 +14,12 @@ from models.dependency import (
     DependencyType,
     Ecosystem,
 )
-import sys
-from pathlib import Path
-
-import pytest
+from models.update import Update, UpdatePolicy, UpdateResult, UpdateStatus, UpdateType
+from models.vulnerability import (
+    Vulnerability,
+    VulnerabilitySeverity,
+    VulnerabilitySource,
+)
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
diff --git a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase10.py b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase10.py
index 33406c0..bac64ed 100644
--- a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase10.py
+++ b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase10.py
@@ -325,7 +325,11 @@ class TestActionGuide(unittest.TestCase):
 
     def test_recommendation_creation(self):
         """æ¸¬è©¦å»ºè­°å‰µå»º"""
-        from implementation.action_guide import ActionPriority, Recommendation, RecommendationType
+        from implementation.action_guide import (
+            ActionPriority,
+            Recommendation,
+            RecommendationType,
+        )
 
         rec = Recommendation(
             id="rec_1",
diff --git a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase2.py b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase2.py
index 36e5242..1617e39 100644
--- a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase2.py
+++ b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase2.py
@@ -3,17 +3,17 @@
 Phase 2 Tests - Analyzers and Utils
 """
 
-from utils.dependency_tree import DependencyTree, RiskLevel, TreeNode
-from utils.audit_logger import AuditEventType, AuditLogger, AuditSeverity
-from models.dependency import Dependency, DependencyType, Ecosystem
-from analyzers.pip_analyzer import PipAnalyzer
-from analyzers.go_analyzer import GoAnalyzer
 import os
 import sys
 import tempfile
 from pathlib import Path
 
 import pytest
+from analyzers.go_analyzer import GoAnalyzer
+from analyzers.pip_analyzer import PipAnalyzer
+from models.dependency import Dependency, DependencyType, Ecosystem
+from utils.audit_logger import AuditEventType, AuditLogger, AuditSeverity
+from utils.dependency_tree import DependencyTree, RiskLevel, TreeNode
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
diff --git a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase3.py b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase3.py
index 24d472c..1d5cc10 100644
--- a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase3.py
+++ b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase3.py
@@ -3,12 +3,12 @@
 Phase 3 Tests - Policy Simulator and Language Boundary
 """
 
-from utils.policy_simulator import (
-    PolicySimulator,
-    SimulationMode,
-    SimulationResult,
-    SimulationScenario,
-)
+import sys
+from pathlib import Path
+
+import pytest
+from models.dependency import Dependency, DependencyAnalysis, DependencyType, Ecosystem
+from models.update import UpdatePolicy, UpdateType
 from utils.language_boundary import (
     LanguageBoundary,
     LanguageRegistry,
@@ -17,12 +17,12 @@ from utils.language_boundary import (
     msg,
     t,
 )
-from models.update import UpdatePolicy, UpdateType
-from models.dependency import Dependency, DependencyAnalysis, DependencyType, Ecosystem
-import sys
-from pathlib import Path
-
-import pytest
+from utils.policy_simulator import (
+    PolicySimulator,
+    SimulationMode,
+    SimulationResult,
+    SimulationScenario,
+)
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
diff --git a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase4.py b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase4.py
index 5b43e0e..b8359f2 100644
--- a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase4.py
+++ b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase4.py
@@ -8,18 +8,17 @@ Phase 4 ä¼æ¥­ç´šåŠŸèƒ½å–®å…ƒæ¸¬è©¦
 - ä¸‹ä¸–ä»£å®‰å…¨æ¨¡çµ„
 """
 
-from enterprise.security import (
-    ComplianceFramework,
-    NextGenSecurity,
-    SBOMFormat,
-    SupplyChainRisk,
-    TrustLevel,
-)
-from enterprise.recommendation import (
-    HealthScore,
-    IntelligentRecommendation,
-    RecommendationType,
-    RiskLevel,
+import os
+import sys
+import unittest
+from datetime import datetime, timedelta
+
+from enterprise.analytics import (
+    CommercialAnalytics,
+    CostCategory,
+    CostItem,
+    TechDebtItem,
+    TechDebtType,
 )
 from enterprise.integration import (
     AuthMethod,
@@ -28,17 +27,19 @@ from enterprise.integration import (
     IntegrationType,
     WebhookEvent,
 )
-from enterprise.analytics import (
-    CommercialAnalytics,
-    CostCategory,
-    CostItem,
-    TechDebtItem,
-    TechDebtType,
+from enterprise.recommendation import (
+    HealthScore,
+    IntelligentRecommendation,
+    RecommendationType,
+    RiskLevel,
+)
+from enterprise.security import (
+    ComplianceFramework,
+    NextGenSecurity,
+    SBOMFormat,
+    SupplyChainRisk,
+    TrustLevel,
 )
-import os
-import sys
-import unittest
-from datetime import datetime, timedelta
 
 # æ·»åŠ è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
diff --git a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase5.py b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase5.py
index ebda9f4..5800c4c 100644
--- a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase5.py
+++ b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase5.py
@@ -12,15 +12,29 @@ Copyright (c) 2024 MachineNativeOps
 MIT License
 """
 
-from strategy.strategy_advisor import (
-    CapabilityLevel,
-    MarketMaturity,
-    MarketTimingAnalysis,
-    StrategicPriority,
-    StrategyAdvisor,
-    StrategyRecommendation,
-    TechCapability,
-    TechCapabilityAssessment,
+import os
+
+# æ¨¡æ“¬å°å…¥ï¼ˆæ¸¬è©¦æ™‚éœ€è¦ç¢ºä¿è·¯å¾‘æ­£ç¢ºï¼‰
+import sys
+import unittest
+from datetime import datetime
+from typing import Any, Dict
+
+from strategy.case_study_engine import (
+    CaseStudy,
+    CaseStudyEngine,
+    DevelopmentStrategy,
+    EvolutionPhase,
+    LessonLearned,
+    PhaseType,
+)
+from strategy.evolution_tracker import (
+    DevelopmentPhase,
+    EvolutionRoadmap,
+    EvolutionTracker,
+    MaturityLevel,
+    PhaseTransition,
+    ProjectMaturity,
 )
 from strategy.resource_optimizer import (
     AllocationStrategy,
@@ -31,29 +45,16 @@ from strategy.resource_optimizer import (
     TeamAllocation,
     TeamRole,
 )
-from strategy.evolution_tracker import (
-    DevelopmentPhase,
-    EvolutionRoadmap,
-    EvolutionTracker,
-    MaturityLevel,
-    PhaseTransition,
-    ProjectMaturity,
-)
-from strategy.case_study_engine import (
-    CaseStudy,
-    CaseStudyEngine,
-    DevelopmentStrategy,
-    EvolutionPhase,
-    LessonLearned,
-    PhaseType,
+from strategy.strategy_advisor import (
+    CapabilityLevel,
+    MarketMaturity,
+    MarketTimingAnalysis,
+    StrategicPriority,
+    StrategyAdvisor,
+    StrategyRecommendation,
+    TechCapability,
+    TechCapabilityAssessment,
 )
-import os
-
-# æ¨¡æ“¬å°å…¥ï¼ˆæ¸¬è©¦æ™‚éœ€è¦ç¢ºä¿è·¯å¾‘æ­£ç¢ºï¼‰
-import sys
-import unittest
-from datetime import datetime
-from typing import Any, Dict
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
diff --git a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase7.py b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase7.py
index 365c83a..38dc75d 100644
--- a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase7.py
+++ b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase7.py
@@ -4,7 +4,11 @@ Phase 7 æ¸¬è©¦ - SMART-V è©•ä¼°æ¡†æ¶
 æ¸¬è©¦ SMART-V é‡åŒ–è©•ä¼°ç³»çµ±çš„å„é …åŠŸèƒ½ã€‚
 """
 
-from evaluation.weight_config import CompanyStage, WeightConfigManager
+import os
+import sys
+import unittest
+
+from evaluation.evaluation_report import EvaluationReportGenerator, ReportConfig
 from evaluation.smartv_framework import (
     AchievabilityEvaluator,
     EvaluationDimension,
@@ -15,10 +19,7 @@ from evaluation.smartv_framework import (
     TechnologyMaturityEvaluator,
     ValueCreationEvaluator,
 )
-from evaluation.evaluation_report import EvaluationReportGenerator, ReportConfig
-import os
-import sys
-import unittest
+from evaluation.weight_config import CompanyStage, WeightConfigManager
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
diff --git a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase8.py b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase8.py
index 246a1d8..335ad54 100644
--- a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase8.py
+++ b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase8.py
@@ -4,16 +4,15 @@ Phase 8 å–®å…ƒæ¸¬è©¦
 Tests for Advanced Prompt Combination Strategy Modules
 """
 
-from combination.quarterly_review import (
-    QuarterlyReviewEngine,
-    ReviewCategory,
-    ReviewStatus,
-)
-from combination.dynamic_adjuster import (
-    AdjustmentDirection,
-    AdjustmentTrigger,
-    DynamicAdjuster,
-    KPIMetric,
+import sys
+import unittest
+from datetime import datetime
+from pathlib import Path
+
+from combination.combination_templates import (
+    CombinationTemplateManager,
+    CompanyStage,
+    TemplateCategory,
 )
 from combination.core_satellite import (
     AllocationRole,
@@ -22,15 +21,17 @@ from combination.core_satellite import (
     PromptAllocation,
     PromptCategory,
 )
-from combination.combination_templates import (
-    CombinationTemplateManager,
-    CompanyStage,
-    TemplateCategory,
+from combination.dynamic_adjuster import (
+    AdjustmentDirection,
+    AdjustmentTrigger,
+    DynamicAdjuster,
+    KPIMetric,
+)
+from combination.quarterly_review import (
+    QuarterlyReviewEngine,
+    ReviewCategory,
+    ReviewStatus,
 )
-import sys
-import unittest
-from datetime import datetime
-from pathlib import Path
 
 sys.path.insert(0, str(Path(__file__).resolve().parents[1] / "src"))
 
diff --git a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase9.py b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase9.py
index d78fea2..f1e6632 100644
--- a/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase9.py
+++ b/workspace/teams/holy-grail/agents/ai-experts/dependency-manager/tests/test_phase9.py
@@ -3,24 +3,25 @@ Phase 9 å–®å…ƒæ¸¬è©¦
 Cross-platform Integration & Risk Management Tests
 """
 
-from crossplatform.web3_integration import (
-    BlockchainType,
-    ConsensusType,
-    DAppAssessment,
-    NFTAssetType,
-    NFTStrategy,
-    SmartContractDev,
-    Web3Integration,
+import os
+import sys
+import unittest
+
+from crossplatform.arvr_integration import (
+    ARVRIntegration,
+    HardwareRequirement,
+    ImmersiveExperience,
+    InteractionMode,
+    MetaversePlatform,
+    MixedReality,
+    XRType,
 )
-from crossplatform.tech_stack_matrix import (
-    BackendArch,
-    DataProcessing,
-    DeploymentStrategy,
-    FrontendTech,
-    StackRecommendation,
-    TechStackMatrix,
+from crossplatform.emergency_response import (
+    EmergencyResponse,
+    PlanType,
+    TriggerCategory,
+    TriggerCondition,
 )
-from crossplatform.risk_assessment import MitigationStrategy, RiskAssessment, RiskCategory, RiskType
 from crossplatform.iot_integration import (
     DeviceInterconnection,
     EdgeComputing,
@@ -30,24 +31,29 @@ from crossplatform.iot_integration import (
     IoTIntegration,
     IoTProtocol,
 )
-from crossplatform.emergency_response import (
-    EmergencyResponse,
-    PlanType,
-    TriggerCategory,
-    TriggerCondition,
+from crossplatform.risk_assessment import (
+    MitigationStrategy,
+    RiskAssessment,
+    RiskCategory,
+    RiskType,
 )
-from crossplatform.arvr_integration import (
-    ARVRIntegration,
-    HardwareRequirement,
-    ImmersiveExperience,
-    InteractionMode,
-    MetaversePlatform,
-    MixedReality,
-    XRType,
+from crossplatform.tech_stack_matrix import (
+    BackendArch,
+    DataProcessing,
+    DeploymentStrategy,
+    FrontendTech,
+    StackRecommendation,
+    TechStackMatrix,
+)
+from crossplatform.web3_integration import (
+    BlockchainType,
+    ConsensusType,
+    DAppAssessment,
+    NFTAssetType,
+    NFTStrategy,
+    SmartContractDev,
+    Web3Integration,
 )
-import os
-import sys
-import unittest
 
 # æ·»åŠ è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
diff --git a/workspace/teams/holy-grail/agents/autonomous/migration/scripts/v1_to_v2.py b/workspace/teams/holy-grail/agents/autonomous/migration/scripts/v1_to_v2.py
index d5ccd7c..2fa3770 100644
--- a/workspace/teams/holy-grail/agents/autonomous/migration/scripts/v1_to_v2.py
+++ b/workspace/teams/holy-grail/agents/autonomous/migration/scripts/v1_to_v2.py
@@ -5,10 +5,11 @@ v1 â†’ v2 é·ç§»è…³æœ¬
 å°‡ v1-python-drones é·ç§»è‡³ v2-multi-islands æ¶æ§‹ã€‚
 """
 
-from migration.migrator import Migrator
 import sys
 from pathlib import Path
 
+from migration.migrator import Migrator
+
 # æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))
 
diff --git a/workspace/teams/holy-grail/agents/autonomous/migration/scripts/v2_to_v1.py b/workspace/teams/holy-grail/agents/autonomous/migration/scripts/v2_to_v1.py
index 738b9dd..5093e76 100644
--- a/workspace/teams/holy-grail/agents/autonomous/migration/scripts/v2_to_v1.py
+++ b/workspace/teams/holy-grail/agents/autonomous/migration/scripts/v2_to_v1.py
@@ -5,10 +5,11 @@ v2 â†’ v1 é™ç´šé·ç§»è…³æœ¬
 å°‡ v2-multi-islands é™ç´šè‡³ v1-python-drones æ¶æ§‹ã€‚
 """
 
-from migration.migrator import Migrator
 import sys
 from pathlib import Path
 
+from migration.migrator import Migrator
+
 # æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))
 
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase10_components.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase10_components.py
index 65fe08d..bf3c289 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase10_components.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase10_components.py
@@ -28,7 +28,10 @@ class TestCircuitBreaker:
 
     def test_circuit_breaker_initial_state(self):
         """Test circuit breaker starts in closed state"""
-        from core.safety_mechanisms.circuit_breaker import CircuitBreaker, CircuitBreakerState
+        from core.safety_mechanisms.circuit_breaker import (
+            CircuitBreaker,
+            CircuitBreakerState,
+        )
 
         breaker = CircuitBreaker()
         assert breaker.state == CircuitBreakerState.CLOSED
@@ -108,7 +111,10 @@ class TestEscalationLadder:
 
     def test_escalation_ladder_initial_state(self):
         """Test escalation ladder starts at normal"""
-        from core.safety_mechanisms.escalation_ladder import EscalationLadder, EscalationLevel
+        from core.safety_mechanisms.escalation_ladder import (
+            EscalationLadder,
+            EscalationLevel,
+        )
 
         ladder = EscalationLadder()
         assert ladder.current_level == EscalationLevel.LEVEL_0_NORMAL
@@ -116,7 +122,10 @@ class TestEscalationLadder:
     @pytest.mark.asyncio
     async def test_escalation_ladder_escalate(self):
         """Test escalating levels"""
-        from core.safety_mechanisms.escalation_ladder import EscalationLadder, EscalationLevel
+        from core.safety_mechanisms.escalation_ladder import (
+            EscalationLadder,
+            EscalationLevel,
+        )
 
         ladder = EscalationLadder()
 
@@ -129,7 +138,10 @@ class TestEscalationLadder:
     @pytest.mark.asyncio
     async def test_escalation_ladder_de_escalate(self):
         """Test de-escalating levels"""
-        from core.safety_mechanisms.escalation_ladder import EscalationLadder, EscalationLevel
+        from core.safety_mechanisms.escalation_ladder import (
+            EscalationLadder,
+            EscalationLevel,
+        )
 
         ladder = EscalationLadder()
 
@@ -141,7 +153,10 @@ class TestEscalationLadder:
     @pytest.mark.asyncio
     async def test_escalation_ladder_set_level(self):
         """Test setting specific level"""
-        from core.safety_mechanisms.escalation_ladder import EscalationLadder, EscalationLevel
+        from core.safety_mechanisms.escalation_ladder import (
+            EscalationLadder,
+            EscalationLevel,
+        )
 
         ladder = EscalationLadder()
 
@@ -191,7 +206,10 @@ class TestRollbackSystem:
     @pytest.mark.asyncio
     async def test_rollback_with_handlers(self):
         """Test rollback with component handlers"""
-        from core.safety_mechanisms.rollback_system import RollbackStrategy, RollbackSystem
+        from core.safety_mechanisms.rollback_system import (
+            RollbackStrategy,
+            RollbackSystem,
+        )
 
         state = {"value": 10}
 
@@ -234,7 +252,10 @@ class TestAnomalyDetector:
 
     def test_anomaly_detector_add_metric(self):
         """Test adding metrics"""
-        from core.safety_mechanisms.anomaly_detector import AnomalyDetector, DetectionStrategy
+        from core.safety_mechanisms.anomaly_detector import (
+            AnomalyDetector,
+            DetectionStrategy,
+        )
 
         detector = AnomalyDetector()
         detector.add_metric(
@@ -246,7 +267,10 @@ class TestAnomalyDetector:
     @pytest.mark.asyncio
     async def test_anomaly_detector_threshold(self):
         """Test threshold-based anomaly detection"""
-        from core.safety_mechanisms.anomaly_detector import AnomalyDetector, DetectionStrategy
+        from core.safety_mechanisms.anomaly_detector import (
+            AnomalyDetector,
+            DetectionStrategy,
+        )
 
         detector = AnomalyDetector()
         detector.add_metric(
@@ -306,7 +330,11 @@ class TestEmergencyStop:
     @pytest.mark.asyncio
     async def test_emergency_stop_trigger(self):
         """Test triggering emergency stop"""
-        from core.safety_mechanisms.emergency_stop import EmergencyStop, StopReason, StopScope
+        from core.safety_mechanisms.emergency_stop import (
+            EmergencyStop,
+            StopReason,
+            StopScope,
+        )
 
         stop = EmergencyStop()
 
@@ -322,7 +350,11 @@ class TestEmergencyStop:
     @pytest.mark.asyncio
     async def test_emergency_stop_recover(self):
         """Test recovery from emergency stop"""
-        from core.safety_mechanisms.emergency_stop import EmergencyStop, StopReason, StopScope
+        from core.safety_mechanisms.emergency_stop import (
+            EmergencyStop,
+            StopReason,
+            StopScope,
+        )
 
         stop = EmergencyStop()
 
@@ -350,7 +382,11 @@ class TestSafetyNet:
 
     def test_safety_net_add_check(self):
         """Test adding safety checks"""
-        from core.safety_mechanisms.safety_net import SafetyCheck, SafetyLayer, SafetyNet
+        from core.safety_mechanisms.safety_net import (
+            SafetyCheck,
+            SafetyLayer,
+            SafetyNet,
+        )
 
         safety = SafetyNet()
 
@@ -382,7 +418,11 @@ class TestSafetyNet:
     @pytest.mark.asyncio
     async def test_safety_net_validate_fail(self):
         """Test safety net validation (failing)"""
-        from core.safety_mechanisms.safety_net import SafetyCheck, SafetyLayer, SafetyNet
+        from core.safety_mechanisms.safety_net import (
+            SafetyCheck,
+            SafetyLayer,
+            SafetyNet,
+        )
 
         safety = SafetyNet()
         safety.add_check(
@@ -455,8 +495,14 @@ class TestSafetyMechanismsIntegration:
     @pytest.mark.asyncio
     async def test_circuit_breaker_with_anomaly_detection(self):
         """Test circuit breaker triggered by anomaly detection"""
-        from core.safety_mechanisms.anomaly_detector import AnomalyDetector, DetectionStrategy
-        from core.safety_mechanisms.circuit_breaker import CircuitBreaker, CircuitBreakerConfig
+        from core.safety_mechanisms.anomaly_detector import (
+            AnomalyDetector,
+            DetectionStrategy,
+        )
+        from core.safety_mechanisms.circuit_breaker import (
+            CircuitBreaker,
+            CircuitBreakerConfig,
+        )
 
         breaker = CircuitBreaker(CircuitBreakerConfig(failure_threshold=1))
         detector = AnomalyDetector()
@@ -472,8 +518,15 @@ class TestSafetyMechanismsIntegration:
     @pytest.mark.asyncio
     async def test_escalation_with_emergency_stop(self):
         """Test escalation ladder triggering emergency stop"""
-        from core.safety_mechanisms.emergency_stop import EmergencyStop, StopReason, StopScope
-        from core.safety_mechanisms.escalation_ladder import EscalationLadder, EscalationLevel
+        from core.safety_mechanisms.emergency_stop import (
+            EmergencyStop,
+            StopReason,
+            StopScope,
+        )
+        from core.safety_mechanisms.escalation_ladder import (
+            EscalationLadder,
+            EscalationLevel,
+        )
 
         ladder = EscalationLadder()
         stop = EmergencyStop()
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase11_components.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase11_components.py
index ddf8596..65257e5 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase11_components.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase11_components.py
@@ -10,11 +10,12 @@ Tests for:
 - ObservabilityPlatform
 """
 
-from core.monitoring_system.smart_anomaly_detector import AnomalySeverity
-from core.monitoring_system.self_learning import PatternType
-from core.monitoring_system.observability_platform import EventType, LogLevel, TraceStatus
-from core.monitoring_system.intelligent_monitoring import MetricType as MT
-from core.monitoring_system.auto_remediation import RemediationStatus, RemediationType
+import asyncio
+import os
+import sys
+from datetime import datetime, timedelta
+
+import pytest
 from core.monitoring_system import (  # Intelligent Monitoring; Smart Anomaly Detection; Auto Diagnosis; Auto Remediation; Self Learning; Observability Platform
     Alert,
     AlertSeverity,
@@ -48,12 +49,15 @@ from core.monitoring_system import (  # Intelligent Monitoring; Smart Anomaly De
     SmartAnomalyDetector,
     TraceSpan,
 )
-import asyncio
-import os
-import sys
-from datetime import datetime, timedelta
-
-import pytest
+from core.monitoring_system.auto_remediation import RemediationStatus, RemediationType
+from core.monitoring_system.intelligent_monitoring import MetricType as MT
+from core.monitoring_system.observability_platform import (
+    EventType,
+    LogLevel,
+    TraceStatus,
+)
+from core.monitoring_system.self_learning import PatternType
+from core.monitoring_system.smart_anomaly_detector import AnomalySeverity
 
 # Add parent directory to path for imports
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase12_components.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase12_components.py
index 7d2a74a..7cad2b6 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase12_components.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase12_components.py
@@ -2,13 +2,16 @@
 Tests for Phase 12: GitHub Issues CI Error Auto-Handler System
 """
 
-# Import Phase 12 components
-from core.ci_error_handler.issue_manager import CIIssue, IssueManager, IssueStatus, IssueTemplate
-from core.ci_error_handler.fix_status_tracker import (
-    FixHistory,
-    FixMetrics,
-    FixStatus,
-    FixStatusTracker,
+import sys
+from datetime import datetime, timedelta
+
+import pytest
+from core.ci_error_handler.auto_fix_engine import (
+    AutoFixEngine,
+    FixAttempt,
+    FixResult,
+    FixRule,
+    FixStrategy,
 )
 from core.ci_error_handler.ci_error_analyzer import (
     CIError,
@@ -17,17 +20,20 @@ from core.ci_error_handler.ci_error_analyzer import (
     ErrorPattern,
     ErrorSeverity,
 )
-from core.ci_error_handler.auto_fix_engine import (
-    AutoFixEngine,
-    FixAttempt,
-    FixResult,
-    FixRule,
-    FixStrategy,
+from core.ci_error_handler.fix_status_tracker import (
+    FixHistory,
+    FixMetrics,
+    FixStatus,
+    FixStatusTracker,
 )
-import sys
-from datetime import datetime, timedelta
 
-import pytest
+# Import Phase 12 components
+from core.ci_error_handler.issue_manager import (
+    CIIssue,
+    IssueManager,
+    IssueStatus,
+    IssueTemplate,
+)
 
 sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh")
 
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase13_components.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase13_components.py
index ad51fae..c32e608 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase13_components.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase13_components.py
@@ -2,33 +2,28 @@
 Phase 13 Tests: Deep Verifiable YAML Module System
 """
 
-# Import Phase 13 components
-from core.yaml_module_system.yaml_schema_validator import (
-    SchemaRegistry,
-    ValidationError,
-    ValidationErrorType,
-    ValidationResult,
-    YAMLSchemaValidator,
-)
-from core.yaml_module_system.yaml_module_definition import (
-    ChangelogEntry,
-    LifecycleState,
-    ModuleLifecycle,
-    ModuleMetadata,
-    ModuleOwner,
-    TestVector,
-    TestVectorType,
-    YAMLModuleDefinition,
+import sys
+from datetime import datetime
+from typing import Any, Dict
+
+import pytest
+from core.yaml_module_system.audit_trail import (
+    AuditAction,
+    AuditEntry,
+    AuditLevel,
+    AuditLogger,
+    ChangeRecord,
+    ChangeTracker,
 )
-from core.yaml_module_system.slsa_compliance import (
-    SBOM,
-    ArtifactSigner,
-    SBOMGenerator,
-    SignatureAlgorithm,
-    SignedArtifact,
-    SLSALevel,
-    SLSAProvenance,
-    SLSAProvenanceGenerator,
+from core.yaml_module_system.ci_verification_pipeline import (
+    CIVerificationPipeline,
+    Evidence,
+    EvidenceCollector,
+    PipelineStage,
+    PipelineStageType,
+    StageResult,
+    StageStatus,
+    VerificationReport,
 )
 from core.yaml_module_system.policy_gate import (
     PolicyAction,
@@ -39,29 +34,35 @@ from core.yaml_module_system.policy_gate import (
     PolicySeverity,
     PolicyViolation,
 )
-from core.yaml_module_system.ci_verification_pipeline import (
-    CIVerificationPipeline,
-    Evidence,
-    EvidenceCollector,
-    PipelineStage,
-    PipelineStageType,
-    StageResult,
-    StageStatus,
-    VerificationReport,
+from core.yaml_module_system.slsa_compliance import (
+    SBOM,
+    ArtifactSigner,
+    SBOMGenerator,
+    SignatureAlgorithm,
+    SignedArtifact,
+    SLSALevel,
+    SLSAProvenance,
+    SLSAProvenanceGenerator,
 )
-from core.yaml_module_system.audit_trail import (
-    AuditAction,
-    AuditEntry,
-    AuditLevel,
-    AuditLogger,
-    ChangeRecord,
-    ChangeTracker,
+from core.yaml_module_system.yaml_module_definition import (
+    ChangelogEntry,
+    LifecycleState,
+    ModuleLifecycle,
+    ModuleMetadata,
+    ModuleOwner,
+    TestVector,
+    TestVectorType,
+    YAMLModuleDefinition,
 )
-import sys
-from datetime import datetime
-from typing import Any, Dict
 
-import pytest
+# Import Phase 13 components
+from core.yaml_module_system.yaml_schema_validator import (
+    SchemaRegistry,
+    ValidationError,
+    ValidationErrorType,
+    ValidationResult,
+    YAMLSchemaValidator,
+)
 
 sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh")
 
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase14_components.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase14_components.py
index 693be7c..4cf947a 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase14_components.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase14_components.py
@@ -7,7 +7,6 @@ from datetime import datetime
 from typing import Any, Dict
 
 import pytest
-
 from core.main_system.automation_pipeline import (
     AutomationPipeline,
     PipelineConfig,
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase3_components.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase3_components.py
index b86bd92..db4c9f0 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase3_components.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase3_components.py
@@ -8,13 +8,16 @@ Tests for:
 - ZeroTouchDeploymentEngine
 """
 
-from core.ai_decision_engine import (
-    AIDecisionEngine,
-    ConfidenceLevel,
-    DecisionContext,
-    DecisionOption,
-    DecisionPriority,
-    DecisionType,
+import asyncio
+import os
+import sys
+
+import pytest
+from automation.zero_touch_deployment import (
+    DeploymentEnvironment,
+    DeploymentStatus,
+    DeploymentStrategy,
+    ZeroTouchDeploymentEngine,
 )
 from bridges.language_bridges import (
     BridgeStatus,
@@ -23,17 +26,14 @@ from bridges.language_bridges import (
     Language,
     LanguageBridgeManager,
 )
-from automation.zero_touch_deployment import (
-    DeploymentEnvironment,
-    DeploymentStatus,
-    DeploymentStrategy,
-    ZeroTouchDeploymentEngine,
+from core.ai_decision_engine import (
+    AIDecisionEngine,
+    ConfidenceLevel,
+    DecisionContext,
+    DecisionOption,
+    DecisionPriority,
+    DecisionType,
 )
-import asyncio
-import os
-import sys
-
-import pytest
 
 # Add paths for imports
 sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh")
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase4_components.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase4_components.py
index 94ab696..babf817 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase4_components.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase4_components.py
@@ -7,15 +7,11 @@ Tests for:
 - AutoGovernanceHub
 """
 
-from core.autonomous_trust_engine import (
-    AutonomousTrustEngine,
-    AutonomyLevel,
-    DecisionOutcome,
-    ProposedAction,
-    RiskLevel,
-    SafetyNet,
-    TrustDomain,
-)
+import asyncio
+import os
+import sys
+
+import pytest
 from core.auto_governance_hub import (
     AutoGovernanceHub,
     ChangeRequest,
@@ -25,11 +21,15 @@ from core.auto_governance_hub import (
     PolicyEnforcement,
     PolicyType,
 )
-import asyncio
-import os
-import sys
-
-import pytest
+from core.autonomous_trust_engine import (
+    AutonomousTrustEngine,
+    AutonomyLevel,
+    DecisionOutcome,
+    ProposedAction,
+    RiskLevel,
+    SafetyNet,
+    TrustDomain,
+)
 
 # Add paths for imports
 sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh")
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase5_components.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase5_components.py
index 1eb311e..1bc9b17 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase5_components.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase5_components.py
@@ -7,12 +7,17 @@ Phase 5 focuses on:
 3. Automatic Bug Detection and Fixing
 """
 
-from hallucination_detector import (
-    HallucinationDetection,
-    HallucinationDetector,
-    HallucinationType,
-    SeverityLevel,
-    ValidationResult,
+import os
+import sys
+
+import pytest
+from auto_bug_detector import (
+    AutoBugDetector,
+    BugCategory,
+    BugFix,
+    DetectedBug,
+    FixConfidence,
+    FixStatus,
 )
 from context_understanding_engine import (
     ContextAnalysis,
@@ -21,18 +26,13 @@ from context_understanding_engine import (
     IntentCategory,
     ParsedIntent,
 )
-from auto_bug_detector import (
-    AutoBugDetector,
-    BugCategory,
-    BugFix,
-    DetectedBug,
-    FixConfidence,
-    FixStatus,
+from hallucination_detector import (
+    HallucinationDetection,
+    HallucinationDetector,
+    HallucinationType,
+    SeverityLevel,
+    ValidationResult,
 )
-import os
-import sys
-
-import pytest
 
 # Add core directory to path
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "..", "core"))
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase6_components.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase6_components.py
index e43fa9b..182515e 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase6_components.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase6_components.py
@@ -11,27 +11,21 @@ Tests for all Phase 6 components:
 - GuardrailSystem (è­·æ¬„ç³»çµ±)
 """
 
-from core.ai_constitution.policy_as_prompt import (
-    EnforcementAction,
-    PolicyAsPrompt,
-    PolicyType,
-)
-from core.ai_constitution.operational_rules import (
-    CommunicationRule,
-    DataHandlingRule,
-    OperationalRuleEngine,
-    ResourceUsageRule,
-    RuleCategory,
-    RuleSeverity,
-    SystemAccessRule,
+import asyncio
+import os
+import sys
+
+import pytest
+from core.ai_constitution.adaptive_guidelines import (
+    AdaptiveGuidelineEngine,
+    ContextualGuideline,
+    DomainGuideline,
+    LearningGuideline,
 )
-from core.ai_constitution.guardrails import (
-    ComplianceGuardrail,
-    EthicsGuardrail,
-    GuardrailSeverity,
-    GuardrailSystem,
-    GuardrailType,
-    SafetyGuardrail,
+from core.ai_constitution.constitution_engine import (
+    ActionProposal,
+    ConstitutionEngine,
+    VerdictType,
 )
 from core.ai_constitution.fundamental_laws import (
     EnforcementLevel,
@@ -42,22 +36,28 @@ from core.ai_constitution.fundamental_laws import (
     LawZero,
     ProposedAction,
 )
-from core.ai_constitution.constitution_engine import (
-    ActionProposal,
-    ConstitutionEngine,
-    VerdictType,
+from core.ai_constitution.guardrails import (
+    ComplianceGuardrail,
+    EthicsGuardrail,
+    GuardrailSeverity,
+    GuardrailSystem,
+    GuardrailType,
+    SafetyGuardrail,
 )
-from core.ai_constitution.adaptive_guidelines import (
-    AdaptiveGuidelineEngine,
-    ContextualGuideline,
-    DomainGuideline,
-    LearningGuideline,
+from core.ai_constitution.operational_rules import (
+    CommunicationRule,
+    DataHandlingRule,
+    OperationalRuleEngine,
+    ResourceUsageRule,
+    RuleCategory,
+    RuleSeverity,
+    SystemAccessRule,
+)
+from core.ai_constitution.policy_as_prompt import (
+    EnforcementAction,
+    PolicyAsPrompt,
+    PolicyType,
 )
-import asyncio
-import os
-import sys
-
-import pytest
 
 # Add the project root to the path
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase8_components.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase8_components.py
index 115fee0..040a838 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase8_components.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase8_components.py
@@ -5,6 +5,11 @@
 â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 """
 
+import asyncio
+import os
+import sys
+
+import pytest
 from core.execution_engine import (
     ActionExecutor,
     ActionPlan,
@@ -31,11 +36,6 @@ from core.execution_engine import (
     VerificationResult,
     VerificationStrategy,
 )
-import asyncio
-import os
-import sys
-
-import pytest
 
 # Add parent directory to path for imports
 sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase8_enhancement.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase8_enhancement.py
index 49bf953..a222772 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase8_enhancement.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase8_enhancement.py
@@ -8,16 +8,32 @@ Tests for:
 - Python Bridge
 """
 
-from core.tech_stack.python_bridge import (
-    EnvironmentType,
-    ExecutionMode,
-    PackageManager,
-    PythonBridge,
-    PythonEnvironment,
-    PythonEnvironmentConfig,
-    PythonExecutor,
-    PythonPackage,
-    PythonVersion,
+import asyncio
+import os
+import sys
+
+import pytest
+from core.tech_stack.architecture_config import (
+    ArchitectureLayer,
+    FrameworkCategory,
+    FrameworkConfig,
+    LanguageConfig,
+    LanguageType,
+    TechStackConfig,
+    get_recommended_stack,
+    get_stack_summary,
+)
+from core.tech_stack.framework_integrations import (
+    AgentConfig,
+    AgentType,
+    AutoGenIntegration,
+    CrewAIIntegration,
+    FrameworkCredentials,
+    FrameworkIntegration,
+    FrameworkOrchestrator,
+    FrameworkStatus,
+    LangChainIntegration,
+    LangGraphIntegration,
 )
 from core.tech_stack.multi_agent_coordinator import (
     AgentCapability,
@@ -34,33 +50,17 @@ from core.tech_stack.multi_agent_coordinator import (
     create_devops_agent,
     create_security_agent,
 )
-from core.tech_stack.framework_integrations import (
-    AgentConfig,
-    AgentType,
-    AutoGenIntegration,
-    CrewAIIntegration,
-    FrameworkCredentials,
-    FrameworkIntegration,
-    FrameworkOrchestrator,
-    FrameworkStatus,
-    LangChainIntegration,
-    LangGraphIntegration,
-)
-from core.tech_stack.architecture_config import (
-    ArchitectureLayer,
-    FrameworkCategory,
-    FrameworkConfig,
-    LanguageConfig,
-    LanguageType,
-    TechStackConfig,
-    get_recommended_stack,
-    get_stack_summary,
+from core.tech_stack.python_bridge import (
+    EnvironmentType,
+    ExecutionMode,
+    PackageManager,
+    PythonBridge,
+    PythonEnvironment,
+    PythonEnvironmentConfig,
+    PythonExecutor,
+    PythonPackage,
+    PythonVersion,
 )
-import asyncio
-import os
-import sys
-
-import pytest
 
 # Add the project root to path
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase9_components.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase9_components.py
index 0308927..08e1307 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_phase9_components.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_phase9_components.py
@@ -4,33 +4,19 @@ Tests for Tool System, LangChain Integration, Agent Orchestration,
 Function Calling, and MCP Integration
 """
 
-from core.execution_architecture.tool_system import (
-    Tool,
-    ToolCategory,
-    ToolExecutor,
-    ToolRegistry,
-    ToolResult,
-    ToolStatus,
-    create_api_tool,
-    create_code_tool,
-    create_database_tool,
-)
-from core.execution_architecture.mcp_integration import (
-    MCPBridge,
-    MCPMessageType,
-    MCPServerConfig,
-    MCPTool,
-    MCPToolCall,
-    MCPToolConsumer,
-    MCPToolProvider,
-    MCPToolResult,
-)
-from core.execution_architecture.langchain_integration import (
-    AgentConfig,
-    ChainBuilder,
-    LangChainToolAdapter,
-    LangChainToolFormat,
-    ReActAgentBuilder,
+import asyncio
+import sys
+from datetime import datetime
+
+import pytest
+from core.execution_architecture.agent_orchestration import (
+    AgentOrchestrator,
+    ExecutionContext,
+    ExecutionPlan,
+    ExecutionStep,
+    OrchestratorConfig,
+    StepStatus,
+    TaskPlanner,
 )
 from core.execution_architecture.function_calling import (
     FunctionCallHandler,
@@ -43,20 +29,34 @@ from core.execution_architecture.function_calling import (
     create_code_function,
     create_query_function,
 )
-from core.execution_architecture.agent_orchestration import (
-    AgentOrchestrator,
-    ExecutionContext,
-    ExecutionPlan,
-    ExecutionStep,
-    OrchestratorConfig,
-    StepStatus,
-    TaskPlanner,
+from core.execution_architecture.langchain_integration import (
+    AgentConfig,
+    ChainBuilder,
+    LangChainToolAdapter,
+    LangChainToolFormat,
+    ReActAgentBuilder,
+)
+from core.execution_architecture.mcp_integration import (
+    MCPBridge,
+    MCPMessageType,
+    MCPServerConfig,
+    MCPTool,
+    MCPToolCall,
+    MCPToolConsumer,
+    MCPToolProvider,
+    MCPToolResult,
+)
+from core.execution_architecture.tool_system import (
+    Tool,
+    ToolCategory,
+    ToolExecutor,
+    ToolRegistry,
+    ToolResult,
+    ToolStatus,
+    create_api_tool,
+    create_code_tool,
+    create_database_tool,
 )
-import asyncio
-import sys
-from datetime import datetime
-
-import pytest
 
 sys.path.insert(0, "/home/runner/work/SynergyMesh/SynergyMesh")
 
diff --git a/workspace/teams/holy-grail/agents/autonomous/tests/test_synergymesh_core.py b/workspace/teams/holy-grail/agents/autonomous/tests/test_synergymesh_core.py
index d428283..b621e3a 100644
--- a/workspace/teams/holy-grail/agents/autonomous/tests/test_synergymesh_core.py
+++ b/workspace/teams/holy-grail/agents/autonomous/tests/test_synergymesh_core.py
@@ -9,47 +9,47 @@ Tests for:
 - EcosystemOrchestrator
 """
 
-from machinenativeops_core.orchestration_layer import (
-    IntentUnderstandingEngine,
-    TaskOrchestrationEngine,
-    TaskType,
-    WorkflowStatus,
+import asyncio
+import os
+import sys
+from datetime import datetime
+
+import pytest
+from machinenativeops_core.autonomous_coordinator import (
+    AutonomousCoordinator,
+    SystemHealth,
+    TaskPriority,
+    TaskStatus,
+)
+from machinenativeops_core.ecosystem_orchestrator import (
+    EcosystemOrchestrator,
+    MessagePriority,
+    MessageType,
+    SubsystemStatus,
+    SubsystemType,
+)
+from machinenativeops_core.natural_language_processor import (
+    IntentType,
+    NaturalLanguageProcessor,
+    ParsedIntent,
 )
 from machinenativeops_core.nli_layer import (
     InteractionMode,
     NaturalLanguageInteractionLayer,
     UserIntent,
 )
+from machinenativeops_core.orchestration_layer import (
+    IntentUnderstandingEngine,
+    TaskOrchestrationEngine,
+    TaskType,
+    WorkflowStatus,
+)
 from machinenativeops_core.self_evolution_engine import (
     EvolutionPhase,
     LearningType,
     OptimizationType,
     SelfEvolutionEngine,
 )
-from machinenativeops_core.natural_language_processor import (
-    IntentType,
-    NaturalLanguageProcessor,
-    ParsedIntent,
-)
-from machinenativeops_core.ecosystem_orchestrator import (
-    EcosystemOrchestrator,
-    MessagePriority,
-    MessageType,
-    SubsystemStatus,
-    SubsystemType,
-)
-from machinenativeops_core.autonomous_coordinator import (
-    AutonomousCoordinator,
-    SystemHealth,
-    TaskPriority,
-    TaskStatus,
-)
-import asyncio
-import os
-import sys
-from datetime import datetime
-
-import pytest
 
 # Add the intelligent-automation directory to path for imports
 _current_dir = os.path.dirname(os.path.abspath(__file__))
diff --git a/workspace/teams/holy-grail/agents/pipeline/__init__.py b/workspace/teams/holy-grail/agents/pipeline/__init__.py
index 584b4ac..b69b532 100644
--- a/workspace/teams/holy-grail/agents/pipeline/__init__.py
+++ b/workspace/teams/holy-grail/agents/pipeline/__init__.py
@@ -5,12 +5,6 @@ AI Agents Network for Instant Generation
 6å€‹å°ˆæ¥­åŒ–AIä»£ç†å¯¦ç¾ä¸¦è¡Œè™•ç†ï¼Œæ¯å€‹ä»£ç†å°ˆæ³¨æ–¼ç‰¹å®šé ˜åŸŸ
 """
 
-from .architecture_design_agent import ArchitectureDesignAgent
-from .testing_agent import TestingAgent
-from .optimization_agent import OptimizationAgent
-from .input_analysis_agent import InputAnalysisAgent
-from .deployment_agent import DeploymentAgent
-from .code_generation_agent import CodeGenerationAgent
 import asyncio
 import logging
 from abc import ABC, abstractmethod
@@ -18,6 +12,13 @@ from dataclasses import dataclass
 from enum import Enum
 from typing import Any, Dict, List, Optional
 
+from .architecture_design_agent import ArchitectureDesignAgent
+from .code_generation_agent import CodeGenerationAgent
+from .deployment_agent import DeploymentAgent
+from .input_analysis_agent import InputAnalysisAgent
+from .optimization_agent import OptimizationAgent
+from .testing_agent import TestingAgent
+
 
 class AgentType(Enum):
     """ä»£ç†é¡å‹æšèˆ‰"""
diff --git a/workspace/teams/holy-grail/agents/services/dependency-manager/src/crossplatform/__init__.py b/workspace/teams/holy-grail/agents/services/dependency-manager/src/crossplatform/__init__.py
index 2066e5b..bd1da89 100644
--- a/workspace/teams/holy-grail/agents/services/dependency-manager/src/crossplatform/__init__.py
+++ b/workspace/teams/holy-grail/agents/services/dependency-manager/src/crossplatform/__init__.py
@@ -5,12 +5,27 @@ Cross-platform Integration Module
 Phase 9: Web3ã€IoTã€AR/VR æ•´åˆä»¥åŠé¢¨éšªç®¡æ§ç³»çµ±
 """
 
-from .arvr_integration import ARVRIntegration, ImmersiveExperience, MetaversePlatform, MixedReality
+from .arvr_integration import (
+    ARVRIntegration,
+    ImmersiveExperience,
+    MetaversePlatform,
+    MixedReality,
+)
 from .emergency_response import EmergencyResponse, PlanType, TriggerCondition
-from .iot_integration import DeviceInterconnection, EdgeComputing, Industry40, IoTIntegration
+from .iot_integration import (
+    DeviceInterconnection,
+    EdgeComputing,
+    Industry40,
+    IoTIntegration,
+)
 from .risk_assessment import MitigationStrategy, RiskAssessment, RiskCategory
 from .tech_stack_matrix import StackRecommendation, TechStackMatrix
-from .web3_integration import DAppAssessment, NFTStrategy, SmartContractDev, Web3Integration
+from .web3_integration import (
+    DAppAssessment,
+    NFTStrategy,
+    SmartContractDev,
+    Web3Integration,
+)
 
 __all__ = [
     "Web3Integration",
diff --git a/workspace/teams/holy-grail/agents/services/dependency-manager/src/strategy/__init__.py b/workspace/teams/holy-grail/agents/services/dependency-manager/src/strategy/__init__.py
index 77758f8..df07281 100644
--- a/workspace/teams/holy-grail/agents/services/dependency-manager/src/strategy/__init__.py
+++ b/workspace/teams/holy-grail/agents/services/dependency-manager/src/strategy/__init__.py
@@ -12,7 +12,12 @@ MIT License
 """
 
 from .case_study_engine import CaseStudy, CaseStudyEngine, EvolutionPhase, LessonLearned
-from .evolution_tracker import EvolutionTracker, MaturityLevel, PhaseTransition, ProjectMaturity
+from .evolution_tracker import (
+    EvolutionTracker,
+    MaturityLevel,
+    PhaseTransition,
+    ProjectMaturity,
+)
 from .resource_optimizer import (
     BudgetAllocation,
     OptimizationResult,
diff --git a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_models.py b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_models.py
index 91de417..d8a4d21 100644
--- a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_models.py
+++ b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_models.py
@@ -3,13 +3,13 @@
 Tests for Dependency Manager Agent
 """
 
-from models.vulnerability import Vulnerability, VulnerabilitySeverity
-from models.update import Update, UpdateResult, UpdateStatus, UpdateType
-from models.dependency import Dependency, DependencyAnalysis, DependencyType, Ecosystem
 import sys
 from pathlib import Path
 
 import pytest
+from models.dependency import Dependency, DependencyAnalysis, DependencyType, Ecosystem
+from models.update import Update, UpdateResult, UpdateStatus, UpdateType
+from models.vulnerability import Vulnerability, VulnerabilitySeverity
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
diff --git a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase10.py b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase10.py
index a483c2e..5e471dd 100644
--- a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase10.py
+++ b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase10.py
@@ -310,7 +310,11 @@ class TestActionGuide(unittest.TestCase):
 
     def test_recommendation_creation(self):
         """æ¸¬è©¦å»ºè­°å‰µå»º"""
-        from implementation.action_guide import ActionPriority, Recommendation, RecommendationType
+        from implementation.action_guide import (
+            ActionPriority,
+            Recommendation,
+            RecommendationType,
+        )
 
         rec = Recommendation(
             id="rec_1",
diff --git a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase2.py b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase2.py
index 9a893e6..f87856c 100644
--- a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase2.py
+++ b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase2.py
@@ -3,17 +3,17 @@
 Phase 2 Tests - Analyzers and Utils
 """
 
-from utils.dependency_tree import DependencyTree, RiskLevel
-from utils.audit_logger import AuditEventType, AuditLogger, AuditSeverity
-from models.dependency import Dependency, DependencyType, Ecosystem
-from analyzers.pip_analyzer import PipAnalyzer
-from analyzers.go_analyzer import GoAnalyzer
 import os
 import sys
 import tempfile
 from pathlib import Path
 
 import pytest
+from analyzers.go_analyzer import GoAnalyzer
+from analyzers.pip_analyzer import PipAnalyzer
+from models.dependency import Dependency, DependencyType, Ecosystem
+from utils.audit_logger import AuditEventType, AuditLogger, AuditSeverity
+from utils.dependency_tree import DependencyTree, RiskLevel
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
diff --git a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase3.py b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase3.py
index 6696a83..fc0ef90 100644
--- a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase3.py
+++ b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase3.py
@@ -3,12 +3,12 @@
 Phase 3 Tests - Policy Simulator and Language Boundary
 """
 
-from utils.policy_simulator import (
-    PolicySimulator,
-    SimulationMode,
-    SimulationResult,
-    SimulationScenario,
-)
+import sys
+from pathlib import Path
+
+import pytest
+from models.dependency import Dependency, DependencyAnalysis, DependencyType, Ecosystem
+from models.update import UpdatePolicy
 from utils.language_boundary import (
     LanguageBoundary,
     LanguageRegistry,
@@ -17,12 +17,12 @@ from utils.language_boundary import (
     msg,
     t,
 )
-from models.update import UpdatePolicy
-from models.dependency import Dependency, DependencyAnalysis, DependencyType, Ecosystem
-import sys
-from pathlib import Path
-
-import pytest
+from utils.policy_simulator import (
+    PolicySimulator,
+    SimulationMode,
+    SimulationResult,
+    SimulationScenario,
+)
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
diff --git a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase4.py b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase4.py
index 2c49e48..76440e4 100644
--- a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase4.py
+++ b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase4.py
@@ -8,17 +8,15 @@ Phase 4 ä¼æ¥­ç´šåŠŸèƒ½å–®å…ƒæ¸¬è©¦
 - ä¸‹ä¸–ä»£å®‰å…¨æ¨¡çµ„
 """
 
-from enterprise.security import (
-    ComplianceFramework,
-    NextGenSecurity,
-    SBOMFormat,
-    SupplyChainRisk,
-    TrustLevel,
-)
-from enterprise.recommendation import (
-    IntelligentRecommendation,
-    RecommendationType,
-    RiskLevel,
+import os
+import sys
+import unittest
+
+from enterprise.analytics import (
+    CommercialAnalytics,
+    CostCategory,
+    TechDebtItem,
+    TechDebtType,
 )
 from enterprise.integration import (
     AuthMethod,
@@ -27,15 +25,18 @@ from enterprise.integration import (
     IntegrationType,
     WebhookEvent,
 )
-from enterprise.analytics import (
-    CommercialAnalytics,
-    CostCategory,
-    TechDebtItem,
-    TechDebtType,
+from enterprise.recommendation import (
+    IntelligentRecommendation,
+    RecommendationType,
+    RiskLevel,
+)
+from enterprise.security import (
+    ComplianceFramework,
+    NextGenSecurity,
+    SBOMFormat,
+    SupplyChainRisk,
+    TrustLevel,
 )
-import os
-import sys
-import unittest
 
 # æ·»åŠ è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
diff --git a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase5.py b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase5.py
index 0cc0cad..0aadb8c 100644
--- a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase5.py
+++ b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase5.py
@@ -11,22 +11,19 @@ Copyright (c) 2024 SynergyMesh
 MIT License
 """
 
-from strategy.strategy_advisor import (
-    CapabilityLevel,
-    MarketMaturity,
-    MarketTimingAnalysis,
-    StrategicPriority,
-    StrategyAdvisor,
-    StrategyRecommendation,
-    TechCapability,
-    TechCapabilityAssessment,
-)
-from strategy.resource_optimizer import (
-    AllocationStrategy,
-    BudgetAllocation,
-    OptimizationResult,
-    ResourceOptimizer,
-    TeamAllocation,
+import os
+
+# æ¨¡æ“¬å°å…¥ï¼ˆæ¸¬è©¦æ™‚éœ€è¦ç¢ºä¿è·¯å¾‘æ­£ç¢ºï¼‰
+import sys
+import unittest
+from datetime import datetime
+
+from strategy.case_study_engine import (
+    CaseStudy,
+    CaseStudyEngine,
+    DevelopmentStrategy,
+    EvolutionPhase,
+    PhaseType,
 )
 from strategy.evolution_tracker import (
     DevelopmentPhase,
@@ -36,19 +33,23 @@ from strategy.evolution_tracker import (
     PhaseTransition,
     ProjectMaturity,
 )
-from strategy.case_study_engine import (
-    CaseStudy,
-    CaseStudyEngine,
-    DevelopmentStrategy,
-    EvolutionPhase,
-    PhaseType,
+from strategy.resource_optimizer import (
+    AllocationStrategy,
+    BudgetAllocation,
+    OptimizationResult,
+    ResourceOptimizer,
+    TeamAllocation,
+)
+from strategy.strategy_advisor import (
+    CapabilityLevel,
+    MarketMaturity,
+    MarketTimingAnalysis,
+    StrategicPriority,
+    StrategyAdvisor,
+    StrategyRecommendation,
+    TechCapability,
+    TechCapabilityAssessment,
 )
-import os
-
-# æ¨¡æ“¬å°å…¥ï¼ˆæ¸¬è©¦æ™‚éœ€è¦ç¢ºä¿è·¯å¾‘æ­£ç¢ºï¼‰
-import sys
-import unittest
-from datetime import datetime
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
diff --git a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase7.py b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase7.py
index 668197b..d619b03 100644
--- a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase7.py
+++ b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase7.py
@@ -4,7 +4,11 @@ Phase 7 æ¸¬è©¦ - SMART-V è©•ä¼°æ¡†æ¶
 æ¸¬è©¦ SMART-V é‡åŒ–è©•ä¼°ç³»çµ±çš„å„é …åŠŸèƒ½ã€‚
 """
 
-from evaluation.weight_config import CompanyStage, WeightConfigManager
+import os
+import sys
+import unittest
+
+from evaluation.evaluation_report import EvaluationReportGenerator
 from evaluation.smartv_framework import (
     AchievabilityEvaluator,
     EvaluationDimension,
@@ -15,10 +19,7 @@ from evaluation.smartv_framework import (
     TechnologyMaturityEvaluator,
     ValueCreationEvaluator,
 )
-from evaluation.evaluation_report import EvaluationReportGenerator
-import os
-import sys
-import unittest
+from evaluation.weight_config import CompanyStage, WeightConfigManager
 
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
diff --git a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase8.py b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase8.py
index 2ab81a3..7c66c93 100644
--- a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase8.py
+++ b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase8.py
@@ -3,25 +3,26 @@ Phase 8 å–®å…ƒæ¸¬è©¦
 Tests for Advanced Prompt Combination Strategy Modules
 """
 
-from combination.quarterly_review import (
-    QuarterlyReviewEngine,
-    ReviewCategory,
-    ReviewStatus,
+import sys
+import unittest
+from pathlib import Path
+
+from combination.combination_templates import (
+    CombinationTemplateManager,
+    CompanyStage,
+)
+from combination.core_satellite import (
+    CoreSatelliteArchitecture,
 )
 from combination.dynamic_adjuster import (
     AdjustmentTrigger,
     DynamicAdjuster,
 )
-from combination.core_satellite import (
-    CoreSatelliteArchitecture,
-)
-from combination.combination_templates import (
-    CombinationTemplateManager,
-    CompanyStage,
+from combination.quarterly_review import (
+    QuarterlyReviewEngine,
+    ReviewCategory,
+    ReviewStatus,
 )
-import sys
-import unittest
-from pathlib import Path
 
 sys.path.insert(0, str(Path(__file__).resolve().parents[1] / "src"))
 
diff --git a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase9.py b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase9.py
index 62ee387..0ab6faa 100644
--- a/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase9.py
+++ b/workspace/teams/holy-grail/agents/services/dependency-manager/tests/test_phase9.py
@@ -3,23 +3,24 @@ Phase 9 å–®å…ƒæ¸¬è©¦
 Cross-platform Integration & Risk Management Tests
 """
 
-from crossplatform.web3_integration import (
-    BlockchainType,
-    ConsensusType,
-    DAppAssessment,
-    NFTAssetType,
-    NFTStrategy,
-    SmartContractDev,
-    Web3Integration,
+import os
+import sys
+import unittest
+
+from crossplatform.arvr_integration import (
+    ARVRIntegration,
+    HardwareRequirement,
+    ImmersiveExperience,
+    InteractionMode,
+    MetaversePlatform,
+    MixedReality,
+    XRType,
 )
-from crossplatform.tech_stack_matrix import (
-    BackendArch,
-    DataProcessing,
-    DeploymentStrategy,
-    FrontendTech,
-    TechStackMatrix,
+from crossplatform.emergency_response import (
+    EmergencyResponse,
+    PlanType,
+    TriggerCategory,
 )
-from crossplatform.risk_assessment import RiskAssessment, RiskCategory, RiskType
 from crossplatform.iot_integration import (
     DeviceInterconnection,
     EdgeComputing,
@@ -29,23 +30,23 @@ from crossplatform.iot_integration import (
     IoTIntegration,
     IoTProtocol,
 )
-from crossplatform.emergency_response import (
-    EmergencyResponse,
-    PlanType,
-    TriggerCategory,
+from crossplatform.risk_assessment import RiskAssessment, RiskCategory, RiskType
+from crossplatform.tech_stack_matrix import (
+    BackendArch,
+    DataProcessing,
+    DeploymentStrategy,
+    FrontendTech,
+    TechStackMatrix,
 )
-from crossplatform.arvr_integration import (
-    ARVRIntegration,
-    HardwareRequirement,
-    ImmersiveExperience,
-    InteractionMode,
-    MetaversePlatform,
-    MixedReality,
-    XRType,
+from crossplatform.web3_integration import (
+    BlockchainType,
+    ConsensusType,
+    DAppAssessment,
+    NFTAssetType,
+    NFTStrategy,
+    SmartContractDev,
+    Web3Integration,
 )
-import os
-import sys
-import unittest
 
 # æ·»åŠ è·¯å¾‘
 sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
diff --git a/workspace/teams/holy-grail/automation/architect/core/orchestration/pipeline.py b/workspace/teams/holy-grail/automation/architect/core/orchestration/pipeline.py
index 003609a..ebd5591 100644
--- a/workspace/teams/holy-grail/automation/architect/core/orchestration/pipeline.py
+++ b/workspace/teams/holy-grail/automation/architect/core/orchestration/pipeline.py
@@ -14,7 +14,12 @@ except ImportError:
 
     logger = logging.getLogger(__name__)
 
-from ..analysis import ArchitectureAnalyzer, PerformanceAnalyzer, SecurityScanner, StaticAnalyzer
+from ..analysis import (
+    ArchitectureAnalyzer,
+    PerformanceAnalyzer,
+    SecurityScanner,
+    StaticAnalyzer,
+)
 from ..repair import ASTTransformer, RepairVerifier, RuleEngine
 
 
diff --git a/workspace/teams/holy-grail/automation/architect/examples/basic_usage.py b/workspace/teams/holy-grail/automation/architect/examples/basic_usage.py
index f80dfb6..f32558b 100644
--- a/workspace/teams/holy-grail/automation/architect/examples/basic_usage.py
+++ b/workspace/teams/holy-grail/automation/architect/examples/basic_usage.py
@@ -5,11 +5,12 @@ Basic Usage Example
 æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Automation Architect ç³»çµ±é€²è¡Œä»£ç¢¼åˆ†æ
 """
 
-from core.orchestration.pipeline import AnalysisPipeline
 import asyncio
 import sys
 from pathlib import Path
 
+from core.orchestration.pipeline import AnalysisPipeline
+
 # æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘ä»¥ä¾¿å°å…¥
 sys.path.insert(0, str(Path(__file__).parent.parent))
 
diff --git a/workspace/teams/holy-grail/automation/architect/tests/unit/test_security_scanner.py b/workspace/teams/holy-grail/automation/architect/tests/unit/test_security_scanner.py
index 854c163..37e6e0e 100644
--- a/workspace/teams/holy-grail/automation/architect/tests/unit/test_security_scanner.py
+++ b/workspace/teams/holy-grail/automation/architect/tests/unit/test_security_scanner.py
@@ -3,12 +3,12 @@ Unit tests for SecurityScanner
 å®‰å…¨æƒæå™¨å–®å…ƒæ¸¬è©¦
 """
 
-from core.analysis.security_scanner import SecurityIssue, SecurityScanner
 import sys
 import tempfile
 from pathlib import Path
 
 import pytest
+from core.analysis.security_scanner import SecurityIssue, SecurityScanner
 
 sys.path.insert(0, str(Path(__file__).parent.parent.parent))
 
diff --git a/workspace/teams/holy-grail/automation/architect/tests/unit/test_static_analyzer.py b/workspace/teams/holy-grail/automation/architect/tests/unit/test_static_analyzer.py
index 6a69e4d..7f23318 100644
--- a/workspace/teams/holy-grail/automation/architect/tests/unit/test_static_analyzer.py
+++ b/workspace/teams/holy-grail/automation/architect/tests/unit/test_static_analyzer.py
@@ -3,12 +3,12 @@ Unit tests for StaticAnalyzer
 éœæ…‹åˆ†æå™¨å–®å…ƒæ¸¬è©¦
 """
 
-from core.analysis.static_analyzer import AnalysisResult, StaticAnalyzer
 import sys
 import tempfile
 from pathlib import Path
 
 import pytest
+from core.analysis.static_analyzer import AnalysisResult, StaticAnalyzer
 
 # æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
 sys.path.insert(0, str(Path(__file__).parent.parent.parent))
diff --git a/workspace/teams/holy-grail/legacy-archive/v1-python-drones/main.py b/workspace/teams/holy-grail/legacy-archive/v1-python-drones/main.py
index 32234d5..297cb66 100644
--- a/workspace/teams/holy-grail/legacy-archive/v1-python-drones/main.py
+++ b/workspace/teams/holy-grail/legacy-archive/v1-python-drones/main.py
@@ -5,12 +5,13 @@ SynergyMesh v1-python-drones ä¸»åŸ·è¡Œå…¥å£
 Python ç„¡äººæ©Ÿç³»çµ±çš„ä¸»è¦å…¥å£é»ï¼Œæä¾›å‘½ä»¤è¡Œä»‹é¢ã€‚
 """
 
-from utils import Colors, print_error, print_info, print_success
-from drones import AutopilotDrone, CoordinatorDrone, DeploymentDrone
 import argparse
 import sys
 from pathlib import Path
 
+from drones import AutopilotDrone, CoordinatorDrone, DeploymentDrone
+from utils import Colors, print_error, print_info, print_success
+
 # ç¢ºä¿å¯ä»¥å°å…¥æœ¬åœ°æ¨¡çµ„
 _current_dir = Path(__file__).resolve().parent
 sys.path.insert(0, str(_current_dir))
diff --git a/workspace/teams/holy-grail/legacy-archive/v1-python-drones/utils/__init__.py b/workspace/teams/holy-grail/legacy-archive/v1-python-drones/utils/__init__.py
index 3ad15ed..f7ea016 100644
--- a/workspace/teams/holy-grail/legacy-archive/v1-python-drones/utils/__init__.py
+++ b/workspace/teams/holy-grail/legacy-archive/v1-python-drones/utils/__init__.py
@@ -2,7 +2,14 @@
 å·¥å…·æ¨¡çµ„
 """
 
-from .helpers import Colors, print_color, print_error, print_info, print_success, print_warn
+from .helpers import (
+    Colors,
+    print_color,
+    print_error,
+    print_info,
+    print_success,
+    print_warn,
+)
 
 __all__ = [
     "Colors",
diff --git a/workspace/teams/holy-grail/legacy-archive/v2-multi-islands/main.py b/workspace/teams/holy-grail/legacy-archive/v2-multi-islands/main.py
index be705fd..3e2528c 100644
--- a/workspace/teams/holy-grail/legacy-archive/v2-multi-islands/main.py
+++ b/workspace/teams/holy-grail/legacy-archive/v2-multi-islands/main.py
@@ -5,13 +5,14 @@ SynergyMesh v2-multi-islands ä¸»åŸ·è¡Œå…¥å£
 å¤šèªè¨€è‡ªå‹•åŒ–ç„¡äººä¹‹å³¶ç³»çµ±çš„ä¸»è¦å…¥å£é»ï¼Œæä¾›å‘½ä»¤è¡Œä»‹é¢ã€‚
 """
 
-from utils import Colors, print_error, print_info, print_success
-from orchestrator import IslandOrchestrator
-from islands import GoIsland, JavaIsland, PythonIsland, RustIsland, TypeScriptIsland
 import argparse
 import sys
 from pathlib import Path
 
+from islands import GoIsland, JavaIsland, PythonIsland, RustIsland, TypeScriptIsland
+from orchestrator import IslandOrchestrator
+from utils import Colors, print_error, print_info, print_success
+
 # ç¢ºä¿å¯ä»¥å°å…¥æœ¬åœ°æ¨¡çµ„
 _current_dir = Path(__file__).resolve().parent
 sys.path.insert(0, str(_current_dir))
diff --git a/workspace/teams/holy-grail/legacy-archive/v2-multi-islands/orchestrator/island_orchestrator.py b/workspace/teams/holy-grail/legacy-archive/v2-multi-islands/orchestrator/island_orchestrator.py
index b3a17ab..cd0e67b 100644
--- a/workspace/teams/holy-grail/legacy-archive/v2-multi-islands/orchestrator/island_orchestrator.py
+++ b/workspace/teams/holy-grail/legacy-archive/v2-multi-islands/orchestrator/island_orchestrator.py
@@ -6,13 +6,14 @@ SynergyMesh å³¶å¶¼å”èª¿å™¨ (Island Orchestrator)
 å°æ‡‰ config/dev/automation/drone-coordinator.py
 """
 
-from utils import print_error, print_info, print_success
 import subprocess
 import sys
 from datetime import datetime
 from pathlib import Path
 from typing import Any
 
+from utils import print_error, print_info, print_success
+
 _current_dir = Path(__file__).resolve().parent
 sys.path.insert(0, str(_current_dir.parent))
 
diff --git a/workspace/teams/holy-grail/legacy-archive/v2-multi-islands/utils/__init__.py b/workspace/teams/holy-grail/legacy-archive/v2-multi-islands/utils/__init__.py
index 3ad15ed..f7ea016 100644
--- a/workspace/teams/holy-grail/legacy-archive/v2-multi-islands/utils/__init__.py
+++ b/workspace/teams/holy-grail/legacy-archive/v2-multi-islands/utils/__init__.py
@@ -2,7 +2,14 @@
 å·¥å…·æ¨¡çµ„
 """
 
-from .helpers import Colors, print_color, print_error, print_info, print_success, print_warn
+from .helpers import (
+    Colors,
+    print_color,
+    print_error,
+    print_info,
+    print_success,
+    print_warn,
+)
 
 __all__ = [
     "Colors",
diff --git a/workspace/tests/quantum/test_repositories.py b/workspace/tests/quantum/test_repositories.py
index 520db79..6361136 100644
--- a/workspace/tests/quantum/test_repositories.py
+++ b/workspace/tests/quantum/test_repositories.py
@@ -7,7 +7,13 @@ import tempfile
 from pathlib import Path
 
 import pytest
-from backend.python.core.entities import Task, TaskStatus, TaskType, Workflow, WorkflowStatus
+from backend.python.core.entities import (
+    Task,
+    TaskStatus,
+    TaskType,
+    Workflow,
+    WorkflowStatus,
+)
 from backend.python.repositories.workflow_repository import WorkflowRepository
 
 
diff --git a/workspace/tests/test_enterprise_integration.py b/workspace/tests/test_enterprise_integration.py
index 51affea..299efe1 100644
--- a/workspace/tests/test_enterprise_integration.py
+++ b/workspace/tests/test_enterprise_integration.py
@@ -11,6 +11,11 @@
 6. æ€§èƒ½å’Œå¯æ“´å±•æ€§æ¸¬è©¦
 """
 
+import asyncio
+import sys
+from pathlib import Path
+
+import pytest
 from core.orchestrators import (
     ComponentType,
     DependencyResolver,
@@ -18,11 +23,6 @@ from core.orchestrators import (
     ExecutionStatus,
     TenantTier,
 )
-import asyncio
-import sys
-from pathlib import Path
-
-import pytest
 
 # æ·»åŠ  src åˆ°è·¯å¾‘
 project_root = Path(__file__).parent.parent
diff --git a/workspace/tests/test_enterprise_orchestrator.py b/workspace/tests/test_enterprise_orchestrator.py
index ba34698..c9165c0 100644
--- a/workspace/tests/test_enterprise_orchestrator.py
+++ b/workspace/tests/test_enterprise_orchestrator.py
@@ -10,6 +10,12 @@ Enterprise SynergyMesh Orchestrator å•å…ƒæµ‹è¯•
 - å®¡è®¡æ—¥å¿—
 """
 
+import asyncio
+import sys
+from datetime import datetime
+from pathlib import Path
+
+import pytest
 from core.orchestrators import (
     ComponentType,
     DependencyResolver,
@@ -19,12 +25,6 @@ from core.orchestrators import (
     RetryPolicy,
     TenantTier,
 )
-import asyncio
-import sys
-from datetime import datetime
-from pathlib import Path
-
-import pytest
 
 # æ·»åŠ  src åˆ°è·¯å¾„
 project_root = Path(__file__).parent.parent
diff --git a/workspace/tests/test_performance_benchmarks.py b/workspace/tests/test_performance_benchmarks.py
index 287355e..e2cc3e9 100644
--- a/workspace/tests/test_performance_benchmarks.py
+++ b/workspace/tests/test_performance_benchmarks.py
@@ -16,18 +16,18 @@
 - å…§å­˜é–‹éŠ·: < 5%
 """
 
-from core.orchestrators import (
-    DependencyResolver,
-    EnterpriseSynergyMeshOrchestrator,
-    RetryPolicy,
-    TenantTier,
-)
 import asyncio
 import sys
 import time
 from pathlib import Path
 
 import pytest
+from core.orchestrators import (
+    DependencyResolver,
+    EnterpriseSynergyMeshOrchestrator,
+    RetryPolicy,
+    TenantTier,
+)
 
 # æ·»åŠ  src åˆ°è·¯å¾‘
 project_root = Path(__file__).parent.parent
diff --git a/workspace/tests/test_refactoring_integration.py b/workspace/tests/test_refactoring_integration.py
index de1f390..521e12b 100644
--- a/workspace/tests/test_refactoring_integration.py
+++ b/workspace/tests/test_refactoring_integration.py
@@ -5,10 +5,11 @@
 é©—è­‰ v1-python-drones å’Œ v2-multi-islands é‡æ§‹å¾Œçš„æ•´åˆæƒ…æ³
 """
 
-import pytest
 import sys
 from pathlib import Path
 
+import pytest
+
 # æ·»åŠ  src ç›®éŒ„åˆ°è·¯å¾‘
 project_root = Path(__file__).parent.parent
 sys.path.insert(0, str(project_root / "src"))
@@ -113,7 +114,9 @@ class TestIslandSystemConversion:
 
     def test_language_island_orchestrator_import(self):
         """æ¸¬è©¦ LanguageIslandOrchestrator å°å…¥"""
-        from core.orchestrators.language_island_orchestrator import LanguageIslandOrchestrator
+        from core.orchestrators.language_island_orchestrator import (
+            LanguageIslandOrchestrator,
+        )
 
         assert LanguageIslandOrchestrator is not None
 
diff --git a/workspace/tests/test_tool_executor_validation.py b/workspace/tests/test_tool_executor_validation.py
index 23aaf95..700307f 100644
--- a/workspace/tests/test_tool_executor_validation.py
+++ b/workspace/tests/test_tool_executor_validation.py
@@ -3,14 +3,15 @@
 Tests for CodeRunner validation logic - context-aware security checks
 """
 
+import sys
+from pathlib import Path
+
+import pytest
 from core.island_ai_runtime.tool_executor import (
     CodeRunner,
     ExecutionRequest,
     ToolType,
 )
-import pytest
-import sys
-from pathlib import Path
 
 # Add src to path for imports
 sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
diff --git a/workspace/tests/test_unified_pipeline_loader.py b/workspace/tests/test_unified_pipeline_loader.py
index ec45031..a8559a6 100644
--- a/workspace/tests/test_unified_pipeline_loader.py
+++ b/workspace/tests/test_unified_pipeline_loader.py
@@ -12,6 +12,11 @@ Tests for 00-namespaces/namespaces-mcp/tools/load_unified_pipeline.py
 5. INSTANT mode detection
 """
 
+import sys
+from dataclasses import dataclass
+from pathlib import Path
+
+import pytest
 from load_unified_pipeline import (
     MANIFEST_PATH,
     CoreScheduling,
@@ -33,11 +38,6 @@ from load_unified_pipeline import (
     validate_latency_compliance,
     validate_parallelism,
 )
-import sys
-from dataclasses import dataclass
-from pathlib import Path
-
-import pytest
 
 # Add namespaces-mcp/tools to path
 project_root = Path(__file__).parent.parent
diff --git a/workspace/tests/unit/test_enterprise_iam_sso.py b/workspace/tests/unit/test_enterprise_iam_sso.py
index 9bf4ae8..9a6e07b 100644
--- a/workspace/tests/unit/test_enterprise_iam_sso.py
+++ b/workspace/tests/unit/test_enterprise_iam_sso.py
@@ -12,14 +12,6 @@ covering security-critical scenarios including:
 - Malformed JWT detection
 """
 
-from enterprise.iam.sso import (
-    HTTPClient,
-    MembershipRepository,
-    SSOManager,
-    SSORepository,
-    UserRepository,
-)
-from enterprise.iam.models import Role, SSOConfig
 import sys
 from datetime import datetime, timedelta
 from pathlib import Path
@@ -27,6 +19,14 @@ from unittest.mock import AsyncMock, Mock, patch
 
 import jwt
 import pytest
+from enterprise.iam.models import Role, SSOConfig
+from enterprise.iam.sso import (
+    HTTPClient,
+    MembershipRepository,
+    SSOManager,
+    SSORepository,
+    UserRepository,
+)
 from jwt.exceptions import DecodeError
 
 # Add src to path
diff --git a/workspace/tools/ai-auto-fix.py b/workspace/tools/ai-auto-fix.py
index 7563851..494c817 100755
--- a/workspace/tools/ai-auto-fix.py
+++ b/workspace/tools/ai-auto-fix.py
@@ -69,7 +69,9 @@ class ArtifactLoader:
         print("ğŸ“¥ Loading analysis artifacts...")
 
         # Load governance report
-        gov_report = self.artifacts_dir / "language-governance-report" / "governance-report.json"
+        gov_report = (
+            self.artifacts_dir / "language-governance-report" / "governance-report.json"
+        )
         if gov_report.exists():
             with open(gov_report, encoding="utf-8") as f:
                 self.governance_data = json.load(f)
@@ -90,14 +92,19 @@ class ArtifactLoader:
                 with open(sarif_file, encoding="utf-8") as f:
                     data = json.load(f)
                     self.codeql_data.append(
-                        {"language": codeql_dir.name.replace("codeql-results-", ""), "data": data}
+                        {
+                            "language": codeql_dir.name.replace("codeql-results-", ""),
+                            "data": data,
+                        }
                     )
         if self.codeql_data:
             print(f"âœ“ Loaded {len(self.codeql_data)} CodeQL report(s)")
 
         # Load AI suggestions
         ai_suggestions_file = (
-            self.artifacts_dir / "consolidated-security-report" / "ai-refactor-suggestions.md"
+            self.artifacts_dir
+            / "consolidated-security-report"
+            / "ai-refactor-suggestions.md"
         )
         if ai_suggestions_file.exists():
             with open(ai_suggestions_file, encoding="utf-8") as f:
@@ -181,7 +188,9 @@ class AIFixGenerator:
         if self.available:
             print("âœ“ Guardrails/OpenAI client configured")
         else:
-            print("âš ï¸  AI client not available. Fixes will be limited to rule-based suggestions.")
+            print(
+                "âš ï¸  AI client not available. Fixes will be limited to rule-based suggestions."
+            )
 
     def generate_fixes(self, issues: list[dict], repo_root: str) -> list[dict]:
         """Generate fixes for the given issues"""
@@ -197,7 +206,9 @@ class AIFixGenerator:
 
         # Generate fixes for governance issues (these are often file movements)
         if "governance" in by_type:
-            fixes.extend(self._generate_governance_fixes(by_type["governance"], repo_root))
+            fixes.extend(
+                self._generate_governance_fixes(by_type["governance"], repo_root)
+            )
 
         # Generate fixes for security issues (code changes)
         if "semgrep" in by_type or "codeql" in by_type:
@@ -205,11 +216,15 @@ class AIFixGenerator:
             if self.available:
                 fixes.extend(self._generate_ai_fixes(security_issues, repo_root))
             else:
-                fixes.extend(self._generate_rule_based_fixes(security_issues, repo_root))
+                fixes.extend(
+                    self._generate_rule_based_fixes(security_issues, repo_root)
+                )
 
         return fixes
 
-    def _generate_governance_fixes(self, issues: list[dict], repo_root: str) -> list[dict]:
+    def _generate_governance_fixes(
+        self, issues: list[dict], repo_root: str
+    ) -> list[dict]:
         """Generate fixes for governance violations"""
         fixes = []
 
@@ -298,7 +313,9 @@ Please provide a fix for this issue. Output as JSON with:
 
         return fixes
 
-    def _generate_rule_based_fixes(self, issues: list[dict], repo_root: str) -> list[dict]:
+    def _generate_rule_based_fixes(
+        self, issues: list[dict], repo_root: str
+    ) -> list[dict]:
         """Generate rule-based fixes when AI is not available"""
         fixes = []
 
@@ -365,7 +382,9 @@ class PatchGenerator:
         lines.append(
             "This PR was automatically generated by the AI Auto-Fix Bot to address violations"
         )
-        lines.append("detected by the Language Governance, CodeQL, and Semgrep workflows.")
+        lines.append(
+            "detected by the Language Governance, CodeQL, and Semgrep workflows."
+        )
         lines.append("")
         lines.append("## Summary")
         lines.append("")
@@ -405,10 +424,14 @@ class PatchGenerator:
 
         lines.append("## Notes")
         lines.append("")
-        lines.append("This PR was generated automatically. Please review carefully before merging.")
+        lines.append(
+            "This PR was generated automatically. Please review carefully before merging."
+        )
         lines.append("")
         lines.append("---")
-        lines.append(f"*Generated at {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}*")
+        lines.append(
+            f"*Generated at {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}*"
+        )
 
         # Write to file
         with open(self.output_dir / "pr-description.md", "w", encoding="utf-8") as f:
diff --git a/workspace/tools/ai-refactor-review.py b/workspace/tools/ai-refactor-review.py
index 1f10f61..deef6fd 100755
--- a/workspace/tools/ai-refactor-review.py
+++ b/workspace/tools/ai-refactor-review.py
@@ -107,7 +107,9 @@ class RuleBasedSuggestionGenerator:
                     "title": "Language Policy Violations",
                     "severity": "ERROR",
                     "count": len(violations_list),
-                    "suggestion": self._generate_language_migration_advice(violations_list),
+                    "suggestion": self._generate_language_migration_advice(
+                        violations_list
+                    ),
                 }
             )
 
@@ -147,10 +149,16 @@ class RuleBasedSuggestionGenerator:
 
             # Specific suggestions based on language
             if lang == "JavaScript":
-                advice.append("- **Recommendation**: Convert to TypeScript for type safety")
-                advice.append("- **Tool**: Use `tsc` compiler or automated migration tools")
+                advice.append(
+                    "- **Recommendation**: Convert to TypeScript for type safety"
+                )
+                advice.append(
+                    "- **Tool**: Use `tsc` compiler or automated migration tools"
+                )
             elif lang == "Python":
-                advice.append("- **Recommendation**: Ensure Python is allowed in this directory")
+                advice.append(
+                    "- **Recommendation**: Ensure Python is allowed in this directory"
+                )
                 advice.append(
                     "- **Check**: Review `config/language-policy.yaml` for directory rules"
                 )
@@ -173,7 +181,9 @@ class RuleBasedSuggestionGenerator:
         for lang, vlist in by_lang.items():
             advice.append(f"**{lang} is Globally Forbidden ({len(vlist)} files)**:")
             advice.append(f"- **Critical Action**: Remove all {lang} files immediately")
-            advice.append(f"- **Files**: {', '.join([v.get('file', '') for v in vlist[:5]])}")
+            advice.append(
+                f"- **Files**: {', '.join([v.get('file', '') for v in vlist[:5]])}"
+            )
             if len(vlist) > 5:
                 advice.append(f"- ... and {len(vlist) - 5} more files")
             advice.append("")
@@ -313,7 +323,9 @@ class AIRefactorReviewer:
             if violations:
                 parts.append(f"## Language Governance Violations ({len(violations)})\n")
                 for v in violations[:20]:  # Top 20
-                    parts.append(f"- {v.get('severity', 'UNKNOWN')}: {v.get('message', '')}")
+                    parts.append(
+                        f"- {v.get('severity', 'UNKNOWN')}: {v.get('message', '')}"
+                    )
                     parts.append(f"  File: {v.get('file', '')}")
                 if len(violations) > 20:
                     parts.append(f"... and {len(violations) - 20} more violations")
@@ -356,7 +368,9 @@ class AIRefactorReviewer:
         # Header
         lines.append("# ğŸ¤– AI-Powered Refactoring Suggestions")
         lines.append("")
-        lines.append(f"**Generated:** {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}")
+        lines.append(
+            f"**Generated:** {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}"
+        )
         lines.append("")
         lines.append("---")
         lines.append("")
@@ -379,7 +393,9 @@ class AIRefactorReviewer:
 
         lines.append(f"**Total Issues Detected:** {total_issues}")
         lines.append("")
-        lines.append("This report provides AI-powered and rule-based suggestions for addressing:")
+        lines.append(
+            "This report provides AI-powered and rule-based suggestions for addressing:"
+        )
         lines.append("- Language governance violations")
         lines.append("- Security vulnerabilities")
         lines.append("- Code quality issues")
@@ -394,10 +410,14 @@ class AIRefactorReviewer:
         if self.governance_data:
             violations = self.governance_data.get("violations", [])
             if violations:
-                suggestions = self.rule_generator.generate_language_suggestions(violations)
+                suggestions = self.rule_generator.generate_language_suggestions(
+                    violations
+                )
                 for sugg in suggestions:
                     emoji = "ğŸ”´" if sugg["severity"] == "CRITICAL" else "âš ï¸"
-                    lines.append(f"### {emoji} {sugg['title']} ({sugg['count']} issues)")
+                    lines.append(
+                        f"### {emoji} {sugg['title']} ({sugg['count']} issues)"
+                    )
                     lines.append("")
                     lines.append(sugg["suggestion"])
                     lines.append("")
@@ -461,7 +481,9 @@ class AIRefactorReviewer:
         lines.append("## ğŸ“š Resources")
         lines.append("")
         lines.append("- [Language Stack Policy](docs/architecture/language-stack.md)")
-        lines.append("- [Language Governance Guide](docs/architecture/language-governance.md)")
+        lines.append(
+            "- [Language Governance Guide](docs/architecture/language-governance.md)"
+        )
         lines.append(
             "- [Exception Request Process](docs/architecture/language-governance.md#ä¾‹å¤–ç”³è«‹)"
         )
@@ -490,9 +512,15 @@ def main():
     parser = argparse.ArgumentParser(description="AI-Powered Refactor Review Tool")
     parser.add_argument("--governance-report", help="Path to governance report JSON")
     parser.add_argument("--semgrep-report", help="Path to Semgrep SARIF report")
-    parser.add_argument("--codeql-reports", help="Directory containing CodeQL SARIF reports")
-    parser.add_argument("--output", default="ai-refactor-suggestions.md", help="Output file path")
-    parser.add_argument("--ai-model", default="gpt-4", help="OpenAI model to use (default: gpt-4)")
+    parser.add_argument(
+        "--codeql-reports", help="Directory containing CodeQL SARIF reports"
+    )
+    parser.add_argument(
+        "--output", default="ai-refactor-suggestions.md", help="Output file path"
+    )
+    parser.add_argument(
+        "--ai-model", default="gpt-4", help="OpenAI model to use (default: gpt-4)"
+    )
 
     args = parser.parse_args()
 
diff --git a/workspace/tools/ai/governance_engine.py b/workspace/tools/ai/governance_engine.py
index c308940..03d10ee 100644
--- a/workspace/tools/ai/governance_engine.py
+++ b/workspace/tools/ai/governance_engine.py
@@ -276,7 +276,9 @@ class AIGovernanceEngine:
         affected_count = context.get("affected_resources", len(resources))
 
         # Assess risk
-        risk_level, risk_score = self.assess_risk(change_type, impact_scope, affected_count)
+        risk_level, risk_score = self.assess_risk(
+            change_type, impact_scope, affected_count
+        )
 
         # Detect patterns
         pattern_analysis = self.detect_naming_patterns(resources)
diff --git a/workspace/tools/automated_directory_restructure.py b/workspace/tools/automated_directory_restructure.py
index 6143799..2b87ecc 100755
--- a/workspace/tools/automated_directory_restructure.py
+++ b/workspace/tools/automated_directory_restructure.py
@@ -30,7 +30,10 @@ import yaml
 logging.basicConfig(
     level=logging.INFO,
     format="%(asctime)s - %(levelname)s - %(message)s",
-    handlers=[logging.FileHandler("restructure.log"), logging.StreamHandler(sys.stdout)],
+    handlers=[
+        logging.FileHandler("restructure.log"),
+        logging.StreamHandler(sys.stdout),
+    ],
 )
 logger = logging.getLogger(__name__)
 
@@ -139,10 +142,21 @@ class DirectoryRestructureTool:
                             "search_engine",
                             "data_pipeline",
                         ],
-                        "monitoring": ["metrics", "logging", "tracing", "alerting", "dashboard"],
+                        "monitoring": [
+                            "metrics",
+                            "logging",
+                            "tracing",
+                            "alerting",
+                            "dashboard",
+                        ],
                     },
                     "shared": {
-                        "types": ["common_types", "api_types", "domain_types", "event_types"],
+                        "types": [
+                            "common_types",
+                            "api_types",
+                            "domain_types",
+                            "event_types",
+                        ],
                         "utils": [
                             "helpers",
                             "validators",
@@ -181,10 +195,19 @@ class DirectoryRestructureTool:
                         "ci-error-handler",
                         "drone-config",
                     ],
-                    "deployment": ["docker-compose", "dockerfile", "nginx", "deployment-pipelines"],
+                    "deployment": [
+                        "docker-compose",
+                        "dockerfile",
+                        "nginx",
+                        "deployment-pipelines",
+                    ],
                     "monitoring": ["prometheus", "grafana", "alerting", "dashboards"],
                     "environments": ["env-files", "environment-configs", "secrets"],
-                    "security": ["security-policies", "safety-mechanisms", "access-control"],
+                    "security": [
+                        "security-policies",
+                        "safety-mechanisms",
+                        "access-control",
+                    ],
                     "build-tools": [
                         "eslint",
                         "jest",
@@ -224,7 +247,9 @@ class DirectoryRestructureTool:
                 shutil.copytree(
                     self.project_root,
                     self.backup_dir,
-                    ignore=shutil.ignore_patterns(".git", "__pycache__", "*.pyc", "node_modules"),
+                    ignore=shutil.ignore_patterns(
+                        ".git", "__pycache__", "*.pyc", "node_modules"
+                    ),
                 )
 
             self.report["operations"].append(
@@ -444,12 +469,21 @@ class DirectoryRestructureTool:
             category_path = self.project_root / "config" / category
             actual[category] = category_path.exists()
 
-        return {"expected": list(expected.keys()), "actual": actual, "valid": all(actual.values())}
+        return {
+            "expected": list(expected.keys()),
+            "actual": actual,
+            "valid": all(actual.values()),
+        }
 
     def _validate_file_integrity(self) -> Dict:
         """é©—è­‰æ–‡ä»¶å®Œæ•´æ€§"""
         # ç°¡åŒ–çš„æ–‡ä»¶å®Œæ•´æ€§æª¢æŸ¥
-        return {"total_files_checked": 0, "missing_files": [], "corrupted_files": [], "valid": True}
+        return {
+            "total_files_checked": 0,
+            "missing_files": [],
+            "corrupted_files": [],
+            "valid": True,
+        }
 
     def _validate_import_consistency(self) -> Dict:
         """é©—è­‰å°å…¥ä¸€è‡´æ€§"""
@@ -537,7 +571,9 @@ class DirectoryRestructureTool:
 def main():
     """ä¸»å‡½æ•¸"""
     parser = argparse.ArgumentParser(description="MachineNativeOps è‡ªå‹•åŒ–ç›®éŒ„é‡æ§‹å·¥å…·")
-    parser.add_argument("--dry-run", action="store_true", help="è©¦é‹è¡Œæ¨¡å¼ï¼Œä¸å¯¦éš›ä¿®æ”¹æ–‡ä»¶")
+    parser.add_argument(
+        "--dry-run", action="store_true", help="è©¦é‹è¡Œæ¨¡å¼ï¼Œä¸å¯¦éš›ä¿®æ”¹æ–‡ä»¶"
+    )
     parser.add_argument(
         "--phase", choices=["src", "config", "all"], default="all", help="æŒ‡å®šé‡æ§‹éšæ®µ"
     )
diff --git a/workspace/tools/automation/engine_base.py b/workspace/tools/automation/engine_base.py
index 26d4f4c..97c7db7 100644
--- a/workspace/tools/automation/engine_base.py
+++ b/workspace/tools/automation/engine_base.py
@@ -374,7 +374,9 @@ class BaseEngine(ABC):
 
         try:
             # åˆå§‹åŒ–çµ„ä»¶
-            self._task_queue = asyncio.Queue(maxsize=self.config.resource.max_queue_size)
+            self._task_queue = asyncio.Queue(
+                maxsize=self.config.resource.max_queue_size
+            )
             self._shutdown_event = asyncio.Event()
 
             # è¼‰å…¥æª¢æŸ¥é»
@@ -440,7 +442,9 @@ class BaseEngine(ABC):
                 await self._save_checkpoint()
 
             # åŸ·è¡Œå­é¡é—œé–‰
-            success = await asyncio.wait_for(self._shutdown(), timeout=self.config.timeout.shutdown)
+            success = await asyncio.wait_for(
+                self._shutdown(), timeout=self.config.timeout.shutdown
+            )
 
             self._state = EngineState.STOPPED
             await self._emit_event("engine.stopped", {})
@@ -517,7 +521,9 @@ class BaseEngine(ABC):
                     continue
 
                 # æª¢æŸ¥ä¸¦ç™¼é™åˆ¶
-                while len(self._active_tasks) >= self.config.resource.max_concurrent_tasks:
+                while (
+                    len(self._active_tasks) >= self.config.resource.max_concurrent_tasks
+                ):
                     await asyncio.sleep(0.1)
 
                 # åŸ·è¡Œä»»å‹™
@@ -583,7 +589,9 @@ class BaseEngine(ABC):
                     self._execute(task), timeout=self.config.timeout.execution
                 )
 
-                result.duration_ms = (datetime.now() - start_time).total_seconds() * 1000
+                result.duration_ms = (
+                    datetime.now() - start_time
+                ).total_seconds() * 1000
                 return result
 
             except tuple(retry_config.retry_on) as e:
@@ -595,7 +603,9 @@ class BaseEngine(ABC):
                     if retry_config.jitter:
                         import random
 
-                        delay *= retry_config.exponential_base + random.uniform(-0.1, 0.1)
+                        delay *= retry_config.exponential_base + random.uniform(
+                            -0.1, 0.1
+                        )
                     else:
                         delay *= retry_config.exponential_base
 
@@ -652,7 +662,9 @@ class BaseEngine(ABC):
                     {
                         "state": self._state.name,
                         "active_tasks": len(self._active_tasks),
-                        "queue_size": self._task_queue.qsize() if self._task_queue else 0,
+                        "queue_size": (
+                            self._task_queue.qsize() if self._task_queue else 0
+                        ),
                     },
                 )
                 await asyncio.sleep(self.config.timeout.heartbeat)
@@ -670,7 +682,9 @@ class BaseEngine(ABC):
             uptime_seconds=self.uptime.total_seconds(),
             tasks_completed=self._tasks_completed,
             tasks_failed=self._tasks_failed,
-            last_activity=self._last_activity.isoformat() if self._last_activity else "",
+            last_activity=(
+                self._last_activity.isoformat() if self._last_activity else ""
+            ),
             error_rate=error_rate,
             details={
                 "active_tasks": len(self._active_tasks),
@@ -727,8 +741,12 @@ class BaseEngine(ABC):
                 with open(checkpoint_file, "r", encoding="utf-8") as f:
                     checkpoint = json.load(f)
 
-                self._tasks_completed = checkpoint.get("statistics", {}).get("tasks_completed", 0)
-                self._tasks_failed = checkpoint.get("statistics", {}).get("tasks_failed", 0)
+                self._tasks_completed = checkpoint.get("statistics", {}).get(
+                    "tasks_completed", 0
+                )
+                self._tasks_failed = checkpoint.get("statistics", {}).get(
+                    "tasks_failed", 0
+                )
                 self._checkpoint_data = checkpoint.get("custom_data", {})
 
                 self._logger.info(f"å·²è¼‰å…¥æª¢æŸ¥é»: {checkpoint_file}")
diff --git a/workspace/tools/automation/engines/baseline_validation_engine.py b/workspace/tools/automation/engines/baseline_validation_engine.py
index ec52ab2..d9b4a1f 100755
--- a/workspace/tools/automation/engines/baseline_validation_engine.py
+++ b/workspace/tools/automation/engines/baseline_validation_engine.py
@@ -139,7 +139,9 @@ class BaselineValidationEngine:
             self.log(error_msg, level="FAIL")
             return False, error_msg
         try:
-            result = subprocess.run(["kubectl"] + args, capture_output=True, text=True, timeout=30)
+            result = subprocess.run(
+                ["kubectl"] + args, capture_output=True, text=True, timeout=30
+            )
             return result.returncode == 0, result.stdout
         except subprocess.TimeoutExpired as e:
             return False, f"Timeout: {str(e)}"
@@ -195,7 +197,9 @@ class BaselineValidationEngine:
             )
             return False
 
-        self.add_result("namespace_exists", Status.PASS, f"Namespace exists: {self.namespace}")
+        self.add_result(
+            "namespace_exists", Status.PASS, f"Namespace exists: {self.namespace}"
+        )
 
         # Check namespace labels
         success, output = self.run_kubectl(
@@ -206,7 +210,9 @@ class BaselineValidationEngine:
             try:
                 labels = json.loads(output) if output else {}
                 required_labels = ["app.kubernetes.io/name"]
-                missing_labels = [label for label in required_labels if label not in labels]
+                missing_labels = [
+                    label for label in required_labels if label not in labels
+                ]
 
                 if missing_labels:
                     self.add_result(
@@ -218,9 +224,13 @@ class BaselineValidationEngine:
                         remediation_command=f"kubectl label namespace {self.namespace} app.kubernetes.io/name={self.namespace}",
                     )
                 else:
-                    self.add_result("namespace_labels", Status.PASS, "All required labels present")
+                    self.add_result(
+                        "namespace_labels", Status.PASS, "All required labels present"
+                    )
             except json.JSONDecodeError:
-                self.add_result("namespace_labels", Status.WARN, "Could not parse namespace labels")
+                self.add_result(
+                    "namespace_labels", Status.WARN, "Could not parse namespace labels"
+                )
 
         return True
 
@@ -228,7 +238,9 @@ class BaselineValidationEngine:
         """Validate ConfigMaps in namespace"""
         self.log("Validating ConfigMaps...")
 
-        success, output = self.run_kubectl(["get", "configmap", "-n", self.namespace, "-o", "json"])
+        success, output = self.run_kubectl(
+            ["get", "configmap", "-n", self.namespace, "-o", "json"]
+        )
 
         if not success:
             self.add_result("configmaps", Status.FAIL, "Could not retrieve ConfigMaps")
@@ -262,7 +274,9 @@ class BaselineValidationEngine:
         )
 
         if not success:
-            self.add_result("deployments", Status.WARN, "Could not retrieve Deployments")
+            self.add_result(
+                "deployments", Status.WARN, "Could not retrieve Deployments"
+            )
             return True
 
         try:
@@ -284,7 +298,9 @@ class BaselineValidationEngine:
 
             if ready_deployments == len(deployments):
                 self.add_result(
-                    "deployments", Status.PASS, f"All {len(deployments)} Deployments are ready"
+                    "deployments",
+                    Status.PASS,
+                    f"All {len(deployments)} Deployments are ready",
                 )
             else:
                 self.add_result(
@@ -295,14 +311,18 @@ class BaselineValidationEngine:
 
             return True
         except json.JSONDecodeError:
-            self.add_result("deployments", Status.FAIL, "Could not parse Deployment data")
+            self.add_result(
+                "deployments", Status.FAIL, "Could not parse Deployment data"
+            )
             return False
 
     def validate_services(self) -> bool:
         """Validate Services in namespace"""
         self.log("Validating Services...")
 
-        success, output = self.run_kubectl(["get", "service", "-n", self.namespace, "-o", "json"])
+        success, output = self.run_kubectl(
+            ["get", "service", "-n", self.namespace, "-o", "json"]
+        )
 
         if not success:
             self.add_result("services", Status.WARN, "Could not retrieve Services")
@@ -336,7 +356,9 @@ class BaselineValidationEngine:
         )
 
         if not success:
-            self.add_result("network_policies", Status.WARN, "Could not retrieve NetworkPolicies")
+            self.add_result(
+                "network_policies", Status.WARN, "Could not retrieve NetworkPolicies"
+            )
             return True
 
         try:
@@ -344,23 +366,35 @@ class BaselineValidationEngine:
             policies = data.get("items", [])
 
             if len(policies) == 0:
-                self.add_result("network_policies", Status.WARN, "No NetworkPolicies found")
+                self.add_result(
+                    "network_policies", Status.WARN, "No NetworkPolicies found"
+                )
             else:
                 self.add_result(
-                    "network_policies", Status.PASS, f"Found {len(policies)} NetworkPolicies"
+                    "network_policies",
+                    Status.PASS,
+                    f"Found {len(policies)} NetworkPolicies",
                 )
 
             return True
         except json.JSONDecodeError:
-            self.add_result("network_policies", Status.FAIL, "Could not parse NetworkPolicy data")
+            self.add_result(
+                "network_policies", Status.FAIL, "Could not parse NetworkPolicy data"
+            )
             return False
 
     def generate_report(self) -> dict:
         """Generate validation report with auto-evolution insights"""
         total_checks = len(self.validation_results)
-        passed_checks = sum(1 for r in self.validation_results if r.status == Status.PASS)
-        failed_checks = sum(1 for r in self.validation_results if r.status == Status.FAIL)
-        warned_checks = sum(1 for r in self.validation_results if r.status == Status.WARN)
+        passed_checks = sum(
+            1 for r in self.validation_results if r.status == Status.PASS
+        )
+        failed_checks = sum(
+            1 for r in self.validation_results if r.status == Status.FAIL
+        )
+        warned_checks = sum(
+            1 for r in self.validation_results if r.status == Status.WARN
+        )
 
         # Collect auto-remediation suggestions
         remediation_plan = [
@@ -446,7 +480,9 @@ class BaselineValidationEngine:
                 f"ğŸ’¡ {report['auto_evolution']['remediations_available']} auto-fix suggestion(s) available:"
             )
             self.log("")
-            for idx, remediation in enumerate(report["auto_evolution"]["remediation_plan"], 1):
+            for idx, remediation in enumerate(
+                report["auto_evolution"]["remediation_plan"], 1
+            ):
                 self.log(f"{idx}. {remediation['check']}")
                 self.log(f"   Issue: {remediation['issue']}")
                 self.log(f"   ğŸ’¡ Suggestion: {remediation['suggestion']}")
@@ -480,7 +516,9 @@ def main():
         description="SynergyMesh Baseline Validation Engine with Auto-Evolution"
     )
     parser.add_argument(
-        "--namespace", default="machinenativenops-system", help="Kubernetes namespace to validate"
+        "--namespace",
+        default="machinenativenops-system",
+        help="Kubernetes namespace to validate",
     )
     parser.add_argument(
         "--auto-evolve",
diff --git a/workspace/tools/automation/engines/generation_engine.py b/workspace/tools/automation/engines/generation_engine.py
index fff25e3..d35c36e 100644
--- a/workspace/tools/automation/engines/generation_engine.py
+++ b/workspace/tools/automation/engines/generation_engine.py
@@ -11,7 +11,6 @@ Generation Engine - ç”Ÿæˆå…¨è‡ªå‹•åŒ–å¼•æ“
 Version: 1.0.0
 """
 
-from engine_base import BaseEngine, EngineConfig, EngineState, EngineType, ExecutionMode, TaskResult
 import asyncio
 import sys
 from datetime import datetime
@@ -19,6 +18,14 @@ from pathlib import Path
 from typing import Any, Dict, List, Optional
 
 import yaml
+from engine_base import (
+    BaseEngine,
+    EngineConfig,
+    EngineState,
+    EngineType,
+    ExecutionMode,
+    TaskResult,
+)
 
 sys.path.insert(0, str(Path(__file__).parent.parent))
 
@@ -63,7 +70,9 @@ class GenerationEngine(BaseEngine):
             elif operation == "generate_all":
                 result = await self._generate_all()
             else:
-                return TaskResult(task_id=task_id, success=False, error=f"æœªçŸ¥æ“ä½œ: {operation}")
+                return TaskResult(
+                    task_id=task_id, success=False, error=f"æœªçŸ¥æ“ä½œ: {operation}"
+                )
 
             return TaskResult(task_id=task_id, success=True, result=result)
 
@@ -83,7 +92,9 @@ class GenerationEngine(BaseEngine):
                 "generate_all",
             ],
             "templates": (
-                list(self._templates_path.glob("*.md")) if self._templates_path.exists() else []
+                list(self._templates_path.glob("*.md"))
+                if self._templates_path.exists()
+                else []
             ),
         }
 
@@ -156,7 +167,9 @@ python tools/refactor/refactor_engine.py rollback --checkpoint latest
         target = Path(target_dir) if target_dir else self._target_path / "03_refactor"
 
         # æƒæ playbook æª”æ¡ˆ
-        playbooks = list(target.glob("*__playbook.md")) + list(target.glob("*_playbook.md"))
+        playbooks = list(target.glob("*__playbook.md")) + list(
+            target.glob("*_playbook.md")
+        )
 
         clusters = []
         for pb in playbooks:
@@ -254,7 +267,9 @@ docs/refactor_playbooks/
         # åˆ—å‡ºå­ç›®éŒ„
         for item in sorted(target.iterdir()):
             if item.is_dir() and not item.name.startswith("."):
-                readme_content += f"- `{item.name}/` - {item.name.replace('_', ' ').title()}\n"
+                readme_content += (
+                    f"- `{item.name}/` - {item.name.replace('_', ' ').title()}\n"
+                )
 
         readme_content += """
 ## ä½¿ç”¨æ–¹å¼
diff --git a/workspace/tools/automation/engines/integration_automation_engine.py b/workspace/tools/automation/engines/integration_automation_engine.py
index bc4ada2..2877c8a 100644
--- a/workspace/tools/automation/engines/integration_automation_engine.py
+++ b/workspace/tools/automation/engines/integration_automation_engine.py
@@ -11,15 +11,6 @@ Integration Automation Engine - æ•´åˆå…¨è‡ªå‹•åŒ–å¼•æ“
 Version: 1.0.0
 """
 
-from engine_base import (
-    BaseEngine,
-    EngineConfig,
-    EngineState,
-    EngineType,
-    ExecutionEngineBase,
-    ExecutionMode,
-    TaskResult,
-)
 import asyncio
 import shutil
 import sys
@@ -29,6 +20,15 @@ from pathlib import Path
 from typing import Any, Dict, List, Optional
 
 import yaml
+from engine_base import (
+    BaseEngine,
+    EngineConfig,
+    EngineState,
+    EngineType,
+    ExecutionEngineBase,
+    ExecutionMode,
+    TaskResult,
+)
 
 sys.path.insert(0, str(Path(__file__).parent.parent))
 
@@ -72,7 +72,9 @@ class IntegrationAutomationEngine(ExecutionEngineBase):
             elif operation == "full_integration":
                 result = await self._full_integration_cycle()
             else:
-                return TaskResult(task_id=task_id, success=False, error=f"æœªçŸ¥æ“ä½œ: {operation}")
+                return TaskResult(
+                    task_id=task_id, success=False, error=f"æœªçŸ¥æ“ä½œ: {operation}"
+                )
 
             return TaskResult(task_id=task_id, success=True, result=result)
 
diff --git a/workspace/tools/automation/engines/refactor_automation_engine.py b/workspace/tools/automation/engines/refactor_automation_engine.py
index 0f52636..941a306 100644
--- a/workspace/tools/automation/engines/refactor_automation_engine.py
+++ b/workspace/tools/automation/engines/refactor_automation_engine.py
@@ -15,16 +15,6 @@ Refactor Automation Engine - é‡æ§‹å…¨è‡ªå‹•åŒ–å¼•æ“
 Version: 1.0.0
 """
 
-from engine_base import (
-    BaseEngine,
-    EngineConfig,
-    EngineState,
-    EngineType,
-    ExecutionEngineBase,
-    ExecutionMode,
-    Priority,
-    TaskResult,
-)
 import asyncio
 import json
 import re
@@ -36,6 +26,16 @@ from pathlib import Path
 from typing import Any, Dict, List, Optional
 
 import yaml
+from engine_base import (
+    BaseEngine,
+    EngineConfig,
+    EngineState,
+    EngineType,
+    ExecutionEngineBase,
+    ExecutionMode,
+    Priority,
+    TaskResult,
+)
 
 sys.path.insert(0, str(Path(__file__).parent.parent))
 
@@ -299,7 +299,9 @@ class RefactorAutomationEngine(ExecutionEngineBase):
 
         # å‰µå»ºå‚™ä»½
         if self._backup_enabled:
-            backup_dir = self._target_path / ".backup" / datetime.now().strftime("%Y%m%d%H%M%S")
+            backup_dir = (
+                self._target_path / ".backup" / datetime.now().strftime("%Y%m%d%H%M%S")
+            )
             backup_dir.mkdir(parents=True, exist_ok=True)
 
         results = {
@@ -579,7 +581,9 @@ class RefactorAutomationEngine(ExecutionEngineBase):
             source = Path(rollback_info["source"])
             source.rename(source.parent / rollback_info["new_name"])
         elif op_type == "update_content":
-            Path(rollback_info["target"]).write_text(rollback_info["content"], encoding="utf-8")
+            Path(rollback_info["target"]).write_text(
+                rollback_info["content"], encoding="utf-8"
+            )
         elif op_type == "restore":
             if Path(rollback_info["source"]).is_file():
                 shutil.copy2(rollback_info["source"], rollback_info["target"])
diff --git a/workspace/tools/automation/engines/validation_automation_engine.py b/workspace/tools/automation/engines/validation_automation_engine.py
index 0ec6cc8..9d4ae28 100644
--- a/workspace/tools/automation/engines/validation_automation_engine.py
+++ b/workspace/tools/automation/engines/validation_automation_engine.py
@@ -11,15 +11,6 @@ Validation Automation Engine - é©—è­‰å…¨è‡ªå‹•åŒ–å¼•æ“
 Version: 1.0.0
 """
 
-from engine_base import (
-    BaseEngine,
-    EngineConfig,
-    EngineState,
-    EngineType,
-    ExecutionMode,
-    TaskResult,
-    ValidationEngineBase,
-)
 import asyncio
 import re
 import sys
@@ -29,6 +20,15 @@ from pathlib import Path
 from typing import Any, Dict, List, Optional
 
 import yaml
+from engine_base import (
+    BaseEngine,
+    EngineConfig,
+    EngineState,
+    EngineType,
+    ExecutionMode,
+    TaskResult,
+    ValidationEngineBase,
+)
 
 sys.path.insert(0, str(Path(__file__).parent.parent))
 
@@ -72,7 +72,9 @@ class ValidationAutomationEngine(ValidationEngineBase):
             elif operation == "auto_fix":
                 result = await self._auto_fix_all()
             else:
-                return TaskResult(task_id=task_id, success=False, error=f"æœªçŸ¥æ“ä½œ: {operation}")
+                return TaskResult(
+                    task_id=task_id, success=False, error=f"æœªçŸ¥æ“ä½œ: {operation}"
+                )
 
             return TaskResult(task_id=task_id, success=True, result=result)
 
diff --git a/workspace/tools/automation/master_orchestrator.py b/workspace/tools/automation/master_orchestrator.py
index e83dead..37f9a9f 100644
--- a/workspace/tools/automation/master_orchestrator.py
+++ b/workspace/tools/automation/master_orchestrator.py
@@ -247,7 +247,9 @@ class EventBus:
             except Exception as e:
                 self._logger.error(f"äº‹ä»¶è™•ç†éŒ¯èª¤: {e}")
 
-    def get_history(self, event_type: str = None, limit: int = 100) -> List[EngineEvent]:
+    def get_history(
+        self, event_type: str = None, limit: int = 100
+    ) -> List[EngineEvent]:
         """ç²å–äº‹ä»¶æ­·å²"""
         events = self._history
         if event_type:
@@ -368,7 +370,9 @@ class EngineRegistry:
         """è¨»å†Šå¼•æ“å¯¦ä¾‹"""
         registration.registered_at = datetime.now().isoformat()
         self._engines[registration.engine_id] = registration
-        self._logger.info(f"å¼•æ“å·²è¨»å†Š: {registration.engine_name} ({registration.engine_id})")
+        self._logger.info(
+            f"å¼•æ“å·²è¨»å†Š: {registration.engine_name} ({registration.engine_id})"
+        )
 
     def unregister_engine(self, engine_id: str):
         """å–æ¶ˆè¨»å†Šå¼•æ“"""
@@ -654,7 +658,9 @@ class EngineRegistry:
                         {
                             "class_name": name,
                             "module_path": str(module_path),
-                            "engine_type": getattr(obj, "ENGINE_TYPE", EngineType.EXECUTION).value,
+                            "engine_type": getattr(
+                                obj, "ENGINE_TYPE", EngineType.EXECUTION
+                            ).value,
                         }
                     )
 
@@ -691,7 +697,9 @@ class EngineScheduler:
         """åœæ­¢èª¿åº¦å™¨"""
         self._running = False
 
-    async def schedule_task(self, task: Dict[str, Any], priority: Priority = Priority.NORMAL):
+    async def schedule_task(
+        self, task: Dict[str, Any], priority: Priority = Priority.NORMAL
+    ):
         """èª¿åº¦ä»»å‹™"""
         await self._task_queue.put((priority.value, task))
 
@@ -752,7 +760,9 @@ class PipelineExecutor:
         self._pipelines[config.pipeline_id] = config
         self._logger.info(f"ç®¡é“å·²è¨»å†Š: {config.name}")
 
-    async def execute_pipeline(self, pipeline_id: str, input_data: Dict = None) -> Dict[str, Any]:
+    async def execute_pipeline(
+        self, pipeline_id: str, input_data: Dict = None
+    ) -> Dict[str, Any]:
         """åŸ·è¡Œç®¡é“"""
         pipeline = self._pipelines.get(pipeline_id)
         if not pipeline:
@@ -805,7 +815,9 @@ class PipelineExecutor:
                 "results": results,
             }
 
-    async def _execute_stage(self, stage: Dict[str, Any], input_data: Dict) -> Dict[str, Any]:
+    async def _execute_stage(
+        self, stage: Dict[str, Any], input_data: Dict
+    ) -> Dict[str, Any]:
         """åŸ·è¡Œå–®ä¸€éšæ®µ"""
         engine_id = stage.get("engine_id")
         engine_type = stage.get("engine_type")
@@ -1093,7 +1105,9 @@ class MasterOrchestrator:
 
         try:
             # å‹•æ…‹è¼‰å…¥æ¨¡çµ„
-            spec = importlib.util.spec_from_file_location(Path(module_path).stem, module_path)
+            spec = importlib.util.spec_from_file_location(
+                Path(module_path).stem, module_path
+            )
             module = importlib.util.module_from_spec(spec)
             spec.loader.exec_module(module)
 
@@ -1205,7 +1219,9 @@ class MasterOrchestrator:
     # ä»»å‹™èª¿åº¦
     # ========================================================================
 
-    async def submit_task(self, task: Dict[str, Any], priority: Priority = Priority.NORMAL):
+    async def submit_task(
+        self, task: Dict[str, Any], priority: Priority = Priority.NORMAL
+    ):
         """æäº¤ä»»å‹™"""
         await self.scheduler.schedule_task(task, priority)
 
@@ -1255,7 +1271,9 @@ class MasterOrchestrator:
 
 
 async def main():
-    parser = argparse.ArgumentParser(description="SynergyMesh Master Orchestrator - ä¸»æ§å¼•æ“å•Ÿå‹•å™¨")
+    parser = argparse.ArgumentParser(
+        description="SynergyMesh Master Orchestrator - ä¸»æ§å¼•æ“å•Ÿå‹•å™¨"
+    )
 
     subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
 
@@ -1308,7 +1326,9 @@ async def main():
     elif args.command == "list":
         await orchestrator.start()
         for engine in orchestrator.registry.get_all_engines():
-            print(f"- {engine.engine_name} ({engine.engine_id}): {engine.engine_type.value}")
+            print(
+                f"- {engine.engine_name} ({engine.engine_id}): {engine.engine_type.value}"
+            )
         await orchestrator.stop()
 
     elif args.command == "execute":
diff --git a/workspace/tools/autonomous_cleanup_toolkit.py b/workspace/tools/autonomous_cleanup_toolkit.py
index 2d7c297..91ca127 100755
--- a/workspace/tools/autonomous_cleanup_toolkit.py
+++ b/workspace/tools/autonomous_cleanup_toolkit.py
@@ -140,7 +140,12 @@ class AutonomousCleanupEngine:
         self.logger = self._setup_logging()
 
         # Statistics
-        self.stats = {"scans_performed": 0, "items_found": 0, "items_fixed": 0, "files_modified": 0}
+        self.stats = {
+            "scans_performed": 0,
+            "items_found": 0,
+            "items_fixed": 0,
+            "files_modified": 0,
+        }
 
     def _setup_logging(self) -> logging.Logger:
         """Setup logging configuration"""
@@ -159,7 +164,9 @@ class AutonomousCleanupEngine:
         ch.setLevel(logging.INFO)
 
         # Formatter
-        formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
+        formatter = logging.Formatter(
+            "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+        )
         fh.setFormatter(formatter)
         ch.setFormatter(formatter)
 
@@ -203,7 +210,9 @@ class AutonomousCleanupEngine:
                 try:
                     content = file_path.read_bytes()
                     md5_hash = hashlib.md5(content).hexdigest()
-                    hash_map[md5_hash].append(str(file_path.relative_to(self.repo_path)))
+                    hash_map[md5_hash].append(
+                        str(file_path.relative_to(self.repo_path))
+                    )
                 except Exception as e:
                     self.logger.warning(f"Error reading {file_path}: {e}")
 
@@ -219,7 +228,10 @@ class AutonomousCleanupEngine:
 
                 duplicate_groups.append(
                     DuplicateGroup(
-                        md5_hash=md5_hash, files=files, size_bytes=size_bytes, removable=removable
+                        md5_hash=md5_hash,
+                        files=files,
+                        size_bytes=size_bytes,
+                        removable=removable,
                     )
                 )
 
@@ -235,7 +247,9 @@ class AutonomousCleanupEngine:
             if file.startswith("legacy/"):
                 removable.append(file)
             # Rule 2: Prefer services/agents/ over agent/
-            elif file.startswith("agent/") and any(f.startswith("services/agents/") for f in files):
+            elif file.startswith("agent/") and any(
+                f.startswith("services/agents/") for f in files
+            ):
                 removable.append(file)
             # Rule 3: Prefer non-backup versions
             elif ".backup" in file or "_backup" in file:
@@ -266,7 +280,8 @@ class AutonomousCleanupEngine:
 
         for py_file in self.repo_path.rglob("*.py"):
             if any(
-                excluded in str(py_file) for excluded in [".venv", "__pycache__", "node_modules"]
+                excluded in str(py_file)
+                for excluded in [".venv", "__pycache__", "node_modules"]
             ):
                 continue
 
@@ -317,7 +332,14 @@ class AutonomousCleanupEngine:
             return "HIGH"
 
         # Check for urgency keywords
-        high_priority_keywords = ["critical", "urgent", "important", "security", "bug", "error"]
+        high_priority_keywords = [
+            "critical",
+            "urgent",
+            "important",
+            "security",
+            "bug",
+            "error",
+        ]
         if any(keyword in message_lower for keyword in high_priority_keywords):
             return "HIGH"
 
@@ -359,7 +381,9 @@ class AutonomousCleanupEngine:
 
                     # Try to find class name
                     class_pattern = re.compile(r"class\s+(\w+)", re.MULTILINE)
-                    class_matches = list(class_pattern.finditer(content[: match.start()]))
+                    class_matches = list(
+                        class_pattern.finditer(content[: match.start()])
+                    )
                     class_name = class_matches[-1].group(1) if class_matches else None
 
                     stubs.append(
@@ -404,7 +428,8 @@ class AutonomousCleanupEngine:
                     "groups": len(duplicates),
                     "total_files": sum(len(g.files) for g in duplicates),
                     "removable": sum(len(g.removable) for g in duplicates),
-                    "potential_savings_kb": sum(g.size_bytes for g in duplicates) / 1024,
+                    "potential_savings_kb": sum(g.size_bytes for g in duplicates)
+                    / 1024,
                 },
                 "todos": {
                     "total": len(todos),
@@ -417,7 +442,9 @@ class AutonomousCleanupEngine:
                         "TODO": len([t for t in todos if t.todo_type == "TODO"]),
                         "FIXME": len([t for t in todos if t.todo_type == "FIXME"]),
                         "HACK": len([t for t in todos if t.todo_type == "HACK"]),
-                        "DEPRECATED": len([t for t in todos if t.todo_type == "DEPRECATED"]),
+                        "DEPRECATED": len(
+                            [t for t in todos if t.todo_type == "DEPRECATED"]
+                        ),
                     },
                 },
                 "not_implemented": {
@@ -456,8 +483,12 @@ class AutonomousCleanupEngine:
         dup_details = report.details.get("duplicates", {})
         print(f"  Groups: {dup_details.get('groups', 0)}")
         print(f"  Total Files: {dup_details.get('total_files', 0)}")
-        print(f"  Removable: {Colors.GREEN}{dup_details.get('removable', 0)}{Colors.END}")
-        print(f"  Potential Savings: {dup_details.get('potential_savings_kb', 0):.2f} KB")
+        print(
+            f"  Removable: {Colors.GREEN}{dup_details.get('removable', 0)}{Colors.END}"
+        )
+        print(
+            f"  Potential Savings: {dup_details.get('potential_savings_kb', 0):.2f} KB"
+        )
 
         # TODOs
         print(f"\n{Colors.BOLD}ğŸ“ TODOs:{Colors.END}")
@@ -508,13 +539,18 @@ def main():
         help="Cleanup phase to execute",
     )
     cleanup_parser.add_argument(
-        "--dry-run", action="store_true", help="Show what would be cleaned without making changes"
+        "--dry-run",
+        action="store_true",
+        help="Show what would be cleaned without making changes",
     )
 
     # Report command
     report_parser = subparsers.add_parser("report", help="Generate report only")
     report_parser.add_argument(
-        "--output", type=Path, default=Path("CLEANUP_REPORT.json"), help="Output file for report"
+        "--output",
+        type=Path,
+        default=Path("CLEANUP_REPORT.json"),
+        help="Output file for report",
     )
 
     args = parser.parse_args()
diff --git a/workspace/tools/bootstrap_from_manifest.py b/workspace/tools/bootstrap_from_manifest.py
index 18da076..ad7d67a 100755
--- a/workspace/tools/bootstrap_from_manifest.py
+++ b/workspace/tools/bootstrap_from_manifest.py
@@ -23,7 +23,9 @@ def parse_args() -> argparse.Namespace:
     parser = argparse.ArgumentParser(
         description="Materialize the Island AI Stage 0 bootstrap manifest",
     )
-    parser.add_argument("manifest", type=Path, help="Path to island.bootstrap.stage0.yaml")
+    parser.add_argument(
+        "manifest", type=Path, help="Path to island.bootstrap.stage0.yaml"
+    )
     parser.add_argument(
         "--apply",
         action="store_true",
@@ -114,7 +116,9 @@ class BootstrapContext:
             try:
                 if tmp_path is not None:
                     os.chmod(tmp_path, 0o600)
-                    subprocess.run(["/bin/bash", tmp_path], check=True, cwd=self.repo_root)
+                    subprocess.run(
+                        ["/bin/bash", tmp_path], check=True, cwd=self.repo_root
+                    )
             finally:
                 if tmp_path is not None:
                     try:
@@ -146,7 +150,9 @@ def _iter_sequence(obj: Any) -> Sequence[Any]:
     return []
 
 
-def scaffold_entries(entries: Sequence[Mapping[str, Any]], ctx: BootstrapContext) -> None:
+def scaffold_entries(
+    entries: Sequence[Mapping[str, Any]], ctx: BootstrapContext
+) -> None:
     for entry in entries:
         base = ctx.repo_root / _as_str(entry.get("base", "."))
         ctx.ensure_directory(base)
@@ -164,7 +170,9 @@ def scaffold_entries(entries: Sequence[Mapping[str, Any]], ctx: BootstrapContext
             ctx.ensure_directory(target)
 
 
-def materialize_templates(templates: Sequence[Mapping[str, Any]], ctx: BootstrapContext) -> None:
+def materialize_templates(
+    templates: Sequence[Mapping[str, Any]], ctx: BootstrapContext
+) -> None:
     for template in templates:
         source = ctx.repo_root / _as_str(template.get("source"))
         target = ctx.repo_root / _as_str(template.get("target"))
@@ -215,7 +223,11 @@ def main() -> None:
 
     ctx = BootstrapContext(repo_root=manifest_path.parent, apply_changes=args.apply)
     automation = spec.get("automation")
-    sequence = automation.get("bootstrap_sequence", []) if isinstance(automation, Mapping) else []
+    sequence = (
+        automation.get("bootstrap_sequence", [])
+        if isinstance(automation, Mapping)
+        else []
+    )
     if not sequence:
         raise SystemExit("No automation.bootstrap_sequence defined in manifest")
 
diff --git a/workspace/tools/build_module.py b/workspace/tools/build_module.py
index 0ef1620..1e8ee20 100755
--- a/workspace/tools/build_module.py
+++ b/workspace/tools/build_module.py
@@ -11,7 +11,9 @@ import yaml
 
 
 def run(cmd, cwd=None):
-    p = subprocess.run(cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
+    p = subprocess.run(
+        cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True
+    )
     print(p.stdout)
     if p.returncode != 0:
         raise RuntimeError(f"Command failed: {' '.join(cmd)}")
diff --git a/workspace/tools/ci-cost-dashboard.py b/workspace/tools/ci-cost-dashboard.py
index d3fbbe2..dccd271 100755
--- a/workspace/tools/ci-cost-dashboard.py
+++ b/workspace/tools/ci-cost-dashboard.py
@@ -151,7 +151,9 @@ def analyze_runs(runs: list[dict[str, Any]]) -> dict[str, Any]:
     # Calculate averages
     for stats in workflow_stats.values():
         if stats["runs"] > 0:
-            stats["avg_duration_minutes"] = stats["total_duration_minutes"] / stats["runs"]
+            stats["avg_duration_minutes"] = (
+                stats["total_duration_minutes"] / stats["runs"]
+            )
 
     return {"workflows": dict(workflow_stats), "totals": total_stats}
 
@@ -174,7 +176,10 @@ def detect_anomalies(analysis: dict[str, Any]) -> list[str]:
             )
 
         # Check for excessive total minutes
-        if stats["total_duration_minutes"] > ANOMALY_THRESHOLDS["max_total_minutes_per_workflow"]:
+        if (
+            stats["total_duration_minutes"]
+            > ANOMALY_THRESHOLDS["max_total_minutes_per_workflow"]
+        ):
             anomalies.append(
                 f"âš ï¸ **{workflow_name}**: Excessive total minutes ({stats['total_duration_minutes']:.0f} min, threshold: {ANOMALY_THRESHOLDS['max_total_minutes_per_workflow']} min)"
             )
@@ -190,16 +195,18 @@ def detect_anomalies(analysis: dict[str, Any]) -> list[str]:
     return anomalies
 
 
-def generate_markdown_report(analysis: dict[str, Any], days: int, anomalies: list[str]) -> str:
+def generate_markdown_report(
+    analysis: dict[str, Any], days: int, anomalies: list[str]
+) -> str:
     """Generate markdown report."""
     now = datetime.utcnow()
-    report_period = (
-        f"{(now - timedelta(days=days)).strftime('%Y-%m-%d')} to {now.strftime('%Y-%m-%d')}"
-    )
+    report_period = f"{(now - timedelta(days=days)).strftime('%Y-%m-%d')} to {now.strftime('%Y-%m-%d')}"
 
     # Sort workflows by cost
     sorted_workflows = sorted(
-        analysis["workflows"].items(), key=lambda x: x[1]["total_cost_usd"], reverse=True
+        analysis["workflows"].items(),
+        key=lambda x: x[1]["total_cost_usd"],
+        reverse=True,
     )
 
     report = f"""# CI Cost Dashboard ğŸ“Š
@@ -237,7 +244,9 @@ def generate_markdown_report(analysis: dict[str, Any], days: int, anomalies: lis
     report += "|------|----------|------|---------|-----------|--------------|-------------|\n"
 
     for idx, (workflow_name, stats) in enumerate(sorted_workflows[:10], 1):
-        success_rate = (stats["successful"] / stats["runs"] * 100) if stats["runs"] > 0 else 0
+        success_rate = (
+            (stats["successful"] / stats["runs"] * 100) if stats["runs"] > 0 else 0
+        )
         report += (
             f"| {idx} | {workflow_name} | {stats['runs']} | "
             f"{stats['total_duration_minutes']:.0f} | ${stats['total_cost_usd']:.2f} | "
@@ -248,8 +257,12 @@ def generate_markdown_report(analysis: dict[str, Any], days: int, anomalies: lis
     report += "\n## ğŸ“ˆ All Workflows Detailed Statistics\n\n"
 
     for workflow_name, stats in sorted_workflows:
-        success_rate = (stats["successful"] / stats["runs"] * 100) if stats["runs"] > 0 else 0
-        failure_rate = (stats["failed"] / stats["runs"] * 100) if stats["runs"] > 0 else 0
+        success_rate = (
+            (stats["successful"] / stats["runs"] * 100) if stats["runs"] > 0 else 0
+        )
+        failure_rate = (
+            (stats["failed"] / stats["runs"] * 100) if stats["runs"] > 0 else 0
+        )
 
         report += f"\n### {workflow_name}\n\n"
         report += "| Metric | Value |\n"
@@ -272,7 +285,9 @@ def generate_markdown_report(analysis: dict[str, Any], days: int, anomalies: lis
 
         # Top branches
         if stats["branches"]:
-            top_branches = sorted(stats["branches"].items(), key=lambda x: x[1], reverse=True)[:5]
+            top_branches = sorted(
+                stats["branches"].items(), key=lambda x: x[1], reverse=True
+            )[:5]
             report += "\n**Top Branches**:\n"
             for branch, count in top_branches:
                 report += f"- `{branch}`: {count} runs\n"
@@ -292,7 +307,9 @@ def generate_markdown_report(analysis: dict[str, Any], days: int, anomalies: lis
             report += "  - Consider: Reducing trigger frequency, using path filters, or consolidating jobs\n"
 
     long_running_workflows = [
-        name for name, stats in analysis["workflows"].items() if stats["avg_duration_minutes"] > 15
+        name
+        for name, stats in analysis["workflows"].items()
+        if stats["avg_duration_minutes"] > 15
     ]
     if long_running_workflows:
         report += "\n### Long-Running Workflows\n\n"
@@ -313,7 +330,9 @@ def main():
     parser = argparse.ArgumentParser(description="Generate CI cost dashboard")
     parser.add_argument("--days", type=int, default=7, help="Number of days to analyze")
     parser.add_argument("--output", type=str, help="Output file path")
-    parser.add_argument("--check-anomalies", action="store_true", help="Check for anomalies only")
+    parser.add_argument(
+        "--check-anomalies", action="store_true", help="Check for anomalies only"
+    )
 
     args = parser.parse_args()
 
diff --git a/workspace/tools/cleanup_duplicates.py b/workspace/tools/cleanup_duplicates.py
index 8c6abfb..c847594 100755
--- a/workspace/tools/cleanup_duplicates.py
+++ b/workspace/tools/cleanup_duplicates.py
@@ -70,7 +70,9 @@ class DuplicatesCleaner:
                 rel_path = agent_file.relative_to(agent_dir)
                 services_file = services_agent_dir / rel_path
 
-                if services_file.exists() and self._files_identical(agent_file, services_file):
+                if services_file.exists() and self._files_identical(
+                    agent_file, services_file
+                ):
                     # ä¿ç•™ services/agents/ ç‰ˆæœ¬ï¼Œç§»é™¤ agent/ ç‰ˆæœ¬
                     self._remove_file(agent_file, f"é‡è¤‡æ–¼ services/agents/{rel_path}")
 
diff --git a/workspace/tools/directory_doc_generator.py b/workspace/tools/directory_doc_generator.py
index 0102a87..4e63551 100755
--- a/workspace/tools/directory_doc_generator.py
+++ b/workspace/tools/directory_doc_generator.py
@@ -78,13 +78,20 @@ class DirectoryDocGenerator:
             "venv",
             ".DS_Store",
         }
-        self.exclude_files = {".gitignore", ".gitkeep", "__init__.py", ".DS_Store", "Thumbs.db"}
+        self.exclude_files = {
+            ".gitignore",
+            ".gitkeep",
+            "__init__.py",
+            ".DS_Store",
+            "Thumbs.db",
+        }
 
     def should_exclude(self, path: Path) -> bool:
         """åˆ¤æ–·æ˜¯å¦æ‡‰è©²æ’é™¤æ­¤è·¯å¾‘"""
         name = path.name
         return any(
-            name == exclude or name.startswith(exclude.rstrip("*")) for exclude in self.exclude_dirs
+            name == exclude or name.startswith(exclude.rstrip("*"))
+            for exclude in self.exclude_dirs
         )
 
     def scan_directory(self, dir_path: Path) -> Dict:
@@ -129,7 +136,9 @@ class DirectoryDocGenerator:
             if file_path.suffix in [".py", ".js", ".ts", ".go", ".rs"]:
                 with open(file_path, "r", encoding="utf-8") as f:
                     lines = [f.readline() for _ in range(10)]
-                    file_info["docstring"] = self.extract_docstring(lines, file_path.suffix)
+                    file_info["docstring"] = self.extract_docstring(
+                        lines, file_path.suffix
+                    )
         except Exception as e:
             file_info["docstring"] = None
 
diff --git a/workspace/tools/docs/analyze_root_reports.py b/workspace/tools/docs/analyze_root_reports.py
index 330c8f4..afe3182 100755
--- a/workspace/tools/docs/analyze_root_reports.py
+++ b/workspace/tools/docs/analyze_root_reports.py
@@ -212,11 +212,17 @@ def _extract_recommendations(sections: list[ReportSection]) -> list[str]:
     return recommendations
 
 
-def _determine_status(metrics: ReportMetrics, content: str) -> tuple[str, bool, bool, bool]:
+def _determine_status(
+    metrics: ReportMetrics, content: str
+) -> tuple[str, bool, bool, bool]:
     """Determine overall status from metrics and content."""
     has_errors = metrics.error_count > 0 or ERROR_PATTERN.search(content) is not None
-    has_warnings = metrics.warning_count > 0 or WARNING_PATTERN.search(content) is not None
-    has_successes = metrics.success_count > 0 or STATUS_PATTERN.search(content) is not None
+    has_warnings = (
+        metrics.warning_count > 0 or WARNING_PATTERN.search(content) is not None
+    )
+    has_successes = (
+        metrics.success_count > 0 or STATUS_PATTERN.search(content) is not None
+    )
 
     if has_errors:
         status = "âŒ Issues Detected"
@@ -294,7 +300,9 @@ def analyze_report(file_path: Path, repo_root: Path) -> ReportAnalysis:
     metrics = _extract_metrics(content)
     key_findings = _extract_key_findings(sections)
     recommendations = _extract_recommendations(sections)
-    status, has_errors, has_warnings, has_successes = _determine_status(metrics, content)
+    status, has_errors, has_warnings, has_successes = _determine_status(
+        metrics, content
+    )
     category = _categorize_report(file_path)
     created_date = _extract_date(content, file_path)
 
@@ -384,7 +392,9 @@ def generate_consolidated_analysis(
         "categories": list(reports_by_category.keys()),
     }
 
-    generated_at = datetime.now(UTC).replace(microsecond=0).isoformat().replace("+00:00", "Z")
+    generated_at = (
+        datetime.now(UTC).replace(microsecond=0).isoformat().replace("+00:00", "Z")
+    )
 
     return ConsolidatedAnalysis(
         generated_at=generated_at,
@@ -687,7 +697,9 @@ def main() -> None:
     # Generate YAML output if requested
     if args.yaml_output:
         if yaml is None:
-            print("Warning: PyYAML not available, skipping YAML output", file=sys.stderr)
+            print(
+                "Warning: PyYAML not available, skipping YAML output", file=sys.stderr
+            )
         else:
             # Convert to dict for YAML serialization
             data = json.loads(render_json_output(consolidated))
diff --git a/workspace/tools/docs/generate_knowledge_graph.py b/workspace/tools/docs/generate_knowledge_graph.py
index 8102d28..5dc0a32 100644
--- a/workspace/tools/docs/generate_knowledge_graph.py
+++ b/workspace/tools/docs/generate_knowledge_graph.py
@@ -199,7 +199,9 @@ class KnowledgeGraphGenerator:
             if item.is_dir():
                 self._process_directory(item, parent_id="system:unmanned-island")
 
-    def _process_directory(self, dir_path: Path, parent_id: str, depth: int = 0) -> None:
+    def _process_directory(
+        self, dir_path: Path, parent_id: str, depth: int = 0
+    ) -> None:
         """Process a directory and its contents."""
         if depth > 3:  # Limit depth
             return
@@ -237,7 +239,13 @@ class KnowledgeGraphGenerator:
 
                 if item.is_dir():
                     self._process_directory(item, node_id, depth + 1)
-                elif item.is_file() and item.suffix in [".py", ".ts", ".js", ".yaml", ".yml"]:
+                elif item.is_file() and item.suffix in [
+                    ".py",
+                    ".ts",
+                    ".js",
+                    ".yaml",
+                    ".yml",
+                ]:
                     self._process_file(item, node_id)
 
     def _process_file(self, file_path: Path, parent_id: str) -> None:
@@ -279,7 +287,9 @@ class KnowledgeGraphGenerator:
             for yaml_file in components_dir.glob("*.yaml"):
                 self._process_mndoc_file(yaml_file, "component", "å…ƒä»¶")
 
-    def _process_mndoc_file(self, file_path: Path, default_type: str, label_zh: str) -> None:
+    def _process_mndoc_file(
+        self, file_path: Path, default_type: str, label_zh: str
+    ) -> None:
         """Process a single MN-DOC YAML file."""
         try:
             with open(file_path, encoding="utf-8") as f:
@@ -327,7 +337,9 @@ class KnowledgeGraphGenerator:
                     else f"capability:{cap.get('id', 'unknown')}"
                 )
                 cap_label = (
-                    cap if isinstance(cap, str) else cap.get("name", cap.get("id", "unknown"))
+                    cap
+                    if isinstance(cap, str)
+                    else cap.get("name", cap.get("id", "unknown"))
                 )
 
                 if self._add_node(
diff --git a/workspace/tools/docs/generate_mndoc_from_readme.py b/workspace/tools/docs/generate_mndoc_from_readme.py
index 969a6d8..9d7bc81 100644
--- a/workspace/tools/docs/generate_mndoc_from_readme.py
+++ b/workspace/tools/docs/generate_mndoc_from_readme.py
@@ -159,7 +159,9 @@ def split_sections(text: str) -> list[dict[str, Any]]:
                 "title": clean_title,
                 "type": classify_section(clean_title),
                 "content_preview": (
-                    section_content[:200] + "..." if len(section_content) > 200 else section_content
+                    section_content[:200] + "..."
+                    if len(section_content) > 200
+                    else section_content
                 ),
             }
         )
diff --git a/workspace/tools/docs/pr_comment_summary.py b/workspace/tools/docs/pr_comment_summary.py
index 0e90a2d..d6484a3 100644
--- a/workspace/tools/docs/pr_comment_summary.py
+++ b/workspace/tools/docs/pr_comment_summary.py
@@ -39,7 +39,10 @@ def generate_stage_summary(results: dict[str, Any]) -> str:
         ("8", "Audit", "audit"),
     ]
 
-    lines = ["| Stage | Name | Status | Duration |", "|-------|------|--------|----------|"]
+    lines = [
+        "| Stage | Name | Status | Duration |",
+        "|-------|------|--------|----------|",
+    ]
 
     for num, name, key in stages:
         stage_result = results.get(key, {})
@@ -130,13 +133,31 @@ def generate_pr_comment(results: dict[str, Any], context: dict[str, str] = None)
     # Determine overall status
     all_passed = all(
         results.get(stage, {}).get("status") in ("success", "skipped")
-        for stage in ["lint", "format", "schema", "vector", "policy", "sbom", "provenance", "audit"]
+        for stage in [
+            "lint",
+            "format",
+            "schema",
+            "vector",
+            "policy",
+            "sbom",
+            "provenance",
+            "audit",
+        ]
     )
 
     header_emoji = "âœ…" if all_passed else "âš ï¸"
-    header_text = "Governance Pipeline Passed" if all_passed else "Governance Pipeline Issues Found"
+    header_text = (
+        "Governance Pipeline Passed"
+        if all_passed
+        else "Governance Pipeline Issues Found"
+    )
 
-    sections = [f"## {header_emoji} {header_text}", "", generate_stage_summary(results), ""]
+    sections = [
+        f"## {header_emoji} {header_text}",
+        "",
+        generate_stage_summary(results),
+        "",
+    ]
 
     # Add details if there are issues
     details = generate_validation_details(results)
@@ -172,7 +193,9 @@ def generate_pr_comment(results: dict[str, Any], context: dict[str, str] = None)
     if all_passed:
         sections.append("*All governance checks completed successfully.* ğŸ‰")
     else:
-        sections.append("*Please review the issues above and address them before merging.*")
+        sections.append(
+            "*Please review the issues above and address them before merging.*"
+        )
 
     return "\n".join(sections)
 
@@ -191,7 +214,10 @@ def main():
     parser.add_argument("--input", "-i", help="Input results file (JSON/YAML)")
     parser.add_argument("--output", "-o", help="Output file (default: stdout)")
     parser.add_argument(
-        "--format", choices=["markdown", "json"], default="markdown", help="Output format"
+        "--format",
+        choices=["markdown", "json"],
+        default="markdown",
+        help="Output format",
     )
     args = parser.parse_args()
 
@@ -220,7 +246,12 @@ def main():
             },
             "vector": {"status": "success", "duration_ms": 800},
             "policy": {"status": "success", "duration_ms": 600, "violations": []},
-            "sbom": {"status": "success", "duration_ms": 1000, "exists": True, "packages": 35},
+            "sbom": {
+                "status": "success",
+                "duration_ms": 1000,
+                "exists": True,
+                "packages": 35,
+            },
             "provenance": {
                 "status": "success",
                 "duration_ms": 500,
diff --git a/workspace/tools/docs/project_to_superroot.py b/workspace/tools/docs/project_to_superroot.py
index 5936db9..942d40c 100644
--- a/workspace/tools/docs/project_to_superroot.py
+++ b/workspace/tools/docs/project_to_superroot.py
@@ -244,7 +244,9 @@ Examples:
         if args.verbose:
             print(f"âœ… Generated: {output_path}")
             print(f"   - Entities: {superroot_data['summary']['total_entities']}")
-            print(f"   - Relationships: {superroot_data['summary']['total_relationships']}")
+            print(
+                f"   - Relationships: {superroot_data['summary']['total_relationships']}"
+            )
             print(
                 f"   - Entity types: {', '.join(superroot_data['summary']['entities_by_type'].keys())}"
             )
diff --git a/workspace/tools/docs/provenance_injector.py b/workspace/tools/docs/provenance_injector.py
index fc20a4f..0e59550 100644
--- a/workspace/tools/docs/provenance_injector.py
+++ b/workspace/tools/docs/provenance_injector.py
@@ -76,7 +76,10 @@ def get_git_info(repo_root: Path) -> dict[str, str]:
 
         # Get remote URL
         result = subprocess.run(
-            ["git", "remote", "get-url", "origin"], cwd=repo_root, capture_output=True, text=True
+            ["git", "remote", "get-url", "origin"],
+            cwd=repo_root,
+            capture_output=True,
+            text=True,
         )
         if result.returncode == 0:
             git_info["remote"] = result.stdout.strip()
@@ -182,7 +185,11 @@ def generate_spdx_sbom(items: list[dict[str, Any]], repo_root: Path) -> dict[str
 
         # Add relationship
         relationships.append(
-            {"spdxElementId": root_id, "relatedSpdxElement": pkg_id, "relationshipType": "CONTAINS"}
+            {
+                "spdxElementId": root_id,
+                "relatedSpdxElement": pkg_id,
+                "relationshipType": "CONTAINS",
+            }
         )
 
     # Document describes root
@@ -202,7 +209,10 @@ def generate_spdx_sbom(items: list[dict[str, Any]], repo_root: Path) -> dict[str
         "documentNamespace": f"https://github.com/Unmanned-Island-admin/SynergyMesh/sbom/{uuid4()}",
         "creationInfo": {
             "created": now.isoformat(),
-            "creators": ["Tool: SynergyMesh Provenance Injector", "Organization: SynergyMesh Team"],
+            "creators": [
+                "Tool: SynergyMesh Provenance Injector",
+                "Organization: SynergyMesh Team",
+            ],
             "licenseListVersion": "3.21",
         },
         "documentDescribes": [root_id],
@@ -232,12 +242,16 @@ def inject_provenance_into_index(
 
     # Write updated index
     with open(output_path, "w", encoding="utf-8") as f:
-        yaml.dump(index, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
+        yaml.dump(
+            index, f, allow_unicode=True, default_flow_style=False, sort_keys=False
+        )
 
     return index
 
 
-def generate_audit_event(action: str, subject: str, details: dict[str, Any]) -> dict[str, Any]:
+def generate_audit_event(
+    action: str, subject: str, details: dict[str, Any]
+) -> dict[str, Any]:
     """Generate an audit event record."""
     now = datetime.now(timezone.utc)
 
@@ -266,15 +280,23 @@ def main():
     parser.add_argument(
         "--input", "-i", default="docs/knowledge_index.yaml", help="Input index file"
     )
-    parser.add_argument("--output", "-o", help="Output file path (default: same as input)")
-    parser.add_argument("--generate-sbom", action="store_true", help="Generate SPDX SBOM")
+    parser.add_argument(
+        "--output", "-o", help="Output file path (default: same as input)"
+    )
+    parser.add_argument(
+        "--generate-sbom", action="store_true", help="Generate SPDX SBOM"
+    )
     parser.add_argument(
         "--generate-provenance", action="store_true", help="Generate SLSA provenance"
     )
-    parser.add_argument("--inject", action="store_true", help="Inject provenance into index")
+    parser.add_argument(
+        "--inject", action="store_true", help="Inject provenance into index"
+    )
     parser.add_argument("--audit", action="store_true", help="Generate audit event")
     parser.add_argument(
-        "--sbom-output", default="governance/sbom/docs-sbom.spdx.json", help="SBOM output path"
+        "--sbom-output",
+        default="governance/sbom/docs-sbom.spdx.json",
+        help="SBOM output path",
     )
     parser.add_argument(
         "--provenance-output",
@@ -344,7 +366,9 @@ def main():
     if args.inject:
         print("ğŸ’‰ æ³¨å…¥æº¯æºè³‡è¨Š...")
         updated_index = inject_provenance_into_index(input_path, output_path, repo_root)
-        items_with_prov = sum(1 for item in updated_index.get("items", []) if "provenance" in item)
+        items_with_prov = sum(
+            1 for item in updated_index.get("items", []) if "provenance" in item
+        )
         print(f"   âœ… å·²æ›´æ–°: {output_path}")
         print(f"   ğŸ“Š {items_with_prov} å€‹é …ç›®å«æœ‰æº¯æºè³‡è¨Š")
         print()
diff --git a/workspace/tools/docs/scan_repo_generate_index.py b/workspace/tools/docs/scan_repo_generate_index.py
index 75fea06..8c0448a 100644
--- a/workspace/tools/docs/scan_repo_generate_index.py
+++ b/workspace/tools/docs/scan_repo_generate_index.py
@@ -232,7 +232,9 @@ def extract_tags(file_path: Path, content: str = None) -> list[str]:
     return sorted(list(tags))[:5]  # Limit to 5 tags
 
 
-def scan_repository(repo_root: Path, include_patterns: list[str] = None) -> list[dict[str, Any]]:
+def scan_repository(
+    repo_root: Path, include_patterns: list[str] = None
+) -> list[dict[str, Any]]:
     """Scan repository and generate index entries."""
     if include_patterns is None:
         include_patterns = ["**/*.md", "**/README.md"]
@@ -255,7 +257,10 @@ def scan_repository(repo_root: Path, include_patterns: list[str] = None) -> list
             seen_paths.add(rel_str)
 
             # Skip node_modules, dist, etc.
-            if any(skip in rel_str for skip in ["node_modules", "dist/", "__pycache__", ".git/"]):
+            if any(
+                skip in rel_str
+                for skip in ["node_modules", "dist/", "__pycache__", ".git/"]
+            ):
                 continue
 
             # Generate entry
@@ -339,12 +344,18 @@ def generate_index(items: list[dict[str, Any]]) -> dict[str, Any]:
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Scan repository and generate docs index")
+    parser = argparse.ArgumentParser(
+        description="Scan repository and generate docs index"
+    )
     parser.add_argument(
         "--output", "-o", default="docs/generated-index.yaml", help="Output file path"
     )
-    parser.add_argument("--dry-run", action="store_true", help="Print output without writing file")
-    parser.add_argument("--json", action="store_true", help="Output as JSON instead of YAML")
+    parser.add_argument(
+        "--dry-run", action="store_true", help="Print output without writing file"
+    )
+    parser.add_argument(
+        "--json", action="store_true", help="Output as JSON instead of YAML"
+    )
     parser.add_argument(
         "--include", nargs="+", default=["**/*.md"], help="Glob patterns to include"
     )
@@ -372,7 +383,11 @@ def main():
         if args.json:
             print(json.dumps(index, indent=2, ensure_ascii=False))
         else:
-            print(yaml.dump(index, allow_unicode=True, default_flow_style=False, sort_keys=False))
+            print(
+                yaml.dump(
+                    index, allow_unicode=True, default_flow_style=False, sort_keys=False
+                )
+            )
     else:
         output_path = repo_root / args.output
         output_path.parent.mkdir(parents=True, exist_ok=True)
@@ -381,7 +396,13 @@ def main():
             if args.json:
                 json.dump(index, f, indent=2, ensure_ascii=False)
             else:
-                yaml.dump(index, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
+                yaml.dump(
+                    index,
+                    f,
+                    allow_unicode=True,
+                    default_flow_style=False,
+                    sort_keys=False,
+                )
 
         print(f"ğŸ’¾ ç´¢å¼•å·²å¯«å…¥: {output_path}")
 
diff --git a/workspace/tools/docs/validate_index.py b/workspace/tools/docs/validate_index.py
index ace01b6..b172478 100644
--- a/workspace/tools/docs/validate_index.py
+++ b/workspace/tools/docs/validate_index.py
@@ -119,7 +119,9 @@ def validate_file_exists(doc: dict[str, Any], repo_root: Path) -> list[str]:
     errors = []
     file_path = repo_root / doc["path"]
     if not file_path.exists():
-        errors.append(f"Document '{doc['id']}' references non-existent file: {doc['path']}")
+        errors.append(
+            f"Document '{doc['id']}' references non-existent file: {doc['path']}"
+        )
     return errors
 
 
@@ -135,18 +137,24 @@ def validate_unique_ids(documents: list[dict[str, Any]]) -> list[str]:
     return errors
 
 
-def validate_relationships(relationships: list[dict[str, Any]], doc_ids: set[str]) -> list[str]:
+def validate_relationships(
+    relationships: list[dict[str, Any]], doc_ids: set[str]
+) -> list[str]:
     """Check that all relationships reference valid document IDs."""
     errors = []
     for rel in relationships:
         if rel.get("from") not in doc_ids:
-            errors.append(f"Relationship references unknown document: {rel.get('from')}")
+            errors.append(
+                f"Relationship references unknown document: {rel.get('from')}"
+            )
         if rel.get("to") not in doc_ids:
             errors.append(f"Relationship references unknown document: {rel.get('to')}")
     return errors
 
 
-def validate_domains(documents: list[dict[str, Any]], categories: dict[str, Any]) -> list[str]:
+def validate_domains(
+    documents: list[dict[str, Any]], categories: dict[str, Any]
+) -> list[str]:
     """Check that all documents use valid domain categories."""
     errors = []
     valid_domains = set(categories.keys())
@@ -170,8 +178,12 @@ def validate_layers(documents: list[dict[str, Any]], layers: list[str]) -> list[
 
 def main():
     parser = argparse.ArgumentParser(description="Validate knowledge index YAML file")
-    parser.add_argument("--verbose", "-v", action="store_true", help="Show detailed output")
-    parser.add_argument("--skip-schema", action="store_true", help="Skip JSON schema validation")
+    parser.add_argument(
+        "--verbose", "-v", action="store_true", help="Show detailed output"
+    )
+    parser.add_argument(
+        "--skip-schema", action="store_true", help="Skip JSON schema validation"
+    )
     args = parser.parse_args()
 
     # Determine paths
diff --git a/workspace/tools/evidence_generator.py b/workspace/tools/evidence_generator.py
index d8de087..49c4d77 100755
--- a/workspace/tools/evidence_generator.py
+++ b/workspace/tools/evidence_generator.py
@@ -29,7 +29,11 @@ def hash_tree(root: Path):
     for p in sorted(root.rglob("*")):
         if p.is_file():
             items.append(
-                {"path": str(p.relative_to(root)), "hash": hash_file(p), "size": p.stat().st_size}
+                {
+                    "path": str(p.relative_to(root)),
+                    "hash": hash_file(p),
+                    "size": p.stat().st_size,
+                }
             )
     # tree hashï¼šä»¥ï¼ˆpath + sha3-512ï¼‰ä¸²æ¥å† sha3-512ï¼ˆç°¡å–®å¯é‡æ’­ï¼‰
     h3 = hashlib.sha3_512()
@@ -123,7 +127,12 @@ def main():
                 "name": "aaps-rootfs",
                 "versionInfo": provenance["commit"],
                 "checksums": (
-                    [{"algorithm": "SHA3-512", "checksumValue": rootfs_hash["sha3-512"]}]
+                    [
+                        {
+                            "algorithm": "SHA3-512",
+                            "checksumValue": rootfs_hash["sha3-512"],
+                        }
+                    ]
                     if rootfs_hash["sha3-512"]
                     else []
                 ),
@@ -152,7 +161,8 @@ def main():
         json.dumps(sbom, ensure_ascii=False, indent=2), encoding="utf-8"
     )
     (evidence_dir / "gate-report.json").write_text(
-        json.dumps({"gates": gate_reports}, ensure_ascii=False, indent=2), encoding="utf-8"
+        json.dumps({"gates": gate_reports}, ensure_ascii=False, indent=2),
+        encoding="utf-8",
     )
 
     print("Evidence generated under dist/evidence/")
diff --git a/workspace/tools/evolution/generate_evolution_report.py b/workspace/tools/evolution/generate_evolution_report.py
index 78c7eeb..a280f9f 100755
--- a/workspace/tools/evolution/generate_evolution_report.py
+++ b/workspace/tools/evolution/generate_evolution_report.py
@@ -81,7 +81,9 @@ def count_semgrep_high(semgrep_path: Path) -> int:
     return high
 
 
-def compute_playbook_coverage(cluster_heatmap_path: Path, playbooks_root: Path) -> float:
+def compute_playbook_coverage(
+    cluster_heatmap_path: Path, playbooks_root: Path
+) -> float:
     """
     æ¦‚å¿µï¼š
       - å¾ cluster-heatmap.json æŠ½å‡ºæ‰€æœ‰ clusters åç¨±ï¼ˆæ‰å¹³çµæ§‹ï¼Œå¦‚ "core/", "services/" ç­‰ï¼‰
@@ -160,7 +162,9 @@ def main():
     # 1) æ”¶é›†åŸå§‹æŒ‡æ¨™
     language_violations_total = count_language_violations(lang_report_path)
     semgrep_high_total = count_semgrep_high(semgrep_path)
-    playbook_coverage_ratio = compute_playbook_coverage(cluster_heatmap_path, playbooks_root)
+    playbook_coverage_ratio = compute_playbook_coverage(
+        cluster_heatmap_path, playbooks_root
+    )
 
     metrics = {
         "language_violations_total": language_violations_total,
@@ -219,7 +223,9 @@ def main():
         yaml.safe_dump(state, f, sort_keys=False, allow_unicode=True)
 
     # 4) æº–å‚™ SYSTEM_EVOLUTION_REPORT.mdï¼ˆäººé¡å¯è®€ï¼‰
-    report_path = ROOT / outputs.get("report_markdown", "docs/SYSTEM_EVOLUTION_REPORT.md")
+    report_path = ROOT / outputs.get(
+        "report_markdown", "docs/SYSTEM_EVOLUTION_REPORT.md"
+    )
     report_path.parent.mkdir(parents=True, exist_ok=True)
 
     lines = []
@@ -237,7 +243,9 @@ def main():
     for obj in scored_objectives:
         lines.append(f"### {obj['name']} (`{obj['id']}`)")
         lines.append(f"- æŒ‡æ¨™ï¼š`{obj['metric']}`")
-        lines.append(f"- ç›®å‰å€¼ï¼š`{obj['value']}`ï¼Œç›®æ¨™ï¼š`{obj['target']}`ï¼ˆ{obj['direction']}ï¼‰")
+        lines.append(
+            f"- ç›®å‰å€¼ï¼š`{obj['value']}`ï¼Œç›®æ¨™ï¼š`{obj['target']}`ï¼ˆ{obj['direction']}ï¼‰"
+        )
         lines.append(f"- æ¬Šé‡ï¼š{obj['weight']}")
         lines.append(f"- å¾—åˆ†ï¼š**{obj['score']}/100**\n")
 
diff --git a/workspace/tools/find_duplicate_scripts.py b/workspace/tools/find_duplicate_scripts.py
index 8f441bd..b35535c 100755
--- a/workspace/tools/find_duplicate_scripts.py
+++ b/workspace/tools/find_duplicate_scripts.py
@@ -17,7 +17,15 @@ class ScriptDuplicateFinder:
     def __init__(self, repo_root: Path):
         self.repo_root = repo_root
         self.script_extensions = {".py", ".sh", ".js", ".ts"}
-        self.skip_dirs = {"node_modules", ".git", "__pycache__", ".venv", "venv", "dist", "build"}
+        self.skip_dirs = {
+            "node_modules",
+            ".git",
+            "__pycache__",
+            ".venv",
+            "venv",
+            "dist",
+            "build",
+        }
 
     def find_duplicates(self) -> Dict[str, List[str]]:
         """æŸ¥æ‰¾é‡è¤‡è…³æœ¬ï¼ˆåŸºæ–¼å…§å®¹å“ˆå¸Œï¼‰"""
@@ -46,7 +54,9 @@ class ScriptDuplicateFinder:
             name_to_files[name].append(rel_path)
 
         # éæ¿¾å‡ºåç¨±é‡è¤‡
-        similar = {name: files for name, files in name_to_files.items() if len(files) > 1}
+        similar = {
+            name: files for name, files in name_to_files.items() if len(files) > 1
+        }
         return similar
 
     def _iter_scripts(self):
@@ -94,7 +104,9 @@ class ScriptDuplicateFinder:
                     print(f"    - {file}")
 
         # 3. çµ±è¨ˆ
-        total_duplicate_files = sum(len(files) - 1 for files in content_duplicates.values())
+        total_duplicate_files = sum(
+            len(files) - 1 for files in content_duplicates.values()
+        )
         print(f"\n\nğŸ“Š çµ±è¨ˆ:")
         print(f"  å¯ç§»é™¤çš„é‡è¤‡æ–‡ä»¶æ•¸: {total_duplicate_files}")
         print(f"  åç¨±è¡çªçµ„æ•¸: {len(name_similar)}")
diff --git a/workspace/tools/generate-hotspot-heatmap.py b/workspace/tools/generate-hotspot-heatmap.py
index 15ccbb3..004f441 100755
--- a/workspace/tools/generate-hotspot-heatmap.py
+++ b/workspace/tools/generate-hotspot-heatmap.py
@@ -46,7 +46,9 @@ def parse_governance_report(report_path: Path) -> list[dict[str, Any]]:
     lines = content.split("\n")
     for line in lines:
         if "â€”" in line and "**" in line:
-            match = re.match(r"-\s*\*\*(.*?)\*\*\s*â€”\s*(.*?)(?:\(Layer:\s*(.*?)\))?$", line)
+            match = re.match(
+                r"-\s*\*\*(.*?)\*\*\s*â€”\s*(.*?)(?:\(Layer:\s*(.*?)\))?$", line
+            )
             if match:
                 file_path = match.group(1).strip()
                 reason = match.group(2).strip()
@@ -55,7 +57,12 @@ def parse_governance_report(report_path: Path) -> list[dict[str, Any]]:
                 violation_type = classify_violation(reason)
 
                 violations.append(
-                    {"file": file_path, "reason": reason, "layer": layer, "type": violation_type}
+                    {
+                        "file": file_path,
+                        "reason": reason,
+                        "layer": layer,
+                        "type": violation_type,
+                    }
                 )
 
     return violations
@@ -67,7 +74,11 @@ def classify_violation(reason: str) -> str:
 
     if "forbidden" in reason_lower or "not allowed" in reason_lower:
         return "forbidden_language"
-    elif "cross-layer" in reason_lower or "layer" in reason_lower or "wrong layer" in reason_lower:
+    elif (
+        "cross-layer" in reason_lower
+        or "layer" in reason_lower
+        or "wrong layer" in reason_lower
+    ):
         return "layer_violation"
     elif "security" in reason_lower or "vulnerability" in reason_lower:
         return "security_issue"
@@ -201,7 +212,9 @@ def generate_hotspot_data():
     repeated_violations = load_violation_history(history_path)
 
     # Aggregate by file
-    file_data = defaultdict(lambda: {"violations": [], "security_issues": 0, "repeated_count": 0})
+    file_data = defaultdict(
+        lambda: {"violations": [], "security_issues": 0, "repeated_count": 0}
+    )
 
     for violation in violations:
         file_path = violation["file"]
@@ -313,7 +326,9 @@ def generate_markdown_report(data: dict[str, Any], project_root: Path):
 
     for hotspot in data["hotspots"][:20]:  # Top 20 hotspots
         violations_str = ", ".join(hotspot["violations"])
-        intensity = "ğŸ”´" if hotspot["score"] >= 70 else "ğŸŸ " if hotspot["score"] >= 40 else "ğŸŸ¡"
+        intensity = (
+            "ğŸ”´" if hotspot["score"] >= 70 else "ğŸŸ " if hotspot["score"] >= 40 else "ğŸŸ¡"
+        )
         report += f"| {intensity} {hotspot['score']} | `{hotspot['file']}` | {hotspot['layer']} | {hotspot['language']} | {violations_str} | {hotspot['security_issues']} |\n"
 
     report += """
diff --git a/workspace/tools/generate-language-dashboard.py b/workspace/tools/generate-language-dashboard.py
index d3ddd9d..16d51a1 100755
--- a/workspace/tools/generate-language-dashboard.py
+++ b/workspace/tools/generate-language-dashboard.py
@@ -76,7 +76,9 @@ def calculate_statistics(
     """Calculate all dashboard statistics"""
     stats = {
         "timestamp": datetime.datetime.utcnow().isoformat() + "Z",
-        "generation_timestamp": datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC"),
+        "generation_timestamp": datetime.datetime.utcnow().strftime(
+            "%Y-%m-%d %H:%M:%S UTC"
+        ),
     }
 
     # Health score
@@ -103,7 +105,10 @@ def calculate_statistics(
 
     # Architecture
     stats["architecture_compliance"] = (
-        health_data.get("components", {}).get("architecture_alignment", {}).get("score", 0) * 5
+        health_data.get("components", {})
+        .get("architecture_alignment", {})
+        .get("score", 0)
+        * 5
     )
 
     # Trends
@@ -230,9 +235,14 @@ def generate_hotspot_table(violations: list[dict]) -> str:
         vdir = "/".join(vfile.split("/")[:2]) if "/" in vfile else vfile
         dir_counts[vdir] += 1
 
-    lines = ["| Directory | Violations | Status |", "|-----------|------------|--------|"]
+    lines = [
+        "| Directory | Violations | Status |",
+        "|-----------|------------|--------|",
+    ]
 
-    for vdir, count in sorted(dir_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
+    for vdir, count in sorted(dir_counts.items(), key=lambda x: x[1], reverse=True)[
+        :10
+    ]:
         status = "ğŸ”´" if count > 10 else "ğŸŸ¡" if count > 5 else "ğŸŸ¢"
         lines.append(f"| `{vdir}` | {count} | {status} |")
 
@@ -251,7 +261,9 @@ def generate_dashboard(args):
     semgrep_data = load_sarif(args.semgrep_results)
 
     console.print("[cyan]Calculating statistics...[/cyan]")
-    stats = calculate_statistics(governance_data, codeql_data, semgrep_data, health_data)
+    stats = calculate_statistics(
+        governance_data, codeql_data, semgrep_data, health_data
+    )
 
     console.print("[cyan]Generating dashboard sections...[/cyan]")
 
@@ -279,7 +291,9 @@ def generate_dashboard(args):
         "COMPLIANCE_STATUS": stats["compliance_status"],
         "FIX_SUCCESS_RATE": "85",  # Placeholder
         "FIX_STATUS": "ğŸŸ¢",
-        "VIOLATIONS_TABLE": generate_violations_table(governance_data.get("violations", [])),
+        "VIOLATIONS_TABLE": generate_violations_table(
+            governance_data.get("violations", [])
+        ),
         "LANGUAGE_DISTRIBUTION_CHART": generate_language_chart(governance_data),
         "HEALTH_SCORE_TREND_CHART": "Trend data not available",
         "VIOLATION_TREND_CHART": generate_trend_chart(history_data),
@@ -310,7 +324,9 @@ def generate_dashboard(args):
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Generate Language Governance Dashboard")
+    parser = argparse.ArgumentParser(
+        description="Generate Language Governance Dashboard"
+    )
     parser.add_argument(
         "--governance-report",
         default="governance/language-governance-report.json",
@@ -327,13 +343,19 @@ def main():
         help="Path to Semgrep SARIF file",
     )
     parser.add_argument(
-        "--history", default="knowledge/language-history.yaml", help="Path to fix history YAML"
+        "--history",
+        default="knowledge/language-history.yaml",
+        help="Path to fix history YAML",
     )
     parser.add_argument(
-        "--health", default="knowledge/language-health-score.yaml", help="Path to health score YAML"
+        "--health",
+        default="knowledge/language-health-score.yaml",
+        help="Path to health score YAML",
     )
     parser.add_argument(
-        "--output", default="docs/LANGUAGE_GOVERNANCE_DASHBOARD.md", help="Output dashboard file"
+        "--output",
+        default="docs/LANGUAGE_GOVERNANCE_DASHBOARD.md",
+        help="Output dashboard file",
     )
 
     args = parser.parse_args()
diff --git a/workspace/tools/generate-migration-flow.py b/workspace/tools/generate-migration-flow.py
index 2467126..576bfe3 100755
--- a/workspace/tools/generate-migration-flow.py
+++ b/workspace/tools/generate-migration-flow.py
@@ -76,7 +76,11 @@ def classify_violation_type(reason: str) -> str:
 
     if "forbidden" in reason_lower or "not allowed" in reason_lower:
         return "forbidden"
-    elif "cross-layer" in reason_lower or "layer" in reason_lower or "wrong layer" in reason_lower:
+    elif (
+        "cross-layer" in reason_lower
+        or "layer" in reason_lower
+        or "wrong layer" in reason_lower
+    ):
         return "layer_violation"
     elif "security" in reason_lower or "vulnerability" in reason_lower:
         return "security"
@@ -148,7 +152,9 @@ def parse_governance_report(report_path: Path) -> list[dict[str, Any]]:
     lines = content.split("\n")
     for line in lines:
         if "â€”" in line and "**" in line:
-            match = re.match(r"-\s*\*\*(.*?)\*\*\s*â€”\s*(.*?)(?:\(Layer:\s*(.*?)\))?$", line)
+            match = re.match(
+                r"-\s*\*\*(.*?)\*\*\s*â€”\s*(.*?)(?:\(Layer:\s*(.*?)\))?$", line
+            )
             if match:
                 file_path = match.group(1).strip()
                 reason = match.group(2).strip()
@@ -189,7 +195,11 @@ def parse_migration_history(history_path: Path) -> list[dict[str, Any]]:
             details = event.get("details", "")
 
             # Look for migration/rewrite patterns
-            if event_type == "fix" or "rewrite" in details.lower() or "move" in details.lower():
+            if (
+                event_type == "fix"
+                or "rewrite" in details.lower()
+                or "move" in details.lower()
+            ):
                 # Try to parse migration info from details
                 # Example: "Moved services/old.cpp to autonomous/new.cpp"
                 # Example: "Rewrote core/util.js to core/util.ts"
@@ -256,7 +266,9 @@ def build_migration_edges(
 
     # Convert to edge list
     for (source, target, edge_type), count in edge_counts.items():
-        edges.append({"source": source, "target": target, "count": count, "type": edge_type})
+        edges.append(
+            {"source": source, "target": target, "count": count, "type": edge_type}
+        )
 
     # Sort by count (highest first)
     edges.sort(key=lambda x: x["count"], reverse=True)
@@ -331,7 +343,9 @@ def generate_migration_flow_data():
     # Calculate statistics
     total_migrations = sum(edge["count"] for edge in edges)
     history_count = sum(edge["count"] for edge in edges if edge["type"] == "history")
-    suggested_count = sum(edge["count"] for edge in edges if edge["type"] == "suggested")
+    suggested_count = sum(
+        edge["count"] for edge in edges if edge["type"] == "suggested"
+    )
 
     # Most common source
     source_counts = defaultdict(int)
@@ -404,9 +418,7 @@ def generate_migration_flow_data():
 """
 
     for edge in edges[:20]:  # Top 20
-        mermaid_content += (
-            f"| `{edge['source']}` | `{edge['target']}` | {edge['count']} | {edge['type']} |\n"
-        )
+        mermaid_content += f"| `{edge['source']}` | `{edge['target']}` | {edge['count']} | {edge['type']} |\n"
 
     mermaid_content += """
 ---
diff --git a/workspace/tools/generate-refactor-playbook.py b/workspace/tools/generate-refactor-playbook.py
index 5eec82b..9f801d2 100755
--- a/workspace/tools/generate-refactor-playbook.py
+++ b/workspace/tools/generate-refactor-playbook.py
@@ -228,14 +228,18 @@ services/gateway/
         print("ğŸ“‚ Loading governance data...")
 
         # Load language governance report
-        gov_report_path = self.repo_root / "governance" / "language-governance-report.md"
+        gov_report_path = (
+            self.repo_root / "governance" / "language-governance-report.md"
+        )
         if gov_report_path.exists():
             self._parse_governance_report(gov_report_path)
         else:
             print(f"âš ï¸ Governance report not found: {gov_report_path}")
 
         # Load hotspot data
-        hotspot_path = self.repo_root / "apps" / "web" / "public" / "data" / "hotspot.json"
+        hotspot_path = (
+            self.repo_root / "apps" / "web" / "public" / "data" / "hotspot.json"
+        )
         if hotspot_path.exists():
             with open(hotspot_path) as f:
                 self.hotspots = json.load(f)
@@ -251,7 +255,9 @@ services/gateway/
             print(f"âš ï¸ Semgrep report not found: {semgrep_path}")
 
         # Load migration flow
-        migration_path = self.repo_root / "apps" / "web" / "public" / "data" / "migration-flow.json"
+        migration_path = (
+            self.repo_root / "apps" / "web" / "public" / "data" / "migration-flow.json"
+        )
         if migration_path.exists():
             with open(migration_path) as f:
                 self.migration_flows = json.load(f)
@@ -259,7 +265,9 @@ services/gateway/
             print(f"âš ï¸ Migration flow not found: {migration_path}")
 
         # Load cluster heatmap
-        cluster_path = self.repo_root / "apps" / "web" / "public" / "data" / "cluster-heatmap.json"
+        cluster_path = (
+            self.repo_root / "apps" / "web" / "public" / "data" / "cluster-heatmap.json"
+        )
         if cluster_path.exists():
             with open(cluster_path) as f:
                 self.clusters = json.load(f)
@@ -267,7 +275,9 @@ services/gateway/
             print(f"âš ï¸ Cluster heatmap not found: {cluster_path}")
 
         # Load global AI suggestions
-        ai_suggestions_path = self.repo_root / "governance" / "ai-refactor-suggestions.md"
+        ai_suggestions_path = (
+            self.repo_root / "governance" / "ai-refactor-suggestions.md"
+        )
         if ai_suggestions_path.exists():
             with open(ai_suggestions_path) as f:
                 self.global_suggestions = f.read()
@@ -306,7 +316,12 @@ services/gateway/
             self.repo_root / "governance" / "language-governance-report.md",
             self.repo_root / "governance" / "semgrep-report.json",
             self.repo_root / "apps" / "web" / "public" / "data" / "hotspot.json",
-            self.repo_root / "apps" / "web" / "public" / "data" / "cluster-heatmap.json",
+            self.repo_root
+            / "apps"
+            / "web"
+            / "public"
+            / "data"
+            / "cluster-heatmap.json",
             self.repo_root / "apps" / "web" / "public" / "data" / "migration-flow.json",
             self.repo_root / "governance" / "ai-refactor-suggestions.md",
         ]
@@ -338,7 +353,9 @@ services/gateway/
                 return False
 
             # Check TTL using configured value
-            cache_time = datetime.fromisoformat(cache_data.get("timestamp", "2000-01-01"))
+            cache_time = datetime.fromisoformat(
+                cache_data.get("timestamp", "2000-01-01")
+            )
             if datetime.now() - cache_time > timedelta(hours=self.cache_ttl_hours):
                 return False
 
@@ -458,7 +475,9 @@ services/gateway/
 
         return incoming, outgoing
 
-    def generate_cluster_prompt(self, cluster_name: str, cluster_score: float = 0) -> str:
+    def generate_cluster_prompt(
+        self, cluster_name: str, cluster_score: float = 0
+    ) -> str:
         """Generate LLM prompt for a specific cluster"""
 
         # Get cluster-specific data
@@ -479,9 +498,9 @@ services/gateway/
             "\n".join(
                 [
                     f"- {h.get('file', 'unknown')} (score={h.get('score', 0)})"
-                    for h in sorted(hotspots, key=lambda x: x.get("score", 0), reverse=True)[
-                        : self.MAX_HOTSPOTS_DISPLAY
-                    ]
+                    for h in sorted(
+                        hotspots, key=lambda x: x.get("score", 0), reverse=True
+                    )[: self.MAX_HOTSPOTS_DISPLAY]
                 ]
             )
             if hotspots
@@ -493,9 +512,9 @@ services/gateway/
             "\n".join(
                 [
                     f"- {s.get('path', 'unknown')} [{s.get('severity', 'UNKNOWN')}] {s.get('rule_id', 'unknown')}: {s.get('message', 'no message')}"
-                    for s in sorted(semgrep, key=lambda x: x.get("severity", "LOW"), reverse=True)[
-                        : self.MAX_SEMGREP_DISPLAY
-                    ]
+                    for s in sorted(
+                        semgrep, key=lambda x: x.get("severity", "LOW"), reverse=True
+                    )[: self.MAX_SEMGREP_DISPLAY]
                 ]
             )
             if semgrep
@@ -549,7 +568,9 @@ services/gateway/
 
         return prompt
 
-    def generate_playbook_stub(self, cluster_name: str, cluster_score: float = 0) -> str:
+    def generate_playbook_stub(
+        self, cluster_name: str, cluster_score: float = 0
+    ) -> str:
         """Generate a stub playbook (without LLM)"""
 
         violations = self._get_cluster_violations(cluster_name)
@@ -594,15 +615,21 @@ services/gateway/
         playbook += f"\n### Hotspot æª”æ¡ˆ ({len(hotspots)})\n\n"
 
         if hotspots:
-            for h in sorted(hotspots, key=lambda x: x.get("score", 0), reverse=True)[:5]:
-                playbook += f"- **{h.get('file', 'unknown')}** (score: {h.get('score', 0)})\n"
+            for h in sorted(hotspots, key=lambda x: x.get("score", 0), reverse=True)[
+                :5
+            ]:
+                playbook += (
+                    f"- **{h.get('file', 'unknown')}** (score: {h.get('score', 0)})\n"
+                )
         else:
             playbook += "âœ… ç„¡ hotspot æª”æ¡ˆ\n"
 
         playbook += f"\n### Semgrep å®‰å…¨å•é¡Œ ({len(semgrep)})\n\n"
 
         if semgrep:
-            for s in sorted(semgrep, key=lambda x: x.get("severity", "LOW"), reverse=True)[:5]:
+            for s in sorted(
+                semgrep, key=lambda x: x.get("severity", "LOW"), reverse=True
+            )[:5]:
                 playbook += f"- [{s.get('severity', 'UNKNOWN')}] **{s.get('path', 'unknown')}**: {s.get('message', 'no message')}\n"
         else:
             playbook += "âœ… ç„¡å®‰å…¨å•é¡Œ\n"
@@ -695,7 +722,9 @@ services/gateway/
         """Generate playbooks for all clusters"""
 
         if not self.clusters:
-            print("âš ï¸  No clusters found. Creating default clusters from directory structure...")
+            print(
+                "âš ï¸  No clusters found. Creating default clusters from directory structure..."
+            )
             self._detect_clusters()
 
         output_dir = self.repo_root / "docs" / "refactor_playbooks"
@@ -707,7 +736,9 @@ services/gateway/
         cached_count = 0
 
         for cluster_name, cluster_data in self.clusters.items():
-            cluster_score = cluster_data.get("score", 0) if isinstance(cluster_data, dict) else 0
+            cluster_score = (
+                cluster_data.get("score", 0) if isinstance(cluster_data, dict) else 0
+            )
 
             print(f"  ğŸ“ {cluster_name} (score: {cluster_score})")
 
@@ -722,7 +753,9 @@ services/gateway/
                     prompt = self.generate_cluster_prompt(cluster_name, cluster_score)
 
                     # Save prompt for manual LLM processing
-                    prompt_file = output_dir / f"{cluster_name.replace('/', '_')}_prompt.txt"
+                    prompt_file = (
+                        output_dir / f"{cluster_name.replace('/', '_')}_prompt.txt"
+                    )
                     with open(prompt_file, "w", encoding="utf-8") as f:
                         f.write(f"System Prompt:\n{self.SYSTEM_PROMPT}\n\n")
                         f.write(f"User Prompt:\n{prompt}\n")
@@ -740,7 +773,9 @@ services/gateway/
                 generated_count += 1
 
             # Save playbook (sanitize cluster name for filename)
-            safe_cluster_name = cluster_name.replace("/", "_").replace("\\", "_").replace("..", "_")
+            safe_cluster_name = (
+                cluster_name.replace("/", "_").replace("\\", "_").replace("..", "_")
+            )
             playbook_file = output_dir / f"{safe_cluster_name}_playbook.md"
             with open(playbook_file, "w", encoding="utf-8") as f:
                 f.write(playbook)
@@ -750,7 +785,9 @@ services/gateway/
         print(f"   ğŸ“Š Stats: {generated_count} generated, {cached_count} from cache")
         if self.cache_enabled:
             cache_hit_rate = (
-                (cached_count / len(self.clusters) * 100) if len(self.clusters) > 0 else 0
+                (cached_count / len(self.clusters) * 100)
+                if len(self.clusters) > 0
+                else 0
             )
             print(f"   âš¡ Cache hit rate: {cache_hit_rate:.1f}%")
 
@@ -804,7 +841,11 @@ services/gateway/
                     lines.append(f"{prefix}{connector}{item.name}/")
                     if depth < max_depth:
                         extension = "    " if is_last_item else "â”‚   "
-                        lines.extend(build_tree(item, prefix + extension, depth + 1, is_last_item))
+                        lines.extend(
+                            build_tree(
+                                item, prefix + extension, depth + 1, is_last_item
+                            )
+                        )
                 else:
                     # Show file with extension
                     lines.append(f"{prefix}{connector}{item.name}")
@@ -895,7 +936,9 @@ def main():
     )
     parser.add_argument("--repo-root", default=".", help="Repository root directory")
     parser.add_argument(
-        "--use-llm", action="store_true", help="Generate LLM prompts (for future LLM integration)"
+        "--use-llm",
+        action="store_true",
+        help="Generate LLM prompts (for future LLM integration)",
     )
     parser.add_argument("--cluster", help="Generate playbook for specific cluster only")
 
diff --git a/workspace/tools/generate-sankey-data.py b/workspace/tools/generate-sankey-data.py
index 1a25bb8..cea54e9 100755
--- a/workspace/tools/generate-sankey-data.py
+++ b/workspace/tools/generate-sankey-data.py
@@ -40,7 +40,9 @@ def parse_governance_report(report_path: Path) -> list[dict[str, Any]]:
     for line in lines:
         if "â€”" in line and "**" in line:
             # Extract file path and reason
-            match = re.match(r"-\s*\*\*(.*?)\*\*\s*â€”\s*(.*?)(?:\(Layer:\s*(.*?)\))?$", line)
+            match = re.match(
+                r"-\s*\*\*(.*?)\*\*\s*â€”\s*(.*?)(?:\(Layer:\s*(.*?)\))?$", line
+            )
             if match:
                 file_path = match.group(1).strip()
                 reason = match.group(2).strip()
@@ -50,10 +52,14 @@ def parse_governance_report(report_path: Path) -> list[dict[str, Any]]:
                 source_layer = determine_layer(file_path)
 
                 # Extract language and violation type
-                language, violation_type = extract_language_and_violation(file_path, reason)
+                language, violation_type = extract_language_and_violation(
+                    file_path, reason
+                )
 
                 # Determine fix target
-                fix_target = determine_fix_target(language, violation_type, source_layer)
+                fix_target = determine_fix_target(
+                    language, violation_type, source_layer
+                )
 
                 violations.append(
                     {
@@ -150,7 +156,9 @@ def aggregate_flows(violations: list[dict[str, Any]]) -> list[dict[str, Any]]:
     flow_map = {}
 
     for v in violations:
-        key = f"{v['sourceLayer']}|{v['language']}|{v['violationType']}|{v['fixTarget']}"
+        key = (
+            f"{v['sourceLayer']}|{v['language']}|{v['violationType']}|{v['fixTarget']}"
+        )
         if key in flow_map:
             flow_map[key]["count"] += 1
         else:
diff --git a/workspace/tools/governance/generate-consolidated-report.py b/workspace/tools/governance/generate-consolidated-report.py
index 87ceb60..71a7d89 100755
--- a/workspace/tools/governance/generate-consolidated-report.py
+++ b/workspace/tools/governance/generate-consolidated-report.py
@@ -115,7 +115,9 @@ def generate_consolidated_report(results_dir: str, output_file: str):
                     f"- {icon} `{v.get('directory', 'unknown')}`: {v.get('message', 'Unknown violation')}\n"
                 )
     else:
-        lines.append("âœ… No language governance data available or no violations found.\n")
+        lines.append(
+            "âœ… No language governance data available or no violations found.\n"
+        )
 
     lines.append("\n---\n\n")
 
@@ -191,7 +193,9 @@ def generate_consolidated_report(results_dir: str, output_file: str):
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Generate Consolidated Security Report")
+    parser = argparse.ArgumentParser(
+        description="Generate Consolidated Security Report"
+    )
     parser.add_argument(
         "--results-dir", required=True, help="Directory containing analysis results"
     )
@@ -199,7 +203,9 @@ def main():
     args = parser.parse_args()
 
     if not os.path.exists(args.results_dir):
-        print(f"Error: Results directory not found: {args.results_dir}", file=sys.stderr)
+        print(
+            f"Error: Results directory not found: {args.results_dir}", file=sys.stderr
+        )
         sys.exit(1)
 
     generate_consolidated_report(args.results_dir, args.output)
diff --git a/workspace/tools/governance/language-governance-analyzer.py b/workspace/tools/governance/language-governance-analyzer.py
index 9888eaa..919b265 100755
--- a/workspace/tools/governance/language-governance-analyzer.py
+++ b/workspace/tools/governance/language-governance-analyzer.py
@@ -18,7 +18,10 @@ from typing import Any, Dict, List
 try:
     import yaml
 except ImportError:
-    print("Error: PyYAML is required. Install it with: pip install pyyaml", file=sys.stderr)
+    print(
+        "Error: PyYAML is required. Install it with: pip install pyyaml",
+        file=sys.stderr,
+    )
     sys.exit(1)
 
 # Language extensions mapping
@@ -63,7 +66,9 @@ def load_policy(config_path: str) -> Dict:
         sys.exit(1)
 
 
-def scan_directory(repo_root: str, exclude_dirs: List[str] = None) -> Dict[str, Dict[str, int]]:
+def scan_directory(
+    repo_root: str, exclude_dirs: List[str] = None
+) -> Dict[str, Dict[str, int]]:
     """Scan repository and count files by language in each directory"""
     if exclude_dirs is None:
         exclude_dirs = [
@@ -115,7 +120,9 @@ def scan_directory(repo_root: str, exclude_dirs: List[str] = None) -> Dict[str,
     return dict(stats)
 
 
-def check_violations(stats: Dict[str, Dict[str, int]], policy: Dict) -> List[Dict[str, Any]]:
+def check_violations(
+    stats: Dict[str, Dict[str, int]], policy: Dict
+) -> List[Dict[str, Any]]:
     """Check for language policy violations"""
     violations = []
     directory_rules = policy.get("directory_rules", {})
@@ -158,7 +165,11 @@ def check_violations(stats: Dict[str, Dict[str, int]], policy: Dict) -> List[Dic
                 config_formats = ["YAML", "JSON", "Markdown", "TOML", "XML"]
 
                 # Check if language is allowed
-                if allowed and language not in allowed and language not in config_formats:
+                if (
+                    allowed
+                    and language not in allowed
+                    and language not in config_formats
+                ):
                     violations.append(
                         {
                             "severity": "ERROR",
@@ -217,9 +228,13 @@ def generate_markdown_report(report: Dict) -> str:
         lines.append("\n## Violations\n")
         for v in report["violations"]:
             icon = (
-                "ğŸ”´" if v["severity"] == "CRITICAL" else "âš ï¸" if v["severity"] == "ERROR" else "ğŸ’¡"
+                "ğŸ”´"
+                if v["severity"] == "CRITICAL"
+                else "âš ï¸" if v["severity"] == "ERROR" else "ğŸ’¡"
+            )
+            lines.append(
+                f"- {icon} **{v['severity']}** in `{v['directory']}`: {v['message']}"
             )
-            lines.append(f"- {icon} **{v['severity']}** in `{v['directory']}`: {v['message']}")
             if "count" in v:
                 lines.append(f" ({v['count']} files)\n")
             else:
@@ -231,7 +246,9 @@ def generate_markdown_report(report: Dict) -> str:
     for directory, languages in sorted(report["stats"].items()):
         if languages:
             lines.append(f"\n### {directory}\n")
-            for lang, count in sorted(languages.items(), key=lambda x: x[1], reverse=True):
+            for lang, count in sorted(
+                languages.items(), key=lambda x: x[1], reverse=True
+            ):
                 lines.append(f"- {lang}: {count} files\n")
 
     return "".join(lines)
@@ -260,7 +277,9 @@ def generate_text_report(report: Dict) -> str:
 
 def main():
     parser = argparse.ArgumentParser(description="Language Governance Analyzer")
-    parser.add_argument("--config", required=True, help="Path to language policy YAML file")
+    parser.add_argument(
+        "--config", required=True, help="Path to language policy YAML file"
+    )
     parser.add_argument("--repo-root", required=True, help="Repository root directory")
     parser.add_argument(
         "--output-format",
diff --git a/workspace/tools/governance/python/naming-migration.py b/workspace/tools/governance/python/naming-migration.py
index eb675a8..542d21a 100755
--- a/workspace/tools/governance/python/naming-migration.py
+++ b/workspace/tools/governance/python/naming-migration.py
@@ -47,12 +47,17 @@ class NamingMigrationTool:
         self.canonical_regex = self.spec["spec"]["naming"]["canonical_regex"]
         self.naming_modes = self.spec["spec"]["naming"]["naming_modes"]
         self.reserved_tokens = self.spec["spec"]["naming"]["reserved_tokens"]
-        self.environments = [e["name"] for e in self.spec["spec"]["naming"]["environments"]]
+        self.environments = [
+            e["name"] for e in self.spec["spec"]["naming"]["environments"]
+        ]
 
     def scan_cluster(self) -> List[Dict]:
         """æƒæé›†ç¾¤ä¸­çš„æ‰€æœ‰ Namespace"""
         if not K8S_AVAILABLE:
-            print("Error: kubernetes package required for cluster scanning", file=sys.stderr)
+            print(
+                "Error: kubernetes package required for cluster scanning",
+                file=sys.stderr,
+            )
             print("Install with: pip install kubernetes", file=sys.stderr)
             sys.exit(1)
 
@@ -131,7 +136,9 @@ class NamingMigrationTool:
             # æª¢æŸ¥ç›¸ä¼¼å‘½åï¼ˆå¯èƒ½å°è‡´æ··æ·†ï¼‰
             similar = self.find_similar_names(name, list(name_map.keys()))
             if similar:
-                conflicts.append({"type": "similar", "name": name, "similar_to": similar})
+                conflicts.append(
+                    {"type": "similar", "name": name, "similar_to": similar}
+                )
 
         return conflicts
 
@@ -274,7 +281,11 @@ class NamingMigrationTool:
             for ns in batch:
                 suggestions = self.generate_suggestions(ns)
                 batch_plan["resources"].append(
-                    {"current_name": ns["name"], "issues": ns["issues"], "suggestions": suggestions}
+                    {
+                        "current_name": ns["name"],
+                        "issues": ns["issues"],
+                        "suggestions": suggestions,
+                    }
                 )
 
             plan["spec"]["batches"].append(batch_plan)
@@ -307,12 +318,18 @@ Examples:
     )
 
     parser.add_argument("--spec", required=True, help="Path to machine-spec.yaml")
-    parser.add_argument("--scan", action="store_true", help="Scan cluster for namespaces")
-    parser.add_argument("--detect-conflicts", action="store_true", help="Detect naming conflicts")
+    parser.add_argument(
+        "--scan", action="store_true", help="Scan cluster for namespaces"
+    )
+    parser.add_argument(
+        "--detect-conflicts", action="store_true", help="Detect naming conflicts"
+    )
     parser.add_argument(
         "--generate-plan", metavar="FILE", help="Generate migration plan (output path)"
     )
-    parser.add_argument("--output", metavar="FILE", help="Output results to file (JSON format)")
+    parser.add_argument(
+        "--output", metavar="FILE", help="Output results to file (JSON format)"
+    )
 
     args = parser.parse_args()
 
@@ -330,7 +347,9 @@ Examples:
         print(f"\n=== Namespace Scan Results ===")
         print(f"Total: {total}")
         print(
-            f"Compliant: {compliant} ({compliant/total*100:.1f}%)" if total > 0 else "Compliant: 0"
+            f"Compliant: {compliant} ({compliant/total*100:.1f}%)"
+            if total > 0
+            else "Compliant: 0"
         )
         print(
             f"Non-compliant: {non_compliant} ({non_compliant/total*100:.1f}%)"
diff --git a/workspace/tools/governance/python/validate_naming.py b/workspace/tools/governance/python/validate_naming.py
index 896b74c..1d7840b 100755
--- a/workspace/tools/governance/python/validate_naming.py
+++ b/workspace/tools/governance/python/validate_naming.py
@@ -102,7 +102,9 @@ class NamingValidator:
         # æå–å‘½åæ¨¡å¼
         pattern = policy["spec"].get("pattern", "")
         # è½¬æ¢æ¨¡æ¿ä¸ºæ­£åˆ™è¡¨è¾¾å¼
-        regex_pattern = r"^(dev|staging|prod)-[a-z0-9-]+-deploy-v\d+\.\d+\.\d+(-[a-zA-Z0-9]+)?$"
+        regex_pattern = (
+            r"^(dev|staging|prod)-[a-z0-9-]+-deploy-v\d+\.\d+\.\d+(-[a-zA-Z0-9]+)?$"
+        )
 
         if not re.match(regex_pattern, name):
             violations.append(
@@ -154,7 +156,9 @@ class NamingValidator:
                         violations.extend(self.validate_k8s_deployment(doc, file_path))
 
         except Exception as e:
-            print(f"{Colors.YELLOW}Warning: Failed to parse {file_path}: {e}{Colors.RESET}")
+            print(
+                f"{Colors.YELLOW}Warning: Failed to parse {file_path}: {e}{Colors.RESET}"
+            )
 
         return violations
 
@@ -166,7 +170,9 @@ class NamingValidator:
 
         for file_path in files:
             if not file_path.exists():
-                print(f"{Colors.YELLOW}Warning: File not found: {file_path}{Colors.RESET}")
+                print(
+                    f"{Colors.YELLOW}Warning: File not found: {file_path}{Colors.RESET}"
+                )
                 continue
 
             total_files += 1
@@ -200,7 +206,9 @@ def generate_report(
         print(f"\n{Colors.BOLD}=== Naming Compliance Report ==={Colors.RESET}\n")
 
         # æ‘˜è¦
-        compliance_rate = (compliant_files / total_files * 100) if total_files > 0 else 0
+        compliance_rate = (
+            (compliant_files / total_files * 100) if total_files > 0 else 0
+        )
         status_color = Colors.GREEN if not violations else Colors.RED
         status = "PASSED" if not violations else "FAILED"
 
@@ -224,7 +232,9 @@ def generate_report(
                 print()
 
         else:
-            print(f"{Colors.GREEN}âœ“ All resources comply with naming standards{Colors.RESET}\n")
+            print(
+                f"{Colors.GREEN}âœ“ All resources comply with naming standards{Colors.RESET}\n"
+            )
 
 
 def main():
@@ -233,26 +243,40 @@ def main():
     )
     parser.add_argument("--files", nargs="+", type=Path, help="Files to validate")
     parser.add_argument(
-        "--files-list", type=Path, help="File containing list of files to validate (one per line)"
+        "--files-list",
+        type=Path,
+        help="File containing list of files to validate (one per line)",
     )
     parser.add_argument(
-        "--policies", type=Path, required=True, help="Directory containing naming policies"
+        "--policies",
+        type=Path,
+        required=True,
+        help="Directory containing naming policies",
     )
     parser.add_argument(
-        "--schemas", type=Path, required=True, help="Directory containing validation schemas"
+        "--schemas",
+        type=Path,
+        required=True,
+        help="Directory containing validation schemas",
+    )
+    parser.add_argument(
+        "--output", type=Path, help="Output file for report (JSON format)"
+    )
+    parser.add_argument(
+        "--format", choices=["text", "json"], default="text", help="Output format"
     )
-    parser.add_argument("--output", type=Path, help="Output file for report (JSON format)")
-    parser.add_argument("--format", choices=["text", "json"], default="text", help="Output format")
     parser.add_argument(
         "--changed-files-only",
         action="store_true",
         help="Only validate changed files (requires git)",
     )
     parser.add_argument(
-        "--base-ref", help="Base git reference for diff (used with --changed-files-only)"
+        "--base-ref",
+        help="Base git reference for diff (used with --changed-files-only)",
     )
     parser.add_argument(
-        "--head-ref", help="Head git reference for diff (used with --changed-files-only)"
+        "--head-ref",
+        help="Head git reference for diff (used with --changed-files-only)",
     )
 
     args = parser.parse_args()
@@ -299,7 +323,9 @@ def main():
     validator = NamingValidator(args.policies, args.schemas)
 
     # æ‰§è¡ŒéªŒè¯
-    violations, total_files, compliant_files = validator.validate_files(files_to_validate)
+    violations, total_files, compliant_files = validator.validate_files(
+        files_to_validate
+    )
 
     # ç”ŸæˆæŠ¥å‘Š
     if args.output:
diff --git a/workspace/tools/governance/validate-governance-matrix.py b/workspace/tools/governance/validate-governance-matrix.py
index 822c488..e28243e 100755
--- a/workspace/tools/governance/validate-governance-matrix.py
+++ b/workspace/tools/governance/validate-governance-matrix.py
@@ -17,7 +17,10 @@ from typing import Any, Dict, List
 try:
     import yaml
 except ImportError:
-    print("Error: PyYAML is required. Install it with: pip install pyyaml", file=sys.stderr)
+    print(
+        "Error: PyYAML is required. Install it with: pip install pyyaml",
+        file=sys.stderr,
+    )
     sys.exit(1)
 
 
@@ -84,7 +87,9 @@ def validate_behavior_contracts(verbose: bool = False) -> bool:
     contracts_dir = "governance/behavior-contracts"
 
     if not os.path.exists(contracts_dir):
-        print(f"Warning: {contracts_dir} not found, skipping validation", file=sys.stderr)
+        print(
+            f"Warning: {contracts_dir} not found, skipping validation", file=sys.stderr
+        )
         return True
 
     contracts = list(Path(contracts_dir).rglob("*.yaml"))
@@ -106,7 +111,10 @@ def validate_schemas(verbose: bool = False) -> bool:
     schemas_dir = "governance/schemas"
 
     if not os.path.exists(schemas_dir):
-        print(f"Warning: {schemas_dir} not found, creating empty validation", file=sys.stderr)
+        print(
+            f"Warning: {schemas_dir} not found, creating empty validation",
+            file=sys.stderr,
+        )
         return True
 
     schemas = list(Path(schemas_dir).rglob("*.json"))
@@ -131,10 +139,15 @@ def validate_policies(verbose: bool = False) -> bool:
     policies_dir = "governance/policies"
 
     if not os.path.exists(policies_dir):
-        print(f"Info: {policies_dir} not found, skipping policy validation", file=sys.stderr)
+        print(
+            f"Info: {policies_dir} not found, skipping policy validation",
+            file=sys.stderr,
+        )
         return True
 
-    policies = list(Path(policies_dir).rglob("*.yaml")) + list(Path(policies_dir).rglob("*.yml"))
+    policies = list(Path(policies_dir).rglob("*.yaml")) + list(
+        Path(policies_dir).rglob("*.yml")
+    )
 
     if verbose:
         print(f"âœ… Policy files found: {len(policies)}")
@@ -148,7 +161,9 @@ def validate_policies(verbose: bool = False) -> bool:
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Validate Architecture Governance Matrix")
+    parser = argparse.ArgumentParser(
+        description="Validate Architecture Governance Matrix"
+    )
     parser.add_argument("--verbose", action="store_true", help="Verbose output")
     args = parser.parse_args()
 
diff --git a/workspace/tools/language-health-score.py b/workspace/tools/language-health-score.py
index d674843..b900b4e 100755
--- a/workspace/tools/language-health-score.py
+++ b/workspace/tools/language-health-score.py
@@ -59,7 +59,9 @@ def save_yaml(path: str, data: dict[str, Any]):
     """å„²å­˜ YAML æª”æ¡ˆ"""
     os.makedirs(os.path.dirname(path), exist_ok=True)
     with open(path, "w", encoding="utf-8") as f:
-        yaml.dump(data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
+        yaml.dump(
+            data, f, default_flow_style=False, allow_unicode=True, sort_keys=False
+        )
 
 
 def calculate_violation_score(governance_report: dict[str, Any]) -> float:
@@ -90,7 +92,9 @@ def calculate_security_score(
 
     # Semgrep çµæœ
     semgrep_results = semgrep_report.get("results", [])
-    semgrep_high = sum(1 for r in semgrep_results if r.get("extra", {}).get("severity") == "ERROR")
+    semgrep_high = sum(
+        1 for r in semgrep_results if r.get("extra", {}).get("severity") == "ERROR"
+    )
     semgrep_medium = sum(
         1 for r in semgrep_results if r.get("extra", {}).get("severity") == "WARNING"
     )
@@ -126,7 +130,8 @@ def calculate_architecture_score(governance_report: dict[str, Any]) -> float:
     arch_violations = [
         v
         for v in violations
-        if "layer" in v.get("message", "").lower() or "directory" in v.get("message", "").lower()
+        if "layer" in v.get("message", "").lower()
+        or "directory" in v.get("message", "").lower()
     ]
 
     if not arch_violations:
@@ -155,7 +160,9 @@ def calculate_trend_score(history: dict[str, Any]) -> float:
     recent_fixes = []
     for fix in fixes:
         try:
-            fix_time = datetime.datetime.fromisoformat(fix["timestamp"].replace("Z", "+00:00"))
+            fix_time = datetime.datetime.fromisoformat(
+                fix["timestamp"].replace("Z", "+00:00")
+            )
             if fix_time >= thirty_days_ago:
                 recent_fixes.append(fix)
         except BaseException:
@@ -268,7 +275,9 @@ def display_score(score_data: dict[str, Any]):
 
 def main():
     parser = argparse.ArgumentParser(description="Calculate language health score")
-    parser.add_argument("--governance-report", required=True, help="Path to governance report JSON")
+    parser.add_argument(
+        "--governance-report", required=True, help="Path to governance report JSON"
+    )
     parser.add_argument("--semgrep-report", help="Path to Semgrep SARIF report")
     parser.add_argument("--codeql-report", help="Path to CodeQL SARIF report")
     parser.add_argument("--history", help="Path to language history YAML")
@@ -290,7 +299,9 @@ def main():
     history = load_yaml(args.history) if args.history else {}
 
     # è¨ˆç®—åˆ†æ•¸
-    score_data = calculate_health_score(governance_report, semgrep_report, codeql_report, history)
+    score_data = calculate_health_score(
+        governance_report, semgrep_report, codeql_report, history
+    )
 
     # å„²å­˜åˆ†æ•¸
     save_yaml(args.output, score_data)
@@ -300,8 +311,12 @@ def main():
     if args.display:
         display_score(score_data)
     else:
-        console.print(f"[bold green]Total Score: {score_data['total_score']:.2f}/100[/bold green]")
-        console.print(f"[bold]Grade: {score_data['grade']} ({score_data['status']})[/bold]")
+        console.print(
+            f"[bold green]Total Score: {score_data['total_score']:.2f}/100[/bold green]"
+        )
+        console.print(
+            f"[bold]Grade: {score_data['grade']} ({score_data['status']})[/bold]"
+        )
 
     console.print("[green]âœ… Health score calculation complete![/green]")
 
diff --git a/workspace/tools/language-history-writer.py b/workspace/tools/language-history-writer.py
index a1cf5d7..b3e936d 100755
--- a/workspace/tools/language-history-writer.py
+++ b/workspace/tools/language-history-writer.py
@@ -53,7 +53,9 @@ def save_language_history(data: dict[str, Any]):
     os.makedirs(os.path.dirname(history_path), exist_ok=True)
 
     with open(history_path, "w", encoding="utf-8") as f:
-        yaml.dump(data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
+        yaml.dump(
+            data, f, default_flow_style=False, allow_unicode=True, sort_keys=False
+        )
 
 
 def add_fix_record(
@@ -149,17 +151,23 @@ def generate_report() -> str:
     stats = history.get("statistics", {})
 
     report = "# Language Governance Fix History Report\n\n"
-    report += f"**Total Fixes**: {history.get('metadata', {}).get('total_fixes', 0)}\n\n"
+    report += (
+        f"**Total Fixes**: {history.get('metadata', {}).get('total_fixes', 0)}\n\n"
+    )
 
     if "by_type" in stats:
         report += "## By Violation Type\n\n"
-        for vtype, count in sorted(stats["by_type"].items(), key=lambda x: x[1], reverse=True):
+        for vtype, count in sorted(
+            stats["by_type"].items(), key=lambda x: x[1], reverse=True
+        ):
             report += f"- **{vtype}**: {count}\n"
         report += "\n"
 
     if "by_action" in stats:
         report += "## By Action\n\n"
-        for action, count in sorted(stats["by_action"].items(), key=lambda x: x[1], reverse=True):
+        for action, count in sorted(
+            stats["by_action"].items(), key=lambda x: x[1], reverse=True
+        ):
             report += f"- **{action}**: {count}\n"
         report += "\n"
 
@@ -184,13 +192,17 @@ def generate_report() -> str:
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Record language governance fix history")
+    parser = argparse.ArgumentParser(
+        description="Record language governance fix history"
+    )
     parser.add_argument(
         "--violation-type",
         required=True,
         help="Type of violation (e.g., 'forbidden-language', 'wrong-layer', 'security-issue')",
     )
-    parser.add_argument("--file-path", required=True, help="Path to the file that was fixed")
+    parser.add_argument(
+        "--file-path", required=True, help="Path to the file that was fixed"
+    )
     parser.add_argument(
         "--action",
         required=True,
@@ -205,8 +217,12 @@ def main():
         choices=["CRITICAL", "ERROR", "WARNING"],
         help="Severity level",
     )
-    parser.add_argument("--fixed-by", default="ai-auto-fix-bot", help="Who/what applied the fix")
-    parser.add_argument("--report", action="store_true", help="Generate and print report")
+    parser.add_argument(
+        "--fixed-by", default="ai-auto-fix-bot", help="Who/what applied the fix"
+    )
+    parser.add_argument(
+        "--report", action="store_true", help="Generate and print report"
+    )
 
     args = parser.parse_args()
 
diff --git a/workspace/tools/lkb-update.py b/workspace/tools/lkb-update.py
index e29726d..b9c1a64 100755
--- a/workspace/tools/lkb-update.py
+++ b/workspace/tools/lkb-update.py
@@ -44,10 +44,14 @@ def save_yaml(path: str, data: dict[str, Any]):
     """å„²å­˜ YAML æª”æ¡ˆ"""
     os.makedirs(os.path.dirname(path), exist_ok=True)
     with open(path, "w", encoding="utf-8") as f:
-        yaml.dump(data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
+        yaml.dump(
+            data, f, default_flow_style=False, allow_unicode=True, sort_keys=False
+        )
 
 
-def update_knowledge_health_report(event: str, description: str, metrics: dict[str, Any] = None):
+def update_knowledge_health_report(
+    event: str, description: str, metrics: dict[str, Any] = None
+):
     """æ›´æ–°çŸ¥è­˜åº«å¥åº·å ±å‘Š"""
     report_path = "docs/knowledge-health-report.yaml"
     now = datetime.datetime.utcnow().isoformat() + "Z"
@@ -194,13 +198,19 @@ For knowledge graph visualization, see `docs/knowledge-graph.yaml`.
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Update Living Knowledge Base after Auto-Fix")
+    parser = argparse.ArgumentParser(
+        description="Update Living Knowledge Base after Auto-Fix"
+    )
     parser.add_argument(
         "--event", required=True, help="Event type (e.g., 'auto-fix', 'manual-fix')"
     )
     parser.add_argument("--description", required=True, help="Event description")
-    parser.add_argument("--violations-fixed", type=int, help="Number of violations fixed")
-    parser.add_argument("--health-score", type=float, help="Current health score (0-100)")
+    parser.add_argument(
+        "--violations-fixed", type=int, help="Number of violations fixed"
+    )
+    parser.add_argument(
+        "--health-score", type=float, help="Current health score (0-100)"
+    )
     parser.add_argument("--files-changed", type=int, help="Number of files changed")
 
     args = parser.parse_args()
@@ -217,7 +227,9 @@ def main():
         metrics["files_changed"] = args.files_changed
 
     # æ›´æ–°çŸ¥è­˜åº«å¥åº·å ±å‘Š
-    update_knowledge_health_report(args.event, args.description, metrics if metrics else None)
+    update_knowledge_health_report(
+        args.event, args.description, metrics if metrics else None
+    )
 
     # æº–å‚™çŸ¥è­˜åœ–è­œç¯€é»
     nodes = [
diff --git a/workspace/tools/load-playbook.py b/workspace/tools/load-playbook.py
index b0cc476..fe88522 100755
--- a/workspace/tools/load-playbook.py
+++ b/workspace/tools/load-playbook.py
@@ -48,7 +48,9 @@ def load_playbook(cluster_id: str, index_path: Path, repo_root: Path) -> dict:
     if not refactor_file:
         raise ValueError(f"No refactor_file specified for cluster '{cluster_id}'")
 
-    playbook_path = repo_root / "docs" / "refactor_playbooks" / "03_refactor" / refactor_file
+    playbook_path = (
+        repo_root / "docs" / "refactor_playbooks" / "03_refactor" / refactor_file
+    )
 
     if not playbook_path.exists():
         raise FileNotFoundError(f"Playbook not found: {playbook_path}")
@@ -114,7 +116,9 @@ def extract_auto_fix_allowed(content: str) -> list[str]:
 
     # Look for subsection "é©åˆ Auto-Fix"
     allowed_section = re.search(
-        r"é©åˆ.*Auto-Fix.*?[:ï¼š](.*?)(?=å¿…é ˆäººå·¥å¯©æŸ¥|##|\Z)", section, re.DOTALL | re.IGNORECASE
+        r"é©åˆ.*Auto-Fix.*?[:ï¼š](.*?)(?=å¿…é ˆäººå·¥å¯©æŸ¥|##|\Z)",
+        section,
+        re.DOTALL | re.IGNORECASE,
     )
 
     if allowed_section:
@@ -152,11 +156,15 @@ def extract_priority_actions(content: str, priority: str) -> dict[str, any]:
         return {"objective": "", "actions": [], "acceptance_criteria": []}
 
     # Extract objective (first paragraph or line after heading)
-    objective_match = re.search(r"ç›®æ¨™[:ï¼š](.*?)(?=\n[-*]|\nè¡Œå‹•|\Z)", section, re.DOTALL)
+    objective_match = re.search(
+        r"ç›®æ¨™[:ï¼š](.*?)(?=\n[-*]|\nè¡Œå‹•|\Z)", section, re.DOTALL
+    )
     objective = objective_match.group(1).strip() if objective_match else ""
 
     # Extract actions (list items under "è¡Œå‹•é …ç›®")
-    actions_section = re.search(r"è¡Œå‹•é …ç›®.*?[:ï¼š](.*?)(?=é©—æ”¶æ¢ä»¶|##|\Z)", section, re.DOTALL)
+    actions_section = re.search(
+        r"è¡Œå‹•é …ç›®.*?[:ï¼š](.*?)(?=é©—æ”¶æ¢ä»¶|##|\Z)", section, re.DOTALL
+    )
     actions = []
     if actions_section:
         actions = extract_list_items(actions_section.group(1))
@@ -199,7 +207,10 @@ def main():
         description="Load refactor playbook and extract auto-fix context"
     )
     parser.add_argument(
-        "--cluster", type=str, required=True, help="Cluster ID (e.g., core/architecture-stability)"
+        "--cluster",
+        type=str,
+        required=True,
+        help="Cluster ID (e.g., core/architecture-stability)",
     )
     parser.add_argument(
         "--index",
@@ -208,10 +219,17 @@ def main():
         help="Path to index.yaml file (relative to repo root)",
     )
     parser.add_argument(
-        "--output", type=str, default="playbook-context.json", help="Output JSON file path"
+        "--output",
+        type=str,
+        default="playbook-context.json",
+        help="Output JSON file path",
+    )
+    parser.add_argument(
+        "--repo-root", type=str, default=".", help="Repository root directory"
+    )
+    parser.add_argument(
+        "--pretty", action="store_true", help="Pretty print JSON output"
     )
-    parser.add_argument("--repo-root", type=str, default=".", help="Repository root directory")
-    parser.add_argument("--pretty", action="store_true", help="Pretty print JSON output")
 
     args = parser.parse_args()
 
diff --git a/workspace/tools/map-violations-to-playbooks.py b/workspace/tools/map-violations-to-playbooks.py
index 995c71b..d4bc3ea 100755
--- a/workspace/tools/map-violations-to-playbooks.py
+++ b/workspace/tools/map-violations-to-playbooks.py
@@ -107,9 +107,12 @@ def generate_summary(hotspot_data: list, index: dict, repo_root: Path) -> str:
         for severity in ["CRITICAL", "HIGH", "MEDIUM", "LOW"]:
             count = severity_counts.get(severity, 0)
             if count > 0:
-                emoji = {"CRITICAL": "ğŸ”´", "HIGH": "ğŸŸ ", "MEDIUM": "ğŸŸ¡", "LOW": "ğŸŸ¢"}.get(
-                    severity, "âšª"
-                )
+                emoji = {
+                    "CRITICAL": "ğŸ”´",
+                    "HIGH": "ğŸŸ ",
+                    "MEDIUM": "ğŸŸ¡",
+                    "LOW": "ğŸŸ¢",
+                }.get(severity, "âšª")
                 summary.append(f"- {emoji} {severity}: {count}\n")
         summary.append("\n")
 
@@ -165,9 +168,14 @@ def main():
         help="Path to index.yaml file (relative to repo root)",
     )
     parser.add_argument(
-        "--output", type=str, default="governance-summary.md", help="Output markdown file path"
+        "--output",
+        type=str,
+        default="governance-summary.md",
+        help="Output markdown file path",
+    )
+    parser.add_argument(
+        "--repo-root", type=str, default=".", help="Repository root directory"
     )
-    parser.add_argument("--repo-root", type=str, default=".", help="Repository root directory")
 
     args = parser.parse_args()
 
diff --git a/workspace/tools/module_graph_gate.py b/workspace/tools/module_graph_gate.py
index 37d97d4..2cafa5c 100755
--- a/workspace/tools/module_graph_gate.py
+++ b/workspace/tools/module_graph_gate.py
@@ -73,8 +73,12 @@ def main():
         result["errors"].append(str(e))
 
     graph = {"nodes": list(mods.keys()), "edges": edges}
-    out_graph.write_text(json.dumps(graph, ensure_ascii=False, indent=2), encoding="utf-8")
-    out_report.write_text(json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8")
+    out_graph.write_text(
+        json.dumps(graph, ensure_ascii=False, indent=2), encoding="utf-8"
+    )
+    out_report.write_text(
+        json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8"
+    )
     print(json.dumps(result, ensure_ascii=False, indent=2))
     return 0 if result["result"] == "pass" else 2
 
diff --git a/workspace/tools/namespace-converter.py b/workspace/tools/namespace-converter.py
index 0c58462..f904086 100644
--- a/workspace/tools/namespace-converter.py
+++ b/workspace/tools/namespace-converter.py
@@ -169,7 +169,9 @@ class NamespaceConverter:
                     print(f"âœ“ Updated {file_path}: {result.conversions} conversions")
             elif result.conversions > 0 and self.dry_run:
                 if self.verbose:
-                    print(f"âŠ¡ Would update {file_path}: {result.conversions} conversions")
+                    print(
+                        f"âŠ¡ Would update {file_path}: {result.conversions} conversions"
+                    )
 
         except Exception as e:
             error_msg = f"Error processing {file_path}: {e}"
@@ -278,7 +280,9 @@ class NamespaceConverter:
         report.append("=" * 80)
 
         if total_conversions == 0 and total_warnings == 0:
-            report.append("âœ“ All files are compliant with MachineNativeOps namespace standards")
+            report.append(
+                "âœ“ All files are compliant with MachineNativeOps namespace standards"
+            )
         elif total_errors == 0:
             report.append("âœ“ Conversion completed successfully")
         else:
@@ -288,7 +292,9 @@ class NamespaceConverter:
 
         return "\n".join(report)
 
-    def save_report(self, report: str, output_path: str = "namespace-conversion-report.txt"):
+    def save_report(
+        self, report: str, output_path: str = "namespace-conversion-report.txt"
+    ):
         """Save report to file."""
         try:
             with open(output_path, "w", encoding="utf-8") as f:
@@ -323,11 +329,19 @@ Examples:
 
     parser.add_argument("path", type=str, help="File or directory path to process")
     parser.add_argument(
-        "--dry-run", action="store_true", help="Show what would be changed without modifying files"
+        "--dry-run",
+        action="store_true",
+        help="Show what would be changed without modifying files",
+    )
+    parser.add_argument(
+        "--verbose", "-v", action="store_true", help="Enable verbose output"
+    )
+    parser.add_argument(
+        "--validate", action="store_true", help="Validate only, do not convert"
+    )
+    parser.add_argument(
+        "--report", action="store_true", help="Generate detailed report file"
     )
-    parser.add_argument("--verbose", "-v", action="store_true", help="Enable verbose output")
-    parser.add_argument("--validate", action="store_true", help="Validate only, do not convert")
-    parser.add_argument("--report", action="store_true", help="Generate detailed report file")
     parser.add_argument(
         "--report-path",
         type=str,
@@ -345,7 +359,9 @@ Examples:
 
     # Create converter
     converter = NamespaceConverter(
-        dry_run=args.dry_run or args.validate, verbose=args.verbose, validate_only=args.validate
+        dry_run=args.dry_run or args.validate,
+        verbose=args.verbose,
+        validate_only=args.validate,
     )
 
     # Load namespace config if available
diff --git a/workspace/tools/namespace-validator.py b/workspace/tools/namespace-validator.py
index 3973f85..aa412d3 100644
--- a/workspace/tools/namespace-validator.py
+++ b/workspace/tools/namespace-validator.py
@@ -111,11 +111,15 @@ class NamespaceValidator:
             for rule_id, rule in self.validation_rules.items():
                 # Check forbidden patterns
                 if "forbidden_pattern" in rule:
-                    self._check_forbidden_pattern(content, lines, file_path, rule_id, rule, result)
+                    self._check_forbidden_pattern(
+                        content, lines, file_path, rule_id, rule, result
+                    )
 
                 # Check required patterns (only for YAML/JSON files)
                 if "pattern" in rule and file_path.suffix in {".yaml", ".yml", ".json"}:
-                    self._check_required_pattern(content, file_path, rule_id, rule, result)
+                    self._check_required_pattern(
+                        content, file_path, rule_id, rule, result
+                    )
 
                 # Check with custom function
                 if "check_function" in rule:
@@ -166,7 +170,12 @@ class NamespaceValidator:
                 )
 
     def _check_required_pattern(
-        self, content: str, file_path: Path, rule_id: str, rule: Dict, result: ValidationResult
+        self,
+        content: str,
+        file_path: Path,
+        rule_id: str,
+        rule: Dict,
+        result: ValidationResult,
     ):
         """Check for required patterns in YAML/JSON files."""
         pattern = rule["pattern"]
@@ -302,10 +311,12 @@ class NamespaceValidator:
         total_files = len(self.results)
         total_issues = sum(len(r.issues) for r in self.results)
         total_errors = sum(
-            len([i for i in r.issues if i.severity == Severity.ERROR]) for r in self.results
+            len([i for i in r.issues if i.severity == Severity.ERROR])
+            for r in self.results
         )
         total_warnings = sum(
-            len([i for i in r.issues if i.severity == Severity.WARNING]) for r in self.results
+            len([i for i in r.issues if i.severity == Severity.WARNING])
+            for r in self.results
         )
         files_passed = sum(1 for r in self.results if r.passed)
 
@@ -358,7 +369,9 @@ class NamespaceValidator:
         report.append("=" * 80)
 
         if total_errors == 0 and total_warnings == 0:
-            report.append("âœ“ All files comply with MachineNativeOps namespace standards")
+            report.append(
+                "âœ“ All files comply with MachineNativeOps namespace standards"
+            )
         elif total_errors == 0:
             report.append(f"âš  Validation completed with {total_warnings} warnings")
         else:
@@ -368,7 +381,9 @@ class NamespaceValidator:
 
         return "\n".join(report)
 
-    def save_report(self, report: str, output_path: str = "namespace-validation-report.txt"):
+    def save_report(
+        self, report: str, output_path: str = "namespace-validation-report.txt"
+    ):
         """Save report to file."""
         try:
             with open(output_path, "w", encoding="utf-8") as f:
@@ -399,9 +414,15 @@ Examples:
     )
 
     parser.add_argument("path", type=str, help="File or directory path to validate")
-    parser.add_argument("--strict", action="store_true", help="Enable strict validation mode")
-    parser.add_argument("--verbose", "-v", action="store_true", help="Enable verbose output")
-    parser.add_argument("--report", action="store_true", help="Generate detailed report file")
+    parser.add_argument(
+        "--strict", action="store_true", help="Enable strict validation mode"
+    )
+    parser.add_argument(
+        "--verbose", "-v", action="store_true", help="Enable verbose output"
+    )
+    parser.add_argument(
+        "--report", action="store_true", help="Generate detailed report file"
+    )
     parser.add_argument(
         "--report-path",
         type=str,
@@ -441,6 +462,7 @@ Examples:
 
     # Exit with appropriate code
     total_errors = sum(
-        len([i for i in r.issues if i.severity == Severity.ERROR]) for r in validator.results
+        len([i for i in r.issues if i.severity == Severity.ERROR])
+        for r in validator.results
     )
     sys.exit(1 if total_errors > 0 else 0)
diff --git a/workspace/tools/path_tools/path_fixer.py b/workspace/tools/path_tools/path_fixer.py
index e6e2bfd..5f21ca2 100755
--- a/workspace/tools/path_tools/path_fixer.py
+++ b/workspace/tools/path_tools/path_fixer.py
@@ -117,7 +117,11 @@ class PathFixer:
                 for match in re.finditer(r"\[([^\]]+)\]\(([^)]+)\)", content):
                     link_text = match.group(1)
                     link_href = match.group(2).split("#")[0]
-                    anchor = match.group(2)[len(link_href) :] if "#" in match.group(2) else ""
+                    anchor = (
+                        match.group(2)[len(link_href) :]
+                        if "#" in match.group(2)
+                        else ""
+                    )
                     line_num = content[: match.start()].count("\n") + 1
 
                     if link_href.startswith(("http://", "https://", "mailto:", "#")):
@@ -164,13 +168,17 @@ class PathFixer:
             except Exception:
                 pass
 
-    def _scan_yaml_for_fixes(self, data: Any, yaml_file: Path, content: str, key_path: str = ""):
+    def _scan_yaml_for_fixes(
+        self, data: Any, yaml_file: Path, content: str, key_path: str = ""
+    ):
         """éè¿´æƒæ YAML ä¸­éœ€è¦ä¿®å¾©çš„è·¯å¾‘"""
         if isinstance(data, dict):
             for key, value in data.items():
                 new_path = f"{key_path}.{key}" if key_path else key
 
-                if key.endswith(("_path", "_file", "path", "file")) and isinstance(value, str):
+                if key.endswith(("_path", "_file", "path", "file")) and isinstance(
+                    value, str
+                ):
                     if (
                         value
                         and value != "_pending"
@@ -348,7 +356,9 @@ class PathFixer:
 def main():
     parser = argparse.ArgumentParser(description="è·¯å¾‘ä¿®å¾©å™¨ - è‡ªå‹•ä¿®å¾©è·¯å¾‘å•é¡Œ")
     parser.add_argument("--target", "-t", default=".", help="ç›®æ¨™ç›®éŒ„")
-    parser.add_argument("--dry-run", "-n", action="store_true", help="ä¹¾é‹è¡Œæ¨¡å¼ (åªåˆ†æä¸ä¿®æ”¹)")
+    parser.add_argument(
+        "--dry-run", "-n", action="store_true", help="ä¹¾é‹è¡Œæ¨¡å¼ (åªåˆ†æä¸ä¿®æ”¹)"
+    )
     parser.add_argument("--fix", action="store_true", help="å¥—ç”¨ä¿®å¾©")
     parser.add_argument("--backup", "-b", action="store_true", help="ä¿®å¾©å‰å‚™ä»½")
     parser.add_argument("--report", "-r", help="è¼¸å‡ºå ±å‘Šæª”æ¡ˆ")
diff --git a/workspace/tools/path_tools/path_scanner.py b/workspace/tools/path_tools/path_scanner.py
index e285cef..ea1a1a2 100755
--- a/workspace/tools/path_tools/path_scanner.py
+++ b/workspace/tools/path_tools/path_scanner.py
@@ -147,7 +147,9 @@ class PathScanner:
                             size=0,
                             is_directory=True,
                             depth=depth,
-                            modified_time=datetime.fromtimestamp(entry.stat().st_mtime).isoformat(),
+                            modified_time=datetime.fromtimestamp(
+                                entry.stat().st_mtime
+                            ).isoformat(),
                         )
                     )
                     self._scan_directory(entry, depth + 1)
@@ -173,9 +175,13 @@ class PathScanner:
                             size=stat.st_size,
                             is_directory=False,
                             depth=depth,
-                            modified_time=datetime.fromtimestamp(stat.st_mtime).isoformat(),
+                            modified_time=datetime.fromtimestamp(
+                                stat.st_mtime
+                            ).isoformat(),
                             hash=(
-                                self._calculate_hash(entry) if stat.st_size < 1024 * 1024 else None
+                                self._calculate_hash(entry)
+                                if stat.st_size < 1024 * 1024
+                                else None
                             ),
                         )
                     )
@@ -245,7 +251,11 @@ class PathScanner:
                     try:
                         resolved.relative_to(self.target_path)
                         is_valid = resolved.exists()
-                        resolved = str(resolved.relative_to(self.target_path)) if is_valid else None
+                        resolved = (
+                            str(resolved.relative_to(self.target_path))
+                            if is_valid
+                            else None
+                        )
                     except ValueError:
                         is_valid = False
                         resolved = None
@@ -277,20 +287,26 @@ class PathScanner:
         except Exception:
             pass
 
-    def _scan_yaml_paths(self, data: Any, file_path: Path, rel_path: str, key_path: str = ""):
+    def _scan_yaml_paths(
+        self, data: Any, file_path: Path, rel_path: str, key_path: str = ""
+    ):
         """éè¿´æƒæ YAML ä¸­çš„è·¯å¾‘"""
         if isinstance(data, dict):
             for key, value in data.items():
                 new_key = f"{key_path}.{key}" if key_path else key
 
-                if key.endswith(("_path", "_file", "path", "file")) and isinstance(value, str):
+                if key.endswith(("_path", "_file", "path", "file")) and isinstance(
+                    value, str
+                ):
                     if value and not value.startswith(("http://", "https://")):
                         resolved = (file_path.parent / value).resolve()
                         try:
                             resolved.relative_to(self.target_path)
                             is_valid = resolved.exists()
                             resolved_str = (
-                                str(resolved.relative_to(self.target_path)) if is_valid else None
+                                str(resolved.relative_to(self.target_path))
+                                if is_valid
+                                else None
                             )
                         except ValueError:
                             is_valid = False
@@ -333,8 +349,12 @@ class PathScanner:
             "total_size_mb": round(total_size / (1024 * 1024), 2),
             "max_depth": max((f.depth for f in self.files), default=0),
             "broken_links_count": len(broken_links),
-            "internal_links_count": len([l for l in self.links if l.link_type == "internal"]),
-            "external_links_count": len([l for l in self.links if l.link_type == "external"]),
+            "internal_links_count": len(
+                [l for l in self.links if l.link_type == "internal"]
+            ),
+            "external_links_count": len(
+                [l for l in self.links if l.link_type == "external"]
+            ),
         }
 
 
diff --git a/workspace/tools/path_tools/path_validator.py b/workspace/tools/path_tools/path_validator.py
index 1e097c2..a13e3be 100755
--- a/workspace/tools/path_tools/path_validator.py
+++ b/workspace/tools/path_tools/path_validator.py
@@ -268,7 +268,9 @@ class PathValidator:
             for key, value in data.items():
                 new_path = f"{key_path}.{key}" if key_path else key
 
-                if key.endswith(("_path", "_file", "path", "file")) and isinstance(value, str):
+                if key.endswith(("_path", "_file", "path", "file")) and isinstance(
+                    value, str
+                ):
                     if (
                         value
                         and value != "_pending"
@@ -282,7 +284,9 @@ class PathValidator:
                                     category=ValidationCategory.REFERENCE.value,
                                     level=ValidationLevel.ERROR.value,
                                     message=f"YAML å¼•ç”¨çš„è·¯å¾‘ä¸å­˜åœ¨: {value}",
-                                    file_path=str(yaml_file.relative_to(self.target_path)),
+                                    file_path=str(
+                                        yaml_file.relative_to(self.target_path)
+                                    ),
                                     suggestion=f"æª¢æŸ¥è·¯å¾‘ {new_path}",
                                 )
                             )
@@ -388,7 +392,9 @@ def main():
         if result.issues:
             print(f"\nğŸ“‹ å•é¡Œåˆ—è¡¨:")
             for issue in result.issues:
-                level_icon = {"error": "âŒ", "warning": "âš ï¸", "info": "â„¹ï¸"}.get(issue.level, "â€¢")
+                level_icon = {"error": "âŒ", "warning": "âš ï¸", "info": "â„¹ï¸"}.get(
+                    issue.level, "â€¢"
+                )
                 print(f"   {level_icon} [{issue.category}] {issue.message}")
                 if issue.file_path:
                     print(
diff --git a/workspace/tools/platform-bootstrap-runner.py b/workspace/tools/platform-bootstrap-runner.py
index 7cd7d71..46ec3b8 100755
--- a/workspace/tools/platform-bootstrap-runner.py
+++ b/workspace/tools/platform-bootstrap-runner.py
@@ -64,7 +64,9 @@ class PlatformBootstrapRunner:
             with open(self.bootstrap_config_file, "r") as f:
                 return yaml.safe_load(f)
         except FileNotFoundError:
-            self.logger.error(f"Bootstrap config not found: {self.bootstrap_config_file}")
+            self.logger.error(
+                f"Bootstrap config not found: {self.bootstrap_config_file}"
+            )
             return {}
         except yaml.YAMLError as e:
             self.logger.error(f"Bootstrap config YAML error: {e}")
@@ -74,7 +76,12 @@ class PlatformBootstrapRunner:
         """Run command with timeout and capture output"""
         try:
             result = subprocess.run(
-                cmd, cwd=self.root_dir, timeout=timeout, capture_output=True, text=True, check=True
+                cmd,
+                cwd=self.root_dir,
+                timeout=timeout,
+                capture_output=True,
+                text=True,
+                check=True,
             )
             return {
                 "success": True,
@@ -97,13 +104,22 @@ class PlatformBootstrapRunner:
                 "stderr": e.stderr,
             }
         except Exception as e:
-            return {"success": False, "error": f"Unexpected error: {str(e)}", "returncode": -1}
+            return {
+                "success": False,
+                "error": f"Unexpected error: {str(e)}",
+                "returncode": -1,
+            }
 
     def step_validate_root_integrity(self) -> Dict[str, Any]:
         """Step 1: Validate root integrity using Root Validator"""
         self.logger.info("Step 1: Validating Root Layer Integrity")
 
-        cmd = [sys.executable, str(self.validator_path), "--root-dir", str(self.root_dir)]
+        cmd = [
+            sys.executable,
+            str(self.validator_path),
+            "--root-dir",
+            str(self.root_dir),
+        ]
         result = self.run_command(cmd, timeout=120)
 
         if result["success"]:
@@ -113,9 +129,12 @@ class PlatformBootstrapRunner:
                 with open(report_file, "r") as f:
                     validation_report = json.load(f)
 
-                self.bootstrap_context["evidence"]["validation_report"] = validation_report
+                self.bootstrap_context["evidence"][
+                    "validation_report"
+                ] = validation_report
                 self.bootstrap_context["evidence"]["validation_success"] = (
-                    validation_report.get("summary", {}).get("overall_status") == "PASSED"
+                    validation_report.get("summary", {}).get("overall_status")
+                    == "PASSED"
                 )
 
                 return {
@@ -163,12 +182,18 @@ class PlatformBootstrapRunner:
                 ["pgrep", "-f", "config-manager"], capture_output=True, text=True
             )
             if result.returncode != 0:
-                return {"status": "FAILED", "message": "Config manager process not found"}
+                return {
+                    "status": "FAILED",
+                    "message": "Config manager process not found",
+                }
 
             pids = result.stdout.strip().split("\n")
 
         except Exception as e:
-            return {"status": "FAILED", "message": f"Failed to verify config-manager: {str(e)}"}
+            return {
+                "status": "FAILED",
+                "message": f"Failed to verify config-manager: {str(e)}",
+            }
 
         # Governance status (simulated for now, but with real verification)
         governance_status = {
@@ -201,7 +226,10 @@ class PlatformBootstrapRunner:
         # Check modules config exists
         modules_file = self.root_dir / "root.modules.yaml"
         if not modules_file.exists():
-            return {"status": "FAILED", "message": "Modules configuration file not found"}
+            return {
+                "status": "FAILED",
+                "message": "Modules configuration file not found",
+            }
 
         try:
             with open(modules_file, "r") as f:
@@ -250,7 +278,9 @@ class PlatformBootstrapRunner:
             with open(status_file, "w") as f:
                 json.dump(registry_status, f, indent=2)
 
-            self.bootstrap_context["evidence"]["module_registry_status"] = registry_status
+            self.bootstrap_context["evidence"][
+                "module_registry_status"
+            ] = registry_status
 
             return {
                 "status": "PASSED",
@@ -259,7 +289,10 @@ class PlatformBootstrapRunner:
             }
 
         except Exception as e:
-            return {"status": "FAILED", "message": f"Failed to load module registry: {str(e)}"}
+            return {
+                "status": "FAILED",
+                "message": f"Failed to load module registry: {str(e)}",
+            }
 
     def step_initialize_trust_chain(self) -> Dict[str, Any]:
         """Step 4: Initialize trust chain (simulated)"""
@@ -355,7 +388,9 @@ class PlatformBootstrapRunner:
             }
 
         pipeline_steps = (
-            bootstrap_config.get("spec", {}).get("bootstrap_pipeline", {}).get("steps", [])
+            bootstrap_config.get("spec", {})
+            .get("bootstrap_pipeline", {})
+            .get("steps", [])
         )
 
         # Execute each step
@@ -397,7 +432,9 @@ class PlatformBootstrapRunner:
                                 "details": result.get("details", {}),
                             }
                         )
-                        self.logger.error(f"âŒ Step {step_name} failed: {result['message']}")
+                        self.logger.error(
+                            f"âŒ Step {step_name} failed: {result['message']}"
+                        )
 
                         # For critical failures, abort bootstrap
                         if step_config.get("failure_action") == "abort_bootstrap":
@@ -439,7 +476,9 @@ class PlatformBootstrapRunner:
 def main():
     import argparse
 
-    parser = argparse.ArgumentParser(description="MachineNativeOps Platform Bootstrap Runner")
+    parser = argparse.ArgumentParser(
+        description="MachineNativeOps Platform Bootstrap Runner"
+    )
     parser.add_argument("--root-dir", default=".", help="Root directory for bootstrap")
     parser.add_argument("--verbose", "-v", action="store_true", help="Verbose logging")
 
diff --git a/workspace/tools/python/governance_agent.py b/workspace/tools/python/governance_agent.py
index eefa200..43c5286 100644
--- a/workspace/tools/python/governance_agent.py
+++ b/workspace/tools/python/governance_agent.py
@@ -34,7 +34,9 @@ class GovernanceAgent:
     def _load_manifest(self):
         """Load the governance manifest."""
         if not self.manifest_path.exists():
-            raise FileNotFoundError(f"Governance manifest not found: {self.manifest_path}")
+            raise FileNotFoundError(
+                f"Governance manifest not found: {self.manifest_path}"
+            )
 
         with open(self.manifest_path, "r") as f:
             self.manifest = yaml.safe_load(f)
@@ -176,7 +178,9 @@ class GovernanceAgent:
             )
 
         # Load naming policy for detailed validation
-        policy_path = Path("workspace/src/governance/10-policy/naming-governance-policy.yaml")
+        policy_path = Path(
+            "workspace/src/governance/10-policy/naming-governance-policy.yaml"
+        )
         if policy_path.exists():
             try:
                 with open(policy_path, "r") as f:
@@ -194,11 +198,15 @@ class GovernanceAgent:
             "timestamp": datetime.utcnow().isoformat(),
             "violations": violations,
             "suggestions": (
-                self._generate_suggestions(name, resource_type, environment) if violations else []
+                self._generate_suggestions(name, resource_type, environment)
+                if violations
+                else []
             ),
         }
 
-    def _generate_suggestions(self, name: str, resource_type: str, environment: str) -> List[str]:
+    def _generate_suggestions(
+        self, name: str, resource_type: str, environment: str
+    ) -> List[str]:
         """Generate suggested valid names."""
         suggestions = []
 
@@ -210,7 +218,9 @@ class GovernanceAgent:
         suggestions.append(f"{environment}-{normalized}")
 
         if "team" in name or "service" in name:
-            suggestions.append(f"{environment}-platform-{resource_type.replace('k8s-', '')}")
+            suggestions.append(
+                f"{environment}-platform-{resource_type.replace('k8s-', '')}"
+            )
 
         return suggestions[:3]
 
@@ -367,7 +377,9 @@ class GovernanceAgent:
             ],
         }
 
-    def create_exception_request(self, exception_data: Dict[str, Any]) -> Dict[str, Any]:
+    def create_exception_request(
+        self, exception_data: Dict[str, Any]
+    ) -> Dict[str, Any]:
         """
         Create an exception request.
 
diff --git a/workspace/tools/quantum-alignment-engine/src/core/transformer.py b/workspace/tools/quantum-alignment-engine/src/core/transformer.py
index b004dcc..3e1b4a7 100644
--- a/workspace/tools/quantum-alignment-engine/src/core/transformer.py
+++ b/workspace/tools/quantum-alignment-engine/src/core/transformer.py
@@ -95,7 +95,9 @@ class SemanticLattice:
         lattice_position = self._find_lattice_position(entangled_state)
 
         return QuantumNode(
-            element=code_element, quantum_state=entangled_state, lattice_position=lattice_position
+            element=code_element,
+            quantum_state=entangled_state,
+            lattice_position=lattice_position,
         )
 
     def _apply_hadamard(self, vector: np.ndarray) -> np.ndarray:
@@ -178,7 +180,9 @@ class NamespaceRegistry:
         manifest_path = Path(self.manifest_path)
 
         if not manifest_path.exists():
-            print(f"âš ï¸  Warning: {self.manifest_path} not found, using default namespaces")
+            print(
+                f"âš ï¸  Warning: {self.manifest_path} not found, using default namespaces"
+            )
             self._load_default_namespaces()
             return
 
@@ -208,7 +212,10 @@ class NamespaceRegistry:
             self.namespaces[ns] = "axiom-naming-v9"
             self.namespace_vectors[ns] = self._generate_namespace_vector(ns)
 
-        self.policies["axiom-naming-v9"] = {"namespaces": default_namespaces, "version": "9.0.0"}
+        self.policies["axiom-naming-v9"] = {
+            "namespaces": default_namespaces,
+            "version": "9.0.0",
+        }
 
     def _generate_namespace_vector(self, namespace: str) -> np.ndarray:
         """
@@ -236,7 +243,9 @@ class NamespaceRegistry:
         """Get semantic vector for namespace"""
         if namespace not in self.namespace_vectors:
             # Generate on-the-fly
-            self.namespace_vectors[namespace] = self._generate_namespace_vector(namespace)
+            self.namespace_vectors[namespace] = self._generate_namespace_vector(
+                namespace
+            )
 
         return self.namespace_vectors[namespace]
 
@@ -322,7 +331,9 @@ class EntanglementMapper:
 
         return best_match
 
-    def _create_entanglement(self, element: CodeElement, namespace: str) -> "QuantumNode":
+    def _create_entanglement(
+        self, element: CodeElement, namespace: str
+    ) -> "QuantumNode":
         """
         Create entangled quantum state between element and namespace
 
@@ -626,7 +637,9 @@ class QuantumCodeTransformer:
 
         for node in semantic_graph.traverse():
             try:
-                remapped = self.entanglement_mapper.remap(node, target_policy=target_policy)
+                remapped = self.entanglement_mapper.remap(
+                    node, target_policy=target_policy
+                )
                 remapped_nodes.append(remapped)
             except SemanticDecoherenceError as e:
                 print(f"  âš ï¸  Warning: {e}")
@@ -638,7 +651,9 @@ class QuantumCodeTransformer:
                 except Exception as e:
                     print(f"  âŒ Failed to correct: {e}")
 
-        print(f"  âœ“ Remapped {len(remapped_nodes)} nodes ({failed_count} with warnings)")
+        print(
+            f"  âœ“ Remapped {len(remapped_nodes)} nodes ({failed_count} with warnings)"
+        )
         print()
 
         # Phase 4: Generate quantum circuit intermediate representation
@@ -772,7 +787,9 @@ class QuantumCodeTransformer:
 
         return graph
 
-    def _find_node_by_name(self, nodes: List[QuantumNode], name: str) -> Optional[QuantumNode]:
+    def _find_node_by_name(
+        self, nodes: List[QuantumNode], name: str
+    ) -> Optional[QuantumNode]:
         """Find node by element name"""
         for node in nodes:
             if node.element.name == name:
@@ -820,7 +837,9 @@ class QuantumCodeTransformer:
         stabilized = calibrator.stabilize(qir)
         return stabilized
 
-    def _collapse_to_classical(self, qir: QuantumIR, output_path: Optional[str] = None) -> str:
+    def _collapse_to_classical(
+        self, qir: QuantumIR, output_path: Optional[str] = None
+    ) -> str:
         """Collapse quantum state to classical code"""
         # Measure quantum state
         classical_code = self._measure_quantum_state(qir)
@@ -833,7 +852,9 @@ class QuantumCodeTransformer:
         measurement = {"circuits": qir.circuits, "metadata": qir.metadata}
         return measurement
 
-    def _generate_classical_code(self, measurement: Dict, output_path: Optional[str] = None) -> str:
+    def _generate_classical_code(
+        self, measurement: Dict, output_path: Optional[str] = None
+    ) -> str:
         """Generate classical code from quantum measurement"""
         if output_path is None:
             output_path = "/workspace/transformed_code"
@@ -854,7 +875,9 @@ class QuantumCodeTransformer:
 
         return str(generated_file)
 
-    def _correct_decoherence(self, node: QuantumNode, target_policy: str) -> QuantumNode:
+    def _correct_decoherence(
+        self, node: QuantumNode, target_policy: str
+    ) -> QuantumNode:
         """Correct decoherence in quantum node"""
         # Apply error correction
         corrected_state = self._apply_error_correction(node.quantum_state)
@@ -907,11 +930,14 @@ def main():
     parser.add_argument("source_path", help="Path to external codebase to transform")
 
     parser.add_argument(
-        "--policy", default="axiom-naming-v9", help="Target policy (default: axiom-naming-v9)"
+        "--policy",
+        default="axiom-naming-v9",
+        help="Target policy (default: axiom-naming-v9)",
     )
 
     parser.add_argument(
-        "--output", help="Output path for transformed code (default: ./transformed_code)"
+        "--output",
+        help="Output path for transformed code (default: ./transformed_code)",
     )
 
     args = parser.parse_args()
diff --git a/workspace/tools/quantum-alignment-engine/tests/test_transformer.py b/workspace/tools/quantum-alignment-engine/tests/test_transformer.py
index a06a201..8f8db1a 100644
--- a/workspace/tools/quantum-alignment-engine/tests/test_transformer.py
+++ b/workspace/tools/quantum-alignment-engine/tests/test_transformer.py
@@ -7,7 +7,6 @@ from pathlib import Path
 
 import numpy as np
 import pytest
-
 from src.core.transformer import (
     CodeElement,
     EntanglementMapper,
@@ -40,7 +39,9 @@ class TestCodeElement:
 
     def test_semantic_vector_normalization(self):
         """Test semantic vector is properly normalized"""
-        element = CodeElement(name="test", semantic_vector=np.random.randn(8192), namespace="test")
+        element = CodeElement(
+            name="test", semantic_vector=np.random.randn(8192), namespace="test"
+        )
 
         norm = np.linalg.norm(element.semantic_vector)
         assert norm > 0
@@ -79,7 +80,9 @@ class TestSemanticLattice:
     def test_lattice_projection(self):
         """Test projecting code element to lattice"""
         lattice = SemanticLattice()
-        element = CodeElement(name="test", semantic_vector=np.random.randn(8192), namespace="test")
+        element = CodeElement(
+            name="test", semantic_vector=np.random.randn(8192), namespace="test"
+        )
 
         node = lattice.project(element)
 
@@ -100,7 +103,9 @@ class TestEntanglementMapper:
         mapper = EntanglementMapper()
         lattice = SemanticLattice()
 
-        element = CodeElement(name="test", semantic_vector=np.random.randn(8192), namespace="test")
+        element = CodeElement(
+            name="test", semantic_vector=np.random.randn(8192), namespace="test"
+        )
 
         node = lattice.project(element)
         features = mapper._extract_features(node)
@@ -121,19 +126,26 @@ class TestEntanglementMapper:
     def test_entanglement_creation(self):
         """Test creating entangled state"""
         mapper = EntanglementMapper()
-        element = CodeElement(name="test", semantic_vector=np.random.randn(8192), namespace="test")
+        element = CodeElement(
+            name="test", semantic_vector=np.random.randn(8192), namespace="test"
+        )
 
         entangled = mapper._create_entanglement(element, "workspace.src.governance")
 
         assert isinstance(entangled, QuantumNode)
-        assert entangled.element.context.get("target_namespace") == "workspace.src.governance"
+        assert (
+            entangled.element.context.get("target_namespace")
+            == "workspace.src.governance"
+        )
 
     def test_coherence_measurement(self):
         """Test measuring quantum coherence"""
         mapper = EntanglementMapper()
         lattice = SemanticLattice()
 
-        element = CodeElement(name="test", semantic_vector=np.random.randn(8192), namespace="test")
+        element = CodeElement(
+            name="test", semantic_vector=np.random.randn(8192), namespace="test"
+        )
 
         node = lattice.project(element)
         coherence = mapper._measure_coherence(node)
@@ -145,7 +157,9 @@ class TestEntanglementMapper:
         mapper = EntanglementMapper()
         lattice = SemanticLattice()
 
-        element = CodeElement(name="test", semantic_vector=np.random.randn(8192), namespace="test")
+        element = CodeElement(
+            name="test", semantic_vector=np.random.randn(8192), namespace="test"
+        )
 
         node = lattice.project(element)
         remapped = mapper.remap(node, "axiom-naming-v9")
@@ -180,7 +194,9 @@ class TestQuantumCodeTransformer:
         transformer = QuantumCodeTransformer()
         lattice = SemanticLattice()
 
-        element = CodeElement(name="test", semantic_vector=np.random.randn(8192), namespace="test")
+        element = CodeElement(
+            name="test", semantic_vector=np.random.randn(8192), namespace="test"
+        )
 
         node = lattice.project(element)
         qir = transformer._compile_to_qir([node])
@@ -193,7 +209,9 @@ class TestQuantumCodeTransformer:
         transformer = QuantumCodeTransformer()
         lattice = SemanticLattice()
 
-        element = CodeElement(name="test", semantic_vector=np.random.randn(8192), namespace="test")
+        element = CodeElement(
+            name="test", semantic_vector=np.random.randn(8192), namespace="test"
+        )
 
         node = lattice.project(element)
         qir = transformer._compile_to_qir([node])
@@ -227,7 +245,9 @@ class TestClass:
         output_path = tmp_path / "output"
 
         result = transformer.transform(
-            str(test_code), target_policy="axiom-naming-v9", output_path=str(output_path)
+            str(test_code),
+            target_policy="axiom-naming-v9",
+            output_path=str(output_path),
         )
 
         # Verify output
@@ -244,7 +264,9 @@ class TestErrorHandling:
         lattice = SemanticLattice()
 
         # Create element with low coherence
-        element = CodeElement(name="test", semantic_vector=np.random.randn(8192), namespace="test")
+        element = CodeElement(
+            name="test", semantic_vector=np.random.randn(8192), namespace="test"
+        )
 
         node = lattice.project(element)
 
diff --git a/workspace/tools/real-module-launcher.py b/workspace/tools/real-module-launcher.py
index 91ae924..38b35b8 100755
--- a/workspace/tools/real-module-launcher.py
+++ b/workspace/tools/real-module-launcher.py
@@ -29,7 +29,9 @@ class RealModuleLauncher:
     """Real module launcher that starts and manages actual processes"""
 
     def __init__(self):
-        self.root_dir = Path(os.getenv("ROOT_DIR", "/workspace/machine-native-ops-aaps"))
+        self.root_dir = Path(
+            os.getenv("ROOT_DIR", "/workspace/machine-native-ops-aaps")
+        )
         self.modules_dir = self.root_dir / "modules"
         self.running_modules = {}
         self.module_configs = {}
@@ -158,7 +160,9 @@ class RealModuleLauncher:
             health_check = module_config.get("health_check", {})
 
             # Determine health check endpoint
-            port = int(os.getenv(f"{module_name.upper().replace('-', '_')}_PORT", "8081"))
+            port = int(
+                os.getenv(f"{module_name.upper().replace('-', '_')}_PORT", "8081")
+            )
             if module_name == "config-manager":
                 port = 8081  # We know this from our test
 
@@ -183,7 +187,9 @@ class RealModuleLauncher:
             logger.error(f"Module {module_name} health check error: {str(e)}")
             return False
         except Exception as e:
-            logger.error(f"Module {module_name} health check unexpected error: {str(e)}")
+            logger.error(
+                f"Module {module_name} health check unexpected error: {str(e)}"
+            )
             return False
 
     def wait_for_ready(self, module_name: str, timeout: int = None) -> bool:
@@ -196,7 +202,9 @@ class RealModuleLauncher:
             logger.error(f"Module {module_name} not found in running modules")
             return False
 
-        logger.info(f"Waiting for module {module_name} to become ready (timeout: {timeout}s)")
+        logger.info(
+            f"Waiting for module {module_name} to become ready (timeout: {timeout}s)"
+        )
 
         start_time = time.time()
 
@@ -237,7 +245,9 @@ class RealModuleLauncher:
                 process.wait(timeout=10)
                 logger.info(f"Module {module_name} stopped gracefully")
             except subprocess.TimeoutExpired:
-                logger.warning(f"Module {module_name} did not stop gracefully, forcing termination")
+                logger.warning(
+                    f"Module {module_name} did not stop gracefully, forcing termination"
+                )
                 process.kill()
                 process.wait()
 
@@ -288,7 +298,12 @@ class RealModuleLauncher:
 
         except Exception as e:
             logger.error(f"Error getting status for module {module_name}: {str(e)}")
-            return {"name": module_name, "status": "error", "running": False, "error": str(e)}
+            return {
+                "name": module_name,
+                "status": "error",
+                "running": False,
+                "error": str(e),
+            }
 
     def get_all_status(self) -> Dict[str, Any]:
         """Get status of all modules"""
diff --git a/workspace/tools/refactor/__init__.py b/workspace/tools/refactor/__init__.py
index 5bf08ef..1aeb446 100644
--- a/workspace/tools/refactor/__init__.py
+++ b/workspace/tools/refactor/__init__.py
@@ -29,12 +29,12 @@ Refactor Tools Package - é‡æ§‹å·¥å…·åŒ…
 Version: 1.0.0
 """
 
-from .validate_structure import StructureValidatorMain as StructureValidator
-from .update_indexes import IndexUpdater
-from .refactor_engine import DirectoryAnalyzer as RefactorEngine
-from .process_legacy_scratch import LegacyScratchProcessor
-from .execute_integration import IntegrationExecutor
 from .cognitive_engine import CognitiveEngine
+from .execute_integration import IntegrationExecutor
+from .process_legacy_scratch import LegacyScratchProcessor
+from .refactor_engine import DirectoryAnalyzer as RefactorEngine
+from .update_indexes import IndexUpdater
+from .validate_structure import StructureValidatorMain as StructureValidator
 
 __version__ = "1.0.0"
 __author__ = "SynergyMesh"
diff --git a/workspace/tools/refactor/auto_refactor.py b/workspace/tools/refactor/auto_refactor.py
index 89e1919..2e2495a 100755
--- a/workspace/tools/refactor/auto_refactor.py
+++ b/workspace/tools/refactor/auto_refactor.py
@@ -24,12 +24,13 @@ Usage:
 â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 """
 
-from refactor_evolution_workflow import REPORTS_DIR, RefactorEvolutionWorkflow
 import argparse
 import asyncio
 import sys
 from pathlib import Path
 
+from refactor_evolution_workflow import REPORTS_DIR, RefactorEvolutionWorkflow
+
 # Add parent directory to path
 # Note: Consider setting PYTHONPATH environment variable as an alternative
 BASE_PATH = Path(__file__).parent.parent.parent
diff --git a/workspace/tools/refactor/cognitive_engine.py b/workspace/tools/refactor/cognitive_engine.py
index 52b8ad8..6e48d16 100644
--- a/workspace/tools/refactor/cognitive_engine.py
+++ b/workspace/tools/refactor/cognitive_engine.py
@@ -221,7 +221,9 @@ class UnderstandingLayer:
         # å¾çµæ§‹åŒ–è¼¸å…¥æå–
         if isinstance(raw_input, dict):
             if "target" in raw_input:
-                entities.append({"type": "path", "value": raw_input["target"], "confidence": 1.0})
+                entities.append(
+                    {"type": "path", "value": raw_input["target"], "confidence": 1.0}
+                )
             if "files" in raw_input:
                 for f in raw_input["files"]:
                     entities.append({"type": "path", "value": f, "confidence": 1.0})
@@ -474,7 +476,9 @@ class ReasoningLayer:
             alternatives=[],
         )
 
-    def _infer_missing_information(self, understanding: UnderstandingResult) -> ReasoningStep:
+    def _infer_missing_information(
+        self, understanding: UnderstandingResult
+    ) -> ReasoningStep:
         """æ¨æ–·ç¼ºå¤±ä¿¡æ¯"""
         hypothesis = "å˜—è©¦æ¨æ–·ç¼ºå¤±çš„é—œéµä¿¡æ¯"
 
@@ -498,12 +502,16 @@ class ReasoningLayer:
             step_id=len(self.reasoning_trace) + 1,
             hypothesis=hypothesis,
             evidence=evidence,
-            conclusion="; ".join(inferences) if inferences else "ç„¡æ³•æœ‰æ•ˆæ¨æ–·ï¼Œéœ€è¦æ›´å¤šä¿¡æ¯",
+            conclusion=(
+                "; ".join(inferences) if inferences else "ç„¡æ³•æœ‰æ•ˆæ¨æ–·ï¼Œéœ€è¦æ›´å¤šä¿¡æ¯"
+            ),
             confidence=0.6 if inferences else 0.3,
             alternatives=["è«‹æ±‚ç”¨æˆ¶æä¾›æ›´å¤šç´°ç¯€"],
         )
 
-    def _reason_intent_clarification(self, understanding: UnderstandingResult) -> ReasoningStep:
+    def _reason_intent_clarification(
+        self, understanding: UnderstandingResult
+    ) -> ReasoningStep:
         """æ¨ç†æ„åœ–æ¾„æ¸…"""
         hypothesis = f"ç”¨æˆ¶æ„åœ– '{understanding.intent}' çš„å…·é«”å«ç¾©"
 
@@ -540,7 +548,10 @@ class ReasoningLayer:
 
         # è­˜åˆ¥è¡çª
         conflicts = []
-        if "scope_limited" in understanding.constraints and len(understanding.entities) == 0:
+        if (
+            "scope_limited" in understanding.constraints
+            and len(understanding.entities) == 0
+        ):
             conflicts.append("ç¯„åœé™åˆ¶ä½†æœªæŒ‡å®šå…·é«”ç›®æ¨™")
 
         if conflicts:
@@ -623,11 +634,13 @@ class ReasoningLayer:
         # é¸æ“‡æœ€å„ªè·¯å¾‘
         if paths:
             optimal = min(
-                paths, key=lambda p: ({"low": 0, "medium": 1, "high": 2}[p["risk"]], p["phases"])
-            )
-            conclusion = (
-                f"æ¨è–¦ç­–ç•¥: {optimal['name']} ({optimal['phases']} éšæ®µ, {optimal['risk']} é¢¨éšª)"
+                paths,
+                key=lambda p: (
+                    {"low": 0, "medium": 1, "high": 2}[p["risk"]],
+                    p["phases"],
+                ),
             )
+            conclusion = f"æ¨è–¦ç­–ç•¥: {optimal['name']} ({optimal['phases']} éšæ®µ, {optimal['risk']} é¢¨éšª)"
         else:
             conclusion = "ä½¿ç”¨é»˜èªåŸ·è¡Œç­–ç•¥"
             optimal = None
@@ -646,7 +659,9 @@ class ReasoningLayer:
         if not self.reasoning_trace:
             return ConfidenceLevel.INSUFFICIENT
 
-        avg_confidence = sum(s.confidence for s in self.reasoning_trace) / len(self.reasoning_trace)
+        avg_confidence = sum(s.confidence for s in self.reasoning_trace) / len(
+            self.reasoning_trace
+        )
 
         if avg_confidence >= 0.8:
             return ConfidenceLevel.HIGH
@@ -659,7 +674,10 @@ class ReasoningLayer:
 
     def needs_external_search(self) -> bool:
         """åˆ¤æ–·æ˜¯å¦éœ€è¦å¤–éƒ¨æœå°‹"""
-        if self.get_confidence_level() in [ConfidenceLevel.LOW, ConfidenceLevel.INSUFFICIENT]:
+        if self.get_confidence_level() in [
+            ConfidenceLevel.LOW,
+            ConfidenceLevel.INSUFFICIENT,
+        ]:
             return True
 
         # æª¢æŸ¥æ˜¯å¦æœ‰æœªè§£æ±ºçš„æ­§ç¾©
@@ -690,7 +708,9 @@ class SearchLayer:
         self.config = config or {}
         self.search_results: List[Dict] = []
 
-    def search(self, queries: List[SearchQuery], context: Optional[Dict] = None) -> List[Dict]:
+    def search(
+        self, queries: List[SearchQuery], context: Optional[Dict] = None
+    ) -> List[Dict]:
         """åŸ·è¡Œæœå°‹"""
         self.search_results = []
 
@@ -736,7 +756,10 @@ class SearchLayer:
                     )
 
                 # å…§å®¹æœå°‹ (é™åˆ¶æ–¼å°æª”æ¡ˆ)
-                if file.suffix in [".md", ".yaml", ".yml", ".py"] and file.stat().st_size < 100000:
+                if (
+                    file.suffix in [".md", ".yaml", ".yml", ".py"]
+                    and file.stat().st_size < 100000
+                ):
                     try:
                         content = file.read_text(encoding="utf-8")
                         if search_term in content.lower():
@@ -919,8 +942,12 @@ class IntegrationLayer:
         """ç¶œåˆç†è§£"""
         return {
             "confirmed_intent": understanding.intent,
-            "validated_entities": [e for e in understanding.entities if e["confidence"] > 0.7],
-            "resolved_ambiguities": self._resolve_ambiguities(understanding, search_results),
+            "validated_entities": [
+                e for e in understanding.entities if e["confidence"] > 0.7
+            ],
+            "resolved_ambiguities": self._resolve_ambiguities(
+                understanding, search_results
+            ),
             "enriched_context": self._enrich_context(understanding, search_results),
         }
 
@@ -932,13 +959,17 @@ class IntegrationLayer:
 
         for ambiguity in understanding.ambiguities:
             # å˜—è©¦å¾æœå°‹çµæœä¸­æ‰¾åˆ°è§£ç­”
-            relevant_results = [r for r in search_results if ambiguity.lower() in str(r).lower()]
+            relevant_results = [
+                r for r in search_results if ambiguity.lower() in str(r).lower()
+            ]
 
             if relevant_results:
                 resolutions.append(
                     {
                         "ambiguity": ambiguity,
-                        "resolution": relevant_results[0].get("content", "å·²æ‰¾åˆ°ç›¸é—œä¿¡æ¯"),
+                        "resolution": relevant_results[0].get(
+                            "content", "å·²æ‰¾åˆ°ç›¸é—œä¿¡æ¯"
+                        ),
                         "confidence": 0.7,
                     }
                 )
@@ -1029,7 +1060,9 @@ class IntegrationLayer:
         if risk_dim.get("data_loss") in ["medium", "high"]:
             risks["factors"].append("æ½›åœ¨æ•¸æ“šä¸Ÿå¤±")
             risks["mitigations"].append("åŸ·è¡Œå‰å‰µå»ºå®Œæ•´å‚™ä»½")
-            risks["overall_level"] = "medium" if risks["overall_level"] == "low" else "high"
+            risks["overall_level"] = (
+                "medium" if risks["overall_level"] == "low" else "high"
+            )
 
         # å¾æ¨ç†ä¸­è­˜åˆ¥é¢¨éšª
         for step in reasoning:
@@ -1049,7 +1082,9 @@ class IntegrationLayer:
         return {
             "understanding_confidence": understanding.completeness_score,
             "reasoning_confidence": (
-                sum(s.confidence for s in reasoning) / len(reasoning) if reasoning else 0.0
+                sum(s.confidence for s in reasoning) / len(reasoning)
+                if reasoning
+                else 0.0
             ),
             "search_confidence": (
                 sum(r.get("relevance", 0) for r in search_results) / len(search_results)
@@ -1100,7 +1135,9 @@ class CognitiveEngine:
         self.search_layer = SearchLayer(config)
         self.integration_layer = IntegrationLayer(config)
 
-    def process(self, raw_input: Dict, context: Optional[Dict] = None) -> CognitiveContext:
+    def process(
+        self, raw_input: Dict, context: Optional[Dict] = None
+    ) -> CognitiveContext:
         """åŸ·è¡Œå®Œæ•´èªçŸ¥è™•ç†"""
         # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
         ctx = CognitiveContext(
@@ -1140,7 +1177,10 @@ class CognitiveEngine:
             print("ğŸ”„ éšæ®µ4: å†æ¨ç†...")
             # æ›´æ–°ç†è§£
             for result in search_results:
-                if result.get("source") == "local" and result.get("type") == "file_match":
+                if (
+                    result.get("source") == "local"
+                    and result.get("type") == "file_match"
+                ):
                     understanding.entities.append(
                         {
                             "type": "discovered_file",
@@ -1209,7 +1249,9 @@ class CognitiveEngine:
             "action_plan": action_plan,
             "requires_confirmation": not can_auto_execute,
             "confirmation_points": (
-                [amb for amb in understanding.ambiguities] if not can_auto_execute else []
+                [amb for amb in understanding.ambiguities]
+                if not can_auto_execute
+                else []
             ),
             "risk_summary": integration.risk_assessment["overall_level"],
             "mitigations": integration.risk_assessment["mitigations"],
@@ -1233,7 +1275,9 @@ def quick_reason(understanding: UnderstandingResult) -> List[ReasoningStep]:
     return layer.reason(understanding)
 
 
-def full_cognitive_process(raw_input: Dict, context: Optional[Dict] = None) -> CognitiveContext:
+def full_cognitive_process(
+    raw_input: Dict, context: Optional[Dict] = None
+) -> CognitiveContext:
     """å®Œæ•´èªçŸ¥è™•ç†"""
     engine = CognitiveEngine()
     return engine.process(raw_input, context)
@@ -1284,7 +1328,9 @@ def main():
         output["full_reasoning_trace"] = result.reasoning_trace
         output["integration_result"] = result.integration_result
 
-    output_str = yaml.dump(output, allow_unicode=True, default_flow_style=False, sort_keys=False)
+    output_str = yaml.dump(
+        output, allow_unicode=True, default_flow_style=False, sort_keys=False
+    )
 
     if args.output:
         with open(args.output, "w", encoding="utf-8") as f:
diff --git a/workspace/tools/refactor/execute_integration.py b/workspace/tools/refactor/execute_integration.py
index 13a188c..9841ec7 100644
--- a/workspace/tools/refactor/execute_integration.py
+++ b/workspace/tools/refactor/execute_integration.py
@@ -341,7 +341,12 @@ class DirectoryMapper:
         return "\n".join(lines)
 
     def _build_tree(
-        self, path: Path, lines: List[str], prefix: str, max_depth: int, current_depth: int
+        self,
+        path: Path,
+        lines: List[str],
+        prefix: str,
+        max_depth: int,
+        current_depth: int,
     ):
         """éè¿´å»ºç«‹æ¨¹çµæ§‹"""
         if current_depth >= max_depth:
@@ -640,7 +645,9 @@ class IntegrationExecutor:
         if embed_marker in target_content:
             # åœ¨ç¾æœ‰æ®µè½å¾Œæ·»åŠ 
             parts = target_content.split(embed_marker)
-            new_content = parts[0] + embed_marker + source_content + "\n\n" + "".join(parts[1:])
+            new_content = (
+                parts[0] + embed_marker + source_content + "\n\n" + "".join(parts[1:])
+            )
         else:
             # æ·»åŠ æ–°æ®µè½
             new_content = target_content + embed_marker + source_content
@@ -674,7 +681,9 @@ class IntegrationExecutor:
             changes=[f"Updated index: {op.target}"],
         )
 
-    def _check_dependencies(self, op: Operation, results: List[OperationResult]) -> bool:
+    def _check_dependencies(
+        self, op: Operation, results: List[OperationResult]
+    ) -> bool:
         """æª¢æŸ¥ä¾è³´æ˜¯å¦æ»¿è¶³"""
         for dep_id in op.depends_on:
             dep_result = next((r for r in results if r.op_id == dep_id), None)
@@ -731,7 +740,9 @@ class IntegrationExecutor:
                 op_id=decision.get("asset_id", "op_001"),
                 op_type=OperationType.MOVE_FILE,
                 source=decision.get("source_path"),
-                target=decision.get("target_directory") + "/" + decision.get("target_filename", ""),
+                target=decision.get("target_directory")
+                + "/"
+                + decision.get("target_filename", ""),
             )
         elif integration_type == "embedded_integration":
             return Operation(
@@ -870,7 +881,9 @@ def main():
     # map å‘½ä»¤
     map_parser = subparsers.add_parser("map", help="ç”Ÿæˆç›®éŒ„åœ–è­œ")
     map_parser.add_argument("--target", "-t", required=True, help="ç›®æ¨™ç›®éŒ„")
-    map_parser.add_argument("--format", "-f", choices=["ascii", "mermaid"], default="ascii")
+    map_parser.add_argument(
+        "--format", "-f", choices=["ascii", "mermaid"], default="ascii"
+    )
     map_parser.add_argument("--output", "-o", help="è¼¸å‡ºæª”æ¡ˆ")
 
     args = parser.parse_args()
diff --git a/workspace/tools/refactor/process_legacy_scratch.py b/workspace/tools/refactor/process_legacy_scratch.py
index d72f2f5..bb71056 100644
--- a/workspace/tools/refactor/process_legacy_scratch.py
+++ b/workspace/tools/refactor/process_legacy_scratch.py
@@ -272,12 +272,17 @@ class VocabularyScanner:
         unique_matches = {}
         for match in matches:
             key = (match.term, match.category)
-            if key not in unique_matches or match.confidence > unique_matches[key].confidence:
+            if (
+                key not in unique_matches
+                or match.confidence > unique_matches[key].confidence
+            ):
                 unique_matches[key] = match
 
         return list(unique_matches.values())
 
-    def extract_domain_classification(self, matches: List[VocabularyMatch]) -> Dict[str, float]:
+    def extract_domain_classification(
+        self, matches: List[VocabularyMatch]
+    ) -> Dict[str, float]:
         """å¾è©å½™åŒ¹é…ä¸­æå–é ˜åŸŸåˆ†é¡"""
         classification = defaultdict(float)
 
@@ -359,7 +364,9 @@ class ReferenceScanner:
 
         return unique
 
-    def _check_reference_exists(self, target: str, source_path: Path, is_internal: bool) -> bool:
+    def _check_reference_exists(
+        self, target: str, source_path: Path, is_internal: bool
+    ) -> bool:
         """æª¢æŸ¥å¼•ç”¨æ˜¯å¦å­˜åœ¨"""
         if not is_internal:
             return True  # å¤–éƒ¨é€£çµå‡è¨­å­˜åœ¨
@@ -460,7 +467,9 @@ class StructureAnalyzer:
             try:
                 data = yaml.safe_load(content)
                 if isinstance(data, dict):
-                    sections = [{"key": k, "type": type(v).__name__} for k, v in data.items()]
+                    sections = [
+                        {"key": k, "type": type(v).__name__} for k, v in data.items()
+                    ]
             except BaseException:
                 pass
 
@@ -577,7 +586,9 @@ class DecisionEngine:
         # æ­¥é©Ÿ5: ç¢ºå®šåµŒå…¥ä½ç½® (å¦‚æœæ˜¯åµŒå…¥å¼æ•´åˆ)
         embedding_loc, embedding_sec = None, None
         if integration_type == IntegrationType.EMBEDDED_INTEGRATION:
-            embedding_loc, embedding_sec = self._determine_embedding_location(analysis, target_dir)
+            embedding_loc, embedding_sec = self._determine_embedding_location(
+                analysis, target_dir
+            )
             reasoning.append(f"åµŒå…¥ä½ç½®: {embedding_loc} / {embedding_sec}")
 
         # æ­¥é©Ÿ6: è¨ˆç®—ç½®ä¿¡åº¦
@@ -636,7 +647,10 @@ class DecisionEngine:
             return IntegrationType.ARCHIVE
 
     def _determine_target_location(
-        self, analysis: AssetAnalysis, primary_domain: str, integration_type: IntegrationType
+        self,
+        analysis: AssetAnalysis,
+        primary_domain: str,
+        integration_type: IntegrationType,
     ) -> Tuple[str, Optional[str]]:
         """ç¢ºå®šç›®æ¨™ä½ç½®"""
         # åŸºæ–¼é ˜åŸŸæ˜ å°„
@@ -698,7 +712,9 @@ class DecisionEngine:
 
         return min(confidence, 1.0)
 
-    def _generate_alternatives(self, analysis: AssetAnalysis, primary_domain: str) -> List[Dict]:
+    def _generate_alternatives(
+        self, analysis: AssetAnalysis, primary_domain: str
+    ) -> List[Dict]:
         """ç”Ÿæˆå‚™é¸æ–¹æ¡ˆ"""
         alternatives = []
 
@@ -778,7 +794,9 @@ class LegacyScratchProcessor:
                         "type": asset_type.value,
                         "stage": stage.value,
                         "size": file.stat().st_size,
-                        "modified": datetime.fromtimestamp(file.stat().st_mtime).isoformat(),
+                        "modified": datetime.fromtimestamp(
+                            file.stat().st_mtime
+                        ).isoformat(),
                     }
                 )
 
@@ -872,7 +890,9 @@ class LegacyScratchProcessor:
 
         return decision
 
-    def batch_process(self, filter_stage: Optional[ProcessingStage] = None) -> List[Dict]:
+    def batch_process(
+        self, filter_stage: Optional[ProcessingStage] = None
+    ) -> List[Dict]:
         """æ‰¹é‡è™•ç†æ‰€æœ‰è³‡ç”¢"""
         print("ğŸ”„ é–‹å§‹æ‰¹é‡è™•ç†...")
 
diff --git a/workspace/tools/refactor/refactor_engine.py b/workspace/tools/refactor/refactor_engine.py
index e9a25a9..2fca60d 100644
--- a/workspace/tools/refactor/refactor_engine.py
+++ b/workspace/tools/refactor/refactor_engine.py
@@ -152,7 +152,9 @@ class DirectoryAnalyzer:
         self._build_files_cache()
 
         overview = self._analyze_overview()
-        print(f"  âœ“ ç›®éŒ„æ¦‚è¦½: {overview['total_files']} æª”æ¡ˆ, {overview['total_directories']} ç›®éŒ„")
+        print(
+            f"  âœ“ ç›®éŒ„æ¦‚è¦½: {overview['total_files']} æª”æ¡ˆ, {overview['total_directories']} ç›®éŒ„"
+        )
 
         problems = self._identify_problems()
         print(f"  âœ“ è­˜åˆ¥å•é¡Œ: {len(problems)} å€‹")
@@ -216,7 +218,9 @@ class DirectoryAnalyzer:
         for f in files:
             try:
                 size = f.stat().st_size
-                sized_files.append({"path": str(f.relative_to(self.target)), "size": size})
+                sized_files.append(
+                    {"path": str(f.relative_to(self.target)), "size": size}
+                )
             except BaseException:
                 pass
         return sorted(sized_files, key=lambda x: -x["size"])[:n]
@@ -429,7 +433,9 @@ class DirectoryAnalyzer:
                     if playbook_path and playbook_path != "_pending":
                         full_path = self.target / playbook_path
                         if not full_path.exists():
-                            issues.append(f"index.yaml å¼•ç”¨ä¸å­˜åœ¨çš„æª”æ¡ˆ: {playbook_path}")
+                            issues.append(
+                                f"index.yaml å¼•ç”¨ä¸å­˜åœ¨çš„æª”æ¡ˆ: {playbook_path}"
+                            )
             except Exception as e:
                 issues.append(f"ç„¡æ³•è§£æ index.yaml: {e}")
 
@@ -530,7 +536,9 @@ class DirectoryAnalyzer:
             rec = {
                 "problem_id": problem.id,
                 "priority": (
-                    "P1" if problem.severity in [SEVERITY_CRITICAL, SEVERITY_HIGH] else "P2"
+                    "P1"
+                    if problem.severity in [SEVERITY_CRITICAL, SEVERITY_HIGH]
+                    else "P2"
                 ),
                 "action": problem.suggested_action,
                 "effort": "low" if problem.category == CATEGORY_NAMING else "medium",
@@ -572,7 +580,11 @@ class PlanGenerator:
                 "total_files": self.analysis.overview["total_files"],
                 "problems_count": len(self.analysis.problems),
                 "critical_problems": len(
-                    [p for p in self.analysis.problems if p.severity == SEVERITY_CRITICAL]
+                    [
+                        p
+                        for p in self.analysis.problems
+                        if p.severity == SEVERITY_CRITICAL
+                    ]
                 ),
                 "high_problems": len(
                     [p for p in self.analysis.problems if p.severity == SEVERITY_HIGH]
@@ -588,7 +600,10 @@ class PlanGenerator:
         phases = []
 
         # P1 éšæ®µ (1-3): ç·Šæ€¥çµæ§‹ä¿®å¾©
-        if any(p.severity in [SEVERITY_CRITICAL, SEVERITY_HIGH] for p in self.analysis.problems):
+        if any(
+            p.severity in [SEVERITY_CRITICAL, SEVERITY_HIGH]
+            for p in self.analysis.problems
+        ):
             phases.extend(self._generate_p1_phases())
 
         # P2 éšæ®µ (4-6): çµ„ç¹”å„ªåŒ–
@@ -683,7 +698,10 @@ class PlanGenerator:
                         priority="P2",
                         description="å»ºç«‹ _legacy_scratch å­ç›®éŒ„çµæ§‹",
                         steps=[
-                            {"operation": "create_directory", "target": "_legacy_scratch/intake/"},
+                            {
+                                "operation": "create_directory",
+                                "target": "_legacy_scratch/intake/",
+                            },
                             {
                                 "operation": "create_directory",
                                 "target": "_legacy_scratch/processing/",
@@ -692,7 +710,10 @@ class PlanGenerator:
                                 "operation": "create_directory",
                                 "target": "_legacy_scratch/analyzed/",
                             },
-                            {"operation": "create_directory", "target": "_legacy_scratch/archive/"},
+                            {
+                                "operation": "create_directory",
+                                "target": "_legacy_scratch/archive/",
+                            },
                         ],
                         validation={"check": "scratch_structure"},
                     )
@@ -916,7 +937,9 @@ class Executor:
         result = {"executed": [], "failed": []}
 
         for i, step in enumerate(phase.steps):
-            step_desc = f"  [{i+1}/{len(phase.steps)}] {step.get('operation', 'unknown')}"
+            step_desc = (
+                f"  [{i+1}/{len(phase.steps)}] {step.get('operation', 'unknown')}"
+            )
 
             if self.dry_run:
                 print(f"{step_desc} â†’ æ¨¡æ“¬å®Œæˆ")
@@ -1050,7 +1073,9 @@ class Executor:
 
                     for old_pattern, new_pattern in patterns:
                         if old_pattern in updated_content:
-                            updated_content = updated_content.replace(old_pattern, new_pattern)
+                            updated_content = updated_content.replace(
+                                old_pattern, new_pattern
+                            )
                             has_changes = True
 
                 # å¦‚æœæœ‰è®Šæ›´ï¼Œå¯«å›æ–‡ä»¶
@@ -1136,7 +1161,9 @@ class Validator:
                     if ref.startswith(("./", "../")) and not ref.startswith("http"):
                         ref_path = file.parent / ref
                         if not ref_path.exists():
-                            errors.append(f"{file.relative_to(self.target)}: æ–·é–‹çš„å¼•ç”¨ {ref}")
+                            errors.append(
+                                f"{file.relative_to(self.target)}: æ–·é–‹çš„å¼•ç”¨ {ref}"
+                            )
             except BaseException:
                 pass
 
@@ -1275,7 +1302,10 @@ def main():
     plan_parser.add_argument("--target", required=True, help="ç›®æ¨™ç›®éŒ„")
     plan_parser.add_argument("--output", required=True, help="è¨ˆç•«è¼¸å‡ºè·¯å¾‘")
     plan_parser.add_argument(
-        "--priority", default="all", choices=["P1", "P2", "P3", "all"], help="å„ªå…ˆç´šç¯©é¸"
+        "--priority",
+        default="all",
+        choices=["P1", "P2", "P3", "all"],
+        help="å„ªå…ˆç´šç¯©é¸",
     )
 
     # execute å‘½ä»¤
@@ -1318,7 +1348,9 @@ def main():
         if args.format == "md":
             output = report_gen.generate_markdown()
         elif args.format == "json":
-            output = json.dumps(report_gen.generate_yaml(), indent=2, ensure_ascii=False)
+            output = json.dumps(
+                report_gen.generate_yaml(), indent=2, ensure_ascii=False
+            )
         else:
             output = yaml.dump(
                 report_gen.generate_yaml(),
@@ -1343,7 +1375,13 @@ def main():
 
         plan_dict = asdict(plan)
         with open(args.output, "w", encoding="utf-8") as f:
-            yaml.dump(plan_dict, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
+            yaml.dump(
+                plan_dict,
+                f,
+                allow_unicode=True,
+                default_flow_style=False,
+                sort_keys=False,
+            )
 
         print(f"\nâœ… è¨ˆç•«å·²ç”Ÿæˆ: {args.output}")
         print(f"   éšæ®µæ•¸: {len(plan.phases)}")
@@ -1404,7 +1442,9 @@ def main():
         print(f"ğŸ”„ å›æ»¾åˆ°æª¢æŸ¥é»: {args.checkpoint}")
 
         # ç¢ºå®šç›®æ¨™ç›®éŒ„
-        target_dir = Path(args.target) if args.target else Path("docs/refactor_playbooks")
+        target_dir = (
+            Path(args.target) if args.target else Path("docs/refactor_playbooks")
+        )
         backup_base = target_dir / ".refactor_backup"
 
         if not backup_base.exists():
@@ -1414,7 +1454,9 @@ def main():
         # æ‰¾åˆ°æª¢æŸ¥é»
         if args.checkpoint == "latest":
             # æ‰¾æœ€æ–°çš„å‚™ä»½
-            checkpoints = sorted([d for d in backup_base.iterdir() if d.is_dir()], reverse=True)
+            checkpoints = sorted(
+                [d for d in backup_base.iterdir() if d.is_dir()], reverse=True
+            )
             if not checkpoints:
                 print("âŒ éŒ¯èª¤: æ²’æœ‰å¯ç”¨çš„æª¢æŸ¥é»")
                 sys.exit(1)
diff --git a/workspace/tools/refactor/refactor_evolution_workflow.py b/workspace/tools/refactor/refactor_evolution_workflow.py
index 0d546d3..c7e193b 100755
--- a/workspace/tools/refactor/refactor_evolution_workflow.py
+++ b/workspace/tools/refactor/refactor_evolution_workflow.py
@@ -163,14 +163,18 @@ class RefactorEvolutionWorkflow:
         for dir_key in ["reports_dir", "plans_dir", "logs_dir", "backup_dir"]:
             dir_path = Path(self.config["output"].get(dir_key, ""))
             if dir_path:
-                dir_path = BASE_PATH / dir_path if not dir_path.is_absolute() else dir_path
+                dir_path = (
+                    BASE_PATH / dir_path if not dir_path.is_absolute() else dir_path
+                )
                 dir_path.mkdir(parents=True, exist_ok=True)
 
     def _initialize_engines(self):
         """Initialize refactor and evolution engines"""
         try:
             # Check refactor engine exists
-            refactor_engine_path = BASE_PATH / self.config["engines"]["refactor_engine"]["path"]
+            refactor_engine_path = (
+                BASE_PATH / self.config["engines"]["refactor_engine"]["path"]
+            )
             if not refactor_engine_path.exists():
                 print(f"âŒ Refactor engine not found: {refactor_engine_path}")
                 return False
@@ -179,7 +183,9 @@ class RefactorEvolutionWorkflow:
             print("âœ… Refactor engine found")
 
             # Check evolution engine exists
-            evolution_engine_path = BASE_PATH / self.config["engines"]["evolution_engine"]["path"]
+            evolution_engine_path = (
+                BASE_PATH / self.config["engines"]["evolution_engine"]["path"]
+            )
             if not evolution_engine_path.exists():
                 print(f"âš ï¸  Evolution engine not found: {evolution_engine_path}")
                 self.evolution_engine = None
@@ -242,7 +248,10 @@ class RefactorEvolutionWorkflow:
         try:
             if check == "git_status_clean":
                 result = subprocess.run(
-                    ["git", "status", "--porcelain"], cwd=BASE_PATH, capture_output=True, text=True
+                    ["git", "status", "--porcelain"],
+                    cwd=BASE_PATH,
+                    capture_output=True,
+                    text=True,
                 )
                 return len(result.stdout.strip()) == 0
 
@@ -269,7 +278,9 @@ class RefactorEvolutionWorkflow:
                 # Basic syntax check for Python files
                 py_files = [str(p) for p in BASE_PATH.glob("**/*.py")]
                 result = subprocess.run(
-                    ["python", "-m", "py_compile"] + py_files, cwd=BASE_PATH, capture_output=True
+                    ["python", "-m", "py_compile"] + py_files,
+                    cwd=BASE_PATH,
+                    capture_output=True,
                 )
                 return result.returncode == 0
 
@@ -329,7 +340,11 @@ class RefactorEvolutionWorkflow:
             traceback.print_exc()
 
             return PhaseResult(
-                phase=phase, success=False, duration_seconds=duration, output={}, error=str(e)
+                phase=phase,
+                success=False,
+                duration_seconds=duration,
+                output={},
+                error=str(e),
             )
 
     async def _run_analysis_phase(self) -> Dict[str, Any]:
@@ -382,7 +397,9 @@ class RefactorEvolutionWorkflow:
             "metrics": self._extract_analysis_metrics(results),
         }
 
-    def _analyze_target(self, target_path: Path, focus_areas: List[str]) -> Dict[str, Any]:
+    def _analyze_target(
+        self, target_path: Path, focus_areas: List[str]
+    ) -> Dict[str, Any]:
         """Analyze a specific target directory"""
         analysis = {
             "path": str(target_path),
@@ -411,7 +428,9 @@ class RefactorEvolutionWorkflow:
 
             # Simple structure analysis
             subdirs = [
-                d for d in target_path.iterdir() if d.is_dir() and not d.name.startswith(".")
+                d
+                for d in target_path.iterdir()
+                if d.is_dir() and not d.name.startswith(".")
             ]
             analysis["subdirectories"] = len(subdirs)
 
@@ -429,7 +448,9 @@ class RefactorEvolutionWorkflow:
                         "High number of subdirectories - consider consolidation"
                     )
                 if analysis["file_counts"]["total"] > max_threshold:
-                    analysis["issues"].append("Large number of files - consider modularization")
+                    analysis["issues"].append(
+                        "Large number of files - consider modularization"
+                    )
 
             if "organization" in focus_areas:
                 has_init = (target_path / "__init__.py").exists()
@@ -437,13 +458,17 @@ class RefactorEvolutionWorkflow:
                 if not has_init and analysis["file_counts"]["python"] > 0:
                     analysis["issues"].append("Missing __init__.py for Python package")
                 if not has_readme:
-                    analysis["recommendations"].append("Add README.md for documentation")
+                    analysis["recommendations"].append(
+                        "Add README.md for documentation"
+                    )
 
         return analysis
 
     def _summarize_analysis(self, results: List[Dict]) -> Dict[str, Any]:
         """Create summary of analysis results"""
-        total_issues = sum(len(r.get("analysis", {}).get("issues", [])) for r in results)
+        total_issues = sum(
+            len(r.get("analysis", {}).get("issues", [])) for r in results
+        )
         total_recommendations = sum(
             len(r.get("analysis", {}).get("recommendations", [])) for r in results
         )
@@ -460,9 +485,12 @@ class RefactorEvolutionWorkflow:
         return {
             "targets_analyzed": len(results),
             "total_files": sum(
-                r.get("analysis", {}).get("file_counts", {}).get("total", 0) for r in results
+                r.get("analysis", {}).get("file_counts", {}).get("total", 0)
+                for r in results
+            ),
+            "total_issues": sum(
+                len(r.get("analysis", {}).get("issues", [])) for r in results
             ),
-            "total_issues": sum(len(r.get("analysis", {}).get("issues", [])) for r in results),
         }
 
     async def _run_planning_phase(self) -> Dict[str, Any]:
@@ -551,14 +579,20 @@ class RefactorEvolutionWorkflow:
 
         # Collect learning data
         learning_data = {
-            "execution_results": [r for r in self.results if r.phase == WorkflowPhase.EXECUTION],
+            "execution_results": [
+                r for r in self.results if r.phase == WorkflowPhase.EXECUTION
+            ],
             "metrics": {
                 "total_phases": len(self.results),
                 "successful_phases": len([r for r in self.results if r.success]),
             },
         }
 
-        return {"success": True, "insights_collected": 0, "metrics": learning_data["metrics"]}
+        return {
+            "success": True,
+            "insights_collected": 0,
+            "metrics": learning_data["metrics"],
+        }
 
     async def _run_evolution_phase(self) -> Dict[str, Any]:
         """Run evolution phase to identify improvements"""
@@ -655,7 +689,9 @@ class RefactorEvolutionWorkflow:
                     WorkflowPhase.ANALYSIS,
                     WorkflowPhase.VALIDATION,
                 ]:
-                    print(f"\nâŒ Critical phase {phase.value} failed, aborting workflow")
+                    print(
+                        f"\nâŒ Critical phase {phase.value} failed, aborting workflow"
+                    )
                     self.state.status = WorkflowStatus.FAILED
                     self.state.error = f"Phase {phase.value} failed"
                     break
@@ -663,7 +699,9 @@ class RefactorEvolutionWorkflow:
         # Finalize
         self.state.end_time = datetime.now()
         self.state.status = (
-            WorkflowStatus.COMPLETED if not self.state.failed_phases else WorkflowStatus.FAILED
+            WorkflowStatus.COMPLETED
+            if not self.state.failed_phases
+            else WorkflowStatus.FAILED
         )
         self.state.current_phase = None
 
@@ -675,10 +713,14 @@ class RefactorEvolutionWorkflow:
             f"{'âœ…' if self.state.status == WorkflowStatus.COMPLETED else 'âŒ'} Workflow {self.state.status.value}"
         )
         print(f"{'='*70}")
-        print(f"Duration: {(self.state.end_time - self.state.start_time).total_seconds():.2f}s")
+        print(
+            f"Duration: {(self.state.end_time - self.state.start_time).total_seconds():.2f}s"
+        )
         print(f"Phases completed: {len(self.state.completed_phases)}/{len(phases)}")
         if self.state.failed_phases:
-            print(f"Phases failed: {', '.join(p.value for p in self.state.failed_phases)}")
+            print(
+                f"Phases failed: {', '.join(p.value for p in self.state.failed_phases)}"
+            )
         print()
 
         return {
@@ -693,7 +735,9 @@ class RefactorEvolutionWorkflow:
         report = {
             "workflow_id": self.state.workflow_id,
             "status": self.state.status.value,
-            "duration_seconds": (self.state.end_time - self.state.start_time).total_seconds(),
+            "duration_seconds": (
+                self.state.end_time - self.state.start_time
+            ).total_seconds(),
             "phases": {
                 "total": len(self.results),
                 "completed": len(self.state.completed_phases),
@@ -710,9 +754,13 @@ class RefactorEvolutionWorkflow:
                 for r in self.results
             ],
             "summary": {
-                "total_duration": (self.state.end_time - self.state.start_time).total_seconds(),
+                "total_duration": (
+                    self.state.end_time - self.state.start_time
+                ).total_seconds(),
                 "success_rate": (
-                    len(self.state.completed_phases) / len(self.results) if self.results else 0
+                    len(self.state.completed_phases) / len(self.results)
+                    if self.results
+                    else 0
                 ),
             },
         }
@@ -790,7 +838,9 @@ Examples:
         return
 
     # Initialize workflow
-    config_path = Path(args.config) if hasattr(args, "config") and args.config else CONFIG_PATH
+    config_path = (
+        Path(args.config) if hasattr(args, "config") and args.config else CONFIG_PATH
+    )
     workflow = RefactorEvolutionWorkflow(config_path)
 
     # Execute command
diff --git a/workspace/tools/refactor/update_indexes.py b/workspace/tools/refactor/update_indexes.py
index 798764c..2f742dd 100644
--- a/workspace/tools/refactor/update_indexes.py
+++ b/workspace/tools/refactor/update_indexes.py
@@ -131,7 +131,9 @@ class IndexScanner:
         for subdir in refactor_path.iterdir():
             if subdir.is_dir() and not subdir.name.startswith(("_", ".")):
                 # æª¢æŸ¥æ˜¯å¦å·²æœ‰ playbook
-                existing = next((c for c in clusters if subdir.name in c.playbook_path), None)
+                existing = next(
+                    (c for c in clusters if subdir.name in c.playbook_path), None
+                )
                 if not existing:
                     clusters.append(
                         ClusterEntry(
@@ -215,7 +217,9 @@ class IndexScanner:
                 priority = "P3"
 
             return ClusterEntry(
-                cluster_id=pb_file.stem.replace("__playbook", "").replace("_playbook", ""),
+                cluster_id=pb_file.stem.replace("__playbook", "").replace(
+                    "_playbook", ""
+                ),
                 name=name,
                 description=description,
                 playbook_path=str(pb_file.relative_to(self.base_path)),
@@ -266,7 +270,11 @@ class IndexScanner:
 
     def _list_files(self, directory: Path) -> List[str]:
         """åˆ—å‡ºç›®éŒ„ä¸­çš„æª”æ¡ˆ"""
-        return [str(f.relative_to(self.base_path)) for f in directory.rglob("*") if f.is_file()]
+        return [
+            str(f.relative_to(self.base_path))
+            for f in directory.rglob("*")
+            if f.is_file()
+        ]
 
 
 # ============================================================================
@@ -338,9 +346,11 @@ class IndexGenerator:
                 )
                 lines.append("")
                 for c in by_priority[priority]:
-                    status_emoji = {"pending": "â³", "active": "ğŸ”„", "completed": "âœ…"}.get(
-                        c.status, "â“"
-                    )
+                    status_emoji = {
+                        "pending": "â³",
+                        "active": "ğŸ”„",
+                        "completed": "âœ…",
+                    }.get(c.status, "â“")
                     if c.playbook_path != "_pending":
                         lines.append(f"- [{c.name}]({c.playbook_path}) {status_emoji}")
                     else:
@@ -442,7 +452,9 @@ class IndexVerifier:
         # é©—è­‰ legacy_assets_index.yaml
         legacy_result = self._verify_legacy_index()
         errors.extend(legacy_result.get("errors", []))
-        sync_status["legacy_assets_index.yaml"] = len(legacy_result.get("errors", [])) == 0
+        sync_status["legacy_assets_index.yaml"] = (
+            len(legacy_result.get("errors", [])) == 0
+        )
 
         # æª¢æŸ¥å­¤ç«‹æª”æ¡ˆ
         orphan_files = self._find_orphan_files()
@@ -610,7 +622,11 @@ class IndexUpdater:
             INDEX_YAML_PATH.parent.mkdir(parents=True, exist_ok=True)
             with open(INDEX_YAML_PATH, "w", encoding="utf-8") as f:
                 yaml.dump(
-                    index_data, f, allow_unicode=True, default_flow_style=False, sort_keys=False
+                    index_data,
+                    f,
+                    allow_unicode=True,
+                    default_flow_style=False,
+                    sort_keys=False,
                 )
 
             print(f"   âœ“ å·²æ›´æ–° ({len(clusters)} å¢é›†)")
@@ -650,7 +666,11 @@ class IndexUpdater:
             LEGACY_INDEX_PATH.parent.mkdir(parents=True, exist_ok=True)
             with open(LEGACY_INDEX_PATH, "w", encoding="utf-8") as f:
                 yaml.dump(
-                    index_data, f, allow_unicode=True, default_flow_style=False, sort_keys=False
+                    index_data,
+                    f,
+                    allow_unicode=True,
+                    default_flow_style=False,
+                    sort_keys=False,
                 )
 
             print(f"   âœ“ å·²æ›´æ–° ({len(assets)} è³‡ç”¢)")
@@ -689,7 +709,9 @@ def main():
     human_parser = subparsers.add_parser("human", help="æ›´æ–° INDEX.md")
 
     # legacy å‘½ä»¤
-    legacy_parser = subparsers.add_parser("legacy", help="æ›´æ–° legacy_assets_index.yaml")
+    legacy_parser = subparsers.add_parser(
+        "legacy", help="æ›´æ–° legacy_assets_index.yaml"
+    )
 
     # verify å‘½ä»¤
     verify_parser = subparsers.add_parser("verify", help="é©—è­‰ç´¢å¼•")
diff --git a/workspace/tools/refactor/validate-phase1.py b/workspace/tools/refactor/validate-phase1.py
index cf683ae..5fb3072 100755
--- a/workspace/tools/refactor/validate-phase1.py
+++ b/workspace/tools/refactor/validate-phase1.py
@@ -65,7 +65,9 @@ class Phase1Validator:
 
         # Check directory exists
         if not self.deliverables_path.exists():
-            self.errors.append(f"Deliverables directory not found: {self.deliverables_path}")
+            self.errors.append(
+                f"Deliverables directory not found: {self.deliverables_path}"
+            )
             return False, self._get_report()
 
         # Validate each deliverable
@@ -188,11 +190,17 @@ class Phase1Validator:
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Validate Phase 1 (Deconstruction) deliverables")
+    parser = argparse.ArgumentParser(
+        description="Validate Phase 1 (Deconstruction) deliverables"
+    )
+    parser.add_argument(
+        "--deliverables-path",
+        required=True,
+        help="Path to Phase 1 deliverables directory",
+    )
     parser.add_argument(
-        "--deliverables-path", required=True, help="Path to Phase 1 deliverables directory"
+        "--output", help="Output validation report to file (JSON format)"
     )
-    parser.add_argument("--output", help="Output validation report to file (JSON format)")
 
     args = parser.parse_args()
 
diff --git a/workspace/tools/refactor/validate-phase2.py b/workspace/tools/refactor/validate-phase2.py
index e49d8e3..b9df8bd 100755
--- a/workspace/tools/refactor/validate-phase2.py
+++ b/workspace/tools/refactor/validate-phase2.py
@@ -62,7 +62,9 @@ class Phase2Validator:
 
         # Check directory exists
         if not self.deliverables_path.exists():
-            self.errors.append(f"Deliverables directory not found: {self.deliverables_path}")
+            self.errors.append(
+                f"Deliverables directory not found: {self.deliverables_path}"
+            )
             return False, self._get_report()
 
         # Validate each deliverable
@@ -139,7 +141,9 @@ class Phase2Validator:
         required_sections = spec.get("required_sections", [])
         for section in required_sections:
             if section.lower() not in content.lower():
-                self.warnings.append(f"{filepath.name}: Missing recommended section: {section}")
+                self.warnings.append(
+                    f"{filepath.name}: Missing recommended section: {section}"
+                )
 
     def _check_integration_tests(self):
         """Check for integration test suites."""
@@ -195,11 +199,17 @@ class Phase2Validator:
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Validate Phase 2 (Integration) deliverables")
+    parser = argparse.ArgumentParser(
+        description="Validate Phase 2 (Integration) deliverables"
+    )
+    parser.add_argument(
+        "--deliverables-path",
+        required=True,
+        help="Path to Phase 2 deliverables directory",
+    )
     parser.add_argument(
-        "--deliverables-path", required=True, help="Path to Phase 2 deliverables directory"
+        "--output", help="Output validation report to file (JSON format)"
     )
-    parser.add_argument("--output", help="Output validation report to file (JSON format)")
 
     args = parser.parse_args()
 
diff --git a/workspace/tools/refactor/validate-phase3.py b/workspace/tools/refactor/validate-phase3.py
index 84cf3af..adc3c6e 100755
--- a/workspace/tools/refactor/validate-phase3.py
+++ b/workspace/tools/refactor/validate-phase3.py
@@ -61,7 +61,9 @@ class Phase3Validator:
 
         # Check directory exists
         if not self.deliverables_path.exists():
-            self.errors.append(f"Deliverables directory not found: {self.deliverables_path}")
+            self.errors.append(
+                f"Deliverables directory not found: {self.deliverables_path}"
+            )
             return False, self._get_report()
 
         # Validate each deliverable
@@ -165,7 +167,9 @@ class Phase3Validator:
         print("ğŸ” Checking architecture compliance...")
 
         # Look for architecture validation config
-        arch_config = self.repo_root / "controlplane" / "config" / "architecture-rules.yaml"
+        arch_config = (
+            self.repo_root / "controlplane" / "config" / "architecture-rules.yaml"
+        )
 
         if not arch_config.exists():
             self.warnings.append("Architecture rules config not found")
@@ -229,7 +233,9 @@ class Phase3Validator:
             if len(self.warnings) == 0:
                 print("âœ… Phase 3 validation PASSED - Ready for deployment")
             else:
-                print("âš ï¸  Phase 3 validation PASSED with warnings - Review before deployment")
+                print(
+                    "âš ï¸  Phase 3 validation PASSED with warnings - Review before deployment"
+                )
         else:
             print("âŒ Phase 3 validation FAILED - Address errors before proceeding")
 
@@ -251,11 +257,17 @@ class Phase3Validator:
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Validate Phase 3 (Refactor) deliverables")
+    parser = argparse.ArgumentParser(
+        description="Validate Phase 3 (Refactor) deliverables"
+    )
+    parser.add_argument(
+        "--deliverables-path",
+        required=True,
+        help="Path to Phase 3 deliverables directory",
+    )
     parser.add_argument(
-        "--deliverables-path", required=True, help="Path to Phase 3 deliverables directory"
+        "--output", help="Output validation report to file (JSON format)"
     )
-    parser.add_argument("--output", help="Output validation report to file (JSON format)")
 
     args = parser.parse_args()
 
diff --git a/workspace/tools/refactor/validate_structure.py b/workspace/tools/refactor/validate_structure.py
index e6d2787..2936fff 100644
--- a/workspace/tools/refactor/validate_structure.py
+++ b/workspace/tools/refactor/validate_structure.py
@@ -389,7 +389,9 @@ class ReferenceValidator:
                 new_path = f"{path}.{key}" if path else key
 
                 # æª¢æŸ¥è·¯å¾‘ç›¸é—œçš„éµ
-                if key.endswith(("_path", "_file", "path", "file")) and isinstance(value, str):
+                if key.endswith(("_path", "_file", "path", "file")) and isinstance(
+                    value, str
+                ):
                     if (
                         value
                         and value != "_pending"
@@ -408,11 +410,15 @@ class ReferenceValidator:
                                 )
                             )
 
-                issues.extend(self._check_yaml_paths(value, yaml_file, target_path, new_path))
+                issues.extend(
+                    self._check_yaml_paths(value, yaml_file, target_path, new_path)
+                )
 
         elif isinstance(data, list):
             for i, item in enumerate(data):
-                issues.extend(self._check_yaml_paths(item, yaml_file, target_path, f"{path}[{i}]"))
+                issues.extend(
+                    self._check_yaml_paths(item, yaml_file, target_path, f"{path}[{i}]")
+                )
 
         return issues
 
@@ -651,7 +657,13 @@ class ContentValidator:
         issues = []
 
         for file in target_path.rglob("*"):
-            if file.is_file() and file.suffix in [".md", ".yaml", ".yml", ".json", ".txt"]:
+            if file.is_file() and file.suffix in [
+                ".md",
+                ".yaml",
+                ".yml",
+                ".json",
+                ".txt",
+            ]:
                 try:
                     file.read_text(encoding="utf-8")
                 except UnicodeDecodeError:
@@ -892,9 +904,13 @@ def main():
 
     # full å‘½ä»¤
     full_parser = subparsers.add_parser("full", help="å®Œæ•´é©—è­‰")
-    full_parser.add_argument("--target", "-t", default=str(PLAYBOOKS_PATH), help="ç›®æ¨™ç›®éŒ„")
+    full_parser.add_argument(
+        "--target", "-t", default=str(PLAYBOOKS_PATH), help="ç›®æ¨™ç›®éŒ„"
+    )
     full_parser.add_argument("--output", "-o", help="è¼¸å‡ºå ±å‘Š")
-    full_parser.add_argument("--format", "-f", choices=["md", "yaml", "json"], default="md")
+    full_parser.add_argument(
+        "--format", "-f", choices=["md", "yaml", "json"], default="md"
+    )
 
     # structure å‘½ä»¤
     struct_parser = subparsers.add_parser("structure", help="çµæ§‹é©—è­‰")
@@ -947,10 +963,14 @@ def main():
                 output = report_gen.generate_markdown(result)
             elif args.format == "yaml":
                 output = yaml.dump(
-                    report_gen.generate_yaml(result), allow_unicode=True, default_flow_style=False
+                    report_gen.generate_yaml(result),
+                    allow_unicode=True,
+                    default_flow_style=False,
                 )
             else:
-                output = json.dumps(report_gen.generate_yaml(result), indent=2, ensure_ascii=False)
+                output = json.dumps(
+                    report_gen.generate_yaml(result), indent=2, ensure_ascii=False
+                )
 
             with open(args.output, "w", encoding="utf-8") as f:
                 f.write(output)
@@ -992,7 +1012,9 @@ def main():
             output = report_gen.generate_markdown(result)
         else:
             output = yaml.dump(
-                report_gen.generate_yaml(result), allow_unicode=True, default_flow_style=False
+                report_gen.generate_yaml(result),
+                allow_unicode=True,
+                default_flow_style=False,
             )
 
         with open(args.output, "w", encoding="utf-8") as f:
diff --git a/workspace/tools/root-validator.py b/workspace/tools/root-validator.py
index 4b3c882..c5d061b 100755
--- a/workspace/tools/root-validator.py
+++ b/workspace/tools/root-validator.py
@@ -47,7 +47,9 @@ class RootValidator:
                 "timestamp": datetime.utcnow().isoformat(),
                 "validator_version": "v1.0.0",
                 "root_directory": str(self.root_dir),
-                "schema_version": self.schema.get("metadata", {}).get("version", "unknown"),
+                "schema_version": self.schema.get("metadata", {}).get(
+                    "version", "unknown"
+                ),
             },
             "file_results": [],
             "consistency_results": [],
@@ -64,7 +66,10 @@ class RootValidator:
         logging.basicConfig(
             level=logging.INFO,
             format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
-            handlers=[logging.FileHandler(log_dir / "root-validator.log"), logging.StreamHandler()],
+            handlers=[
+                logging.FileHandler(log_dir / "root-validator.log"),
+                logging.StreamHandler(),
+            ],
         )
         self.logger = logging.getLogger("RootValidator")
 
@@ -85,7 +90,9 @@ class RootValidator:
         self.logger.info("Stage 1: File existence check")
 
         required_files = []
-        for category, files in self.schema.get("spec", {}).get("root_file_types", {}).items():
+        for category, files in (
+            self.schema.get("spec", {}).get("root_file_types", {}).items()
+        ):
             required_files.extend(files)
 
         results = []
@@ -163,7 +170,9 @@ class RootValidator:
                 }
 
             # Check required universal metadata
-            universal_metadata = self.schema.get("spec", {}).get("universal_metadata", {})
+            universal_metadata = self.schema.get("spec", {}).get(
+                "universal_metadata", {}
+            )
             required_fields = universal_metadata.get("required_fields", [])
 
             for field in required_fields:
@@ -263,7 +272,9 @@ class RootValidator:
 
         return results
 
-    def check_circular_dependencies(self, dependency_graph: Dict[str, List[str]]) -> Dict[str, Any]:
+    def check_circular_dependencies(
+        self, dependency_graph: Dict[str, List[str]]
+    ) -> Dict[str, Any]:
         """Check for circular dependencies using DFS"""
 
         def dfs(node, visited, rec_stack):
@@ -366,7 +377,9 @@ class RootValidator:
                 hash_lock["files"][file_pattern] = {
                     "hash": file_hash,
                     "size": file_path.stat().st_size,
-                    "modified": datetime.fromtimestamp(file_path.stat().st_mtime).isoformat(),
+                    "modified": datetime.fromtimestamp(
+                        file_path.stat().st_mtime
+                    ).isoformat(),
                 }
 
         return hash_lock
@@ -380,7 +393,10 @@ class RootValidator:
             "files_failed": self.stats["failed_files"],
             "total_errors": self.stats["errors"],
             "total_warnings": self.stats["warnings"],
-            "success_rate": (self.stats["passed_files"] / max(self.stats["total_files"], 1)) * 100,
+            "success_rate": (
+                self.stats["passed_files"] / max(self.stats["total_files"], 1)
+            )
+            * 100,
             "overall_status": "PASSED" if self.stats["errors"] == 0 else "FAILED",
         }
 
@@ -438,7 +454,9 @@ class RootValidator:
 
 
 def main():
-    parser = argparse.ArgumentParser(description="MachineNativeOps Root Layer Validator")
+    parser = argparse.ArgumentParser(
+        description="MachineNativeOps Root Layer Validator"
+    )
     parser.add_argument("--root-dir", default=".", help="Root directory to validate")
     parser.add_argument("--verbose", "-v", action="store_true", help="Verbose logging")
 
@@ -471,7 +489,9 @@ def main():
     else:
         print(f"\nâœ… All validations passed!")
         if "hash_lock" in results:
-            print(f"ğŸ” Hash lock generated for {len(results['hash_lock']['files'])} files")
+            print(
+                f"ğŸ” Hash lock generated for {len(results['hash_lock']['files'])} files"
+            )
         sys.exit(0)
 
 
diff --git a/workspace/tools/root_schema_gate.py b/workspace/tools/root_schema_gate.py
index e815046..df498a3 100755
--- a/workspace/tools/root_schema_gate.py
+++ b/workspace/tools/root_schema_gate.py
@@ -34,7 +34,9 @@ def main():
         report["result"] = "fail"
         report["errors"].append(str(e))
 
-    report_path.write_text(json.dumps(report, ensure_ascii=False, indent=2), encoding="utf-8")
+    report_path.write_text(
+        json.dumps(report, ensure_ascii=False, indent=2), encoding="utf-8"
+    )
     print(json.dumps(report, ensure_ascii=False, indent=2))
     return 0 if report["result"] == "pass" else 2
 
diff --git a/workspace/tools/rootfs_assembler.py b/workspace/tools/rootfs_assembler.py
index 6aa7f45..59e17f7 100755
--- a/workspace/tools/rootfs_assembler.py
+++ b/workspace/tools/rootfs_assembler.py
@@ -70,7 +70,9 @@ def main():
     # ç”¢å‡º tree/manifestï¼ˆå…ˆä¸ hashï¼Œhash äº¤çµ¦ evidence gateï¼‰
     for p in sorted(rootfs.rglob("*")):
         if p.is_file():
-            manifest.append({"path": str(p.relative_to(rootfs)), "size": p.stat().st_size})
+            manifest.append(
+                {"path": str(p.relative_to(rootfs)), "size": p.stat().st_size}
+            )
 
     (repo / "dist/reports").mkdir(parents=True, exist_ok=True)
     (repo / "dist/reports/rootfs.manifest.json").write_text(
diff --git a/workspace/tools/scan_tech_debt.py b/workspace/tools/scan_tech_debt.py
index 376c384..9d1bb4a 100755
--- a/workspace/tools/scan_tech_debt.py
+++ b/workspace/tools/scan_tech_debt.py
@@ -47,7 +47,17 @@ class TechDebtScanner:
         self.report = DebtReport()
 
         # è¦æƒæçš„æ–‡ä»¶æ“´å±•å
-        self.extensions = {".py", ".js", ".ts", ".tsx", ".jsx", ".yaml", ".yml", ".md", ".sh"}
+        self.extensions = {
+            ".py",
+            ".js",
+            ".ts",
+            ".tsx",
+            ".jsx",
+            ".yaml",
+            ".yml",
+            ".md",
+            ".sh",
+        }
 
         # è¦è·³éçš„ç›®éŒ„
         self.skip_dirs = {
@@ -136,7 +146,14 @@ class TechDebtScanner:
         message_lower = message.lower()
 
         # é«˜å„ªå…ˆç´šé—œéµè©
-        high_keywords = ["security", "critical", "urgent", "bug", "broken", "fix immediately"]
+        high_keywords = [
+            "security",
+            "critical",
+            "urgent",
+            "bug",
+            "broken",
+            "fix immediately",
+        ]
         # ä¸­å„ªå…ˆç´šé—œéµè©
         medium_keywords = ["important", "should", "refactor", "improve"]
 
@@ -159,7 +176,8 @@ class TechDebtScanner:
         for func_name in functions:
             # æŸ¥æ‰¾å‡½æ•¸é«”
             func_pattern = re.compile(
-                rf"def\s+{re.escape(func_name)}\([^)]*\):(.+?)(?=\ndef\s|\nclass\s|\Z)", re.DOTALL
+                rf"def\s+{re.escape(func_name)}\([^)]*\):(.+?)(?=\ndef\s|\nclass\s|\Z)",
+                re.DOTALL,
             )
             match = func_pattern.search(content)
 
@@ -194,14 +212,18 @@ class TechDebtScanner:
             self.report.by_severity[item.severity] += 1
 
             # æŒ‰ç›®éŒ„åˆ†é¡
-            directory = str(Path(item.file_path).parts[0]) if "/" in item.file_path else "root"
+            directory = (
+                str(Path(item.file_path).parts[0]) if "/" in item.file_path else "root"
+            )
             self.report.by_directory[directory] += 1
 
     def generate_report(self) -> Dict:
         """ç”Ÿæˆè©³ç´°å ±å‘Š"""
         # æŒ‰åš´é‡ç¨‹åº¦æ’åº
         high_priority = [item for item in self.report.items if item.severity == "HIGH"]
-        medium_priority = [item for item in self.report.items if item.severity == "MEDIUM"]
+        medium_priority = [
+            item for item in self.report.items if item.severity == "MEDIUM"
+        ]
         low_priority = [item for item in self.report.items if item.severity == "LOW"]
 
         return {
@@ -243,13 +265,23 @@ class TechDebtScanner:
         print(f"ç›®æ¨™æ¸›å°‘è‡³: {self.report.total_items // 2} (-50%)")
 
         print("\næŒ‰é¡å‹åˆ†ä½ˆ:")
-        for debt_type, count in sorted(self.report.by_type.items(), key=lambda x: -x[1]):
-            print(f"  {debt_type:15} {count:4} ({count/self.report.total_items*100:.1f}%)")
+        for debt_type, count in sorted(
+            self.report.by_type.items(), key=lambda x: -x[1]
+        ):
+            print(
+                f"  {debt_type:15} {count:4} ({count/self.report.total_items*100:.1f}%)"
+            )
 
         print("\næŒ‰åš´é‡ç¨‹åº¦åˆ†ä½ˆ:")
-        for severity, count in sorted(self.report.by_severity.items(), key=lambda x: -x[1]):
-            emoji = "ğŸ”´" if severity == "HIGH" else "ğŸŸ¡" if severity == "MEDIUM" else "ğŸŸ¢"
-            print(f"  {emoji} {severity:8} {count:4} ({count/self.report.total_items*100:.1f}%)")
+        for severity, count in sorted(
+            self.report.by_severity.items(), key=lambda x: -x[1]
+        ):
+            emoji = (
+                "ğŸ”´" if severity == "HIGH" else "ğŸŸ¡" if severity == "MEDIUM" else "ğŸŸ¢"
+            )
+            print(
+                f"  {emoji} {severity:8} {count:4} ({count/self.report.total_items*100:.1f}%)"
+            )
 
         print("\næŒ‰ç›®éŒ„åˆ†ä½ˆ (Top 5):")
         top_dirs = sorted(self.report.by_directory.items(), key=lambda x: -x[1])[:5]
diff --git a/workspace/tools/scripts/manage-secret-patterns.py b/workspace/tools/scripts/manage-secret-patterns.py
index df7a24e..deda74b 100755
--- a/workspace/tools/scripts/manage-secret-patterns.py
+++ b/workspace/tools/scripts/manage-secret-patterns.py
@@ -196,7 +196,9 @@ class SecretPatternManager:
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Manage GitHub Secret Scanning custom patterns")
+    parser = argparse.ArgumentParser(
+        description="Manage GitHub Secret Scanning custom patterns"
+    )
     parser.add_argument(
         "action",
         choices=["list", "create", "update", "delete", "deploy", "export", "import"],
@@ -204,7 +206,9 @@ def main():
     )
     parser.add_argument("--org", required=True, help="GitHub organization name")
     parser.add_argument("--token", help="GitHub token (or set GITHUB_TOKEN env var)")
-    parser.add_argument("--pattern-id", type=int, help="Pattern ID for update/delete/get")
+    parser.add_argument(
+        "--pattern-id", type=int, help="Pattern ID for update/delete/get"
+    )
     parser.add_argument("--file", help="File path for export/import")
     parser.add_argument("--name", help="Pattern name for create")
     parser.add_argument("--regex", help="Pattern regex for create")
@@ -215,7 +219,9 @@ def main():
     # Get token from args or environment
     token = args.token or os.getenv("GITHUB_TOKEN")
     if not token:
-        print("âŒ Error: GitHub token required. Set GITHUB_TOKEN env var or use --token")
+        print(
+            "âŒ Error: GitHub token required. Set GITHUB_TOKEN env var or use --token"
+        )
         sys.exit(1)
 
     manager = SecretPatternManager(token)
@@ -229,10 +235,16 @@ def main():
 
         elif args.action == "create":
             if not all([args.name, args.regex, args.secret_type]):
-                print("âŒ Error: --name, --regex, and --secret-type required for create")
+                print(
+                    "âŒ Error: --name, --regex, and --secret-type required for create"
+                )
                 sys.exit(1)
 
-            pattern_data = {"name": args.name, "regex": args.regex, "secret_type": args.secret_type}
+            pattern_data = {
+                "name": args.name,
+                "regex": args.regex,
+                "secret_type": args.secret_type,
+            }
             manager.create_custom_pattern(args.org, pattern_data)
 
         elif args.action == "update":
diff --git a/workspace/tools/scripts/validate_auto_fix_bot_config.py b/workspace/tools/scripts/validate_auto_fix_bot_config.py
index 9a2bb0b..9491aa7 100644
--- a/workspace/tools/scripts/validate_auto_fix_bot_config.py
+++ b/workspace/tools/scripts/validate_auto_fix_bot_config.py
@@ -138,7 +138,14 @@ def validate_fix_rules(fix_rules: List[Dict[str, Any]]) -> List[str]:
     allowed_priorities = ["critical", "high", "medium", "low"]
 
     for i, rule in enumerate(fix_rules):
-        required_fields = ["name", "priority", "enabled", "scope", "triggers", "actions"]
+        required_fields = [
+            "name",
+            "priority",
+            "enabled",
+            "scope",
+            "triggers",
+            "actions",
+        ]
         for field in required_fields:
             if field not in rule:
                 issues.append(f"fix_rules[{i}] ç¼ºå°‘å¿…è¦æ¬„ä½: {field}")
@@ -242,7 +249,9 @@ def main():
         for issue in bot_issues:
             print(f"âŒ {issue}")
         sys.exit(1)
-    print(f"âœ… Bot é…ç½®é©—è­‰é€šé ({len(config.get('bot_config', {}).get('scopes', []))} å€‹ç¯„åœ)")
+    print(
+        f"âœ… Bot é…ç½®é©—è­‰é€šé ({len(config.get('bot_config', {}).get('scopes', []))} å€‹ç¯„åœ)"
+    )
     print()
 
     # é©—è­‰ä¿®å¾©è¦å‰‡
@@ -291,7 +300,9 @@ def main():
     print(f"  âœ… é©—è­‰ç¯„åœ: {len(config.get('bot_config', {}).get('scopes', []))}")
     print(f"  âœ… ä¿®å¾©è¦å‰‡: {len(config.get('fix_rules', []))}")
     print(f"  âœ… Policy Gates: {len(config.get('policy_gates', []))}")
-    print(f"  âœ… è­‰æ“šç”Ÿæˆå™¨: {len(config.get('evidence_generation', {}).get('generators', []))}")
+    print(
+        f"  âœ… è­‰æ“šç”Ÿæˆå™¨: {len(config.get('evidence_generation', {}).get('generators', []))}"
+    )
     print(f"  âœ… é€šçŸ¥é »é“: {len(config.get('notifications', {}).get('channels', {}))}")
     print(f"  âœ… ç›£æ§æŒ‡æ¨™: {len(config.get('monitoring', {}).get('metrics', []))}")
     print("=" * 60)
diff --git a/workspace/tools/scripts/vulnerability-alert-handler.py b/workspace/tools/scripts/vulnerability-alert-handler.py
index 101ffc3..fa62587 100755
--- a/workspace/tools/scripts/vulnerability-alert-handler.py
+++ b/workspace/tools/scripts/vulnerability-alert-handler.py
@@ -91,20 +91,26 @@ class VulnerabilityManager:
                         "vulnerabilities", []
                     )
                     if vulnerabilities:
-                        fixed_version = vulnerabilities[0].get("patched_versions", "N/A")
+                        fixed_version = vulnerabilities[0].get(
+                            "patched_versions", "N/A"
+                        )
 
                     alert = VulnerabilityAlert(
                         id=str(alert_data["number"]),
                         severity=alert_data["security_advisory"]["severity"].lower(),
                         package_name=alert_data["dependency"]["package"]["name"],
-                        affected_version=alert_data["dependency"].get("manifest_path", "N/A"),
+                        affected_version=alert_data["dependency"].get(
+                            "manifest_path", "N/A"
+                        ),
                         fixed_version=fixed_version,
                         cve_id=alert_data["security_advisory"].get("cve_id"),
                         repository=alert_data.get("repository", {}).get(
                             "full_name", f"{self.org}/{repo}"
                         ),
                         created_at=alert_data["created_at"],
-                        manifest_path=alert_data["dependency"].get("manifest_path", "N/A"),
+                        manifest_path=alert_data["dependency"].get(
+                            "manifest_path", "N/A"
+                        ),
                     )
                     alerts.append(alert)
 
@@ -132,7 +138,9 @@ class VulnerabilityManager:
 
             if alert.severity == "critical":
                 categories["critical_immediate"].append(alert)
-            elif alert.severity == "high" or (alert.severity == "moderate" and age_days > 7):
+            elif alert.severity == "high" or (
+                alert.severity == "moderate" and age_days > 7
+            ):
                 categories["high_urgent"].append(alert)
             elif alert.severity in ["moderate", "medium"] or age_days > 30:
                 categories["moderate_scheduled"].append(alert)
@@ -225,15 +233,21 @@ class VulnerabilityManager:
                     "medium": "ğŸŸ¡",
                     "low": "ğŸŸ¢",
                 }
-                report += f"{emoji.get(severity, 'âšª')} **{severity.upper()}**: {count}\n"
+                report += (
+                    f"{emoji.get(severity, 'âšª')} **{severity.upper()}**: {count}\n"
+                )
 
         # å—å½±éŸ¿çš„å¥—ä»¶çµ±è¨ˆ
         package_counts = {}
         for alert in alerts:
-            package_counts[alert.package_name] = package_counts.get(alert.package_name, 0) + 1
+            package_counts[alert.package_name] = (
+                package_counts.get(alert.package_name, 0) + 1
+            )
 
         report += "\n### å—å½±éŸ¿å¥—ä»¶ TOP 10\n\n"
-        sorted_packages = sorted(package_counts.items(), key=lambda x: x[1], reverse=True)[:10]
+        sorted_packages = sorted(
+            package_counts.items(), key=lambda x: x[1], reverse=True
+        )[:10]
         for i, (package, count) in enumerate(sorted_packages, 1):
             report += f"{i}. **{package}**: {count} å€‹æ¼æ´\n"
 
@@ -264,7 +278,9 @@ class VulnerabilityManager:
         high_alerts = [a for a in alerts if a.severity == "high"]
         if high_alerts:
             report += f"### âš ï¸  é«˜å„ªå…ˆç´šé …ç›®ï¼ˆHighï¼‰\n\n"
-            report += f"ç™¼ç¾ {len(high_alerts)} å€‹é«˜åš´é‡åº¦æ¼æ´ï¼Œå»ºè­°åœ¨ 24 å°æ™‚å…§è™•ç†ã€‚\n\n"
+            report += (
+                f"ç™¼ç¾ {len(high_alerts)} å€‹é«˜åš´é‡åº¦æ¼æ´ï¼Œå»ºè­°åœ¨ 24 å°æ™‚å…§è™•ç†ã€‚\n\n"
+            )
 
         # SLA å»ºè­°
         report += "\n## SLA å»ºè­°\n\n"
@@ -282,11 +298,15 @@ class VulnerabilityManager:
     ) -> List[VulnerabilityAlert]:
         """æ ¹æ“šåš´é‡åº¦éæ¿¾å‘Šè­¦"""
         threshold = self.SEVERITY_ORDER.get(min_severity.lower(), 0)
-        return [a for a in alerts if self.SEVERITY_ORDER.get(a.severity, 0) >= threshold]
+        return [
+            a for a in alerts if self.SEVERITY_ORDER.get(a.severity, 0) >= threshold
+        ]
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Vulnerability Alert Handler - ä¼æ¥­ç´šæ¼æ´ç®¡ç†å·¥å…·")
+    parser = argparse.ArgumentParser(
+        description="Vulnerability Alert Handler - ä¼æ¥­ç´šæ¼æ´ç®¡ç†å·¥å…·"
+    )
     parser.add_argument("--token", help="GitHub Token")
     parser.add_argument("--org", required=True, help="Organization name")
     parser.add_argument("--repo", help="Repository name (optional)")
@@ -297,7 +317,10 @@ def main():
         help="Minimum severity to report",
     )
     parser.add_argument(
-        "--output-format", choices=["markdown", "json"], default="markdown", help="Output format"
+        "--output-format",
+        choices=["markdown", "json"],
+        default="markdown",
+        help="Output format",
     )
     parser.add_argument("--output-file", help="Output file path")
 
@@ -320,7 +343,9 @@ def main():
 
     # Filter by severity
     filtered_alerts = vm.filter_by_severity(alerts, args.severity_threshold)
-    print(f"After filtering by {args.severity_threshold}: {len(filtered_alerts)} alerts")
+    print(
+        f"After filtering by {args.severity_threshold}: {len(filtered_alerts)} alerts"
+    )
 
     # Generate output
     if args.output_format == "json":
diff --git a/workspace/tools/semantic-commit-generator.py b/workspace/tools/semantic-commit-generator.py
index 1649821..c88109e 100755
--- a/workspace/tools/semantic-commit-generator.py
+++ b/workspace/tools/semantic-commit-generator.py
@@ -27,11 +27,10 @@ Semantic Commit Message Generator
 import argparse
 import os
 
+from guardrails_client import chat_completion, get_api_key, is_client_available
 from rich import print
 from rich.console import Console
 
-from guardrails_client import chat_completion, get_api_key, is_client_available
-
 console = Console()
 
 
@@ -92,7 +91,9 @@ Generate the commit message:"""
         return commit_msg
 
     except Exception as e:
-        console.print(f"[yellow]AI generation failed: {e}. Using rule-based generation[/yellow]")
+        console.print(
+            f"[yellow]AI generation failed: {e}. Using rule-based generation[/yellow]"
+        )
         return generate_semantic_commit_rules(files, action, reason, violation_type)
 
 
@@ -105,7 +106,10 @@ def generate_semantic_commit_rules(
     commit_type = "fix"
     scope = "governance"
 
-    if "security" in violation_type.lower() or "vulnerability" in violation_type.lower():
+    if (
+        "security" in violation_type.lower()
+        or "vulnerability" in violation_type.lower()
+    ):
         commit_type = "fix"
         scope = "security"
     elif "language" in violation_type.lower() or "governance" in violation_type.lower():
@@ -217,9 +221,13 @@ def validate_commit_message(commit_msg: str) -> bool:
 
 def main():
     parser = argparse.ArgumentParser(description="Generate semantic commit message")
-    parser.add_argument("--files", nargs="+", required=True, help="List of files changed")
     parser.add_argument(
-        "--action", required=True, help="Action taken (e.g., 'removed', 'moved', 'refactored')"
+        "--files", nargs="+", required=True, help="List of files changed"
+    )
+    parser.add_argument(
+        "--action",
+        required=True,
+        help="Action taken (e.g., 'removed', 'moved', 'refactored')",
     )
     parser.add_argument("--reason", required=True, help="Reason for the change")
     parser.add_argument(
@@ -227,8 +235,12 @@ def main():
         required=True,
         help="Type of violation (e.g., 'language-governance', 'security')",
     )
-    parser.add_argument("--use-ai", action="store_true", help="Use AI to generate commit message")
-    parser.add_argument("--api-key", help="OpenAI API key (or use OPENAI_API_KEY env var)")
+    parser.add_argument(
+        "--use-ai", action="store_true", help="Use AI to generate commit message"
+    )
+    parser.add_argument(
+        "--api-key", help="OpenAI API key (or use OPENAI_API_KEY env var)"
+    )
     parser.add_argument("--output", help="Output file for commit message")
 
     args = parser.parse_args()
diff --git a/workspace/tools/subtree_integrate.py b/workspace/tools/subtree_integrate.py
index 5e16ae4..855dd88 100755
--- a/workspace/tools/subtree_integrate.py
+++ b/workspace/tools/subtree_integrate.py
@@ -76,7 +76,10 @@ class SubtreeHelper:
         return repos
 
     def print_repositories(
-        self, core_only: bool = False, repo_name: Optional[str] = None, format: str = "pipe"
+        self,
+        core_only: bool = False,
+        repo_name: Optional[str] = None,
+        format: str = "pipe",
     ):
         """
         Print repositories in specified format
@@ -131,7 +134,10 @@ class SubtreeHelper:
         target_dir = self.repo_root / prefix
         if not target_dir.exists():
             print(f"âŒ Directory not found: {target_dir}", file=sys.stderr)
-            print(f"   Run: ./tools/integrate_repositories.sh --repo {name}", file=sys.stderr)
+            print(
+                f"   Run: ./tools/integrate_repositories.sh --repo {name}",
+                file=sys.stderr,
+            )
             sys.exit(1)
 
         # Build command
@@ -237,7 +243,9 @@ class SubtreeHelper:
                 not_integrated += 1
 
         print("=" * 80)
-        print(f"Total: {len(all_repos)} | Integrated: {integrated} | Pending: {not_integrated}")
+        print(
+            f"Total: {len(all_repos)} | Integrated: {integrated} | Pending: {not_integrated}"
+        )
 
 
 def main():
@@ -252,18 +260,28 @@ def main():
 
     parser.add_argument("--list", action="store_true", help="List repositories")
 
-    parser.add_argument("--core-only", action="store_true", help="Only core repositories")
+    parser.add_argument(
+        "--core-only", action="store_true", help="Only core repositories"
+    )
 
     parser.add_argument("--repo", type=str, help="Specific repository name")
 
     parser.add_argument(
-        "--format", choices=["pipe", "table", "json"], default="pipe", help="Output format"
+        "--format",
+        choices=["pipe", "table", "json"],
+        default="pipe",
+        help="Output format",
     )
 
-    parser.add_argument("--update", type=str, metavar="REPO_NAME", help="Update existing subtree")
+    parser.add_argument(
+        "--update", type=str, metavar="REPO_NAME", help="Update existing subtree"
+    )
 
     parser.add_argument(
-        "--push", type=str, metavar="REPO_NAME", help="Push changes back to source repository"
+        "--push",
+        type=str,
+        metavar="REPO_NAME",
+        help="Push changes back to source repository",
     )
 
     parser.add_argument(
@@ -279,7 +297,9 @@ def main():
 
     # Execute command
     if args.list:
-        helper.print_repositories(core_only=args.core_only, repo_name=args.repo, format=args.format)
+        helper.print_repositories(
+            core_only=args.core_only, repo_name=args.repo, format=args.format
+        )
     elif args.update:
         squash = not args.no_squash
         success = helper.update_subtree(args.update, squash=squash)
diff --git a/workspace/tools/sync_external_repos.py b/workspace/tools/sync_external_repos.py
index 62dde4b..d383ac5 100755
--- a/workspace/tools/sync_external_repos.py
+++ b/workspace/tools/sync_external_repos.py
@@ -132,7 +132,9 @@ class RepoSyncer:
 
         # Target directory
         target_dir = self.external_dir / name
-        temp_dir = Path(f"/tmp/keystone_sync_{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
+        temp_dir = Path(
+            f"/tmp/keystone_sync_{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
+        )
 
         try:
             # Clone repository
@@ -191,7 +193,9 @@ class RepoSyncer:
 
     def _apply_exclusions(self, repo_dir: Path) -> int:
         """Apply exclusion patterns"""
-        exclude_patterns = self.config.get("sync_options", {}).get("exclude_patterns", [])
+        exclude_patterns = self.config.get("sync_options", {}).get(
+            "exclude_patterns", []
+        )
         removed_count = 0
 
         for pattern in exclude_patterns:
@@ -231,7 +235,9 @@ class RepoSyncer:
         with open(metadata_file, "w") as f:
             json.dump(metadata, f, indent=2)
 
-    def sync_all(self, core_only: bool = False, exclude_core: bool = False, dry_run: bool = False):
+    def sync_all(
+        self, core_only: bool = False, exclude_core: bool = False, dry_run: bool = False
+    ):
         """Sync all repositories"""
         log_info("=" * 60)
         log_info("Multi-Repository Sync Tool")
@@ -249,7 +255,9 @@ class RepoSyncer:
         elif exclude_core:
             # Exclude core repositories (for hybrid mode)
             repos_to_sync = self.config.get("sync_repositories", [])
-            log_info(f"Syncing {len(repos_to_sync)} REGULAR repositories (excluding core)")
+            log_info(
+                f"Syncing {len(repos_to_sync)} REGULAR repositories (excluding core)"
+            )
         else:
             core_repos = self.config.get("core_repositories", [])
             sync_repos = self.config.get("sync_repositories", [])
@@ -314,10 +322,14 @@ class RepoSyncer:
         log_info("=" * 60)
 
         if self.stats["success"] > 0:
-            log_success(f"\nâœ¨ {self.stats['success']} repositories synced to: {self.external_dir}")
+            log_success(
+                f"\nâœ¨ {self.stats['success']} repositories synced to: {self.external_dir}"
+            )
             log_info("Next steps:")
             log_info("  1. Review changes: git status")
-            log_info("  2. Commit: git add external/ && git commit -m 'chore: sync external repos'")
+            log_info(
+                "  2. Commit: git add external/ && git commit -m 'chore: sync external repos'"
+            )
             log_info("  3. Push: git push")
 
 
@@ -329,14 +341,18 @@ def main():
         default=Path("config/external_repos.yaml"),
         help="Configuration file path",
     )
-    parser.add_argument("--core-only", action="store_true", help="Sync core repositories only")
+    parser.add_argument(
+        "--core-only", action="store_true", help="Sync core repositories only"
+    )
     parser.add_argument(
         "--exclude-core",
         action="store_true",
         help="Exclude core repositories (sync regular repos only, for hybrid mode)",
     )
     parser.add_argument("--repo", type=str, help="Sync single repository by name")
-    parser.add_argument("--dry-run", action="store_true", help="Dry run mode (no actual changes)")
+    parser.add_argument(
+        "--dry-run", action="store_true", help="Dry run mode (no actual changes)"
+    )
 
     args = parser.parse_args()
 
@@ -348,7 +364,9 @@ def main():
         syncer.sync_single(args.repo, dry_run=args.dry_run)
     else:
         syncer.sync_all(
-            core_only=args.core_only, exclude_core=args.exclude_core, dry_run=args.dry_run
+            core_only=args.core_only,
+            exclude_core=args.exclude_core,
+            dry_run=args.dry_run,
         )
 
 
diff --git a/workspace/tools/utilities/validate_vectors.py b/workspace/tools/utilities/validate_vectors.py
index aad8b36..ef6290a 100755
--- a/workspace/tools/utilities/validate_vectors.py
+++ b/workspace/tools/utilities/validate_vectors.py
@@ -91,16 +91,22 @@ def generate_slsa_evidence(
 
 def main():
     """Main function."""
-    parser = argparse.ArgumentParser(description="Validate test vectors against JSON schema")
+    parser = argparse.ArgumentParser(
+        description="Validate test vectors against JSON schema"
+    )
     parser.add_argument("file_path", type=Path, help="Path to the test vector file")
-    parser.add_argument("--schema", type=Path, required=True, help="Path to JSON schema file")
+    parser.add_argument(
+        "--schema", type=Path, required=True, help="Path to JSON schema file"
+    )
     parser.add_argument(
         "--output-format",
         choices=["slsa", "json", "text"],
         default="text",
         help="Output format (default: text)",
     )
-    parser.add_argument("--evidence-dir", type=Path, help="Directory to store validation evidence")
+    parser.add_argument(
+        "--evidence-dir", type=Path, help="Directory to store validation evidence"
+    )
 
     args = parser.parse_args()
 
diff --git a/workspace/tools/utilities/validate_yaml.py b/workspace/tools/utilities/validate_yaml.py
index d30e509..1873961 100755
--- a/workspace/tools/utilities/validate_yaml.py
+++ b/workspace/tools/utilities/validate_yaml.py
@@ -229,7 +229,9 @@ def main():
                 data = load_yaml(yaml_file)
                 schema = load_json_schema(schema_path)
 
-                schema_ok, schema_msg = validate_against_schema(data, schema, yaml_file.name)
+                schema_ok, schema_msg = validate_against_schema(
+                    data, schema, yaml_file.name
+                )
                 print(f"  {schema_msg}")
 
                 if not schema_ok:
diff --git a/workspace/tools/validate-refactor-index.py b/workspace/tools/validate-refactor-index.py
index a5c160e..9d3f6b8 100755
--- a/workspace/tools/validate-refactor-index.py
+++ b/workspace/tools/validate-refactor-index.py
@@ -37,7 +37,9 @@ class RefactorIndexValidator:
 
     def load_legacy_assets_index(self) -> dict:
         """Load the legacy assets index"""
-        assets_path = self.refactor_root / "01_deconstruction" / "legacy_assets_index.yaml"
+        assets_path = (
+            self.refactor_root / "01_deconstruction" / "legacy_assets_index.yaml"
+        )
         if not assets_path.exists():
             self.errors.append(f"legacy_assets_index.yaml not found at {assets_path}")
             return {}
@@ -45,7 +47,9 @@ class RefactorIndexValidator:
         with open(assets_path, encoding="utf-8") as f:
             return yaml.safe_load(f)
 
-    def validate_file_exists(self, file_path: str, cluster_id: str, field_name: str) -> bool:
+    def validate_file_exists(
+        self, file_path: str, cluster_id: str, field_name: str
+    ) -> bool:
         """Check if a referenced file exists"""
         if not file_path:
             return True  # Empty is okay for optional fields
@@ -55,7 +59,9 @@ class RefactorIndexValidator:
         full_path = (base_path / file_path).resolve()
 
         if not full_path.exists():
-            self.errors.append(f"Cluster '{cluster_id}': {field_name} file not found: {file_path}")
+            self.errors.append(
+                f"Cluster '{cluster_id}': {field_name} file not found: {file_path}"
+            )
             return False
         return True
 
@@ -84,11 +90,15 @@ class RefactorIndexValidator:
         required_fields = ["cluster_id", "domain", "status", "refactor_file"]
         for field in required_fields:
             if field not in cluster or not cluster[field]:
-                self.errors.append(f"Cluster '{cluster_id}': Missing required field '{field}'")
+                self.errors.append(
+                    f"Cluster '{cluster_id}': Missing required field '{field}'"
+                )
                 return False
 
         # Validate file references
-        self.validate_file_exists(cluster.get("refactor_file", ""), cluster_id, "refactor_file")
+        self.validate_file_exists(
+            cluster.get("refactor_file", ""), cluster_id, "refactor_file"
+        )
         self.validate_file_exists(
             cluster.get("deconstruction_file", ""), cluster_id, "deconstruction_file"
         )
@@ -201,7 +211,9 @@ def main():
     """Main entry point"""
     import argparse
 
-    parser = argparse.ArgumentParser(description="Validate refactor playbook index consistency")
+    parser = argparse.ArgumentParser(
+        description="Validate refactor playbook index consistency"
+    )
     parser.add_argument(
         "--repo-root",
         type=Path,
diff --git a/workspace/tools/validate_directory_docs.py b/workspace/tools/validate_directory_docs.py
index e93adff..4fe7144 100755
--- a/workspace/tools/validate_directory_docs.py
+++ b/workspace/tools/validate_directory_docs.py
@@ -124,7 +124,9 @@ class DirectoryDocValidator:
         """æª¢æŸ¥æª”æ¡ˆèªªæ˜æ ¼å¼"""
         # æå–æª”æ¡ˆèªªæ˜ç« ç¯€
         file_section_match = re.search(
-            r"(## æª”æ¡ˆèªªæ˜|## æª”æ¡ˆé€Ÿè¦½ï¼ˆäººè©±ç‰ˆï¼‰)\s*\n(.*?)(?=\n## |$)", content, re.DOTALL
+            r"(## æª”æ¡ˆèªªæ˜|## æª”æ¡ˆé€Ÿè¦½ï¼ˆäººè©±ç‰ˆï¼‰)\s*\n(.*?)(?=\n## |$)",
+            content,
+            re.DOTALL,
         )
 
         if not file_section_match:
@@ -139,7 +141,8 @@ class DirectoryDocValidator:
         for file_name in file_entries:
             # æª¢æŸ¥æ˜¯å¦æœ‰è·è²¬ã€åŠŸèƒ½ã€ä¾è³´ä¸‰é …
             file_desc_pattern = re.compile(
-                rf"### {re.escape(file_name)}\s*\n" r"(.*?)(?=\n### |\n## |$)", re.DOTALL
+                rf"### {re.escape(file_name)}\s*\n" r"(.*?)(?=\n### |\n## |$)",
+                re.DOTALL,
             )
 
             match = file_desc_pattern.search(file_section)
@@ -173,7 +176,9 @@ class DirectoryDocValidator:
             actual_files = [
                 f.name
                 for f in dir_path.iterdir()
-                if f.is_file() and f.name != "DIRECTORY.md" and not f.name.startswith(".")
+                if f.is_file()
+                and f.name != "DIRECTORY.md"
+                and not f.name.startswith(".")
             ]
 
             documented_files = set(file_entries)
@@ -183,10 +188,14 @@ class DirectoryDocValidator:
             extra = documented_files - actual_files_set
 
             if missing:
-                result["warnings"].append(f'ä»¥ä¸‹æª”æ¡ˆæœªåœ¨æ–‡æª”ä¸­èªªæ˜: {", ".join(missing)}')
+                result["warnings"].append(
+                    f'ä»¥ä¸‹æª”æ¡ˆæœªåœ¨æ–‡æª”ä¸­èªªæ˜: {", ".join(missing)}'
+                )
 
             if extra:
-                result["warnings"].append(f'æ–‡æª”ä¸­èªªæ˜äº†ä¸å­˜åœ¨çš„æª”æ¡ˆ: {", ".join(extra)}')
+                result["warnings"].append(
+                    f'æ–‡æª”ä¸­èªªæ˜äº†ä¸å­˜åœ¨çš„æª”æ¡ˆ: {", ".join(extra)}'
+                )
         except Exception as e:
             result["warnings"].append(f"ç„¡æ³•æª¢æŸ¥å¯¦éš›æª”æ¡ˆ: {str(e)}")
 
@@ -209,7 +218,10 @@ class DirectoryDocValidator:
 
                 if match:
                     section_content = match.group(1).strip()
-                    if not section_content or len(section_content) < MIN_SECTION_CONTENT_LENGTH:
+                    if (
+                        not section_content
+                        or len(section_content) < MIN_SECTION_CONTENT_LENGTH
+                    ):
                         result["warnings"].append(f"ç« ç¯€ {section} å…§å®¹éå°‘æˆ–ç‚ºç©º")
 
     def check_markdown_format(self, content: str, result: Dict):
@@ -319,7 +331,9 @@ class DirectoryDocValidator:
             for error in all_errors:
                 error_counts[error] = error_counts.get(error, 0) + 1
 
-            for error, count in sorted(error_counts.items(), key=lambda x: x[1], reverse=True)[:5]:
+            for error, count in sorted(
+                error_counts.items(), key=lambda x: x[1], reverse=True
+            )[:5]:
                 report += f"- {error} ({count}æ¬¡)\n"
 
         if all_warnings:
@@ -328,9 +342,9 @@ class DirectoryDocValidator:
             for warning in all_warnings:
                 warning_counts[warning] = warning_counts.get(warning, 0) + 1
 
-            for warning, count in sorted(warning_counts.items(), key=lambda x: x[1], reverse=True)[
-                :5
-            ]:
+            for warning, count in sorted(
+                warning_counts.items(), key=lambda x: x[1], reverse=True
+            )[:5]:
                 report += f"- {warning} ({count}æ¬¡)\n"
 
         return report
diff --git a/workspace/tools/validate_restructure.py b/workspace/tools/validate_restructure.py
index 6514afd..36ccac9 100755
--- a/workspace/tools/validate_restructure.py
+++ b/workspace/tools/validate_restructure.py
@@ -25,7 +25,9 @@ from pathlib import Path
 from typing import Dict, List, Optional, Set, Tuple
 
 # è¨­ç½®æ—¥èªŒ
-logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
+logging.basicConfig(
+    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
+)
 logger = logging.getLogger(__name__)
 
 
@@ -126,10 +128,21 @@ class RestructureValidator:
                         "search_engine",
                         "data_pipeline",
                     ],
-                    "monitoring": ["metrics", "logging", "tracing", "alerting", "dashboard"],
+                    "monitoring": [
+                        "metrics",
+                        "logging",
+                        "tracing",
+                        "alerting",
+                        "dashboard",
+                    ],
                 },
                 "shared": {
-                    "types": ["common_types", "api_types", "domain_types", "event_types"],
+                    "types": [
+                        "common_types",
+                        "api_types",
+                        "domain_types",
+                        "event_types",
+                    ],
                     "utils": [
                         "helpers",
                         "validators",
@@ -166,10 +179,19 @@ class RestructureValidator:
                     "ci-error-handler",
                     "drone-config",
                 ],
-                "deployment": ["docker-compose", "dockerfile", "nginx", "deployment-pipelines"],
+                "deployment": [
+                    "docker-compose",
+                    "dockerfile",
+                    "nginx",
+                    "deployment-pipelines",
+                ],
                 "monitoring": ["prometheus", "grafana", "alerting", "dashboards"],
                 "environments": ["env-files", "environment-configs", "secrets"],
-                "security": ["security-policies", "safety-mechanisms", "access-control"],
+                "security": [
+                    "security-policies",
+                    "safety-mechanisms",
+                    "access-control",
+                ],
                 "build-tools": [
                     "eslint",
                     "jest",
@@ -253,7 +275,12 @@ class RestructureValidator:
         """é©—è­‰æ–‡ä»¶å®Œæ•´æ€§"""
         logger.info("ğŸ“ é©—è­‰æ–‡ä»¶å®Œæ•´æ€§...")
 
-        result = {"valid": True, "missing_files": [], "empty_files": [], "total_files": 0}
+        result = {
+            "valid": True,
+            "missing_files": [],
+            "empty_files": [],
+            "total_files": 0,
+        }
 
         # æª¢æŸ¥é—œéµæ–‡ä»¶
         critical_files = [
@@ -295,7 +322,12 @@ class RestructureValidator:
         """é©—è­‰ Python å°å…¥è·¯å¾‘"""
         logger.info("ğŸ”— é©—è­‰å°å…¥è·¯å¾‘...")
 
-        result = {"valid": True, "broken_imports": [], "fixed_imports": [], "files_checked": 0}
+        result = {
+            "valid": True,
+            "broken_imports": [],
+            "fixed_imports": [],
+            "files_checked": 0,
+        }
 
         # æƒææ‰€æœ‰ Python æ–‡ä»¶
         for py_file in self.project_root.rglob("*.py"):
@@ -356,7 +388,9 @@ class RestructureValidator:
                         old_path.replace("/", "."), new_path.replace("/", ".")
                     )
                     self._fix_import_in_file(file_path, module_name, new_module)
-                    result["fixed_imports"].append(f"{file_path}: {module_name} -> {new_module}")
+                    result["fixed_imports"].append(
+                        f"{file_path}: {module_name} -> {new_module}"
+                    )
 
     def _fix_import_in_file(self, file_path: Path, old_import: str, new_import: str):
         """ä¿®å¾©æ–‡ä»¶ä¸­çš„å°å…¥"""
@@ -411,7 +445,9 @@ class RestructureValidator:
 
                 for key in check["required_keys"]:
                     if key not in config:
-                        result["invalid_configs"].append(f"{check['path']}: ç¼ºå°‘éµ '{key}'")
+                        result["invalid_configs"].append(
+                            f"{check['path']}: ç¼ºå°‘éµ '{key}'"
+                        )
                         result["valid"] = False
 
             except Exception as e:
diff --git a/workspace/tools/validation/adaptive_decision_engine.py b/workspace/tools/validation/adaptive_decision_engine.py
index 20db776..12e20bb 100644
--- a/workspace/tools/validation/adaptive_decision_engine.py
+++ b/workspace/tools/validation/adaptive_decision_engine.py
@@ -138,7 +138,9 @@ class DynamicPolicyController:
             ),
         }
 
-    def adjust_parameters(self, noise_level: float, coherence_time: float) -> DynamicParameters:
+    def adjust_parameters(
+        self, noise_level: float, coherence_time: float
+    ) -> DynamicParameters:
         """
         æ ¹æ“šé‡å­ç‹€æ…‹èª¿æ•´åƒæ•¸
 
@@ -176,7 +178,9 @@ class DynamicPolicyController:
         return self.presets["standard_v3"]
 
     def activate_emergency_mode(
-        self, strategy: str = "classic_aggressive", quantum_preset: str = "lightweight_v2"
+        self,
+        strategy: str = "classic_aggressive",
+        quantum_preset: str = "lightweight_v2",
     ):
         """å•Ÿç”¨ç·Šæ€¥æ¨¡å¼"""
         self.emergency_mode = True
@@ -204,12 +208,17 @@ class FusionEngine:
             # ç°¡åŒ–çš„è²è‘‰æ–¯èåˆ
             prior = 0.5
             likelihood = classic_score * quantum_score
-            return (likelihood * prior) / ((likelihood * prior) + ((1 - likelihood) * (1 - prior)))
+            return (likelihood * prior) / (
+                (likelihood * prior) + ((1 - likelihood) * (1 - prior))
+            )
         else:
             # é›†æˆæŠ•ç¥¨
             threshold = 0.6
             votes = sum(
-                [1 if classic_score > threshold else 0, 1 if quantum_score > threshold else 0]
+                [
+                    1 if classic_score > threshold else 0,
+                    1 if quantum_score > threshold else 0,
+                ]
             )
             return 1.0 if votes >= 1 else 0.0
 
@@ -272,13 +281,20 @@ class FusionEngine:
             quantum_score = quantum_dict.get(dim_name, 0.99)
 
             hybrid_score = self.fuse_scores(
-                classic_score, quantum_score, params.classic_weight, params.quantum_weight
+                classic_score,
+                quantum_score,
+                params.classic_weight,
+                params.quantum_weight,
             )
 
             status = (
                 ValidationStatus.PASS
                 if hybrid_score > 0.9
-                else ValidationStatus.WARNING if hybrid_score > 0.7 else ValidationStatus.FAIL
+                else (
+                    ValidationStatus.WARNING
+                    if hybrid_score > 0.7
+                    else ValidationStatus.FAIL
+                )
             )
 
             dimensions.append(
@@ -299,7 +315,9 @@ class FusionEngine:
         overall_status = (
             ValidationStatus.PASS
             if total_score > 0.9
-            else ValidationStatus.WARNING if total_score > 0.7 else ValidationStatus.FAIL
+            else (
+                ValidationStatus.WARNING if total_score > 0.7 else ValidationStatus.FAIL
+            )
         )
 
         return HybridDecision(
@@ -380,7 +398,9 @@ class AdaptiveDecisionEngine:
         return {
             "validation_report": {
                 "document": document_path,
-                "timestamp": datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
+                "timestamp": datetime.now(timezone.utc)
+                .isoformat()
+                .replace("+00:00", "Z"),
                 "overall_status": decision.overall_status.value,
                 "confidence": round(decision.confidence, 4),
                 "verification_matrix": [
@@ -437,7 +457,9 @@ def main():
     """ä¸»å‡½æ•¸"""
     import argparse
 
-    parser = argparse.ArgumentParser(description="è‡ªé©æ‡‰æ±ºç­–å¼•æ“ - MachineNativeOps é©—è­‰ç³»çµ±")
+    parser = argparse.ArgumentParser(
+        description="è‡ªé©æ‡‰æ±ºç­–å¼•æ“ - MachineNativeOps é©—è­‰ç³»çµ±"
+    )
     parser.add_argument("--demo", action="store_true", help="é‹è¡Œæ¼”ç¤ºæ¨¡å¼")
     parser.add_argument("--output", default=None, help="è¼¸å‡ºæ–‡ä»¶è·¯å¾‘")
 
diff --git a/workspace/tools/validation/emergency_mode_manager.py b/workspace/tools/validation/emergency_mode_manager.py
index 4e9058d..2c473eb 100644
--- a/workspace/tools/validation/emergency_mode_manager.py
+++ b/workspace/tools/validation/emergency_mode_manager.py
@@ -170,14 +170,25 @@ class EmergencyModeManager:
         }
 
         # ç‹€æ…‹è½‰æ›é‚è¼¯
-        if level == EmergencyLevel.EMERGENCY and previous_level != EmergencyLevel.EMERGENCY:
+        if (
+            level == EmergencyLevel.EMERGENCY
+            and previous_level != EmergencyLevel.EMERGENCY
+        ):
             self._activate_emergency(health, "Multiple critical conditions detected")
             response["action_taken"] = "emergency_activated"
-        elif level == EmergencyLevel.CRITICAL and previous_level == EmergencyLevel.NORMAL:
-            self._activate_fallback(FallbackStrategy.LIGHTWEIGHT, "Critical condition detected")
+        elif (
+            level == EmergencyLevel.CRITICAL and previous_level == EmergencyLevel.NORMAL
+        ):
+            self._activate_fallback(
+                FallbackStrategy.LIGHTWEIGHT, "Critical condition detected"
+            )
             response["action_taken"] = "fallback_activated"
-        elif level == EmergencyLevel.WARNING and previous_level == EmergencyLevel.NORMAL:
-            self._activate_fallback(FallbackStrategy.STANDBY, "Warning conditions detected")
+        elif (
+            level == EmergencyLevel.WARNING and previous_level == EmergencyLevel.NORMAL
+        ):
+            self._activate_fallback(
+                FallbackStrategy.STANDBY, "Warning conditions detected"
+            )
             response["action_taken"] = "standby_activated"
         elif level == EmergencyLevel.NORMAL and previous_level != EmergencyLevel.NORMAL:
             self._attempt_recovery()
@@ -198,7 +209,9 @@ class EmergencyModeManager:
 
         self.state.level = EmergencyLevel.EMERGENCY
         self.state.strategy = FallbackStrategy.CLASSIC_AGGRESSIVE
-        self.state.activated_at = datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")
+        self.state.activated_at = (
+            datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")
+        )
         self.state.reason = reason
         self.state.recovery_attempts = 0
 
@@ -208,7 +221,9 @@ class EmergencyModeManager:
 
         self.state.level = EmergencyLevel.WARNING
         self.state.strategy = strategy
-        self.state.activated_at = datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")
+        self.state.activated_at = (
+            datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")
+        )
         self.state.reason = reason
 
     def _attempt_recovery(self):
@@ -220,7 +235,9 @@ class EmergencyModeManager:
         self.state.recovery_attempts += 1
 
         if self.state.recovery_attempts >= self.state.max_recovery_attempts:
-            logger.warning(f"Max recovery attempts ({self.state.max_recovery_attempts}) reached")
+            logger.warning(
+                f"Max recovery attempts ({self.state.max_recovery_attempts}) reached"
+            )
             return
 
         logger.info(
@@ -288,18 +305,26 @@ def run_demo():
     # å ´æ™¯ 1ï¼šæ­£å¸¸ç‹€æ…‹
     print("\nğŸ“— å ´æ™¯ 1ï¼šæ­£å¸¸é‹è¡Œ")
     print("-" * 50)
-    health_normal = SystemHealth(coherence=0.85, noise_level=0.10, error_rate=0.01, latency_ms=150)
+    health_normal = SystemHealth(
+        coherence=0.85, noise_level=0.10, error_rate=0.01, latency_ms=150
+    )
     result = manager.check_and_respond(health_normal)
-    print(f"å¥åº·è©•ä¼°: coherence={health_normal.coherence}, noise={health_normal.noise_level}")
+    print(
+        f"å¥åº·è©•ä¼°: coherence={health_normal.coherence}, noise={health_normal.noise_level}"
+    )
     print(f"è¡Œå‹•: {result['action_taken']}")
     print(f"ç­‰ç´š: {result['current_level']}")
 
     # å ´æ™¯ 2ï¼šè­¦å‘Šç‹€æ…‹
     print("\nğŸ“™ å ´æ™¯ 2ï¼šè­¦å‘Šæ¢ä»¶")
     print("-" * 50)
-    health_warning = SystemHealth(coherence=0.76, noise_level=0.16, error_rate=0.02, latency_ms=200)
+    health_warning = SystemHealth(
+        coherence=0.76, noise_level=0.16, error_rate=0.02, latency_ms=200
+    )
     result = manager.check_and_respond(health_warning)
-    print(f"å¥åº·è©•ä¼°: coherence={health_warning.coherence}, noise={health_warning.noise_level}")
+    print(
+        f"å¥åº·è©•ä¼°: coherence={health_warning.coherence}, noise={health_warning.noise_level}"
+    )
     print(f"è¡Œå‹•: {result['action_taken']}")
     print(f"ç­‰ç´š: {result['current_level']}")
 
@@ -310,7 +335,9 @@ def run_demo():
         coherence=0.65, noise_level=0.25, error_rate=0.08, latency_ms=900
     )
     result = manager.check_and_respond(health_emergency)
-    print(f"å¥åº·è©•ä¼°: coherence={health_emergency.coherence}, noise={health_emergency.noise_level}")
+    print(
+        f"å¥åº·è©•ä¼°: coherence={health_emergency.coherence}, noise={health_emergency.noise_level}"
+    )
     print(f"è¡Œå‹•: {result['action_taken']}")
     print(f"ç­‰ç´š: {result['current_level']}")
 
@@ -321,7 +348,9 @@ def run_demo():
         coherence=0.82, noise_level=0.12, error_rate=0.02, latency_ms=180
     )
     result = manager.check_and_respond(health_recovered)
-    print(f"å¥åº·è©•ä¼°: coherence={health_recovered.coherence}, noise={health_recovered.noise_level}")
+    print(
+        f"å¥åº·è©•ä¼°: coherence={health_recovered.coherence}, noise={health_recovered.noise_level}"
+    )
     print(f"è¡Œå‹•: {result['action_taken']}")
     print(f"ç­‰ç´š: {result['current_level']}")
 
@@ -336,7 +365,9 @@ def main():
     """ä¸»å‡½æ•¸"""
     import argparse
 
-    parser = argparse.ArgumentParser(description="ç·Šæ€¥æ¨¡å¼ç®¡ç†å™¨ - MachineNativeOps é©—è­‰ç³»çµ±")
+    parser = argparse.ArgumentParser(
+        description="ç·Šæ€¥æ¨¡å¼ç®¡ç†å™¨ - MachineNativeOps é©—è­‰ç³»çµ±"
+    )
     parser.add_argument(
         "command",
         nargs="?",
@@ -344,7 +375,9 @@ def main():
         default="status",
         help="åŸ·è¡Œçš„å‘½ä»¤",
     )
-    parser.add_argument("--reason", default="Manual activation", help="å•Ÿç”¨ç·Šæ€¥æ¨¡å¼çš„åŸå› ")
+    parser.add_argument(
+        "--reason", default="Manual activation", help="å•Ÿç”¨ç·Šæ€¥æ¨¡å¼çš„åŸå› "
+    )
     parser.add_argument("--json", action="store_true", help="ä»¥ JSON æ ¼å¼è¼¸å‡º")
 
     args = parser.parse_args()
diff --git a/workspace/tools/validation/quantum_feature_extractor.py b/workspace/tools/validation/quantum_feature_extractor.py
index 09a6e5d..09b03c6 100644
--- a/workspace/tools/validation/quantum_feature_extractor.py
+++ b/workspace/tools/validation/quantum_feature_extractor.py
@@ -145,7 +145,8 @@ class QuantumFeatureExtractor:
             name=path.name,
             path=str(path.absolute()),
             size=len(content),
-            last_modified=datetime.fromtimestamp(path.stat().st_mtime).isoformat() + "Z",
+            last_modified=datetime.fromtimestamp(path.stat().st_mtime).isoformat()
+            + "Z",
             sha256=hashlib.sha256(content).hexdigest(),
             sha512=hashlib.sha512(content).hexdigest(),
         )
@@ -183,7 +184,9 @@ class QuantumFeatureExtractor:
             error_mitigated=self.error_mitigation,
         )
 
-    def generate_quantum_signature(self, doc_path: str, features: QuantumFeatures) -> str:
+    def generate_quantum_signature(
+        self, doc_path: str, features: QuantumFeatures
+    ) -> str:
         """
         ç”Ÿæˆé‡å­ç°½å
 
@@ -195,7 +198,9 @@ class QuantumFeatureExtractor:
             str: é‡å­ç°½åå­—ç¬¦ä¸²
         """
         # çµ„åˆç‰¹å¾µç”Ÿæˆç°½åç¨®å­
-        seed_data = f"{doc_path}:{features.metrics.coherence}:{features.metrics.fidelity}"
+        seed_data = (
+            f"{doc_path}:{features.metrics.coherence}:{features.metrics.fidelity}"
+        )
         signature_hash = hashlib.sha256(seed_data.encode()).hexdigest()[:16]
 
         return f"qsig:2:{self.backend}:0x{signature_hash}"
@@ -255,11 +260,17 @@ def main():
     """ä¸»å‡½æ•¸"""
     import argparse
 
-    parser = argparse.ArgumentParser(description="é‡å­ç‰¹å¾µæå–å™¨ - MachineNativeOps é©—è­‰ç³»çµ±")
+    parser = argparse.ArgumentParser(
+        description="é‡å­ç‰¹å¾µæå–å™¨ - MachineNativeOps é©—è­‰ç³»çµ±"
+    )
     parser.add_argument("document", nargs="?", default=None, help="è¦è™•ç†çš„æ–‡æª”è·¯å¾‘")
-    parser.add_argument("--backend", default="ibm_kyiv", help="é‡å­å¾Œç«¯ (default: ibm_kyiv)")
+    parser.add_argument(
+        "--backend", default="ibm_kyiv", help="é‡å­å¾Œç«¯ (default: ibm_kyiv)"
+    )
     parser.add_argument("--depth", type=int, default=8, help="é›»è·¯æ·±åº¦ (default: 8)")
-    parser.add_argument("--shots", type=int, default=1024, help="æ¸¬é‡æ¬¡æ•¸ (default: 1024)")
+    parser.add_argument(
+        "--shots", type=int, default=1024, help="æ¸¬é‡æ¬¡æ•¸ (default: 1024)"
+    )
     parser.add_argument("--output", default=None, help="è¼¸å‡ºæ–‡ä»¶è·¯å¾‘")
 
     args = parser.parse_args()
diff --git a/workspace/tools/validation/validate-artifact.py b/workspace/tools/validation/validate-artifact.py
index 003e445..094ca46 100755
--- a/workspace/tools/validation/validate-artifact.py
+++ b/workspace/tools/validation/validate-artifact.py
@@ -31,7 +31,9 @@ import yaml
 class ValidationResult:
     """Validation result container with enhanced details"""
 
-    def __init__(self, level: str, status: str, message: str, details: Optional[Dict] = None):
+    def __init__(
+        self, level: str, status: str, message: str, details: Optional[Dict] = None
+    ):
         self.level = level
         self.status = status  # pass, fail, warning
         self.message = message
@@ -53,7 +55,10 @@ class ArtifactValidator:
     """Artifact validator with complete 5-level validation pipeline"""
 
     def __init__(
-        self, artifact_paths: List[str], validation_level: str = "all", strict: bool = False
+        self,
+        artifact_paths: List[str],
+        validation_level: str = "all",
+        strict: bool = False,
     ):
         self.artifact_paths = artifact_paths
         self.validation_level = validation_level
@@ -182,7 +187,9 @@ class ArtifactValidator:
         warnings = [r for r in self.results if r.status == "warning"]
 
         if failures:
-            print(f"\nâŒ Validation FAILED: {len(failures)} error(s), {len(warnings)} warning(s)")
+            print(
+                f"\nâŒ Validation FAILED: {len(failures)} error(s), {len(warnings)} warning(s)"
+            )
             for failure in failures:
                 print(f"   - [{failure.level}] {failure.message}")
                 if failure.details.get("path"):
@@ -261,7 +268,10 @@ class ArtifactValidator:
                         level="structural",
                         status="fail",
                         message="metadata must be an object",
-                        details={"path": artifact_path, "type": type(metadata).__name__},
+                        details={
+                            "path": artifact_path,
+                            "type": type(metadata).__name__,
+                        },
                     )
                 )
                 continue
@@ -302,7 +312,8 @@ class ArtifactValidator:
 
             # If all checks passed for this artifact
             if not any(
-                r.status == "fail" and r.details.get("path") == artifact_path for r in self.results
+                r.status == "fail" and r.details.get("path") == artifact_path
+                for r in self.results
             ):
                 self.results.append(
                     ValidationResult(
@@ -385,7 +396,9 @@ class ArtifactValidator:
                     level="semantic",
                     status="warning",
                     message="Semantic root not loaded, skipping semantic validation",
-                    details={"note": "Place semantic root at root/.root.semantic-root.yaml"},
+                    details={
+                        "note": "Place semantic root at root/.root.semantic-root.yaml"
+                    },
                 )
             )
             print("     âš ï¸  Semantic root not found, skipping")
@@ -428,7 +441,9 @@ class ArtifactValidator:
                 )
             else:
                 # Validate version compatibility
-                semantic_root_version = self.semantic_root.get("metadata", {}).get("version", "")
+                semantic_root_version = self.semantic_root.get("metadata", {}).get(
+                    "version", ""
+                )
                 if semantic_root_ref != semantic_root_version:
                     self.results.append(
                         ValidationResult(
@@ -445,7 +460,9 @@ class ArtifactValidator:
 
             # Validate concepts if present
             spec = artifact.get("spec", {})
-            artifact_concepts = spec.get("generation", {}).get("forward", {}).get("concepts", [])
+            artifact_concepts = (
+                spec.get("generation", {}).get("forward", {}).get("concepts", [])
+            )
 
             if artifact_concepts:
                 for concept in artifact_concepts:
@@ -454,7 +471,10 @@ class ArtifactValidator:
 
                     if extends:
                         # Check if parent concept exists
-                        if extends not in base_concepts and extends not in derived_concepts:
+                        if (
+                            extends not in base_concepts
+                            and extends not in derived_concepts
+                        ):
                             self.results.append(
                                 ValidationResult(
                                     level="semantic",
@@ -485,7 +505,9 @@ class ArtifactValidator:
 
                     # Validate concept definition completeness
                     required_concept_fields = ["name", "definition"]
-                    missing_fields = [f for f in required_concept_fields if not concept.get(f)]
+                    missing_fields = [
+                        f for f in required_concept_fields if not concept.get(f)
+                    ]
 
                     if missing_fields:
                         self.results.append(
@@ -660,7 +682,9 @@ class ArtifactValidator:
         ]
         return any(re.match(pattern, version.replace(" ", "")) for pattern in patterns)
 
-    def _detect_circular_dependencies(self, graph: Dict[str, List[str]]) -> List[List[str]]:
+    def _detect_circular_dependencies(
+        self, graph: Dict[str, List[str]]
+    ) -> List[List[str]]:
         """Detect circular dependencies using DFS-based cycle detection"""
         cycles = []
         visited = set()
@@ -740,9 +764,9 @@ class ArtifactValidator:
                                 "path": artifact_path,
                                 "name": artifact_name,
                                 "pattern": name_pattern,
-                                "examples": naming_conventions.get("artifact_naming", {}).get(
-                                    "examples", []
-                                ),
+                                "examples": naming_conventions.get(
+                                    "artifact_naming", {}
+                                ).get("examples", []),
                             },
                         )
                     )
@@ -763,9 +787,9 @@ class ArtifactValidator:
                                 "path": artifact_path,
                                 "version": version,
                                 "pattern": version_pattern,
-                                "examples": naming_conventions.get("version_naming", {}).get(
-                                    "examples", []
-                                ),
+                                "examples": naming_conventions.get(
+                                    "version_naming", {}
+                                ).get("examples", []),
                             },
                         )
                     )
@@ -809,7 +833,9 @@ class ArtifactValidator:
             else:
                 # Check required documentation fields
                 required_doc_fields = ["overview"]
-                missing_doc = [f for f in required_doc_fields if not documentation.get(f)]
+                missing_doc = [
+                    f for f in required_doc_fields if not documentation.get(f)
+                ]
 
                 if missing_doc:
                     self.results.append(
@@ -817,7 +843,10 @@ class ArtifactValidator:
                             level="governance",
                             status="warning",
                             message=f"Documentation missing recommended fields: {', '.join(missing_doc)}",
-                            details={"path": artifact_path, "missing_fields": missing_doc},
+                            details={
+                                "path": artifact_path,
+                                "missing_fields": missing_doc,
+                            },
                         )
                     )
 
@@ -915,7 +944,9 @@ class ArtifactValidator:
 
             if not all_closures_passed:
                 failed_closures = [
-                    level for level, status in closure_status.items() if status == "fail"
+                    level
+                    for level, status in closure_status.items()
+                    if status == "fail"
                 ]
 
                 self.results.append(
@@ -925,10 +956,18 @@ class ArtifactValidator:
                         message=f"Closure validation failed: {', '.join(failed_closures)} closure not achieved",
                         details={
                             "path": artifact_path,
-                            "dependency_closure": "pass" if dependency_closure_passed else "fail",
-                            "semantic_closure": "pass" if semantic_closure_passed else "fail",
-                            "governance_closure": "pass" if governance_closure_passed else "fail",
-                            "structural_closure": "pass" if structural_closure_passed else "fail",
+                            "dependency_closure": (
+                                "pass" if dependency_closure_passed else "fail"
+                            ),
+                            "semantic_closure": (
+                                "pass" if semantic_closure_passed else "fail"
+                            ),
+                            "governance_closure": (
+                                "pass" if governance_closure_passed else "fail"
+                            ),
+                            "structural_closure": (
+                                "pass" if structural_closure_passed else "fail"
+                            ),
                             "failed_levels": failed_closures,
                         },
                     )
@@ -1004,7 +1043,9 @@ class ArtifactValidator:
                 # Detailed validation results by level
                 "validation_results": {
                     "structural": {
-                        "status": self._get_level_status(results_by_level.get("structural", [])),
+                        "status": self._get_level_status(
+                            results_by_level.get("structural", [])
+                        ),
                         "checks": len(results_by_level.get("structural", [])),
                         "passed": len(
                             [
@@ -1027,16 +1068,28 @@ class ArtifactValidator:
                                 if r.status == "warning"
                             ]
                         ),
-                        "details": [r.to_dict() for r in results_by_level.get("structural", [])],
+                        "details": [
+                            r.to_dict() for r in results_by_level.get("structural", [])
+                        ],
                     },
                     "semantic": {
-                        "status": self._get_level_status(results_by_level.get("semantic", [])),
+                        "status": self._get_level_status(
+                            results_by_level.get("semantic", [])
+                        ),
                         "checks": len(results_by_level.get("semantic", [])),
                         "passed": len(
-                            [r for r in results_by_level.get("semantic", []) if r.status == "pass"]
+                            [
+                                r
+                                for r in results_by_level.get("semantic", [])
+                                if r.status == "pass"
+                            ]
                         ),
                         "failed": len(
-                            [r for r in results_by_level.get("semantic", []) if r.status == "fail"]
+                            [
+                                r
+                                for r in results_by_level.get("semantic", [])
+                                if r.status == "fail"
+                            ]
                         ),
                         "warnings": len(
                             [
@@ -1045,10 +1098,14 @@ class ArtifactValidator:
                                 if r.status == "warning"
                             ]
                         ),
-                        "details": [r.to_dict() for r in results_by_level.get("semantic", [])],
+                        "details": [
+                            r.to_dict() for r in results_by_level.get("semantic", [])
+                        ],
                     },
                     "dependency": {
-                        "status": self._get_level_status(results_by_level.get("dependency", [])),
+                        "status": self._get_level_status(
+                            results_by_level.get("dependency", [])
+                        ),
                         "checks": len(results_by_level.get("dependency", [])),
                         "passed": len(
                             [
@@ -1071,10 +1128,14 @@ class ArtifactValidator:
                                 if r.status == "warning"
                             ]
                         ),
-                        "details": [r.to_dict() for r in results_by_level.get("dependency", [])],
+                        "details": [
+                            r.to_dict() for r in results_by_level.get("dependency", [])
+                        ],
                     },
                     "governance": {
-                        "status": self._get_level_status(results_by_level.get("governance", [])),
+                        "status": self._get_level_status(
+                            results_by_level.get("governance", [])
+                        ),
                         "checks": len(results_by_level.get("governance", [])),
                         "passed": len(
                             [
@@ -1097,16 +1158,28 @@ class ArtifactValidator:
                                 if r.status == "warning"
                             ]
                         ),
-                        "details": [r.to_dict() for r in results_by_level.get("governance", [])],
+                        "details": [
+                            r.to_dict() for r in results_by_level.get("governance", [])
+                        ],
                     },
                     "closure": {
-                        "status": self._get_level_status(results_by_level.get("closure", [])),
+                        "status": self._get_level_status(
+                            results_by_level.get("closure", [])
+                        ),
                         "checks": len(results_by_level.get("closure", [])),
                         "passed": len(
-                            [r for r in results_by_level.get("closure", []) if r.status == "pass"]
+                            [
+                                r
+                                for r in results_by_level.get("closure", [])
+                                if r.status == "pass"
+                            ]
                         ),
                         "failed": len(
-                            [r for r in results_by_level.get("closure", []) if r.status == "fail"]
+                            [
+                                r
+                                for r in results_by_level.get("closure", [])
+                                if r.status == "fail"
+                            ]
                         ),
                         "warnings": len(
                             [
@@ -1115,7 +1188,9 @@ class ArtifactValidator:
                                 if r.status == "warning"
                             ]
                         ),
-                        "details": [r.to_dict() for r in results_by_level.get("closure", [])],
+                        "details": [
+                            r.to_dict() for r in results_by_level.get("closure", [])
+                        ],
                     },
                 },
                 # Governance compliance summary
@@ -1146,11 +1221,17 @@ class ArtifactValidator:
                 "warnings": len([r for r in self.results if r.status == "warning"]),
                 # Closure status
                 "closure_achieved": overall_status == "passed",
-                "dependency_closure": self._get_level_status(results_by_level.get("dependency", []))
+                "dependency_closure": self._get_level_status(
+                    results_by_level.get("dependency", [])
+                )
                 == "pass",
-                "semantic_closure": self._get_level_status(results_by_level.get("semantic", []))
+                "semantic_closure": self._get_level_status(
+                    results_by_level.get("semantic", [])
+                )
                 == "pass",
-                "governance_closure": self._get_level_status(results_by_level.get("governance", []))
+                "governance_closure": self._get_level_status(
+                    results_by_level.get("governance", [])
+                )
                 == "pass",
             },
         }
@@ -1162,7 +1243,11 @@ class ArtifactValidator:
 
             with open(output_file, "w") as f:
                 yaml.dump(
-                    attestation, f, default_flow_style=False, allow_unicode=True, sort_keys=False
+                    attestation,
+                    f,
+                    default_flow_style=False,
+                    allow_unicode=True,
+                    sort_keys=False,
                 )
             print(f"ğŸ“œ Attestation saved to: {output_path}")
 
@@ -1210,17 +1295,30 @@ Examples:
 
     parser.add_argument(
         "--level",
-        choices=["structural", "semantic", "dependency", "governance", "closure", "all"],
+        choices=[
+            "structural",
+            "semantic",
+            "dependency",
+            "governance",
+            "closure",
+            "all",
+        ],
         default="all",
         help="Validation level to run (default: all)",
     )
 
-    parser.add_argument("artifacts", nargs="*", help="Artifact files to validate (YAML format)")
+    parser.add_argument(
+        "artifacts", nargs="*", help="Artifact files to validate (YAML format)"
+    )
 
-    parser.add_argument("--attestation", help="Path to save attestation bundle (YAML format)")
+    parser.add_argument(
+        "--attestation", help="Path to save attestation bundle (YAML format)"
+    )
 
     parser.add_argument(
-        "--strict", action="store_true", help="Fail on warnings (treat warnings as failures)"
+        "--strict",
+        action="store_true",
+        help="Fail on warnings (treat warnings as failures)",
     )
 
     parser.add_argument("--version", action="version", version="%(prog)s 2.0.0")
diff --git a/workspace/tools/validation/validate_pr1023_layers.py b/workspace/tools/validation/validate_pr1023_layers.py
index f759ee7..0115898 100644
--- a/workspace/tools/validation/validate_pr1023_layers.py
+++ b/workspace/tools/validation/validate_pr1023_layers.py
@@ -111,7 +111,11 @@ def main() -> int:
     all_passed = all(r["passed"] for r in results)
 
     if args.json_output:
-        print(json.dumps({"passed": all_passed, "results": results}, indent=2, ensure_ascii=False))
+        print(
+            json.dumps(
+                {"passed": all_passed, "results": results}, indent=2, ensure_ascii=False
+            )
+        )
     else:
         for result in results:
             status = "PASS" if result["passed"] else "FAIL"
diff --git a/workspace/tools/validation/world_class_validation.py b/workspace/tools/validation/world_class_validation.py
index cb141e0..ac07290 100644
--- a/workspace/tools/validation/world_class_validation.py
+++ b/workspace/tools/validation/world_class_validation.py
@@ -17,7 +17,9 @@ from typing import List, Optional
 import yaml
 
 MANIFEST_PATH = Path("workspace/config/validation/world-class-validation.yaml")
-SCHEMA_PATH = Path("workspace/config/validation/schemas/world-class-validation.schema.json")
+SCHEMA_PATH = Path(
+    "workspace/config/validation/schemas/world-class-validation.schema.json"
+)
 
 
 @dataclass
@@ -70,7 +72,8 @@ def load_manifest(path: Path = MANIFEST_PATH) -> WorldClassValidationManifest:
     data = yaml.safe_load(path.read_text(encoding="utf-8"))
     spec = data["spec"]
     dims = [
-        EnhancedValidationDimension(**item) for item in spec.get("enhancedValidationDimensions", [])
+        EnhancedValidationDimension(**item)
+        for item in spec.get("enhancedValidationDimensions", [])
     ]
     perf = PerformanceTargets(**spec["performanceTargets"])
     impl = ImplementationRequirements(**spec["implementationRequirements"])
diff --git a/workspace/tools/verify-namespace-alignment.py b/workspace/tools/verify-namespace-alignment.py
index 8013c92..7d01707 100755
--- a/workspace/tools/verify-namespace-alignment.py
+++ b/workspace/tools/verify-namespace-alignment.py
@@ -101,7 +101,8 @@ def run_basic_verification(report: VerificationReport):
         checks = [
             config["spec"]["namespaces"]["primary"]["name"] == "machinenativeops",
             config["spec"]["domains"]["primary"] == "machinenativeops.io",
-            config["spec"]["domains"]["registry"]["host"] == "registry.machinenativeops.io",
+            config["spec"]["domains"]["registry"]["host"]
+            == "registry.machinenativeops.io",
             config["spec"]["filesystem"]["directories"]["certificates"]
             == "/etc/machinenativeops/pkl",
             config["spec"]["etcd"]["cluster_name"] == "super-agent-etcd-cluster",
@@ -109,11 +110,17 @@ def run_basic_verification(report: VerificationReport):
 
         if all(checks):
             report.add_result(
-                "basic", "Namespace consistency check", True, "All 5 namespace alignments verified"
+                "basic",
+                "Namespace consistency check",
+                True,
+                "All 5 namespace alignments verified",
             )
         else:
             report.add_result(
-                "basic", "Namespace consistency check", False, f"Only {sum(checks)}/5 checks passed"
+                "basic",
+                "Namespace consistency check",
+                False,
+                f"Only {sum(checks)}/5 checks passed",
             )
     except Exception as e:
         report.add_result("basic", "Namespace consistency check", False, str(e))
@@ -121,7 +128,12 @@ def run_basic_verification(report: VerificationReport):
     # 3. Conversion report check
     try:
         result = subprocess.run(
-            ["python3", "tools/namespace-converter.py", "--dry-run", "mno-namespace.yaml"],
+            [
+                "python3",
+                "tools/namespace-converter.py",
+                "--dry-run",
+                "mno-namespace.yaml",
+            ],
             capture_output=True,
             text=True,
             timeout=30,
@@ -138,10 +150,15 @@ def run_basic_verification(report: VerificationReport):
             )
         else:
             report.add_result(
-                "basic", "Conversion report (0 missing references)", False, "Converter failed"
+                "basic",
+                "Conversion report (0 missing references)",
+                False,
+                "Converter failed",
             )
     except Exception as e:
-        report.add_result("basic", "Conversion report (0 missing references)", False, str(e))
+        report.add_result(
+            "basic", "Conversion report (0 missing references)", False, str(e)
+        )
 
     # 4. Resource type standardization
     try:
@@ -204,7 +221,9 @@ def run_advanced_verification(report: VerificationReport):
                 f"Missing files: {', '.join(missing_files)}",
             )
     except Exception as e:
-        report.add_result("advanced", "Architecture pattern verification", False, str(e))
+        report.add_result(
+            "advanced", "Architecture pattern verification", False, str(e)
+        )
 
     # 2. Deployment configuration test
     try:
@@ -219,7 +238,10 @@ def run_advanced_verification(report: VerificationReport):
             )
         else:
             report.add_result(
-                "advanced", "Deployment configuration test", False, "setup.py is missing"
+                "advanced",
+                "Deployment configuration test",
+                False,
+                "setup.py is missing",
             )
     except Exception as e:
         report.add_result("advanced", "Deployment configuration test", False, str(e))
@@ -237,7 +259,10 @@ def run_advanced_verification(report: VerificationReport):
         )
 
         report.add_result(
-            "advanced", "Integration point check", True, "All modules import successfully"
+            "advanced",
+            "Integration point check",
+            True,
+            "All modules import successfully",
         )
     except Exception as e:
         report.add_result("advanced", "Integration point check", False, str(e))
@@ -306,7 +331,10 @@ def run_production_verification(report: VerificationReport):
             )
         else:
             report.add_result(
-                "production", "End-to-end functional testing", False, "App status check failed"
+                "production",
+                "End-to-end functional testing",
+                False,
+                "App status check failed",
             )
     except Exception as e:
         report.add_result("production", "End-to-end functional testing", False, str(e))
@@ -322,7 +350,9 @@ def run_production_verification(report: VerificationReport):
             r'secret\s*=\s*["\'][^"\']+["\']',
         ]
 
-        python_files = list(Path("engine/machinenativenops-auto-monitor/src").rglob("*.py"))
+        python_files = list(
+            Path("engine/machinenativenops-auto-monitor/src").rglob("*.py")
+        )
         found_secrets = []
 
         for py_file in python_files:
@@ -346,7 +376,9 @@ def run_production_verification(report: VerificationReport):
                 f"Potential secrets found in: {', '.join(found_secrets)}",
             )
     except Exception as e:
-        report.add_result("production", "Security scan (no hardcoded secrets)", False, str(e))
+        report.add_result(
+            "production", "Security scan (no hardcoded secrets)", False, str(e)
+        )
 
     # 3. Load test (simulated)
     try:
@@ -376,7 +408,9 @@ def run_production_verification(report: VerificationReport):
                 f"Too slow: {duration:.3f}s",
             )
     except Exception as e:
-        report.add_result("production", "Load test (1000 config creations)", False, str(e))
+        report.add_result(
+            "production", "Load test (1000 config creations)", False, str(e)
+        )
 
     # 4. Recovery test (error handling)
     try:
@@ -398,7 +432,10 @@ def run_production_verification(report: VerificationReport):
             )
         else:
             report.add_result(
-                "production", "Recovery test (error handling)", False, "Invalid config not detected"
+                "production",
+                "Recovery test (error handling)",
+                False,
+                "Invalid config not detected",
             )
     except Exception as e:
         # Exception during validation is also acceptable
diff --git a/workspace/tools/verify_p0_safety.py b/workspace/tools/verify_p0_safety.py
index ce03fe1..cdf97ab 100755
--- a/workspace/tools/verify_p0_safety.py
+++ b/workspace/tools/verify_p0_safety.py
@@ -128,7 +128,8 @@ class P0SafetyVerifier:
 
         config_files = [
             self.repo_root / "config/safety-mechanisms.yaml",
-            self.repo_root / "src/autonomous/infrastructure/config/safety-mechanisms.yaml",
+            self.repo_root
+            / "src/autonomous/infrastructure/config/safety-mechanisms.yaml",
         ]
 
         found_config = None
@@ -155,7 +156,9 @@ class P0SafetyVerifier:
             # æª¢æŸ¥é—œéµé…ç½®é …
             checks = {
                 "safety.enabled": config.get("safety", {}).get("enabled", False),
-                "circuit_breaker.enabled": config.get("circuit_breaker", {}).get("enabled", False),
+                "circuit_breaker.enabled": config.get("circuit_breaker", {}).get(
+                    "enabled", False
+                ),
                 "escalation_ladder.enabled": config.get("escalation_ladder", {}).get(
                     "enabled", False
                 ),
@@ -218,7 +221,9 @@ class P0SafetyVerifier:
                     message=f"ç›£æ§é…ç½®å·²å­˜åœ¨ ({len(prometheus_files)} å€‹ Prometheus é…ç½®)",
                     details={
                         "prometheus_files": [str(f) for f in prometheus_files],
-                        "monitoring_dirs": [str(d) for d in monitoring_dirs if d.exists()],
+                        "monitoring_dirs": [
+                            str(d) for d in monitoring_dirs if d.exists()
+                        ],
                     },
                 )
             )
@@ -262,7 +267,10 @@ class P0SafetyVerifier:
                                     item="æ¸¬è©¦è¦†è“‹ç‡ç›®æ¨™",
                                     status="PASS",
                                     message=f"è¦†è“‹ç‡ç›®æ¨™å·²è¨­ç½®: {target}%",
-                                    details={"target": target, "config": str(pytest_config)},
+                                    details={
+                                        "target": target,
+                                        "config": str(pytest_config),
+                                    },
                                 )
                             )
                             print(f"   âœ… PASS: è¦†è“‹ç‡ç›®æ¨™ {target}%")
@@ -332,7 +340,9 @@ class P0SafetyVerifier:
             print("   âŒ FAIL: æœªæ‰¾åˆ°workflowsç›®éŒ„")
             return
 
-        workflow_files = list(workflows_dir.glob("*.yml")) + list(workflows_dir.glob("*.yaml"))
+        workflow_files = list(workflows_dir.glob("*.yml")) + list(
+            workflows_dir.glob("*.yaml")
+        )
 
         if not workflow_files:
             self.results.append(
